---
layout: default
title: 04. 처리율 제한 장치의 설계
parent: 가상면접 사례로 배우는 대규모 시스템 설계 기초
---
# 04. 처리율 제한 장치의 설계
---


네트워크 시스템에서 처리율 제한 장치는 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치다.

예를들면 API요청 횟수가 제한 장치에 정의된 임게치를 넘어서면 추가로 도달한 모든 호출은 처리가 중단된다.

- 사용자는 초당 2회 이상 새 글을 올릴 수 없다.
- 같은 IP 주소는 하루에 10개 이상의 계정을 생성할 수 없다.
- 같은 디바이스로는 주당 5회 이상 리워드를 요청할 수 없다.

이번 장에서는 이 처리율 제한 장치를 설계한다.

장점
- DoS 공격에 의한 자원 고갈을 방지할 수 있다.
- 비용을 절감한다. 또한 API횟수 를 확인하고 횟수를 제한하여 비용을 절감할 수 있다
- 서버 과부하를 막는다. 봇에서 오는 트래픽이나 사용자의 잘못된 이용 패턴으로 유발되는 트래픽을 걸러낼 수 있다.

폭넓게 채택된 기술인 클라우드 마이크로서비스의 경우, 처리율 제한 장치는 보통 API 게이트웨이라 불리는 컴포넌트에 구현된다.

API 게이트웨이는 처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 관리 등을 지원하는 완전 위탁관리형 서비스, 즉 클라우드 업체가 유지 보수를 담당하는 서비스이다.

처리율 제한 장치를 서버에두는지 게이트웨이에 두는지 정답은 없다.

처리율 제한 장치를 직접 만드는 데는 시간이 든다. 충분한 인력이 없다면 사용 API게이트웨이를 쓰는 것이 바람직한 방법일 것이다.

### 처리율 제한 알고리즘
- 토큰 버킷
- 누출 버킷
- 고정 윈도 카운터
- 이동 윈도 로그
- 이동 윈도 카운터

토큰 버킷
토큰 버킷은 지정된 용량을 갖는 컨테이너이다.
![[Pasted image 20240802011623.png]]
각 요청은 처리될 때마다 하나의 토큰을 사용한다. 요청이 도착하면 토큰이 있는지 검사하고 있다면 토큰을 사용하여 요청 시스템에 전달한다. 토큰이 없다면 해당 요청은 버려진다.


장점
구현이쉽다
메모리 사용 측면에서도 효율적
짧은 시간에 집중되는 트래픽도 처리 가능하다.

단점
버킷 크기와 토큰 공급률이라는 두가지 값을 적절하게 튜닝하는 것이 까다롭다


누출 버킷 알고리즘
토큰 버킷과 비슷하지만 요청 처리율이 고정되어있다는 점이 다르다.
FIFO 큐로 구현한다.

- 요청이 도착하면 큐가 가득차있는지 본다. 빈자리가 있는 경우 큐에 요청을 추가한다.
- 가득 차 있는 경우 새 요청은 버린다.
- 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.

![[Pasted image 20240802011935.png]]

장점
큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적
고정된 처리율로 안정적 출력

단점
단시간에 많은 트래픽이 몰리는 경우 요청을 제때 처리 못하면 최신 요청이 버려진다.
마찬가지로 튜닝이 까다롭다

### 고정 윈도 카운터 알고리즘

- 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터를 붙인다.
- 요청이 접수될 때마다 이 카운터의 값은 1씩 증가한다.
- 이 카운터의 값이 사전에 설정된 임계치에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버려진다.

![[Pasted image 20240818171537.png]]

이 알고리즘의 가장 큰 문제는 윈도의 경계 부근에 순간적으로 많은 트래픽이 집중될 경우 윈도에 할당된 양보다 더 많은 요청이 처리될 수 있다는 것이다.
![[Pasted image 20240818171914.png]]
예를 들어 분당 최대 5개의 요청만을 허용하는 시스템이 있다. 윈도우 카운트는 매분마다 초기화 된다. 2:00:00와 2:01:00 사이에 5개의 요청이 들어왔고 2:01:00과 2:02:00사이에 또 5개의 요청이 들어왔다. 윈도우 위치를 옮겨보면 2:00:30부터 2:01:30까지 10개를 처리한다. 허용 한도의 2배를 처리한것.

장점
- 메모리 효율이 좋다
- 이해하기 쉽다
- 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다.
단점
- 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 된다.

### 이동 윈도 로깅 알고리즘
고정 윈도 카운터 알고리즘을 해결한 알고리즘이다.

- 이 알고리즘은 요청 타임스탬프를 추적한다.
- 새 요청이 오면 만료된 타임스탬프는 제거한다.
- 새 요청의 타임스탬프를 로그에 추가한다.
- 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다. 그렇지 않으면 처리를 거부한다.
![[Pasted image 20240818172445.png]]


장점
- 이 알고리즘이 구현하는 처리율 제한 메커니즘은 아주 정교하다. 어느 순간의 윈도를 보더라도, 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.
단점
- 이 알고리즘은 다량의 메모리를 사용하는데, 거부된 요청의 타임스탬프도 보관하기 때문이다.

### 이동 윈도 카운터 알고리즘
고정 윈도 카운터 알고리즘과 이동 윈도 로깅 알고리즘을 결합한 것이다.
![[Pasted image 20240818172621.png]]

처리율 제한 장치가 한도가 분당 7개 요청으로 설정되어 있다고 하고, 이전 1분 동안 5개의 요청이, 그리고 현재 1분동안 3개의 요청이 왔다고 가정하자.
현재 1분의 30% 시점에 도착한 새 요청의 경우, 현재 윈도에 몇개의 요청이 온것으로 보고 처리해야할까?

현재 1분간의 요청 수 + 직전 1분간의 요청 수 x 이동 윈도와 직전 1분이 겹치는 비율
공식에 따르면 3 + 5 x 70% = 6.5개다. 반올림하거나 반내림하여 쓸 수 있다.

장점
- 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽도 잘 대응한다.
- 메모리 효율이 좋다

단점
- 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨하다. (실험에 따르면 40억개 요청중 버려진것은 0.003%로 문제가 크지않음)


#### 분산 환경에서의 처리율 제한 장치 구현
병렬 스레드를 지원하도록 시스템을 확장하는 것은 또다른 문제다.
다음 두가지 어려운 문제를 풀어야 한다.
- 경쟁 조건
- 동기화

##### 경쟁 조건
![[Pasted image 20240818174120.png]]

경쟁 조건 문제를 해결하는 가장 널리 알려진 해결책은 락이다.
하지만 락은 시스템의 성능을 상당히 떨어뜨린다는 문제가 있다.
락 대신 쓸 수 있는 해결책이 두 가지 있는데
- 루아 스크립트
- 정렬 집합
이라는 레디스 자료구조를 쓰는 것이다.

>Lua 스크립트는 Redis 내에서 실행되는 작은 프로그램입니다. Redis에서 Lua 스크립트를 사용하면 여러 Redis 명령을 하나의 원자적 작업으로 실행할 수 있습니다. 다른 클라이언트가 중간에 끼어들 수 없어 race condition을 방지할 수 있습니다.


> 정렬 집합(Sorted Set)은 Redis의 자료구조 중 하나로, 각 요소가 점수(score)와 값(value)의 쌍으로 구성됩니다. 이 구조는 요소들을 점수에 따라 자동으로 정렬합니다. 이 작업은 원자적으로 수행되므로 race condition이 발생하지 않습니다. 원자성: ZINCRBY 명령은 원자적으로 실행되어 동시성 문제를 방지합니다.



##### 동기화 이슈
![[Pasted image 20240818175134.png]]
분산환경에서 동기화는 중요한 요소이다. 처리율 제한 장치 서버를 여러대 두게 되면 동기화가 필요해진다. 하나의 레디스 서버를 두고 두개의 처리 장치가 하나의 레디스를 바라봄으로써 처리율 제한을 올바르게 수행할 수 있다.

##### 모니터링
처리율 제한 장치를 설치한 이후에 효과적으로 동작하고 있는지 보기 위해 데이터를 모을 필요가 있다.
- 채택된 처리율 제한 알고리즘이 효과적이다.
- 정의한 처리율 제한 규칙이 효과적이다.
