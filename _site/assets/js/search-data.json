{"0": {
    "doc": "01. IAM",
    "title": "01. IAM",
    "content": ". IAM = identity and Access Managememt, Gloval service . iam에서는 사용자를 생성하고 그룹에 배치하기 때문에 글로벌 서비스에 해당된다. 우리는 aws 계정을 만들때 이미IAM을 사용한것이다. 우리가 만든것은 root 계정이고, 이것은 공유하지도 사용하지도 말아야한다. 그대신 우리는 사용자를 생성해서 사용한다. 그룹에 속하지 않는 사용자도 있다. 또한 사용자가 다수의 그룹에 속할 수 있다. 이를 위해 사용자 또는 그룹에 iam정책이라고 불리는 json문서를 지정할 수 있다. aws는 사용자에게 최소한의 권한만 부여하는것을 원칙으로 한다. 사용자 생성 . ![[Pasted image 20231109002219.png]] . | 사용자를 id센터에서 사용하시겠습니까? 해당 옵션은 권장 사항이지만, 설정이 복잡하고 SAA시험을 보기 위해서는 IAM사용자에대해 알아야한다. 그래서 권장사항을 선택하지않는다. | . ![[Pasted image 20231109002514.png]] . | 자동 생성된 암호 보통 남에게 계정을 생성해줄때나 자동 생성 암호를 사용하고, 본인이 사용할것이니 지정암호를 선택한다. | . ![[Pasted image 20231109002642.png]] 그룹을 생성해서 그룹에 사용자를 추가한다. ![[Pasted image 20231109002724.png]] admin이라는 그룹을 생성해본다. AdministratorAccess 가 뭔지는 설명도안해주네 . ![[Pasted image 20231109002817.png]] 사용자 그룹 생성을 하면 admin 그룹에 사용자를 지정해서 넘어갈 수 있다. ![[Pasted image 20231109002905.png]] 태그는 달아도 아무 효과 없다. 그저 정보일뿐 . ![[Pasted image 20231109003054.png]] 사용자 그룹에 들어가면 그룹에 지정된 사용자와 권한을 볼 수 있다. ![[Pasted image 20231109003231.png]] 계정 별칭은 계정에 더 빠르게 로그인하기위해 설정할 수 있는 기능이다. 계정 별칭으로 minsu-aws-v2를 생성하면 아래와 같은 로그인 url을 받을 수 있다. https://minsu-aws-v2.signin.aws.amazon.com/console 굳이 위의 주소를 사용해서 접속 할 필요는 없지만, 편의 기능이다. IAM 정책 . 그룹별로 사용자에게 권한을 줄 수 있다. 그룹이 없는 사용자에게는 인라인 정책이란것을 부여 할 수 있다. 사용자는 다수의 그룹을 지정받을 수 있다. 권한 json . { \"Version\" : \"2012-10-17\", \"Id\" : \"S3-Account-Permissions\", \"Statement\" : [ { \"Sid\" : \"1\", \"Effect\" : \"Allow\", \"Principal\" : { \"AWS\" : [\"arn:aws:iam::123456789012:root\"] }, \"Action\" : [ \"s3:GetObject\", \"s3:PutObject\" ], \"Resource\" : [\"arn:aws:s3:::mybucket/*\"] } ] } . Sid 는 선택사항 . Effect는 특정 api에 접근하는걸 허용하는지 여부를 정한다. Principal은 특정 정책이 적용될 사용자, 계정, 혹은 역할로 구성된다. 위 예시에서는 aws계정의 루트 계정이 적용되어있다. Action은 Effect에 기반해 허용 및 거부되는 api 호출 목록이다. Resource는 적용될 action의 리소스 목록이다. Condition은 위에 예시에 없지만 Statement가 언제 적용될지 결정한다. Policies 탭에가면 aws에 있는 모든 정책을 볼 수 있다. 진입해보면 위의 json 형태의 권한을 볼 수 있다. visual editor를 통해 간편하게 권한을 고를 수 있다. | Password Policy : 비밀번호 정책을 정해서 보안을 강화한다. | 다요소인증(MFA) : 필수 사용을 권장, 비밀번호 + 보안장치(MFA 토큰발급)를 사용하여 보안을 강화한다. | . MFA . | 가상 MFA device : 구글 인증기 | U2F : 물리적 디바이스로 USB처럼 생김 | 하드웨어 키 팝 : 디바이스에 인증 코드가 뜸 | . 비밀번호 정책 정하기 Account setting - Password policy - edit . MFA(멀티팩터) 정책 정하기 아이폰이나 인증기기를 잃어버릴것 같으면 사용해선 안된다. (root사용자만 가능?)우측 상단 계정 이름 클릭 - Security credentials . aws에 접근하는 방법 . | 웹 : 아이디와 비밀번호 MFA로 보호됨 | CLI : 엑세스키에의해 보호됨 | SDK(개발자 키트) : 애플리케이션 코드 내에서 api를 호출할때 사용 CLI와 같은방식으로 보호됨 | . CLI 명령어는 aws로 시작한다. (ex. aws s3 cp…) 몇몇은 CLI로만 aws를 관리한다. window에서 CLI 설정 . 구글 aws CLI install windows 검색 - 그냥 msi 인스톨러를 통해 설치하면됨. cmd 에서 aws –version 명령어 실행해서 잘 나오면 된것임 . user - {사용자} - Security credentials - create access key - command line interface (CLI) - aws는 access키 말고 다른 방식(cloud shell)을 권장하지만 그냥 진행 . 키를 발급받았다면 aws cli에서 access키를 설정해야함 . aws configure . 위 명령어를 실행하면 access key, secret access key, region, 기본 출력형식을 입력하라고함. 기본 출력형식은 그냥 엔터를 치고 넘어간다. 명령어 써보기 . aws iam list-users . 위 명령어를 사용하면 내 계정의 모든 사용자가 나온다. AWS CloudShell: Region 가용성 위 서비스는 모든 리전에서 사용할 수 있지 않다. 가능한 목록 (이후 업데이트 될 수 있음) . - 미국 동부(오하이오) - 미국 동부(버지니아 북부) - 미국 서부(오리곤) - 아시아 태평양(뭄바이) - 아시아 태평양(시드니) - 아시아 태평양(도쿄) - 유럽(프랑크푸르트) - 유럽(아일랜드) . aws웹의 상단에 터미널 모양 아이콘이 있음. 해당 아이콘을 클릭하면 웹 페이지가 터미널 ui가 있는곳으로 이동됨. cloud shell 에는 전체 저장소가 있다. text파일을 만들고 cloud shell을 다시 실행하면 text파일이 남아있다는것을 알 수 있다. 용량은 얼마나되는거야 그럼? . IAM Role . 서비스에 권한 부여. 예를들어 ec2에서 어떤 작업을 수행하려고 할 때 권한을 부여해야한다. 이를 위해 IAM Role을 만들어 ec2에 부여하고 ec2인스턴스가 aws에 있는 정보에 접근할때 . IAM Role을 사용하게 된다. ec2이외의 예로는 람다와 CludFormation 등등이 있다. IAM - 역할 - 역할 만들기 . ![[Pasted image 20231111104254.png]] 위와 같은 화면에서 aws서비스만 시험범위이다. 서비스 또는 사용 사례 목록을 보면 role을 부여할 수 있는 서비스 목록이 전부 뜬다. ![[Pasted image 20231111104537.png]] 예제로 읽기 권한만 추가 . ![[Pasted image 20231111105348.png]] 이름만 지정하고 그외에는 아무것도 건들지 않고 생성 버튼 클릭 . IAM 보안 도구 . IAM 자격 증명 보고서(account-level) . 보고서에는 계정에 있는 사용자와 다양한 자격 증명 상태를 포함한다. IAM 액세스 관리자(user-level) . 사용자에게 부여된 서비스의 권한과 해당 서비스에 마지막으로 액세스한 시간이 보인다. 이를 통해 어떤 권한이 사용되지 않는지 볼 수 있다. 따라서 사용자의 권한을 줄여 최소권한의 원칙을 지킬 수 있다. IAM 자격 증명 보고서 만들기 . IAM - 자격증명 보고서 - 다운로드 리포트 ![[Pasted image 20231111115630.png]] 위와같은 엑셀 파일을 받을 수 있다. ##### 액세스 관리자 User - 관리자 계정 클릭 - Access Advisor 4시간동안의 활동 내역이 보임 ![[Pasted image 20231111115911.png]] 위 서비스중 AWS App2Container와 Alexa for Business는 사용되지 않는것으로 확인되면 지우는것이 좋다. 퀴즈 오답 노트 . ![[Pasted image 20231111122315.png]] . IAM 사용자 그룹은 IAM 사용자 및 기타 사용자 그룹을 포함할 수 있습니다. (예 / 아니오) 정답 : IAM 사용자 그룹은 IAM 사용자만을 포함할 수 있다. ",
    "url": "/docs/aws/01.%20IAM.html",
    
    "relUrl": "/docs/aws/01.%20IAM.html"
  },"1": {
    "doc": "01. 객체, 설계",
    "title": "01. 객체, 설계",
    "content": ". 티켓 판매 애플리케이션 구현하기 … 각 클래스 구현 생략 … . 마틴에 따르면 모든 모듈은 제대로 실행돼야 하고, 변경이 용이해야 하며, 이해하기 쉬워야 한다. 앞에서 작성한 프로그램은 관람객들을 입장시키는 데 필요한 기능을 오류 없이 정확하게 수행하고 있다. 따라서 제대로 동작해야 한다는 제약은 만족시킨다. 하지만 불행하게도 변경 용이성과 읽는 사람과의 의사소통이라는 목적은 만족시키지 못한다. 지금부터 그 이유를 살펴보자. 소극장은 관람객의 가방을 열어 그 안에 초대장이 들어 있는지 살펴본다. 가방 안에 초대장이 들어 있으면 판 매원은 매표소에 보관돼 있는 티켓을 관람객의 가방 안으로 옮긴다. 가방 안에 초대장이 들어 있지 않다면 관 람객의 가방에서 티켓 금액만큼의 현금을 꺼내 매표소에 적립한 후에 매표소에 보관돼 있는 티켓을 관람객 의 가방 안으로 옮긴다. 위 기능에는 문제가 있다. 관람객과 판매원이 소극장의 통제를 받는 수동적인 존재라는 점이다. 관람객 입장에서 문제는 소극장이라는 제3자가 초대장을 확인하기 위해 관람객의 가방을 마음대로 열어 본다는 데 있다. 이해 가능한 코드란 그 동작이 우리의 예상에서 크게 벗어나지 않는 코드다. 앞에서 살펴본 예제는 우리의 예상을 벗어난다. 코드를 이해하기 어렵게 만드는 또다른 이유는 이 코드를 이해하기 위해서는 여러 가지 세부적인 내용들을 한꺼번에 기억하고 있어야 한다는 점이다. Theater의 enter 메서드를 이해하기 위해서는 Audience가 Bag을 가지고 있고, Bag 안에는 현금과 티켓이 들어 있으며 TicketSeller가 TicketOffice에 티켓을 판매하고, TicketOffice안에 돈과 티켓이 보관돼 있다는 모든 사실을 동시에 기억하고 있어야 한다. 이는 코드를 읽고 이해하는 사람에게 큰 부담이다. 가장 심각한 문제는 Audience와 TicketSeller를 변경할 경우 Theater도 함께 변경해야 한다는 사실이다. (변경에 취약하다는 것) . 이 코드는 관객이 현금과 초대장을 보관하기 위해 항상 가방을 들고다닌다고 가정한다. 관객이 현금이 아닌 신용카드를 이용해서 결제한다면? 등과 같은 다양한 이유로 모든 코드가 일시에 흔들리게 된다. 이것은 객체 사이의 의존성과 관련된 문제다. 그렇다고 해서 객체 사이의 의존성을 완전히 없애는 것이 정답은 아니다. 최소한의 의존성만 유지하고 불필요 한 의존성을 제거해야한다. ![[Pasted image 20240523011538.png]] . 해결 방법은 간단하다. Theater가 Audience와 TicketSeller에 관해 너무 세세한 부분까지 알지 못하도록 정보를 차단하면 된다. 관람객이 가방을 가지고 있다는 사실과 판매원이 매표소에서 티켓을 판매한다는 사실을 Theater가 알아야 할 필요가 없다. Theater가 원하는 것은 관람객이 소극장에 입장하는 것 뿐이다. 따라서 관람객이 스스로 가방 안의 현금과 초대장을 처리하고 판매원이 스스로 매표소의 티켓과 판매 요금을 다루게 한다면 이 모든 문제를 한 번에 해결할 수 있을 것이다. 다시 말해서 관람객과 판매원을 자율적인 존재로 만들면 되는 것이다. ![[Pasted image 20240523012402.png]] . ![[Pasted image 20240523012545.png]] . 판매자가 티켓을 판매하기 위해 TicketOffice를 사용하는 모든 부분을 TicketSeller 내부로 옮기고, 관람객이 티켓을 구매하기 위해 Bag을 사용하는 모든 부분을 Audience 내부로 옮긴 것이다. 핵심은 객체 내부의 상태를 캡슐화하고 객체 간에 오직 메시지를 통해서만 상호작용하도록 만드는 것이다. 변경하기 쉬운 설계는 한 번에 하나의 클래스만 변경할 수 있는 설계다. 절차적 프로그래밍은 프로세스가 필요한 모든 데이터에 의존해야 한다는 근본적인 문제점 때문에 변경에 취약할 수밖에 없다. 절차 지향과 객체 지향 방식의 근본적인 차이를 만드는 것은 책임의 이동이다. ![[Pasted image 20240523013252.png]] . ![[Pasted image 20240523013302.png]] . 수정한 설계가 이전 설계보다 좋아졌다. 하지만 아직도 개선의 여지가 있다. Audience의 Bag을 보면 Audience처럼 스스로 자기 자신을 책임지고 있지 않다. Bag을 자율적인 존재로 바꿔보자. TicketSeller 역시 TicketOffice의 자율권을 침해한다. TicketSeller는 TicketOffice에 있는 Ticket을 마음대로 꺼내서 자기 멋대로 Audience에게 팔고 돈을 집어넣는다. ![[Pasted image 20240523013735.png]] . 직관에 따르는 코드는 이해하기가 더 쉬운 경향이 있다. 그러나 Theater는 어떤가? Bag은? Ticketoffice는? 이들은 실세계에서는 자율적인 존재가 아니다. 그럼에도 우리는 이들을 관람객이나 판매원과 같은 생물처럼 다뤘다. 무생물 역 시 스스로 행동하고 자기 자신을 책임지는 자율적인 존재로 취급한 것이다. 현실에서는 수동적인 존재라고 하더라도 일단 객체지향의 세계에 들어오면 모든 것이 능동적이고 자율적인 존재로 바뀐다. 좋은 설계란 무엇일까? 우리가 짜는 프로그램은 두 가지 요구사항을 만족시켜야 한다. 요구하는 기능을 온전히 수행하면서 변경을 수용할 수 있는 코드 요구사항 변경은 필연적으로 코드 수정을 초래하고, 코드 수정을 회피하려는 가장 큰 원인은 두려움이다. 두려움은 요구사항 변경으로 인해 버그를 추가할지도 모른다는 불확실성에 기인한다. 따라서 진정으로 원하는 것은 변경에 유연하게 대응할 수 있는 코드다. 객체지향은 과거의 다른 방법보다 안정감을 준다 . 변경 가능한 코드란 이해하기 쉬운 코드다. 객체지향 패러다임은 세상을 바라보는 방식대로 코드를 작성할 수 있게 돕는다. 훌륭한 객체지향 설계란 협력하는 객체 사이의 의존성을 적절하게 관리하는 설계다. ",
    "url": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/01.%20%EA%B0%9D%EC%B2%B4,%20%EC%84%A4%EA%B3%84.html",
    
    "relUrl": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/01.%20%EA%B0%9D%EC%B2%B4,%20%EC%84%A4%EA%B3%84.html"
  },"2": {
    "doc": "01. 구글 엔지니어는 어떻게 일할까",
    "title": "1장",
    "content": ". 시간 위를 걷는 프로그래밍 . 소프트 웨어 언제니어링은 코드를 작성하는 행위에 더하여, 시간의 흐름에 발맞춰 한 조직이 코드를 구축하고 유지보수하는데 관련된 모든것 입니다. 개발자께서 “안 돼”라고 말씀하셨다 . 개발자에게 무언가 요청하면 일단 “안 돼”라고 답하지만, 위에서 ‘쪼으면’ 결국 해낸다는것… 이유는 뭘까? 쪼을수록 개발자들은 ‘프로그래밍’에 집중하고 ‘소프트웨어 언지니어링’에서 해야 할 일들을 소홀히 하기 때문입니다. (테스트 코드, 코드 리뷰, 프로세스 자동화 등) . 주인을 찾습니다! . 쳇바퀴 돌듯 어제와 똑같은 업무 방식, 쌓여만 가는 기술 부채, 데드라인에 쫓겨 단편적인 프로그래밍에서 헤어나오지 못하는 하루하루, 아무도 이런 삶을 꿈꾸지 않습니다. 엔지니어링의 주인이 되어야 이런 삶에서 벗어나, ‘시간위를 걸어’ 원하는 목적지까지 안전하게. 갈 수있습니다. 구글은 다르게 일한다 . 무엇이 다른가? . | 코드리뷰 | 버전 관리와 브랜치 전략 | 문서자료도 코드처럼 | 테스트 스위트 분류 | 빌드 시스템 | 오픈소스st + 비욘세 규칙 | . 코드리뷰 . 코딩 == 소프트웨어 엔지니어의 핵심 역량 많은 사람이 팀을 이뤄 하나의 소프트웨어를 만들어갑니다. 하지만 서로가 작성한 코드에 대해 이야기 할 . 수있는 수단은 코드리뷰가 거의 유일합니다. 그래서 구글은 코드 리뷰에 심혈을 기울입니다. |   | 대다수 기업 | 구글 | . | 리뷰 전 자동검증 | O or X | 정적 분석, (대다수의) 테스트 | . | 테스트 누락시 리뷰 거부 | X | O | . | 리뷰어 역할 구분 | X | 다른 엔지니어, 코드 소유자, 가동성 인증자 | . 구글에서는 3가지 역할의 리뷰어가 승인하여야 변경된 코드를 커밋할 수 있습니다. | 역할 | 할당 | 리뷰 관점 | . | 다른 엔지니어 | 팀원 | 작성자가 의도한 작업을 코드가 적절하게 수행하는가? | . | 코드 소유자 | 테크 리드,해당 기술 전문가 | 체크인해도 될 만큼 변경 코드가 적절한가? | . | 가독성 인증자 | 가독성 인증자 | 해당 언어의 스타일과 모범 사례를 잘 따르는가? | . 버전 관리와 브랜치 전략 . |   | 대다수 기업 | 구글 | . | 리포지터리 형태 | 멀티리포 | 모노리포 | . | 원-버전 규칙 | X | O | . | 개발 즈랜치 | O | X | . 구글은 기본적으로 모든 프로젝트를 하나의 리포지터리에서 관리합니다. 그래서 구글의 리포지터리에는 20억 라인이 넘는 코드가 담겨있습니다. 각종 프로젝트에서 사용하는 의존성들(참조 모듈, 서드파티 라이브러리 등) 역시 해당 리포지터리에 두고 모든 의존성의 안정돈 버전을 . 단하나씩만 존재하게 관리합니다. 버전업이 필요하다면 모든 프로젝트가..? 그걸 귀찮아하지 않고 진행하는게 소프트웨어 엔지니어? 일단 일관된 버전을 가져가는걸로 타협하자 . 문서자료도 코드처럼 . 문서 자료는 처음엔 멋저보이고 유용하지만, 시간이 지날수록 골칫거리가 되기 쉽습니다. 문서자료는 코드와 달리 동작하지 않아서 문제가 즉시 드러나지 않기 때문입니다. | 코드 | 문서자료 | . | 규칙, 지침, 스타일 가이드 | 규칙, 구문 규정, 스타일 가이드 | . | 소유자 배정 | 소유자 배정 | . | 원-버전 규칙 | 주제별 표준 문서 지정 | . | 버전 관리 | 버전 관리 | . | 코드 리뷰 | 변경 시 리뷰(코드와 해당 문서자료를 하나의 변경으로 묶어 처리) | . | 이슈 추적 | 이슈 추적 | . 구글은 보시다시피 문서자료도 코드처럼 관리합니다. 너무빡센데,,, 해외는 한국처럼 일하는 시간이 많지 않은게 확실할까? 하다보면 괜찮은가? 우리 유닛에 바로 도입하기엔 어려울듯 . 테스트 스위트 분류 . | 일반적인 테스트 분류 | 구글의 테스트 분류 | . | 단위 테스트,통합 테스트,시스템 테스트 | 작은 테스트,중간 크기 테스트,큰 테스트 | . 따로 설명이 더 없네..? . 빌드 시스템 . |   | 대다수 기업 | 구글 | . | 빌드 시스템 유형 | 태스크 기반 | 아티펙트 기반 | . | 대표 도구 | Gradle, Maven, Make, Ant | Blaze, Bazel, Pants, Buck | . 태스크 기반 빌드 시스템에서는 결과물을 만들어내는 과정을 스크립트 언어로 명령 하나하나를 기술합니다. 그래서 프로젝트가 커지면 빌드 전담 인력을 두어야 할 만큼 스크립트를 관리하는 일이 복잡해집니다. 아티팩트 기반 빌드는 이 문제를 해결할 수 있으며, 그외의 장점도 있습니다 . 오픈소스st + 비욘세 규칙 . 구글은 모든 프로젝트가 사내 엔지니어에게 공개되어 있습니다. 구글의 엔지니어라면 누구든 버그를 패치 할 수 있고 심지어 원하는 기능도 추가 할 수 있습니다. (리뷰를 통해) . 비욘세 규칙 . A프로젝트의 코드를 변경하자 A에 의존하는 B프로젝트가 오작동 하기 시작했면 누구의 책임인지를 놓고 논쟁하게 될 것 입니다. 이 상황에서 구글은 ‘비욘세 규칙’을 적용합니다. ‘비욘세 규칙’은 “너에게 중요한 기능이었다면 테스트를 준비했어야지”라고 풀어 이야기할 . 수있는 규칙으로, ‘싱글 레이디스’의 가사 “네가 진심으로 좋아했다면 반지를 줬어야지”에서 착안했습니다 . ㅋㅋ . B팀이 지속적 통합 시스템에 등록해둔 테스트들이 모두 통과된다면 문제를 해결할 책임은 전적으로 B팀이 집니다. 각 팀은 CI를 믿고 자신들의 제품에 원하는 기능을 자유롭게 추가 할 수 있습니다. 구글은 조급하게 top down으로 바꾸려는 시도 보다는, 실무자들이 스스로 느끼고 따르도록 유도했습니다. 심리적 안전을 토대로 소통하고 함께 배우는 문화를 조성하는데 힘쏟았습니다. 겸손, 존중, 신뢰 위에 위대한 팀을 만들기 위해 노력했습니다. | 구글 | 안티 패턴 | . | 지속 가능성 | 눈앞의 데드라인 | . | 엔지니어 주도 개발 문화 | 임원, 관리자, SE팀 등 비-실무자가 주도 | . | 스스로 느끼고 따르도록 | 하향식 | . | 심리적 안전, 소통, 함께 성장 | 소통 단절, 개인 성장은 각자도생 | . | 팀워크 중심 | 개인 역량/실적 중심 | . [[02. 구글 엔지니어는 어떻게 일할까]] . ",
    "url": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/01.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html#1%EC%9E%A5",
    
    "relUrl": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/01.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html#1장"
  },"3": {
    "doc": "01. 구글 엔지니어는 어떻게 일할까",
    "title": "01. 구글 엔지니어는 어떻게 일할까",
    "content": " ",
    "url": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/01.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html",
    
    "relUrl": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/01.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html"
  },"4": {
    "doc": "01. 사용자 수에 따른 규모 확장성",
    "title": "01. 사용자 수에 따른 규모 확장성",
    "content": ". ",
    "url": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/01.%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%88%98%EC%97%90%20%EB%94%B0%EB%A5%B8%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5%EC%84%B1.html",
    
    "relUrl": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/01.%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%88%98%EC%97%90%20%EB%94%B0%EB%A5%B8%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5%EC%84%B1.html"
  },"5": {
    "doc": "01. 사용자 수에 따른 규모 확장성",
    "title": "로드 벨런서",
    "content": "로드밸런서는 부하 분산 집합에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할을 한다. ![[Pasted image 20240802003341.png]] . ",
    "url": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/01.%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%88%98%EC%97%90%20%EB%94%B0%EB%A5%B8%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5%EC%84%B1.html#%EB%A1%9C%EB%93%9C-%EB%B2%A8%EB%9F%B0%EC%84%9C",
    
    "relUrl": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/01.%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%88%98%EC%97%90%20%EB%94%B0%EB%A5%B8%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5%EC%84%B1.html#로드-벨런서"
  },"6": {
    "doc": "01. 사용자 수에 따른 규모 확장성",
    "title": "캐시",
    "content": "캐시 사용시 유의할 점 어떤 상황에 바람직한가? 어떤 데이터를 캐시에 두어야하는가? 캐시에 보관된 데이터는 어떻게 만료 되는가? 일관성은 어떻게 유지되는가? . 장애는 어떻게 대처할 것인가? 캐시 서버를 한대만 두는 경우 해당 서버는 단일 장애 지점(Single Point Of Failure)이 되어버릴 가능성이 있다. 단일 장애 지점이란 어떤 특정 지점에서의 장애가 전체 시스템의 동작을 중단시켜버릴 수 있는 경우를 일컫는다. SOPF를 피하려면 여러 지역에 걸쳐 캐시 서버를 분산시켜야 한다. 캐시 메모리는 얼마나 크게 잡을 것인가? . 데이터 방출 정책은 무엇인가? 캐시가 꽉 차버리면 추가로 캐시에 데이터를 넣어야 할 경우 기존 데이터를 내보내야 한다. 가장 널리 쓰이는 것은 LRU이다. ",
    "url": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/01.%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%88%98%EC%97%90%20%EB%94%B0%EB%A5%B8%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5%EC%84%B1.html#%EC%BA%90%EC%8B%9C",
    
    "relUrl": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/01.%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%88%98%EC%97%90%20%EB%94%B0%EB%A5%B8%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5%EC%84%B1.html#캐시"
  },"7": {
    "doc": "01. 사용자 수에 따른 규모 확장성",
    "title": "콘텐츠 전송 네트워크 CDN",
    "content": "사용시 고려사항 비용 : 자주 사용되지 않는 콘텐츠를 캐싱하는 것은 이득이 크지 않으므로, CDN에서 빼는것을 고려하도록 하자. 만료 시한 : 시의성이 중요한 콘텐츠의 경우 만료 시점을 잘 정해야 한다. 너무 길지도 않고 짧지도 않아야 한다. 너무 길면 콘텐츠의 신선도는 떨어지고, 너무 짧으면 서버에 빈번히 접속하게 되어 좋지 않다. CDN 장애에 대한 대처 방안: CDN 자체가 죽었을 경우 웹사이트 / 애플리케이션이 어떻게 동작해야 하는지 고려해야 한다. CDN이 응답하지 않을경우 문제를 감지하여 원본 서버로부터 직접 콘텐츠를 가져오도록 클라이언트를 구성하는 것이 필요할 수도 있다. ",
    "url": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/01.%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%88%98%EC%97%90%20%EB%94%B0%EB%A5%B8%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5%EC%84%B1.html#%EC%BD%98%ED%85%90%EC%B8%A0-%EC%A0%84%EC%86%A1-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-cdn",
    
    "relUrl": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/01.%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%88%98%EC%97%90%20%EB%94%B0%EB%A5%B8%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5%EC%84%B1.html#콘텐츠-전송-네트워크-cdn"
  },"8": {
    "doc": "01. 사용자 수에 따른 규모 확장성",
    "title": "무상태 웹 계층",
    "content": "상태 정보 의존적인 아키텍처 ![[Pasted image 20240802000434.png]] 사용자 A의 세션 정보나 프로파일 이미지 같은 상태 정보는 서버1에 저장된다. 사용자 A를 인증하기 위해 HTTP 요청은 반드시 서버1로 전송되어야 한다. 요청이 서버 2로 전송되면 인증은 실패할 것인데, 서버2에 사용자A에 관한 데이터는 보관되어 있지 않기 때문이다. 문제는 같은 클라이언트로부터의 요청은 항상 같은 서버로 전송되어야 한다. 대부분의 로드밸런서가 이를 지원하기 위해 고정 세션이라는 기능을 제공하고 있는데, 이는 로드밸런서에 부담을 준다. 무상태 아키텍처 ![[Pasted image 20240802000720.png]] . ",
    "url": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/01.%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%88%98%EC%97%90%20%EB%94%B0%EB%A5%B8%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5%EC%84%B1.html#%EB%AC%B4%EC%83%81%ED%83%9C-%EC%9B%B9-%EA%B3%84%EC%B8%B5",
    
    "relUrl": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/01.%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%88%98%EC%97%90%20%EB%94%B0%EB%A5%B8%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5%EC%84%B1.html#무상태-웹-계층"
  },"9": {
    "doc": "01. 사용자 수에 따른 규모 확장성",
    "title": "메시지 큐",
    "content": "메세지 큐는 메시지의 무손실을 보장하는 비동기 통신을 지원하는 컴포넌트다. 메시지의 버퍼 역할을 하며, 비동기적으로 전송한다. ![[Pasted image 20240802000942.png]] . 메시지 큐를 이용하면 서비스 또는 서버 간 결합이 느스해져서, 규모 확장성이 보장되어야 하는 안정적 애플리케이션을 구성하기 좋다. 작업이 오래걸릴 수 있는 프로세스는 비동기적으로 처리하면 편리하다. ",
    "url": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/01.%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%88%98%EC%97%90%20%EB%94%B0%EB%A5%B8%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5%EC%84%B1.html#%EB%A9%94%EC%8B%9C%EC%A7%80-%ED%81%90",
    
    "relUrl": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/01.%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%88%98%EC%97%90%20%EB%94%B0%EB%A5%B8%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5%EC%84%B1.html#메시지-큐"
  },"10": {
    "doc": "01. 사용자 수에 따른 규모 확장성",
    "title": "로그, 메트릭 그리고 자동화",
    "content": "소규모 웹 사이트를 만들 때는 로그나 메트릭, 자동화 같은 것은 하면 좋지만 꼭 할 필요는 없었다. 하지만 웹 사이트와 함께 규모가 커지고 나면, 그런 도구에 필수적으로 투자해야한다. 메트릭 가운데 특히 유용한 것을 몇가지 살펴보면 호스트 단위 메트릭 : CPU, 메모리, 디스크 I/O 종합 메트릭 : 데이터베이스 계층의 성능, 캐시 계층의 성능 핵심 비즈니스 메트릭 : 일별 능동 사용자, 수익, 재방문 . 자동화 : 빌드, 테스트, 배포 등의 절차를 자동화 하여 개발 생산성을 크게 향상시킬 수 있다. ",
    "url": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/01.%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%88%98%EC%97%90%20%EB%94%B0%EB%A5%B8%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5%EC%84%B1.html#%EB%A1%9C%EA%B7%B8-%EB%A9%94%ED%8A%B8%EB%A6%AD-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%EC%9E%90%EB%8F%99%ED%99%94",
    
    "relUrl": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/01.%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%88%98%EC%97%90%20%EB%94%B0%EB%A5%B8%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5%EC%84%B1.html#로그-메트릭-그리고-자동화"
  },"11": {
    "doc": "01. 사용자 수에 따른 규모 확장성",
    "title": "데이터베이스의 규모 확장",
    "content": "스택오버플로는 2013년 한 해 동안 방문한 천만 명의 사용자 전부를 단 한대의 마스터 데이터베이스로 처리하였다. 하지만 이런 스케일업에는 몇 가지 심각한 약점이 있다. | 성능을 무한으로 증설할 수 없으니 결국 감당하기 어려워진다. | Single Point Of Failure로 인한 위험성이 크다. | 비용이 많이 든다. 성능이 좋을수록 가격이 올라가기 마련이다. | . 샤딩 . 샤딩은 대규모 데이터베이스를 샤드라고 부르는 작은 단위로 분할하는 기술을 일컫는다. 모든 샤드는 같은 스키마를 쓰지만 샤드에 보관되는 데이터 사이에는 중복이 없다. ![[Pasted image 20240802002421.png]] ![[Pasted image 20240802002429.png]] 이 사례는 user_id % 4를 해시 함수로 사용하여 데이터가 보관되는 샤드를 정한다. 샤딩 전략을 구현할 때 고려해야 할 가장 중요한 것은 샤딩 키를 어떻게 정하느냐 하는 것이다. (‘파티션 키’라고도 부름) . 샤딩은 훌륭한 기술이지만 완벽하지 않다. 샤딩을 도입하면 시스템이 복잡해지고 풀어야 할 새로운 문제도 생긴다. 데이터의 재 샤딩 재 샤딩은 다음과 같은 경우에 필요하다. | 데이터가 너무 많아져서 하나의 샤드로는 더 이상 감당하기 어려울 때 | 샤드 간 데이터 분포가 균등하지 못하여 어떤 샤드에 할당된 공간 소모가 다른 샤드에 비해 빨리 진행될 때 | 핫스팟 키 문제라고도 불리는 문제로, 특정 샤드에 질의가 집중되어 서버에 과부하가 걸리는 문제 | 조인과 비정규화 문제 : 일단 하나의 데이터베이스를 여러 샤드 서버로 쪼개고 나면 여러 샤드에 걸친 데이터를 조인하기가 힘들어진다. 이를 해결하는 한 가지 방법은 데이터베이스를 비정규화하여 하나의 테이블에서 질의가 수행될 수 있도록 하는 것이다. | . 시스템의 규모를 확장하는 것은 지속적이고 반복적인 과정이다. 이번 장의 내용을 정리해보면 다음과 같다 . | 웹 계층은 무상태 계층으로 | 모든 계층에 다중화 도입 | 가능한 한 많은 데이터를 캐시할 것 | 여러 데이터 센터를 지원할 것 | 정적 콘텐츠는 CDN을 통해 서비스할 것 | 데이터 계층은 샤딩을 통해 그 규모를 확장할 것 | 각 계층은 샤딩을 통해 그 규모를 확장할 것 | 각 계층은 독립적 서비스로 분리할 것 | 시스템을 지속적으로 모니터링하고, 자동화 도구들을 활용할 것 | . ",
    "url": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/01.%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%88%98%EC%97%90%20%EB%94%B0%EB%A5%B8%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5%EC%84%B1.html#%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4%EC%9D%98-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5",
    
    "relUrl": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/01.%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%88%98%EC%97%90%20%EB%94%B0%EB%A5%B8%20%EA%B7%9C%EB%AA%A8%20%ED%99%95%EC%9E%A5%EC%84%B1.html#데이터베이스의-규모-확장"
  },"12": {
    "doc": "02. EC2",
    "title": "02. EC2",
    "content": ". 최소한의 비용 사용 . 대시보드 . 아래와 같은 과정을 통해 사용자도 비용 청구 정보에 접근 할 수 있다. (루트 계정 로그인) - 우측 상단 계정 클릭 - my billing dashboard - (아래로 스크롤) 청구 정보에 접근하기 위한 IAM 사용자와 역할 편집 - Activate IAM Access . 위의 과정이 옜날버전이라 사라진듯하다. https://us-east-1.console.aws.amazon.com/billing/home#/account 해당 주소를 통해 접근해보자. ![[Pasted image 20231111131432.png]] 해당 페이지에 들어가면 위와같이 활성화 할수 있는 편집창이 있다. 잘 찾아보자. 이후 사용자 계정에서 청구서를 조회 할 수 있게 되며, 대시보드를 통해 서비스별로 청구된 가격을 볼 수 있으며, 사용되지 않는 서비스는 삭제되어야한다. 무료 등급의 경우 LNB에 Free Tier의 메뉴를 볼 수 있다. 해당 페이지에서는 각 서비스별 무료 사용량을 알 수 있으며 이를 활용하여 무엇을 잘 못 사용하고 있는지 여부를 확인 할 수 있다. AWS 예산 . 비용에대한 알림을 받으려면 aws예산을 만들어야한다. 이를 통해 한도에 도달하기 직전에 알림을 받을 수 있다. LNB에서 예산(Budgets) 클릭으로 해당 페이지에 접근하여 예산 생성을 진행 . ![[Pasted image 20231111132941.png]] 지출이 아예 없도록 관리해주는 템플릿도 존재한다! . ![[Pasted image 20231111133102.png]] 아예 막는것은 아니고 예산이 1달러로 설정되어 비용이 발생하자마자 사용자에게 알려주는듯 하다. EC2 . Elastic Compute Cloud . 버추얼 머신 - EC2 스토리지 확장 - EBS 로드밸런서 - ELB 오토 스케일링 - ASG 방화벽 - Firewall rules 처음 설정 데이터 - Bootstrap script . | 부팅할때만 동작하고 동작하지않음 | 모든 명령어는 sudo로 동작함 | . 인스턴스 생성 . ec2 콘솔 - instances - lunch instances . ![[Pasted image 20231111141455.png]] . 선택하고있는 옵션 말고 맨위의 옵션이 기본값인데 왜 저걸 선택했을까? 그 이유는 영상이 옜날거라 해당 옵션이 없었다. 그냥 영상 따라서 진행해보자. ![[Pasted image 20231111141733.png]] 인스턴스 유형에따라 가격이 달라진다. (성능 선택) . ![[Pasted image 20231111141918.png]] ssh접근을 위한 key pair 생성 . ![[Pasted image 20231111142047.png]] 키 페어 유형은 암호화 방식을 선택하는것이며, 프라이빗 키 파일 형식은 .pem : mac, linux, after windows(7,8 이후) 에서 지원 .ppk : window7,8 or Putty에서 사용 적합 . ![[Pasted image 20231111142434.png]] ![[Pasted image 20231111142546.png]] . 인스턴스 생성시 방화벽을 설정 할 수 있으며, 예제에서는 Create security group을 선택한다. 웹서비스를 위한 인스턴스이기 때문에 인터넷에서 HTPP 트래픽 허용을 체크하고, HTTPS는 따로 사용할 예정이 없기 때문에 체크하지 않는다. ![[Pasted image 20231111142906.png]] 스토리지 옵션에서 세부사항을 보게되면 종료 시 삭제의 옵션이 예로 되어있는데, 이는 인스턴스가 종료될때 데이터가 모두 삭제된다는 것을 의미하니 주의할것. ![[Pasted image 20231111143833.png]] 세부사항 옵션을 펼친뒤 스크롤을 쭉 내리면 사용자 데이터라는 옵션이 있다. 여기서 Bootstrap script를 작성 할 수 있다. #!/bin/bash # Use this for you're user data (script from top to bottom) # install https (Linux 2 version) yum update -y yum install -y httpd systemctl start httpd systemctl enable httpd echo \"&lt;h1&gt;Hello world from $(hostname -f)&lt;/h1&gt;\" &gt; /var/www/html/index.html . 위 스크립트 copy, paste . ![[Pasted image 20231111144727.png]] 완료하고나면 퍼블릭 ip주소와 프라이빗 ip주소를 알 수 있다. 위 사진에서 퍼블릭 ip주소를 가렸지만, 사실 인스턴스가 중지되었다가 다시 실행되면 주소가 바뀌어 그럴필요가 없다. ![[Pasted image 20231111150604.png]] 퍼블릭 DNS로 접근하면 위와같은 페이지를 볼 수 있다. 처음에 script를 잘못 작성해서 재부팅하면 될줄알았는데, 결국 인스턴스를 다시 만들었다. 해결 방법있는지 아시는분? . 인스턴스 타입 . m5.2xlarge . | m : instance class (m은 범용이라는 뜻) | 5 : generation | 2xlarge : 크기 (크기가 클수록 더 많은 메모리와 cpu를 가짐) | . 범용의 인스턴스는 웹 서버나 코드 저장소와 같은 다양한 작업에 적합 컴퓨팅, 메모리, 네트워킹 간의 균형도 잘 맞음 . t 도 범용 인스턴스라는데? . 고성능 프로세서 컴퓨터는 cpu를 뜻하는 c로 시작함 메모리 특화는 ram을 뜻하는 r로 시작함. 대용량 메모리는 x1 또는 z1으로 표현하기도함 스토리지 특화(DB 서버에 적합)은 i, g, h 로 시작함 . 보안 그룹(방화벽) . 인스턴스에 들어오고 나가는 트래픽을 제어한다 허용 규칙만 포함한다 . 컴퓨터의 위치(ip)나 다른 보안 그룹을 참조해 규칙을 만들 수 있다. 통제 . | 포트 | ip | 인바운드 규칙 | 아웃바운드 규칙 | . 기본적으로 인바운드는 막혀있으며 아웃바운드는 모두 허용이다. AWS에서 \"인바운드(Inbound)\" 및 \"아웃바운드(Outbound)\"는 네트워크 트래픽의 방향을 나타냅니다. 이 용어들은 일반적으로 다음과 같은 의미를 갖습니다. 1. **인바운드(Inbound):** - 인바운드 트래픽은 네트워크로 들어오는 데이터를 나타냅니다. - 예를 들어, 사용자가 웹 브라우저를 사용하여 웹 서버에 요청을 보내면 이는 웹 서버에 대한 인바운드 트래픽입니다. 2. **아웃바운드(Outbound):** - 아웃바운드 트래픽은 네트워크에서 나가는 데이터를 나타냅니다. - 예를 들어, 서버가 클라이언트에게 응답을 보내는 것은 아웃바운드 트래픽입니다. 허용되지 않은 포트로 접근하면 time out . 인스턴스는 여러 보안 그룹을 가질 수 있다. 보안 그룹은 지역과 vpc 결합으로 통제되어 있어, 지역이 바뀌면 새 보안그룹을 생성하거나 다른 vpc를 생성해야한다. VPC란? VPC(Virtual Private Cloud)는 Amazon Web Services (AWS)에서 제공하는 가상 네트워크 환경을 나타냅니다. VPC는 사용자가 정의하고 구성할 수 있는 가상의 네트워크로, AWS 클라우드에서 리소스를 배치하고 네트워크를 구축할 수 있게 해줍니다. 간단히 말해, AWS에서 제공하는 클라우드 환경에서 사용자가 자신만의 가상 네트워크를 생성할 수 있는 서비스입니다. 보안그룹은 ec2 외부에서 동작하는것이므로 ec2 인스턴스는 인지 할 수 없다. ssh 액세스를 위해 하나의 별도 보안그룹을 유지하는 것이 좋다. (복잡하기 때문에 별도 관리) . 타임아웃으로 연결이 실패된거라면 보안그룹을 의심해보는것이 좋다. 연결이 거부됐다면, 트래픽은 통과했지만 애플리케이션에 문제가 있거나 실행되지 않는등의 이슈로 볼 수 있다. 보안 그룹 사용의 예로 . A인스턴스에 보안그룹1 (보안그룹1과 보안그룹2의 인바운드 허용)을 설정하고 B인스턴스에 보안그룹2만 적용해 둔다면 두 인스턴스는 간단하고 자유롭게 통신이 가능하다. C인스턴스도 마찬가지로 보안그룹1을 설정한다면 A인스턴스와 B인스턴스 자유롭게 통신이 가능하다. IP에 구에받지않고..! D인스턴스가 보안그룹3을 설정하고 A,B,C가 통신한다면 같은 포트로 접근 했더라도 실패한다. 어떤 포트를 알아야 할까? . SSH : 22 : secure shell FTP : 21 : file transfer protocol SFTP : 22 : secure file transfer protocal HTTP : 80 : access unsecured website HTTPS : 443 : access secured website RDP : 3389 : remote desktop protocol . 보안 그룹 설정 . 네트워크 및 보안 - 보안 그룹 ![[Pasted image 20231111160350.png]] 위 사진과 같이 규칙을 변경 할 수 있다. ssh . 명령줄로 아마존 서버를 컨트롤 .pem 또는 .ppk파일 필요, 파일 이름에 공백이 있어선 안됨. 인스턴스의 외부망 주소가 필요하며, 해당 인스턴스는 ssh 포트인 22번 포트가 허용된 보안 그룹에 속해있어야함. ssh ec2-user@{외부망 주소} . ec2-user라고 하는 이유는 Amazon Linux 2 AMI에는 이미 사용자가 하나 설정되어있는데 그 사용자 이름이 ec2-user이기 때문이다. 해당 명령어를 실행하면 실패 할텐데 이유는 .pem파일을 적용하지 않았기 때문이다. ssh -i {파일이름.pem} ec2-user@{외부망 주소} . 해당 파일이 있는 위치에서 위의 명령어 실행 . ![[Pasted image 20231111162235.png]] . 보호되지 않은 키 파일이 있다고 뜬다. 우리는 이것의 권한을 변경 해야 한다 . chmod 0400 EC2Tutorial.pem . ![[Pasted image 20231111162523.png]] 다시 명령어를 실행하면 ssh 접속에 성공 한다. 인스턴스에 role 부여하기 . 인스턴스 - Actions - Security - Modify IAM Role . ![[Pasted image 20231111163843.png]] . ![[Pasted image 20231111163936.png]] 설정을 마치고 aws iam list-users를 실행하면 위 사진과 같은 리턴값을 받을 수 있다. role을 부여하지않고 aws configure 명령어를 통해 access key 와 secret key를 입력해놓는다면 ssh로 연결하는 모든 사용자가 아무 권한이나 사용할 수 있기때문에 절대 해서는 안된다. ec2 구매 옵션 . EC2 on Demand . | Linux, windows - 1초 단위로 청구됨 | other - 1시간 단위로 청구됨 | . EC2 On-Demand 인스턴스는 다음과 같은 특징을 가지고 있습니다. | 순간적인 확장성: 필요에 따라 인스턴스를 즉시 프로비저닝하여 애플리케이션 요구 사항에 대응할 수 있습니다. | 시간당 청구: 사용한 만큼만 지불하며, 인스턴스를 중지하면 과금이 중단됩니다. | 가격의 예측 가능성: 고정된 요금 모델이 아니라 사용한 시간에 비례하여 지불하므로 예측 가능한 비용 모델을 제공합니다. | . EC2 Reserved Instances . | 온디맨드에 비해 72%할인을 제공 | 특정한 인스턴스 속성 예약 (인스턴스타입, 리전, 테넌시, OS 등) | 계약 기간을 1년 또는 3년으로 지정해서 더 많은 할인 | 선결제, 부분선결제, 후불로 나뉠 수 있고 할인률이 다르다 | . Convertible Reserved Instances . | 인스턴스의 속성을 바꿀 수 있다. | 그냥 예약제보다 할인률이 떨어진다. | . EC2 Saving Plans . | 최대 70% 할인 | 1년내지 3년동안 시간당 10달러로 약정 | 한도를 넘어가면 온디맨드 타입으로 변경됨 | 사양을 선택해서 인스턴스를 생성하지만 고정이다 | . EC2 Spot Instances . | 최대 90% 할인 | 지불하려는 최대가격을 설정하고, 그 가격이 넘어가면 인스턴스가 손실된다. | 사용 시간이 유연하고, 중요하지않은 작업 처리(DB같은 역할은 해서는 안됨) | 중단 또는 종료 후 새로운 인스턴스로 띄우는 옵션이 있다. 유애기간은 2분 | 스팟 블록 . | 1~6시간만 동작하는 조건으로 인스턴스를 회수하지 않는다. | . | 스팟 인스턴스는 1회성과 영구성이 있다. | 1회성은 한번 실행후 인스턴스가 종료되면 다시 실행시키지 않는다. | 영구성은 인스턴스가 종료되면 이를 감지하고 다시 실행시킨다. | 영구성 스팟으로 설정했을경우 스팟 요청먼저 취소하고 인스턴스를 종료해야 스팟 요청이 다시 인스턴스를 실행시키지 않는다. 스팟 플릿(무리) . | . | . | 정의한 가격으로 다양한 런치 풀을 설정한다(인스턴스타입, 용량, 성능 등) | 플릿은 가장 적합한 런치 풀을 선택한다. | 원하는 예산 또는 용량에 도달하면 정지한다. | 스팟 플릿은 가장 낮은 가격인 풀에서 인스턴스를 시작하기 때문에 비용이 최적화된다. | 워크로드가 매우 짧은 경우 좋은 옵션이다. | 다양한 방법으로 스팟 인스턴스를 실행 할 수 있다. | 원하는 인스턴스 유형과 AZ를 정확히 알고있는 경우 효율이 좋다. | . EC2 Dedicated Hosts . | 전용 호스트 | 가장 비싼 옵션 | 라이선싱 모델과 함께 제공되는 소프트웨어인 경우, 규정이나 법규를 반드시 준수해야 하는 회사를 갖고있는경우 | . EC2 Dedicated Instance . | 전용 하드웨어에서 실행 | 같은 계정에서 다른 인스턴스와 함께 하드웨어를 공유 할 수 있다. | 인스턴스 배치에 대한 통제권은 없다 | . EC2 Capacity Reservations . | 용량 예약 | 원하는 기간동안 특정한 AZ에서 온디맨드 인스턴스를 예약할 수 있다. | 기간 약정이 없으며 언제라도 용량을 예약하고 취소 할 수 있다. | 사용하지 않더라도 요금이 부가된다. | 단기간이고 지속적으로 사용되야할때 사용 | . Availability Zone 가용 영역은 각각 고유한 식별자로 구분되며, 일반적으로 “us-east-1a”, “us-east-1b”와 같이 표현됩니다. 이렇게 각각의 가용 영역은 AWS 클라우드의 물리적 분리와 격리를 제공하여 고가용성 및 내결함성을 강화합니다. ",
    "url": "/docs/aws/02.%20EC2.html",
    
    "relUrl": "/docs/aws/02.%20EC2.html"
  },"13": {
    "doc": "02. 개략적인 규모 추정",
    "title": "02. 개략적인 규모 추정",
    "content": ". ",
    "url": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/02.%20%EA%B0%9C%EB%9E%B5%EC%A0%81%EC%9D%B8%20%EA%B7%9C%EB%AA%A8%20%EC%B6%94%EC%A0%95.html",
    
    "relUrl": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/02.%20%EA%B0%9C%EB%9E%B5%EC%A0%81%EC%9D%B8%20%EA%B7%9C%EB%AA%A8%20%EC%B6%94%EC%A0%95.html"
  },"14": {
    "doc": "02. 개략적인 규모 추정",
    "title": "2의 제곱수",
    "content": "분산 시스템에서 다루는 데이터 양은 엄청나게 커질 수 있으나 그 계산법은 기본을 크게 벗어나지 않는다. | 2의 x 제곱 | 근사치 | 이름 | 축약형 | . | 10 | 1천(thousand) | 1킬로바이트(Kilobyte) | 1KB | . | 20 | 1백만(million) | 1메가바이트(Megabyte) | 1MB | . | 30 | 10억(billion) | 1기가바이트(Gigabyte) | 1GB | . | 40 | 1조(trillion) | 1테라바이트(Terabyte) | 1TB | . | 50 | 1000조(quadrillion) | 1페타바이트(Petabyte) | 1PB | . ",
    "url": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/02.%20%EA%B0%9C%EB%9E%B5%EC%A0%81%EC%9D%B8%20%EA%B7%9C%EB%AA%A8%20%EC%B6%94%EC%A0%95.html#2%EC%9D%98-%EC%A0%9C%EA%B3%B1%EC%88%98",
    
    "relUrl": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/02.%20%EA%B0%9C%EB%9E%B5%EC%A0%81%EC%9D%B8%20%EA%B7%9C%EB%AA%A8%20%EC%B6%94%EC%A0%95.html#2의-제곱수"
  },"15": {
    "doc": "02. 개략적인 규모 추정",
    "title": "모든 프로그래머가 알아야 하는 응답지연 값",
    "content": "| 연산명 | 시간 | . | L1 캐시 참조 | 0.5ns | . | 분기 예측 오류(branch mispredict) | 5ns | . | L2 캐시 참조 | 7ns | . | 뮤텍스(mutex) 락/언락 | 100ns | . | 주 메모리 참조 | 100ns | . | Zippy로 1 KB 압축 | 10,000ns = 10us | . | 1Gbps 네트워크로2KB 전송 | 20,000ns = 20us | . | 메모리에서 1 MB 순차적으로 read | 250,000ns = 250us | . | 같은 데이터 센터 내에서의 메시지 왕복 지연시간 | 500,000ns = 500us | . | 디스크 탐색(seek) | 10,000,000ns = 10ms | . | 네트워크에서 1 MB 순차적으로 read | 10,000,000ns = 10ms | . | 디스크에서 1 MB 순차적으로 read | 30,000,000ns = 30ms | . | 한 패킷의 CA(캘리포니아)로부터 네덜란드까지의 왕복 지연시간 | 150,000,000ns = 150ms | . ns= nanosecond(나노초), us = microsecond(마이크로초), ms= millisecond(밀리초) 1나노초 = 109초 1마이크로초 = 106초 = 1,000나노초 1밀리초= 103초 = 1,000µs = 1,000,000ns . 이 수들을 알기 쉽게 시각화하기 위해, 한 구글 엔지니어가 개발한 도구가 있다. ![[Pasted image 20240802004450.png]] . 위 수치를 통해 알수있는것 . | 디스크 탐색은 가능한 피해야 한다. | 단순한 압축 알고리즘은 빠르다. | 데이터를 인터넷으로 전송하기 전에 가능하면 압축하라 | 데이터 센터는 보통 여러 지역에 분산되어 있고, 센터들 간에 데이터를 주고받는 데는 시간이 걸린다. | . ",
    "url": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/02.%20%EA%B0%9C%EB%9E%B5%EC%A0%81%EC%9D%B8%20%EA%B7%9C%EB%AA%A8%20%EC%B6%94%EC%A0%95.html#%EB%AA%A8%EB%93%A0-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EA%B0%80-%EC%95%8C%EC%95%84%EC%95%BC-%ED%95%98%EB%8A%94-%EC%9D%91%EB%8B%B5%EC%A7%80%EC%97%B0-%EA%B0%92",
    
    "relUrl": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/02.%20%EA%B0%9C%EB%9E%B5%EC%A0%81%EC%9D%B8%20%EA%B7%9C%EB%AA%A8%20%EC%B6%94%EC%A0%95.html#모든-프로그래머가-알아야-하는-응답지연-값"
  },"16": {
    "doc": "02. 개략적인 규모 추정",
    "title": "예제: 트위터 QPS와 저장소 요구량 추정",
    "content": "QPS는 Queries Per Second(초당 쿼리 수)의 약자이다. 트위터의 실제 성능이나 요구사항과는 아무 관계가 없다. 가정 . | 월간 능동 사용자는 3억명이다. | 50%의 사용자가 트위터를 매일 사용한다. | 평균적으로 각 사용자는 매일 2건의 트윗을 올린다. | 미디어를 포함하는 트윗은 10% 정도다. | 데이터는 5년간 보관된다. | . 추정 . | 일간 능동 사용자 = 3억 x 50% = 1.5억 | QPS = 1.5억 x 2트윗 / (24시간 x 60분 x 60초 ) = 3500 | 최대 QPS = 2 x QPS = 약 7000 | . 미디어 저장을 위한 저장소 요구량 . | 평균 트윗 크기 . | tweet_id에 64바이트 | 텍스트에 140바이트 | 미디어에 1MB | . | 미디어 저장소 요구량 : 1.5억 x 2 x 10% x 1MB = 30TB / 일 | 5년간 미디어를 보관하기 위한 저장소 요구량 : 30TB x 365 x 5 = 55PB | . ",
    "url": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/02.%20%EA%B0%9C%EB%9E%B5%EC%A0%81%EC%9D%B8%20%EA%B7%9C%EB%AA%A8%20%EC%B6%94%EC%A0%95.html#%EC%98%88%EC%A0%9C-%ED%8A%B8%EC%9C%84%ED%84%B0-qps%EC%99%80-%EC%A0%80%EC%9E%A5%EC%86%8C-%EC%9A%94%EA%B5%AC%EB%9F%89-%EC%B6%94%EC%A0%95",
    
    "relUrl": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/02.%20%EA%B0%9C%EB%9E%B5%EC%A0%81%EC%9D%B8%20%EA%B7%9C%EB%AA%A8%20%EC%B6%94%EC%A0%95.html#예제-트위터-qps와-저장소-요구량-추정"
  },"17": {
    "doc": "02. 객체지향 프로그래밍",
    "title": "02. 객체지향 프로그래밍",
    "content": ". 협력, 객체, 클래스 . 진정한 객체지향 패러다임으로의 전환은 클래스가 아닌 객체에 초점을 맞출 때에만 얻을 수 있다. 이를 위해서는 다음 두 가지에 집중해야 한다. | 어떤 클래스 필요한지 고민하기 전에 어떤 객체들이 필요한지 고민하라. | 객체를 독립적인 존재가 아니라 기능을 구현하기 위해 협력하는 공동체의 일원으로 봐야 한다. | . 도메인의 구조를 따르는 프로그램 구조 영화 애매 시스템의 목적은 영화를 좀 더 쉽고 빠르게 예매하려는 사용자의 문제를 해결하려는 것이다. 이처럼 문제를 해결하기 위해 사용자가 프로그램을 사용하는 분야를 도메인이라고 부른다. 객체지향 패러다임이 강력한 이유는 요구사항을 분석하는 초기 단계부터 프로그램을 구현하는 마지막 단계까지 객체라는 동일한 추상화 기법을 사용할 수 있기 때문이다. ![[Pasted image 20240525141257.png]] . ![[Pasted image 20240525142553.png]] . 클래스를 구현하거나 다른 개발자에 의해 개발된 클래스를 사용할 때 가장 중요한 것은 클래스의 경계를 구분 짓는 것이다. 클래스는 내부와 외부로 구분되며 훌륭한 클래스를 설계하기 위한 핵심은 어떤 부분을 외부에 공개하고 어떤 부분을 감출지를 결정하는 것이다. 클래스의 내부와 외부를 구분해야 하는 이유는 경계의 명확성이 객체의 자율성을 보장하기 때문이다. 자율적인 객체 객체는 상태와 행동을 함께 가지는 복합적이며, 자율적인 존재이다. 객체 내부에 대한 접근을 통제하는 이유는 객체를 자율적인 존재로 만들기 위해서다. 외부에서 접근 가능한 부분을 “퍼블릭 인터페이스” 라고 부른다. 내부에서만 접근 가능한 부분은 “구현” 이라고 부른다. 인터페이스와 구현의 분리 원칙은 훌륭한 객체지향 프로그램을 만들기 위해 따라야 하는 핵심 원칙이다. 프로그래머의 자유 프로그래머의 역할을 클래스 작성자와 클라이언트 프로그래머로 구분하는 것이 유용하다. 클라이언트 작성자는 새로운 데이터 타입을 프로그램에 추가하고, 클라이언트 프로그래머는 클래스 작성자가 추가한 데이터 타입을 사용한다. 클라이언트 프로그래머의 목표는 필요한 클래스들을 엮어서 애플리케이션을 빠르고 안정적으로 구축하는 것이다. 클래스 작성자는 클라이언트 프로그래머에게 필요한 부분만 공개하고 나머지는 꽁꽁 숨겨야 한다. 조직에서 이러는건 말도안되는데 이중 인격이 되어야하는걸까? . 협력하는 객체들의 공동체 ![[Pasted image 20240525144555.png]] 영화를 예매하기 위해 인스턴스들은 서로의 메서드를 호출하며 상호작용한다. 이처럼 시스템의 어떤 기능을 구현하기 위해 객체들 사이에 이뤄지는 상호작용을 협력이라고 부른다. 객체지향 프로그램을 작성할 때는 먼저 협력의 관점에서 어떤 객체가 필요한지를 결정하고, 객체들의 공통 상태와 행위를 구현하기 위해 클래스를 작성한다. 영화 가격 계산에 참여하는 모든 클래스 사이의 관계를 다이어그램으로 표현한 것이다. ![[Pasted image 20240525144752.png]] DiscountPolicy 안에 중복 코드를 두고 Amount, Percent클래스가 이 클래스를 상속 받는다. 실제 애플리케이션에서 DiscountPolicy의 인스턴스를 생성할 필요가 없기 때문에 추상클래스로 구현한다. DiscountPolicy는 할인 여부와 요금 계산에 필요한 전체적인 흐름은 정의하지만 실제로 요금을 계산하는 부분은 추상 메서드인 getDiscountAmount 메서드에게 위임한다. /* 많은 사람들이 오버라이딩(overriding)과 오버로딩(overloading)의 개념을 혼동한다. 오버라이딩은 부모 클래스에 정의된 같은 이름, 같은 파라미터 목록을 가진 메서드를 자식 클래스에서 재정의하는 경우를 가리킨다. 오버로딩은 메서드의 이름은 같지만 제공되는 파라미터의 목록이 다르다. 다음은 오버로딩의 예를 나타낸 것이다. */ public class Money { public Money plus (Money amount) { return new Money(this.amount.add (amount.amount)); ｝ public Money plus(long amount) { return new Money(this.amount.add(BigDecimal.valueOf (amount))); } ｝ . 할인 정책 구성하기 하나의 영화에 대해 하나의 할인 정책만 설정할 수 있지만, 할인 조건의 경우에는 여러 개를 적용할 수 있다. DiscountPolicy의 생성자는 이런 제약을 강제한다. Movie의 생성자는 오직 하나의 DiscountPolicy 인스턴스만 받을 수 있도록 선언돼 있다. public abstract class DiscountPolicy { public DiscountPolicy (DiscountCondition ... conditions) { this.conditions = Arrays.asList(conditions); } } . #### 추상 클래스(Abstract Class) 사용 시기 1. 공통된 상태를 가질 때: - 여러 클래스가 공통된 속성(필드)을 가져야 할 때, 추상 클래스에서 이러한 필드를 정의하고 상속받는 클래스에서 사용할 수 있습니다. 2. 상속받은 클래스에서 기본 동작을 재사용할 때: - 추상 클래스는 구현된 메서드를 가질 수 있기 때문에, 공통된 기본 동작을 상속받는 클래스들에서 재사용할 수 있습니다. 3. is-a 관계가 명확할 때: - 클래스들 간의 명확한 상속 관계가 있을 때, 추상 클래스가 적합합니다. 4. 생성자와 비정적 초기화 블록이 필요할 때: - 추상 클래스는 생성자와 비정적 초기화 블록을 가질 수 있습니다. #### 인터페이스(Interface) 사용 시기 1. 다중 상속이 필요할 때: - Java는 다중 상속을 허용하지 않지만, 인터페이스를 통해 여러 인터페이스를 구현할 수 있습니다. 2. 행위(behavior)를 정의할 때: - 인터페이스는 클래스들이 수행해야 하는 행위를 정의할 때 적합합니다. 3. 구현 상속이 필요 없을 때: - 인터페이스는 상태(필드)를 가질 수 없고, 오직 상수와 추상 메서드(그리고 Java 8 이후부터는 디폴트 메서드와 static 메서드)를 가질 수 있습니다. 상태를 공유할 필요가 없을 때 사용합니다. 4. 기능 확장이 필요할 때: - Java 8 이후부터 인터페이스는 디폴트 메서드를 지원하여, 기존 구현에 영향을 주지 않고 새로운 메서드를 추가할 수 있습니다. 비정적 초기화 블록(Instance Initialization Block) 1. 정의: 비정적 초기화 블록은 중괄호 `{}` 안에 작성된 코드 블록으로, 객체가 생성될 때 실행됩니다. 2. 구문: 비정적 초기화 블록은 클래스 내에 직접 정의되며, 명시적인 이름이 없습니다. 3. 호출: 객체가 생성될 때마다 생성자 호출 전에 자동으로 실행됩니다. 여러 개의 비정적 초기화 블록이 있는 경우, 정의된 순서대로 실행됩니다. 4. 목적: 여러 생성자에서 공통적으로 실행해야 하는 초기화 코드가 있을 때 유용합니다. 이 블록을 사용하면 코드 중복을 줄일 수 있습니다. 5. 매개변수: 비정적 초기화 블록은 매개변수를 가질 수 없습니다. 상속과 다형성 . ![[Pasted image 20240525220805.png]] 설계가 유연해질수록 코드를 이해하고 디버깅하기는 점점 더 어려워진다. 반면 유연성을 억제하면 코드를 이해하고 디버깅하기는 쉬워지지만 재사용성과 확장성은 낮아진다. 훌륭한 객체지향 설계자로 성장하기 위해서는 항상 유연성과 가독성 사이에서 고민해야 한다. 무조껀 유연한 설계도, 읽기 쉬운 코드도 정답이 아니다. 차이에 의한 프로그래밍 . 클래스를 하나 추가하고싶은데 그 클래스가 기존의 어떤 클래스와 매우 흡사하다고 가정해보자. 그 클래스의 코드를 가져와 약간만 추가하거나 수정해서 새로운 클래스를 만들 수 있다면 좋을 것이다. 더 좋은 방법은 클래스의 코드를 전혀 수정하지 않고도 재사용하는 것일 것이다. 이를 가능하게 하는것이 상속이다. 상속과 인터페이스 . 상속이 가치 있는 이유는 부모 클래스가 제공하는 모든 인터페이스를 자식 클래스가 물려받을 수 있기 때문이다. 인터페이스는 객체가 이해할 수 있는 메시지의 목록을 정의한다는 것을 기억하자. 상속을 통해 자식 클래스는 자신의 인터페이스에 부모 클래스의 인터페이스를 포함하게 된다. 결과적으로 외부 객체는 자식 클래스를 부모 클래스와 동일한 타입으로 간주할 수 있다. 자식 클래스가 부모 클래스를 대신하는 것을 업캐스팅이라고 부른다. 다형성 . 다시 한번 강조하지만 메시지와 메서드는 다른 개념이다. Movie와 협력하는 객체가 AmountDiscountPolicy 라면 AmountDiscountPolicy에서 오버라이딩한 메서드가 실행될 것이다. PercentDiscountPolicy가 연결된 경우에는 PercentDiscountPolicy에서 오버라이딩한 메서드가 실행될 것이다. 이처럼 동일한 메시지를 전송하지만 실제로 어떤 메서드가 실행될 것인지는 메시지를 수신하는 객체의 클래스가 무엇이냐에 따라 달라진다. 이를 다형성이라 부른다. 인터페이스와 다형성 . ![[Pasted image 20240525220739.png]] 종종 구현은 공유할 필요가 없고 순수하게 인터페이스만 공유하고 싶을 때가 있다. 추상 클래스를 이용해 다형성을 구현했던 할인 정책과 달리 할인 조건은 구현을 공유할 필요가 없기 때문에 자바의 인터페이스 타입 계층을 구현했다. 추상화의 힘 . 추상화의 첫 번째 장점은 추상화의 계층만 따로 떼어 놓고 살펴보면 요구사항의 정책을 높은 수준에서 서술할 수 있다는 것이다. 두 번째 장점은 추상화를 이용하면 설계가 좀 더 유연해진다는 것이다. 새로운 자식 클래스들은 추상화를 이용해서 정의한 상위의 협력 흐름을 그대로 따르게 된다. 이 개념은 매우 중요한데, 재사용 가능한 설계의 기본을 이루는 디자인 패턴이나 프레임워크 모두 추상화를 이용해 상위 정책을 정의하는 객체지향의 메커니즘을 활용하고 있기 때문이다. 추상화를 이용해 상위 정책을 표현하면 기존 구조를 수정하지 않고도 새로운 기능을 쉽게 추가하고 확장할 수 있다. ![[Pasted image 20240525222520.png]] . 추상 클래스와 인터페이스 트레이드 오프 . ![[Pasted image 20240525223306.png]] 이상적으로는 인터페이스를 사용하도록 변경한 설계가 더 좋을 것이다. 현실적으로는 NoneDiscountPolicy만을 위해 인터페이스를 추가하는 것이 과하다는 생각이 들 수도 있을 것이다. 어쨋든 변경 전의 NoneDiscountPolicy 클래스 역시 할인 금액이 0원이라는 사실을 효과적으로 전달하기 때문이다. 이 책에서는 설명을 단순화하기 위해 인터페이스를 사용하지 않는 원래의 설계에 기반해서 설명을 이어갈 것이다. 여기서 이야기하고 싶은 사실은 구현과 관련된 모든 것들이 트레이드오프의 대상이 될 수 있다는 사실이다. 모든 코드에는 합당한 이유가 있어야 한다. 코드 재사용 . 상속은 코드를 재사용하기 위해 널리 사용되는 방법이다. 널리 사용되는 방법이라고 해서 가장 좋은 방법인 것은 아니다.코드 재사용을 위해서는 상속보다는 합성이 더 좋은 방법이라는 이야기를 많이 들었을 것이다. 합성은 다른 객체의 인스턴스를 자신의 인스턴스 변수로 포함해서 재사용하는 방법을 말한다. 상속 . ![[Pasted image 20240525223908.png]] 상속은 두 가지 관점에서 설계에 안좋은 영향을 미친다. 하나는 상속이 캡슐화를 위반한다는 것이고, 다른 하나는 설계를 유연하지 못하게 만든다는 것이다. 상속의 가장 큰 문제는 캡슐화를 위반한다는 것이다. 상속을 이용하기 위해서는 부모 클래스의 내부 구조를 잘 알고있어야 한다. 결과적으로 부모 클래스의 구현이 자식 클래스에게 노출되기 때문에 캡슐화가 약화된다. 강하게 결합되기 때문에 부모 클래스를 변경할 때 자식 클래스도 함께 변경될 확률을 높인다. 결과적으로 상속은 코드를 변경하기 어려워진다. 합성 . 상속과 다른 점은 상속이 부모 클래스의 코드와 자식 클래스의 코드를 컴파일 시점에 하나의 단위로 강하게 결합하는 데 비해 인터페이스를 통해 약하게 결합된다는 것이다. 실제로 Movie는 DiscountPolicy가 외부에 CalculateDiscountAmount 메서드를 제공한다는 사실만 알고 내부 구현에 대해서는 전혀 알지 못한다. 이처럼 인터페이스에 정의된 메시지를 통해서만 코드를 재사용하는 방법을 합성이라고 한다. 합성은 상속이 가지는 두가지 문제점을 모두 해결한다. 그렇다고 해서 상속을 절대 사용하지 말라는 것은 아니다. 대부분의 설계에서는 상속과 합성을 함께 사용해야 한다. ",
    "url": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/02.%20%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%20%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D.html",
    
    "relUrl": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/02.%20%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%20%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D.html"
  },"18": {
    "doc": "02. 구글 엔지니어는 어떻게 일할까",
    "title": "2장",
    "content": ". 내 코드를 숨기고 싶어요 . 사람들은 자신이 진행 중인 작업물을 다른 사람이 보고 판단하는걸 두려워합니다. 너두? . 어쩌면 이런 두렴움은 인간의 본성에 속할 것입니다. 누구라도 비난받고 싶어 하지 않으며, 작업물이 완성되기 전이라면 더욱 그렇습니다. 불안감은 사실 . 더 큰 문제의 징후입니다. 전체 신화 . 파이썬 창시자 귀도 반 로섬 . 파이썬은 온전히 귀도 반 로섬의 작품일까요? 그가 첫 번째 버전을 작성한 건 사실입니다. 하지만 그 후 버전들은 수천 명의 사람이 아이디어를 모으고 기능을 개발하고 버그를 수정하며 만들었습니다. 인간은 본능적으로 리더와 롤모델을 찾고, 그들을 우상화하고 흉내 내려 합니다. 내면 깊숙한 곳에서 많은 엔지니어가 자신이 천재로 비치기를 원합니다. 저자의 친구가 실제로 한 말 “다른 사람들이 아직 완성되지 않은 내 코드를 보는건 진짜 겁이나. 그걸 진지하게 보고 내가 바보라고 생각할 것 같아” . 이는 프로그래머들이 느끼는 매우 일반적인 감정이라서 자연스럽게 동굴에 숨어 일하고 일하고 다듬고 또 다듬습니다. 숨기는 건 해롭다 . 만약 여러분이 오롯이 홀로 일한다면 실패할 위험성을 불필요하게 키우고 자신의 설장 잠재력을 속이는 것입니다. 자신이 올바른 길을 걷고 있음을 어떻게 확인할 수있을까요? . 조기 감지 . 아이디어를 세상으로부터 숨기고 완벽히 다듬어질 때까지 아무도 들여다보지 못하게 하는건 엄청난 도박입니다. 피드백을 조기에 받을수록 위험이 크게 줄어듭니다. 공유는 ‘버스 지수’를 높여주기도 합니다. 버스 지수 . 몇 명의 팀원이 버스에 치어서 일을 할 수 없게 될 때 프로젝트가 망하게 되는지 나타내는 지수 . 여러분의 프로젝트에는 필요 지식과 노하우가 얼마나 분산되어 있나요? 원리를 아는사람이 나뿐이라면 내가 해고될 가능성은 극히 낮습니다. 하지만 내가 버스에 치인다면 프로젝트는 아마 망할 것입니다. 혼자 일하게 되면 버스 지수 외에 전반적인 진행 속도도 해롭습니다. 혼자 일한다는 것은 고된 싸움이며 사람들의 기대보다 훨씬 느리다는 점을 잊기 쉽습니다. 혼자 일하면서 얼마나 많이 배울 수 있을까요? 진척도는? 스택 오버플로로도 다양한 견해를 얻을 수있지만 직접 체득한 경험을 대체할 수는 없습니다. 혼자 잘못된 길로 접어들었다가 뒤늦게 깨닫고 빠져나오는데 수많은 시간을 낭비한 경험이 있을것입니다. 어깨 너머로 살펴보다가 잘못된 점을 즉시 짚어주고 해법을 알려줄 동료가 두어 명만 있더라도 그 경험이 얼마나 달라졌을지 상상해보세요 . 결론은, 숨기지 말자 . 여러분의 천금 같은 시간을 낭비할 가능성을 더 걱정해야 합니다. 엔지니어링은 팀의 단합된 노력입니다. 다른사람과 함께 일해야 합니다. 비전을 공유하세요. 역할을 나누세요. 다른 이로부터 배우세요. 멋진 팀을 만드세요. 모든건 팀에 달렸다 . 사회적 상호작용 세 기둥 . | 겸손 : 당신의 코드는 우주의 중심이 아닙니다. 당신이 모든 것을 알지도 완벽하지도 않습니다. | 존중 : 함께 일하는 동료를 진심으로 생각합니다. 친절하게 대하고 그들의 능력과 성취에 감사해합니다. | 신뢰 : 동료들이 유능하고 올바른 일을 하리라 믿습니다. 필요하다면 그들에게 스스로 방향을 정하게 해도 좋습니다. | . 자존심 버리기 . 비평하고 비평받는 배우기 . 빠르게 실패하고 반복하기 . 구글에서는 ‘실패는 선택이다’ 라는 말이 있습니다. ‘가끔씩 실패하지 않는다면 충분히 혁신적이지 않거나 위험을 충분히 감수하지 않은 것이다.’라는 믿음이 널리 통용됩니다. 실패를 ‘배우고 다음 단계로 넘어갈 . 수있는 절호의 기회’라고 생각하는 것이죠. 비난 없는 포스트모템 문화 . 프로젝트를 마친 후 전 과정을 되돌아보며 잘된 점과 잘못된 점을 되돌아 보는 사후 검토 작업 . 포스트 모템 문서가 쓸모 없는 사죄, 변명, 지적으로 채워지지 않도록 각별히 주의하세요. 제대로 된 포스트모템에는 무엇을 배웠는지와 배운 것을 토대로 앞으로 무엇을 바꿀지가 담겨야합니다. 인내심을 기르자 . 팀원과의 개발 방식을 존중하고 맞지 않는다면 인내심을 잃지 않고 새로운 협업 방식을 찾아내야합니다. 마음을 열고 받아들이자 . 배우는데 열려 있을수록 여러분의 영향력도 커집니다. 주변 사람들이 아무리 설득해봐도 고집을 굽히지 않는 사람이 껴 있는 팀을 상상해보세요. [[03. 구글 엔지니어는 어떻게 일할까]] . ",
    "url": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/02.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html#2%EC%9E%A5",
    
    "relUrl": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/02.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html#2장"
  },"19": {
    "doc": "02. 구글 엔지니어는 어떻게 일할까",
    "title": "02. 구글 엔지니어는 어떻게 일할까",
    "content": " ",
    "url": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/02.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html",
    
    "relUrl": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/02.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html"
  },"20": {
    "doc": "03. EC2 - associate level",
    "title": "03. EC2 - associate level",
    "content": ". 공용 ip - 인터넷 전역에 액세스 사설 ip - 사설 네트우크 내에서만 액세스 . 공용 ip는 전체 웹에서 유일한 것 ip로 지리적 위치를 찾을 수 있다. 사설 ip는 오직 사설 네트워크 안에서만 식별 될 수 있다. 따라서 사설 네트워크 안에서만 유일 . 탄력적 ip - ec2인스턴스를 시작하고 중지할때 공용 ip를 바꿀 수 있다. 고정된 공용 ip를 사용하려면 탄력적 ip가 필요하다? . 계정당 탄력적ip를 5개만 쓸 수 있다. 결론적으로 탄력적 ip는 사용하지 않는 것이 좋다. -&gt; 좋지않은 구조 대신 DNS를 할당한다. 탄련적 ip 주소를 가지고 있는데 사용하지 않으면 요금이 부과된다. ",
    "url": "/docs/aws/03.%20EC2%20-%20associate%20level.html",
    
    "relUrl": "/docs/aws/03.%20EC2%20-%20associate%20level.html"
  },"21": {
    "doc": "03. EC2 - associate level",
    "title": "배치 그룹",
    "content": "ec2 인스턴스가 aws 인프라에 배치되는 방식을 제어할때 사용 . | 클러스터 배치 그룹 . | 같은 하드웨어 랙, 동일 가용 영역 | 단일 가용 영역 내에서 지연 시간이 짧은 하드웨어 설정 | 단점 . | 하드웨어에 실패가 발생하면 모든 인스턴스에 영향 | . | . | 분산 배치 그룹 . | 모든 인스턴스가 다른 하드웨어에 분산 | 여러 가용 영역에 걸쳐 있을 수 있다. | 크리티컬 애플리케이션이 있는 경우 분산 배치그룹사용 | 단점 . | 배치 그룹당 가용 영역당 7개의 인스턴스만 가질 수 있다 (배치 그룹 규모에 제한이 있) | . | . | 분할 배치 그룹 . | 여러 파티션에 인스턴스가 분할 되어있다. | 가용 영역당 최대 7개의 파티션이 있을 수 있다. | 각 파티션은 aws의 랙을 나타낸다. | 이 파티션은 가용 영역 내의 다양한 하드웨어 랙 세트에 의존한다. | 랙 실패로부터 보다 안전 | 최대 수백개의 ec2 인스턴스 설정 가능 | 빅데이터 애플리케이션에 적합 | 메타 데이터를 통해 파티션과의 연결고리 파악 | . | . Q 배치그룹 설정 안하면 어케댐? A 배치 그룹을 명시적으로 설정하지 않으면 해당 인스턴스는 기본적으로 기본 배치 그룹에 속하게 되므로 별도의 설정이 필요하지 않습니다. 기본 배치 그룹의 주요 특징과 제한사항은 다음과 같습니다 제한 없음: 기본 배치 그룹은 특정한 제한이나 규칙이 없이 EC2 인스턴스를 시작할 수 있는 그룹입니다. 가용 영역 간 분산 불가능: 기본 배치 그룹은 여러 가용 영역 간에 인스턴스를 분산시키는 것이 불가능합니다. 한 가용 영역에 속한 여러 인스턴스 간에는 분산될 수 있지만, 다른 가용 영역에 있는 인스턴스와는 분산되지 않습니다. 미국 동부 (Northern Virginia) 리전은 여러 가용 영역 (예: us-east-1a, us-east-1b, us-east-1c 등)이 있음. 동일 하드웨어에 인스턴스 배치: 같은 기본 배치 그룹에 속한 인스턴스들은 동일한 하드웨어에 배치됩니다. 이는 성능 최적화와 관련이 있습니다. ",
    "url": "/docs/aws/03.%20EC2%20-%20associate%20level.html#%EB%B0%B0%EC%B9%98-%EA%B7%B8%EB%A3%B9",
    
    "relUrl": "/docs/aws/03.%20EC2%20-%20associate%20level.html#배치-그룹"
  },"22": {
    "doc": "03. EC2 - associate level",
    "title": "탄력적 네트워크 (ENI)",
    "content": "eni는 ec2가 네트워크에 연결할 수 있도록 도와줌 . 주요 사설 IPv4 하나 이상의 보조 IPv4를 가질 수 있다 . eni는 사설 및 공용 ip가 한개씩 제공된다. eni에 하나 이상의 보안 그룹을 연결할 수 있다. 인스턴스와 독립적으로 eni를 생성하고 즉시 연결하거나 장애 조치를 위해 ec2 인스턴스에 이동시킬 수 있다. eni는 가용영역에 바인딩 된다. A인스턴스에 문제가 발생했을때 . B인스턴스로 보조ip를 옮겨서 A인스턴스 장애 조치를 할 수 있다. eni를 연결한 인스턴스를 “종료”하게되면 직접만든 eni는 남고 인스턴스가 실행될때 자동으로 만들어진 eni만 삭제된다 . ",
    "url": "/docs/aws/03.%20EC2%20-%20associate%20level.html#%ED%83%84%EB%A0%A5%EC%A0%81-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-eni",
    
    "relUrl": "/docs/aws/03.%20EC2%20-%20associate%20level.html#탄력적-네트워크-eni"
  },"23": {
    "doc": "03. EC2 - associate level",
    "title": "Hibernate (절전모드)",
    "content": "ec2가 절전모드에 들어가게 되면 ram에 있던 인메모리 상태는 그대로 보존 -&gt; 부팅이 빠르다는 말 . 절전 모드를 사용하면 aws의 인스턴스 상태는 stop으로 뜨지만 운영체제는 꺼진것으로 인식하지않는다. ec2가 절전 모드에 들어가면 ebs(Elastic Block Store)볼륨에 ram의 내용이 암호회되어 덤프된다. 그리고 인스턴스가 종료되면 ram이 사라진다 인스턴스를 다시 실행시키면 ebs에서 불러와 ram에 다시 적재한다 . 사용 예제 . | 오래 실행되는 프로세스를 갖고 있고 중지하지 않을때 | RAM 상태를 저장하고싶을떄 | 빠르게 재부팅하고싶을때 | . 인스턴스의 최대 RAM크기는 150GB EBS볼륨에만 저장 할 수 있으며 암호화가 되어야한다 모든 인스턴스에 사용 가능 최대 60일까지 절전모드 가능 . 절전모드를 사용하면 ebs를 사용하는지 용량은 충분한지, 암호화를 사용하는지 여부를 잘 확인해야한다. Q 안했으면 어쩔껀데? 비용청구 및 보안에 취약하다는듯하다 . ",
    "url": "/docs/aws/03.%20EC2%20-%20associate%20level.html#hibernate-%EC%A0%88%EC%A0%84%EB%AA%A8%EB%93%9C",
    
    "relUrl": "/docs/aws/03.%20EC2%20-%20associate%20level.html#hibernate-절전모드"
  },"24": {
    "doc": "03. 구글 엔지니어는 어떻게 일할까",
    "title": "3장",
    "content": ". ",
    "url": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/03.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html#3%EC%9E%A5",
    
    "relUrl": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/03.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html#3장"
  },"25": {
    "doc": "03. 구글 엔지니어는 어떻게 일할까",
    "title": "성장하는 조직 이끌기",
    "content": " ",
    "url": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/03.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html#%EC%84%B1%EC%9E%A5%ED%95%98%EB%8A%94-%EC%A1%B0%EC%A7%81-%EC%9D%B4%EB%81%8C%EA%B8%B0",
    
    "relUrl": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/03.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html#성장하는-조직-이끌기"
  },"26": {
    "doc": "03. 구글 엔지니어는 어떻게 일할까",
    "title": "늘 결정하라",
    "content": "핵심 트레이드 오프 파악하기 . 정의상 중요하고 모호한 문제에는 마법같은 ‘은총알’이 없습니다. 세상이 끝날 때까지 어떤 상황에서든 옳은 답이란 없습니다. ‘특정 상황에서의 최선의 답’이 있을뿐, 그마저도 거의 언제나 몇 가지 면에서는 절충을 해야합니다. 모든 트레이드오프를 테이블 위에 올려놓고 모두에게 설명한 다음 어떻게 균형을 맞출지를 결정하도록 돕는 것이 여러분의 일입니다. 결정하고 반복하기 . 어떤 트레이드오프가 존재하고 어떻게 작용하는지를 이해하고 나면 여러분의 힘이 커집니다. 그리고 다음 달이 되면 트레이드오프들을 다시 평가하고 균형점도 새로 잡아야합니다. 바로 ‘늘 결정하라’라고 부르는 이유입니다. ",
    "url": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/03.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html#%EB%8A%98-%EA%B2%B0%EC%A0%95%ED%95%98%EB%9D%BC",
    
    "relUrl": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/03.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html#늘-결정하라"
  },"27": {
    "doc": "03. 구글 엔지니어는 어떻게 일할까",
    "title": "늘 떠나라",
    "content": "팀원이 아플 수도 있고, 다른 팀이나 회사로 떠날 수있고, 먼 곳으로 이사 갈 수도 있습니다. 여러분이 단일 장애점인지 확인해 볼 수 있는 테스트가 있습니다. 여러분이 어디론가 사라진다면, 팀이 여전히 순항할까요? . 그렇지 않았다면 여러분은 스스로를 단일 장애점으로 만든 것 입니다. 그렇다면 고쳐야죠. 제가 잘못했습니다..! . 자율 주행 팀을 만들어라 . 문제 공간 분할하기 . 하위 문제를 다른 리더에게 위임하기 . 모든 관리 책에서 빼놓지 않고 이야기하는 주제가 ‘위임’입니다. 위임을 배우기란 정말 어렵기 때문입니다. 왜일까요? “무언가를 제대로 하고싶다면 스스로 하라”라는 말이 있듯 효율성과 성취 측면에서 우리의 본능에 정면으로 배치하기 때문입니다. 과제를 던져준 후, 실패하고 다시 시도하고 또 도전하도록 놔두세요. ‘빠르게 실패하고 반복하라’. 실리콘 밸리에서 통용되는 격언입니다. 정말 시급한 문제가 아니라면 꾹 참고 다른 이에게 맡기세요. 조율하고 반복하기 . 팀 정체성 설정 시 주의점 . ",
    "url": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/03.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html#%EB%8A%98-%EB%96%A0%EB%82%98%EB%9D%BC",
    
    "relUrl": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/03.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html#늘-떠나라"
  },"28": {
    "doc": "03. 구글 엔지니어는 어떻게 일할까",
    "title": "늘 확장하라",
    "content": "성공 사이클 . | 분석 : 문제가 주어지고 해결하기 위한 씨름을 시작합니다. 모든 트레이드오프를 찾아 관리 방안을 합의합니다. | 분투 : 팀이 준비가 덜 되었다고 생각하더라도 일에 착수합니다. 실패할 경우에도 대비해야 합니다. 실패하면 다시 시도하고 또 반복합니다. 부하 리더들과 현장 전문가들의 의견을 개진하도록 분위기를 조성하고 경청, 전력을 고안해야 합니다. | 견인 : 문제 정복 시작 | 보상 : 성공을 축하 (문제가 풀리지 않았는데) &amp;. 새로운 문제 | . 인력 충원은 없으니 인원을 절반으로 나누어 절반의 시간을 할애하는 압축 단계에 들어섭니다. 새로운 문제를 정복하고 압축하는 방법을 찾아낸 다음 또 다른 문제를 배정받아 반복하는 식으로 말입니다. 중요한 일 vs 급한 일 . 리더가 되면 마치 소방관 같다고 느껴졌을 것입니다. 능동형 일보다는 상황에 맞춰 대응하는 반응형 일의 비중이 커지기 때문입니다. 이메일, 채팅방, 회의 같은 모든 소통 경로로부터 서비스 거부 공격이 들어와 여러분의 시간과 집중력을 고갈시키려들 것입니다. 실제로도 자칫하다가는 여러분에게 주어진 시간 100%가 반응형 모드로 허비됩니다. 맞아요. 조급함은 리더인 여러분의 효율을 갉아먹는 가장 큰 적입니다. 스스로를 완전한 반응형 모드로 전황해버리면 삶 전체의 순간순간을 오로지 ‘급한’ 일만 처리하면서 흘려보내게 됩니다. 멀리 보면 중요하지 않은 일들임에도 말이죠. 그렇다면 급한 일이 아니라 중요한 일에 더 몰두하려면 어떻게 해야할까요? . | 위임하자 : 죄책감, 효율을 생각하지말고, 다른 사람 다른 리더가 처리하기에 좋은 훈련 수단이 될 수 있습니다. | 따로 정기적으로 시간을 내자 : 정기적으로 2시간 이상씩 방해받지 않고 중요한 일을 처리하는 시간을 마련 | 나에게 효과가 있는 추적 시스템을 마련하자 : 작업에 우선순위를 매기고 진행 상황을 추적하는 다양한 방법을 활용합니다. (불렛 저널 방법과 같은) | . 공 떨어뜨리기 . 공을 자꾸 놓치다 보면 주늑이 들어 죄책감에 빠지기 쉽습니다. 이쯤에서 한 걸음 물러나 상황을 냉정하게 관찰해보죠. 어차피 공 몇 개는 떨어뜨릴 수밖에 없다면 ‘실수로’보다는 ‘의도적으로’떨어뜨리는게 낫지 않을까요? 그렇다면 최소한 어느 정도로의 통제력을 유지할 수있으니까요 . 인생이 빛나는 정리의 마법 (곤도)- 더난출판사 2012 3층선반이 있을때 가장 아래 20% : 쓸모없는 물건 중간 60% : 중요할 수도 아닐 수도한 물건 가장 위 20% : 소중한 나머지 물건 곤도는 ‘진짜 정리’를 가장아래 20%칸이 아닌 가장위 20%칸에 무엇을 둘지 골라내는 것이라고 주장합니다. 정말 중요한 물건만 추리고 나머지 80%를 버려야합니다. 에너지 관리하기 . | 진짜 휴가 떠나기 : 주말은 휴가가 아닙니다 | 일과 쉽게 단절하기 : 일에서 신경을 끄려거든 업무용 랩톱은 회사에 두고 떠나세요. | 진짜 주말 보내기 | 매일매일 휴식하기 | 스스로에게 정신 건강의 날을 가질 수 있는 권한 부여하기 : 여러분이 내뿝는 어두운 기운이 주변 모두의 분위기를 가라앉게 하고 떄로는 끔찍한 결정으로 이어지기도 합니다. | . 마치며 . 두 배로 열심히 일한다고 해서 훌륭한 리더가 아닙니다. 대신 늘 결정하고, 늘 떠나고, 늘 확장하도록 노력하기 바랍니다. ",
    "url": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/03.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html#%EB%8A%98-%ED%99%95%EC%9E%A5%ED%95%98%EB%9D%BC",
    
    "relUrl": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/03.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html#늘-확장하라"
  },"29": {
    "doc": "03. 구글 엔지니어는 어떻게 일할까",
    "title": "03. 구글 엔지니어는 어떻게 일할까",
    "content": " ",
    "url": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/03.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html",
    
    "relUrl": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/03.%20%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C.html"
  },"30": {
    "doc": "03. 역할, 책임, 협력",
    "title": "03. 역할, 책임, 협력",
    "content": ". 객체지향 패러다임의 관점에서 핵심은 역할, 책임, 협력이다. 클래스, 상속, 지연 바인딩이 중요하지 않은 것은 아니지만 객체지향 패러다임의 본질과는 거리가 멀다. ![[Pasted image 20240525225331.png]] . 협력 . 두 객체 사이의 협력은 하나의 객체가 다른 객체에게 도움을 요청할 때 시작된다. 메시지 전송은 객체 사이의 협력을 위해 사용할 수 있는 유일한 커뮤니케이션 수단이다. 객체는 다른 객체의 상세한 내부 구현에 직접 접근할 수 없기 때문에 오직 메시지 전송을 통해서만 자신의 요청을 전달할 수 있다. 협력이 설계를 위한 문맥을 결정한다. 애플리케이션 안에 어떤 객체가 필요하다면 그 이유는 단 하나여야 한다. 그 객체가 어떤 협력에 참여하고 있기 떄문이다. 그리고 객체가 협력에 참여할 수 있는 이유는 협력에 필요한 적절한 행동을 보유하고 있기 때문이다. 상태는 객체가 행동하는 데 필요한 정보에 의해 결정되고 행동은 협력 안에서 객체가 처리할 메시지로 결정된다. 결과적으로 객체가 참여하는 협력이 객체를 구성하는 행동과 상태 모두를 결정한다. 따라서 협력은 객체를 설계하는 데 필요한 일종의 문맥을 제공한다. 책임이란 무엇인가 . 크레이그 라만은 객체의 책임은 크게 하는것, 아는것 두가지 범주로 나누어 세분화하고있다 . | 하는것 . | 객체를 생성하거나 계산을 수행하는 등의 스스로 하는것 | 다른 객체의 행동을 시작시키는 것 | 다른 객체의 활동을 제어하고 조절하는것 | . | 아는것 . | 사적인 정보에 관해 아는것 | 관련된 객체에 관해 아는 것 | 자신이 유도하거나 계산할 수 있는 것에 관해 아는 것 | . | . 영화 애매 시스템에서 Screening의 책임은 영화를 예매하는 것이다. 또한 자신이 상영할 영화를 알고 있어야 한다. movie의 책임은 요금을 계산하는 것이다. 또한 가격과 어떤 할인 정책이 적용됐는지도 알고 있어야 한다. ![[Pasted image 20240526121705.png]] . 객체에게 책임을 할당하기 위해서는 먼저 협력이라는 문맥을 정의해야 한다. 협력을 설계하는 출발점은 시스템이 사용자에게 제공하는 기능을 시스템이 담당할 하나의 책임으로 바라보는 것이다. 영화 시스템을 예로 시스템이 사용자에게 제공해야 할 기능은 영화를 예매하는 것이고 이 기능을 시스템이 제공할 책임으로 할당할 것이다. 객체가 책임을 수행하는 유일한 방법은 메시지를 전송하는 것이므로 예매하라 라는 이름의 메시지로 협력을 시작하다. 메시지를 선택했으면 처리할 적절한 객체를 선택해야한다. 영화 애매를 예로는 영화 예매와 관련된 정보를 가장 많이 알고있는 객체에게 책임을 할당하는 것이 바람직하다. (Screening) . 영화 예매를 위해서는 가격을 계산해야 한다. Screening은 예매에 대해서는 잘 알지라도 가격에 대해서는 잘 모른다. 가격을 계산하기 위해서는 가격과 할인 정책이 필요하다. 이 모든 정보를 알고 있는 객체는 Movie이다. 가격과 계산의 책임을 Movie에 할당한다. 이와 같이 책임 중심으로 설계하는 방법을 책임 주도 설계라고 한다. 아래는 앞의 설계 방법의 과정을 정리한 것이다. | 시스템이 사용자에게 제공해야 하는 기능인 시스템 책임을 파악한다 | 시스템 책임을 더 작은 책임으로 분할한다 | 분할된 책임을 수행할 수 있는 적절한 객체 또는 역할을 찾아 책임을 할당한다. | 객체가 책임을 수행하는 도중 다른 객체의 도움이 필요한 경우 이를 책임질 적절한 객체 또는 역할을 찾는다. | 해당 객체 또는 역할에게 책임을 할당함으로써 두 객체가 협력하게 한다. | . 그럼 순서가 객체 먼저 만들고, 메시지 선정하고, 메시지를 만든다? . 메시지가 객체를 결정한다 . 객체에게 책임을 할당하는 데 필요한 메시지를 먼저 식별하고 메시지를 처리할 객체를 나중에 선택했다는 것이 중요하다. 메시지가 객체를 선택하게 해야 하는 두 가지 중요한 이유가 있다. | 객체가 최소한의 인터페이스를 가질 수 있게된다. | 필요한 메시지가 식별될 때까지 객체의 퍼블릭 인터페이스에 어떤 것도 추가하지 않기 때문에 객체는 애플리케이션에 크지도, 작지도 않은 꼭 필요한 크기의 프벌릭 인터페이스를 가질 수 있다. | . | 객체는 충분히 추상적인 인터페이스를 가질 수 있게 된다. | . 행동이 상태를 결정한다 . 쉽게 빠질 수 있는 실수는 객체의 행동이 아니라 상태에 초점을 맞추는 것이다. 필요한 상태가 무엇인지를 결정하고 그 후에 상태에 필요한 행동을 결정한다. 이러한 방식은 객체의 내부 구현이 객체의 퍼블릭 인터페이스에 노출되도록 만들기 때문에 캡슐화를 저해한다. 객체의 내부 구현을 변경하면 퍼블릭 인터페이스도 함께 변경되고, 결국 객체에 의존하는 클라이언트로 변경의 영향이 전파된다. 상태는 객체가 행동을 정상적으로 수행하기 위해 필요한 재료일 뿐이다. 역할과 협력 . 영화 예매 협력에서 예매하라는 메시지를 처리하기에 적합학 객체로 Screening을 선택했다. 하나의 단계처럼 보이는 이 책임 할당 과정은 실제로 두 개의 독립적인 단계가 합쳐지 것이다. 첫 번째 단계는 영화를 예매할 수 있는 적절한 역할이 무엇인가를 찾는 것이고, 두 번째 단계는 역할을 수행할 객체로 Screening 인스턴스를 선택하는 것이다. 어떤 이유로 역할이라는 개념을 이용해서 설계 과정을 더 번거롭게 만드는 것일까? 역할이 없어도 객체만으로 충분히 협력을 설계할 수 있는 것 아닐까? . 유연하고 재사용 가능한 협력 . 역할이 중요한 이유는 역할을 통해 유연하고 재사용 가능한 협력을 얻을 수 있기 때문이다. ![[Pasted image 20240526125148.png]] ![[Pasted image 20240526125201.png]] . 영화 예매 도메인에는 금액 할인 정책과 비율 할인 정책이라는 두 가지 종류의 가격 할인 정책이 존재 하기 때문에 AmountDiscountPolicy 인스턴스와 PercentDiscountPolicy 인스턴스라는 두 가지 종류의 객 체가 할인 요금을 계산하라 메시지에 응답할 수 있어야 한다. 그렇다면 두 종류의 객체가 참여하는 협력을 개별적으로 만들어야 할까? . 안타깝게도 이런 방법으로 두 협력을 구현하면 대부분의 코드가 중복되고 말 것이다. 프로그래밍에서 코드 중복은 모든 문제의 근원이기 때문에 이런 방법은 피해야 한다. 문제를 해결하기 위해서는 객체가 아닌 책임에 초점을 맞춰야 한다. ![[Pasted image 20240526231309.png]] . 요점은 동일한 책임을 수행하는 역할을 기반으로 두 개의 협력을 하나로 통합할 수 있다는 것이다. 따라서 역할을 이용하면 불필요한 중복 코드를 제거할 수 있다. 객체 대 역할 . 역할은 객체가 참여할 수 있는 일종의 슬롯이다. 오직 한 종류의 객체만 협력에 참여하는 상황에서 역할이라는 개념을 고려하는 것이 유용할까? 협력에 참여하는 후보가 여러 종류의 객체에 의해 수행될 필요가 있다면 그 후보는 역할이 되지만 단지 한 종류의 객체만이 협력에 참여할 필요가 있다면 후보는 객체가 된다. ![[Pasted image 20240526234523.png]] . 역할과 추상화 . 추상화를 이용한 설계가 가질 수 있는 두 가지 장점은 추상화 계층만을 이용하면 중요한 정책을 상위 수준에서 단순화할 수 있다는것과 설계가 좀 더 유연해진다는것이 있다. 역할은 책임을 바탕으로 객체의 종류를 숨기기 때문에 이런 관점에서 역할을 객체의 추상화로 볼 수 있다. ![[Pasted image 20240526234927.png]] . 협력이라는 관점에서는 세부적인 사항을 무시하고 추상화에 집중하는 것이 유용하다. 요금 계산에서 세부 사항은 할인 정책과 할인 조건의 종류다. 따라서 세부사항을 무시하고 DiscountPolicy와 DiscountCondition만 바라보면 상황을 추상화할 수 있다. ![[Pasted image 20240527002655.png]] ![[Pasted image 20240527002956.png]] 객체에게 중요한 것은 행동이다. 역할이 중요한 이유는 동일한 협력을 수행하는 개체들을 추상화할 수 있기 때문이다. 배우와 배역 . 연극이 시작되면 연극에 참여하는 그 순간만큼은 배우들은 사라지고 배역만 남는다. 무대의 막이 내리면 배역은 사라지고 본래의 배우로 돌아오게 된다. 역극의 배역과 배우 간의 관계에 대해 다음과 같은 특성이 존재한다. | 배역은 연극 배우가 특정 연극에서 연기하는 역할이다. | 배역은 연극이 상영되는 동안에만 존재하는 일시적인 개념이다 | 연극이 끝나면 연극 배우는 배역이라는 역할을 벗어 버리고 원래의 연극 배우로 돌아온다 | 서로 다른 배우들이 동일한 배역을 연기할 수 있다. | 하나의 배우가 다양한 연극 안에서 서로 다른 배역을 연길할 수 있다. | . 연극 안에서 배역을 연기하는 배우라는 은유는 협력 안에서 역할을 수행하는 객체라는 관점을 담아낸다. 협력이라는 문맥 안에서 역할은 특정한 협력에 참여해서 책임을 수행하는 객체의 일부다. 역할은 페르소나이다. ",
    "url": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/03.%20%EC%97%AD%ED%95%A0,%20%EC%B1%85%EC%9E%84,%20%ED%98%91%EB%A0%A5.html",
    
    "relUrl": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/03.%20%EC%97%AD%ED%95%A0,%20%EC%B1%85%EC%9E%84,%20%ED%98%91%EB%A0%A5.html"
  },"31": {
    "doc": "04. EC2 - EBS",
    "title": "04. EC2 - EBS",
    "content": ". EBS (Elastic Block Store) 인스턴스가 실행중인 동안 연결 가능한 네트워크 드라이브 . 인스턴스가 종료된 이후에도 데이터 유지 가능 . CCP레벨의 EBS볼륨은 하나의 EBS는 하나의 EC2 인스턴스에만 마운트 가능 . 또한 EBS 볼륨을 생성할때는 특정 가용 역역에서만 사용 가능 스냅샷을 이용하면 다른 가용 영역으로도 볼륨을 옮길 수 있다 . CCP 레벨 : 하나의 EBS는 하나의 EC2 인스턴스에만 마운트 가능 / 어소시에이트 레벨: 일부 EBS 다중 연결 . EBS볼륨은 꼭 인스턴스에 연결되야하지는 않다 . 기본적으로 인스턴스 종료시 삭제 옵션이 활성화 되어있다. EBS 스냅샷 기능 . EBS Snapshot Archive . | 최대75%할인 | 아카이브를 복원하는데 최대 24시간에서 72시간 | . EBS Bin for EBS Snapshot . | Snapshot을 영구 삭제하는 대신 휴지통에 넣을 수 있다 | 실수로 삭제하는 경우 휴지통에서 복원 가능 | 휴지통 보관 기간은 1일에서 1년 사이 | . Fas Snapshot Restore . | 스냅샷을 완전 초기화해 첫 사용에서의 지연 시간을 없애는 기능 | 스냅샷의 크기가 크거나 EC2 인스턴스를 빠르게 초기화해야 할 때 유용하다 | 비용이 많이든다 | . AMI (Amazon Machine Image) . | EC2 인스턴스를 통해 만든 이미지 통칭 | A Public AMI : AWS에서 지원 | Your own AMI : 본인이 만든 | An AWS Marketplace AMI : 다른사람이 만든 . | 기업에서 본인의 소프트웨어까지 넣어두고 판매 | . | . 설정을 어디까지 따주는거임? . EC2 Instance Store . 인스턴스를 담고있는 물리적 하드웨어 드라이브 . 성능은 좋지만 인스턴스를 중지,종료하면 해당 스토리지는 손실된 . 버퍼, 캐시, 스크래치 데이터 또는 임시 콘텐츠를 사용하려는 경우에 사용 . 장기적인 스토리지는 EBS가 맞음 . EC2 인스턴스 스토리지에 데이터를 저장하려면 날아갈 우려가 있으므로 백업해둬야한다 . 성능이 아주 뛰어난 하드웨어가 연결된 경우 EC2 인스턴스 스토어를 생각해야한다? . EBS 볼륨 유형 . 총 6가지 . | gp2/gp3 . | 범용 | . | io1/io2 . | 성능좋은 | . | st1 . | 저비용 | 잦은 접근과 처리량 | . | sc1 . | 가장 비용이 적게드는 HDD 볼륨 | 접근 빈도가 낮은 워크로드를 위해 | . | . IOPS 초당 I/O 작업 수 . EC2에서는 gp2/gp3 io1/io2만이 부팅 볼륨으로 사용될 수 있다. 시험에는 gp2와 IOPS 프로비저닝이 가장 중요하다 . gp2는 짧은 지연시간, 시스템 부팅 볼륨, 가상 데스크톱, 개발, 테스트 환경에서 사용할 수 있다 . 크기는 1GB에서 16TB까지 다양하다 . gp2 gp3차이 . | gp3 . | 최신 세대의 볼륨 | 기본 성능으로 3,000 IOPS 초당 125MB | IOPS는 16,000 1,000MB 까지 증가시킬 수 있다 | . | gp2 . | 볼륨이 더 작음 | IOPS가 볼륨과 연결되어있어 더 큰 볼륨을 사용해야 IOPS를 늘릴 수 있다. | . | . IOPS 성능을 유지할 필요가 있는 주요 어플리케이션이나 데이터베이스에서는 gp2/gp3 또는 io1/io2를 사용하는게 좋다 . io1/io2 . | 4GB ~ 16TB | Nitro EC2 인스턴스에서는 최대 64,000 IOPS까지 가능 아닌경우 32,000 | io1/io2 는 gp3와 같이 독자적으로 IOPS를 증가시킬 수 있다 | io1/io2 중 무조껀 io2를 사용하는게 좋다. 동일한 비용으로 내구성과 기기당 IOPS의 수가 더 높다 | io2 . | 지연시간이 밀리세컨 이하 | IOPS 대 GB 비율이 1,000:1일때 최대 256,000 IOPS | . | . 프로비저닝이란? 프로비저닝은 서버, 애플리케이션, 네트워크 구성, 스토리지, 엣지 기기 등을 배포하는 과정에서 초기 단계에 해당합니다. st1, sc1 . | HDD | 최대 16TB . | st1 . | 빅데이터나 데이터 웨어하우징 로그처리에 적합 | 최대 처리량은 초당 500MB IOPS 최대 500 | . | sc1 . | 아카이브 데이터용 | 집근 빈도가 낮은 데이터에 사용 | 최저 비용으로 데이터 저장 | 250MB IOPS 250 | . | . | . 다중연결 EBS . | 여러 EC2 인스턴스에 연결 | o1/io2만 사용 가능 | 각 인스턴스는 고성능 볼륨에 대한 읽기 및 쓰기 권한을 전부 갖는다 | 한 AZ에서 다른 AZ로 EBS 연결은 불가능 | 한번에 16개의 EC2인스턴스만 가능 | 반드시 클러스터 인식 파일 시스템을 사용해야한다 XFS, EX4와는 다름 | . EBS 암호화 . 암호화는 인스턴스 - 볼륨 전송데이터, 볼륨 ,스냅샷, 스냅샷으로 생성된 볼륨 모두에 동시다발적으로 발생 . 암호화는 지연시간에는 영향이 거의 없다 . KMS를 통한 암호화 . 암호화 되지 않은 EBS 암호화 하는방법 EBS를 스냅샷 생성시점에 암호화 설정을 한다 암호화 된 스냅샷을 볼륨으로 생성한다 볼륨은 암호화된 스냅샷을 기준으로 했기때문에 자동으로 암호화가 설정되어있다. EFS (Elastic FIle System) . 관리형 NFS이다 (네트워크 파일 시스템) . 많은 EC2 인스턴스에 마운트 될 수 있다 . 서로 다른 가용영역도 가능 . 가용성이 높고 확장성이 뛰어나며 비싸다. gp2 EBS 볼륨의 약 3배 . 사용량에 따라 비용을 지뷸하므로 용량을 설정할 필요가 없다 . 사용사례 . | 콘텐츠관리 | 웹 서빙 | 데이터 공유 | Wordpress | . 내부적으로 NFS 프로토콜을 사용하며 EFS에 대한 액세스를 제어하려면 보안 그룹을 성정해야한다 . 윈도우가 아닌 Linux 기반의 AMI와만 호환된다 . EBS(탄력적 블록 저장소)와 EFS(탄력적 파일 시스템)는 AWS에서 제공하는 스토리지 서비스입니다. EBS는 블록 수준 저장소이고 EFS는 파일 수준 저장소입니다. | EFS 스케일은 동시에 NFS 클라이언트 수천개와 10GB이상의 처리량 | PB 규모의 네트워크 파일 시스템으로 자동 확장할 수 있다. | 성능 모드를 설정할 수 있다. | 범용 - 지연 시간에 민감한 웹서버나 CMS | 최대 I/O - 처치량 최대화 지연시간이 더 긴, 병렬성이 높음, 빅데이터 또는 미디어 처리가 필요한경우 | . | 처리량 모드 . | busting - 1TB, 초당 50MiB ~ 100MiB 버스트 | Provisioned - 스토리지 크기 관계없이 처리량을 설정하고싶은경우 1TB, 1GiB를 처리 | Elastic - 워크로드에 따라 처리량을 자동 조절 읽기는 3GiB, 쓰기는 1GiB | . | . Storage Classes . | Storage Tiers . | 며칠 후 파일을 다른 계층으로 옮길 수 있는 기능 . | 표준 계층은 자주 액세스하는 파일을 위한 계층이다 | 자주 액세스하지 않는 계층은 EFS-IA인데, 이 계층에서 파일을 검색할 경우 비용이 발생한다. | 하지만 EFS-IA에 저장하면 비용이 감소된다. | EFS-IA를 사용하려면 수명 주기 정책을 사용해야한다 | . | . | . ",
    "url": "/docs/aws/04.%20EC2%20-%20EBS.html",
    
    "relUrl": "/docs/aws/04.%20EC2%20-%20EBS.html"
  },"32": {
    "doc": "04. Real MySQL 8.0",
    "title": "4장",
    "content": ". ",
    "url": "/docs/mysql/04.%20Real%20MySQL%208.0.html#4%EC%9E%A5",
    
    "relUrl": "/docs/mysql/04.%20Real%20MySQL%208.0.html#4장"
  },"33": {
    "doc": "04. Real MySQL 8.0",
    "title": "MySQL 엔진 아키텍처",
    "content": "| ![[C613C2B1-91A0-4A2F-B8C5-D66870866BED_1_201_a.jpeg | 400]] | . MySQL은 일반 사용 RDBMS와 같이 대부분의 프로그래밍 언어로부터 접근 방법을 모두 지원한다. MySQL 서버는 크게 MySQL엔진과 스토리지 엔진으로 구분할 수 있다. MySQL 엔진 : 사람의 머리 역할 스토리지 엔진 : 손발 역할 . MySQL 엔진 . MySQL 엔진은 클라이언트로부터의 접속 및 쿼리 요청을 처리하는 커넥션 핸들러와 SQL 파서 . 및전처리기, 쿼리의 최적화된 실행을 위한 옵티마이저가 중심을 이룬다 . 스토리지 엔진 . 실제 데이터를 디스크 스토리지에 저장하거나 디스크 스토리지로부터 데이터를 읽어오는 부분은 스토리지 엔진이 전담한다. MySQL 엔진은 하나지만 스토리지 엔진은 여러 개를 동시에 사용할 수 있다. CREATE TABLE test_table (fd1 INT, fd2 INT) ENGGINE=INNODB; . 위 예제에서 test_table은 InnoDB 스토리지 엔진을 사용하도록 정의한 것이다. 스토리지 엔진은 핸들러 API를 만족하면 누구든지 스토리지 엔진을 구현해서 MySQL 서버에 추가해서 사용할 수 있다. 핸들러 API . SHOW GLOBAL STATUS LIKE 'Handler%'; . | ![[Pasted image 20240414140846.png | 400]] | . 이 핸들러 API를 통해 얼마나 많은 데이터(레코드) 작업이 있었는지 위의 명령어로 확인할 수 있다. ![[C34B9B6D-E798-4C02-9C97-A49CB3D999C8_1_201_a.jpeg|400]] MySQL 서버는 프로세스 기반이 아니라 스레드 기반으로 작동하며, 크게 Foreground 스레드와 Background 스레드로 구분할 수 있다. MySQL 서버에서 실행 중인 스레드의 목록은 다음과 같이 performance_schema 데이터베이스의 threads테이블을 통해 확인할 수 있다. SELECT THREAD_ID, NAME, THREAD_ID, PROCESSLIST_HOST FROM performance_schema.threads ORDER BY TYPE, THREAD_ID . 백그라운드 스레드의 개수는 MySQL 서버의 설정 내용에 따라 가변적일 수 있다. 동일한 이름의 스레드가 2개 이상씩 보이는것은 MySQL 서버의 설정 내용에 의해 여러 스레드가 동일 작업을 병렬로 처리하는 경우다. foreground thread (클라이언트 스레드) . foreground thread는 최소한의 MySQL 서버에 접속된 클라이언트의 수만큼 존재하며, 주로 각클라이언트 사용자가 요청하는 쿼리 문장을 처리한다. 클라이언트 사용자가 작업을 마치고 커넥션을 종료하면 해당 커넥션을 담당하는 스레드는 다시 스레드 캐시로 되돌아간다. 스레드 캐시는 일정 갯수를 유지하며 갯수를 넘어간경우 그냥 종료시킨다. 최대 스레드 개수는 thread_cache_size 시스템 변수로 설정한다. 포그라운드 스레드는 데이터를 MySQL의 데이터 버퍼나 캐시로부터 가져오며, 버퍼나 캐시에 없는 경우에는 직접 디스크의 데이터나 인덱스 파일로부터 데이터를 읽어와서 작업을 처리한다. InnoDB를 사용할 경우 데이터 버퍼나 캐시까지만 포그라운드 스레드가 처리하고, 나머지 버퍼로부터 디스크까지 기록하는 작업은 백그라운드 스레드가 처리한다. MyISAM InnoDB와 같은 스토리지 엔진으로 책에서 설명이 나오지만, 최근 버전의 MySQL에서는 InnoDB가 기본 저장 엔진으로 설정되어 있으며, InnoDB는 트랜잭션 처리와 외래 키 제약 조건을 지원하여 데이터의 무결성을 더 잘 보장합니다. 따라서 MyISAM의 언급은 제외하겠습니다. background thread (백그라운드 스레드) . InnoDB는 다음과 같이 여러 가지 작업이 백그라운드로 처리된다. | Insert Buffer를 병합하는 스레드 | 로그를 디스크로 기록하는 스레드 | InnoDB 버퍼 풀의 데이터를 디스크에 기록하는 스레드 | 데이터를 버퍼로 읽어 오는 스레드 | 잠금이나 데드락을 모니터링하는 스레드 | . innodb_write_io_threads와 innodb_read_io_threads 시스템 변수로 스레드의 개수를 정할 수 있다. \bInnodb에서 데이터를 읽는 작업은 주로 클라이언트 스레드에서 처리되기 때문에 읽기 스레드는 많이 설정할 필요가 없지만 쓰기 스레드는 아주 많은 작업을 백그라운드로 처리하기 때문에 일반적인 내장 디스크를 사용할 때는 2~4 정도 . DAS나 SAN과 같은 스토리지를 사용할 때는 디스크를 최적으로 사용할 수 있을만큼 충분히 설정하는것이 좋다 . DAS와 SAN은 서버와 스토리지 시스템 간의 연결 방식을 나타내는 용어입니다. 1. DAS (Direct-Attached Storage): DAS는 직접 연결된 스토리지로, 서버와 스토리지 장치가 직접 연결되어 있는 구성을 말합니다. 일반적으로 서버에 내장된 디스크, 외부 디스크 배열 또는 스토리지 장치를 의미합니다. DAS는 서버와의 직접 연결로 인해 낮은 지연 시간과 높은 대역폭을 제공할 수 있습니다. 그러나 DAS는 하나의 서버에만 연결되어 있으므로 확장성이 제한적입니다. 2. SAN (Storage Area Network): SAN은 네트워크를 통해 여러 대의 서버와 여러 개의 스토리지 장치를 연결하는 스토리지 아키텍처입니다. SAN은 일반적으로 광 케이블이나 전기 케이블을 사용하여 서버와 스토리지 장치를 연결하며, 스토리지 리소스를 논리적으로 풀링하여 여러 서버에서 공유할 수 있습니다. SAN을 사용하면 데이터 공유, 효율적인 용량 활용, 장애 허용성, 백업 및 복구 등 다양한 기능을 제공할 수 있습니다. 메모리 할당 및 사용 구조 . ![[Pasted image 20240414145423.png|400]] MySQL에서 사용되는 메모리 공간은 크게 글로벌 메모리 영역과 로컬(세션) 메모리 영역으로 구분할 수 있다. 글로벌 메모리 영역 . 일반적으로 클라이언트 스레드의 수와 무관하게 하나의 메모리 공간만 할당한다. 단, 필요에 따라 2개 이상의 메모리 공간을 할당받을 수도 있지만 클라이언트 스레드 수와는 무관하다. 생성된 글로벌 영역이 N개라 하더라도 모든 스레드에 의해 공유된다. 로컬 메모리 영역 . 세션 메모리 영역이라고도 표현한다. MySQL서버상에 존재하는 클라이언트 스레드가 쿼리를 처리하는 데 사용하는 메모리 영역이다. MySQL서버에 접속하면 MySQL서버에서는 클라이언트 커넥션으로부터의 요청을 처리하기 위해 스레드를 하나씩 할당한다. 클라이언트 스레드가 사용하는 메모리 공간이라고 해서 클라이언트 메모리 영역이라고도 한다. 로컬 메모리는 스레드별로 독립적으로 할당되며 절대 공유되어 사용되지 않는다. 일반적으로 글로벌 메모리 영역의 크기는 주의해서 설정하지만 로컬 메모리 영역은 그렇지않다. 이럴 경우 희박한 가능성으로 MySQL서버가 메모리 부족으로 멈춰버릴 수도 있다. 로컬 메모리 영역은 필요할때만 공간이 할당된다. 버퍼에 따라 커넥션을 연결이 끊긴후 또는 쿼리 실행후 공간을 해제한다. 플러그인 스토리지 엔진 모델 . ![[Pasted image 20240414154444.png|400]] MySQL의 독특한 구조 중 대표적인 것이 바로 플러그인 모델이다. 전문 검색 엔진 을 위한 검색어 파서도 플러그인 형태로 개발해서 사용할 수 있다. ![[Pasted image 20240414154512.png]] MySQL에서 쿼리가 실행되는 과정은 위 그림과 같다. 거의 대부분의 작업이 MySQL 엔진에서 처리되고, 마지막에 ‘읽기/쓰기’ 작업만 스토리지 엔진에 의해 처리된다. MySQL 엔진이 각 스토리지 엔진에게 데이터를 읽어오거나 저장하도록 명령하려면 반드시 핸들러를 통해야 한다는 점을 기억하자. 하나의 쿼리는 여러 하위 작업으로 나뉘는데, 각 하위 작업이 MySQL 엔진 영역에서 처리되는지 아니면 스토리지 영역에서 처리되는지 구분할 줄 알아야한다. 컴포넌트 . MySQL 서버의 플러그인은 몇가지 단점이 있는데, 컴포넌트는 이러한 담점을 보완해서 구현했다. | 플러그인은 오직 MySQL 서버와 인터페이스할 수 있고, 플러그인끼리는 통신할 수 없음 | 플러그인은 MySQL 서버의 변수나 함수를 직접 호출하기 때문에 안전하지 않음(캡슐화 불가능) | 플러그인은 상호 의존 관계를 설정할 수 없어서 초기화가 어려움 | . 쿼리 실행 구조 . ![[Pasted image 20240414160015.png|400]] . 쿼리 파서 . 사용자 요청으로 들어온 쿼리 문장을 토큰으로 분리해 트리 형태의 구조로 만들어내는 작업을 의미한다. 쿼리 기본 문법 오류는 이 과정에서 발견되고 사용자에게 오류 메시지가 전달된다. 전처리기 . 쿼리문장에 구조적인 문제점이 있는지 확인한다. 각 토큰을 테이블 이름이나 칼럼 이름 또는 내장 함수와 같은 개체를 매핑해 해당 객체의 존재 여부와 객체 접근의 접근 권한 등을 확인하는 과정을 이 단계에서 수행한다. 옵티마이저 . 쿼리 문장을 저렴한 비용으로 가장 빠르게 처리할지를 결정하는 역할을 담당한다. 이 책에서는 옵티마이저가 선택하는 내용을 설명하고, 어떻게 하면 옵티마이저가 더 나은 선택을 할 수 있게 유도하는 가를 알려줄 것이다. 실행 엔진 . (쿼리 실행기) 실행 엔진의 역할은 아래와 같다. 옵티마이저가 GROUP BY를 처리하기 위해 임시 테이블을 사용하기로 결정했다고 해보자. | 실행 엔진이 핸들러에게 임시 테이블을 만들라고 요청 | 다시 실행 엔진은 WHERE절에 일치하는 레코드를 읽어오라고 핸들러에게 요청 | 읽어온 레코드들은 1번에서 준비한 임시 테이블로 저장하라고 다시 핸들러에게 요청 | 데이터가 준비된 임시 테이블에서 필요한 방식으로 데이터를 읽어 오라고 핸들러에게 다시 요청 | 최종적으로 실행 엔진은 결과를 사용자나 다른 모듈로 넘김 | . 핸들러 (스토리지 엔진) . 핸들러는 결국 스토리지 엔진을 의미한다. 실행 엔진의 요청에 따라 데이터를 디스크로 저장하고 디스크로부터 읽어오는 역할을 한다. 쿼리 캐시 . SQL의 실행 결과를 메모리에 캐시하고, 동일 SQL 쿼리가 실행되면 테이블을 읽지 않고 즉시 결과를 반환하기 때문에 매우 빠른 성능을 보인다. 하지만 쿼리 캐시는 테이블의 데이터가 변경되면 캐시에 저장된 결과 중에서 변경된 테이블과 관련된 것들은 모두 삭제해야 했다. 이는 심각한 동시 처리 성능 저하를 유발한다. 결국 쿼리 캐시는 MySQL 서버의 기능에서 완전히 제거되었다. 스레드 풀 . MySQL 서버 엔터프라이즈 에디션은 스레드 풀을 지원하지만 커뮤니티 에디션은 스레드 풀 기능을 지원하지 않는다. 스레드 풀을 적용한다고해서 눈에 띄는 성능 향상을 보여준 경우는 드물다. CPU시간을 제대로 확보하지 못하는 경우에는 쿼리 처리가 더 느려지는 사례도 발생할 수 있다. 적절히 처리한다면 불필요한 컨텍스트 스위치를 줄여 오버헤드를 낮출 수 있다. 일반적으로 CPU코어의 갯수와 맞추는 것이 CPU프로세서 친화도를 높이는데 좋다. 스레드 그룹의 모든 스레드가 일을 처리하고있다면, . | 새로운 작업 스레드 추가 | 기존 스레드 완료 대기 판단을 해야한다. 스레드 풀의 타이머 스레드는 주기적으로 스레드 그룹의 상태를 체크해서 thread_pool_stall_limit 시스템 변수에 정의된 밀리초만큼 작업 스레드가 지금 처리 중인 작업을 끝내지 못하면 새로운 스레드를 생성해서 스레드 그룹에 추가한다. 전체 스레드 풀에 있는 스레드의 갯수는 thread_pool_max_threads 시스템 변수에 설정된 갯수를 넘어설 수 없다. thread_pool_stall_limit을 0에 가까운 수로 설정할거라면 스레드 풀을 사용하지 않는것이 좋다. | . 우선순위 쿠를 이용해 작업 순서를 바꿀 수 있다. 트랜잭션 지원 메타데이터 . 데이터베이스 서버에서 테이블의 구조 정보와 스토어드 프로그램 등의 정보를 데이터 딕셔너리 또는 메타데이터라고 한다. MySQL 8.0 버전부터는 테이블의 구조 정보나 스토어드 프로그램의 코드 관련 정보를 모두 InnoDB의 테이블에 저장하도록 개선됐다. MySQL서버가 작동하는데 기본적으로 필요한 테이블들을 묶어서 시스템 테이블이라고 하는데, 대표적으로 사용자의 인증과 권한에 관련된 테이블이 있다. 시스템 테이블과 딕셔너리 정보를 모두 모아서 mysql DB에 저장하고 있다. mysql DB는 통째로 mysql.idb라는 이름의 테이블스페이스에 저장된다. *.idb파일을 다룰때는 특별히 주의해야한다. InnoDB 스토리지 엔진 아키텍처 . | ![[Pasted image 20240418222057.png | 400]] | . 프라이머리 키에 의한 클러스터링 . InnoDB의 모든 테이블은 기본적으로 프라이머리 키를 기준으로 클러스터링되어 저장된다. 모든 세컨더리 인덱스는 레코드의 주소 대신 프라이머리 키의 값을 논리적인 주소로 사용한다. ??? . 프라이머리 키를 기준으로 클러스터링 되기 때문에 프라이머리 키를 이용한 레인지 스캔은 상당히 빨리 처리될 수 있다. 외래 키 지원 . 외래 키에 대한 지원은 InnoDB 스토리지 엔진 레벨에서 지원하는 기능이다. (MyISAM, MEMORY테이블에서는 불가능) . 외래 키는 데이터베이스 서버 운영의 불편함 때문에 서비스용 데이터베이스에서는 생성하지 않는 경우도 자주 있는데, 그렇다 하더라도 개발 환경의 데이터베이스에서는 좋은 가이드 역할을 할 수 있다. InnoDB에서 외래 키는 부모 테이블과 자식 테이블 모두 해당 컬럼에 인덱스 생성이 필요하고, 변경 시에는 반드시 부모 테이블이나 자식 테이블에 데이터가 있는지 체크하는 작업이 필요하므로 잠금이 여러 테이블로 전파되고, 그로 인해 데드락이 발생할 때가 많으므로 개발할때도 외래 키의 존재에 주의하는것이 좋다. 부모 테이블과 자식 테이블의 관계를 명확히 파악해서 순서대로 작업한다면 문제없이 실행할 수 있지만 외래 키가 복잡하게 얽힌 경우에는 그렇게 간단하지 않다. 급한 경우에는 foreign_key_checks 시스템 변수를 OFF로 설정하면 외래 키 관계에 대한 체크 작업을 일시적으로 멈출 수 있다. foreign_key_checks가 비활성화 되면 외래키 관계의 부모 테이블에 대한 작업(ON DELETE CASCADE와 UPDATE CASCADE 옵션)도 무시된다. MVCC (Multi Version COncurrency Control) . 일반적으로 레코드 레벨의 트랜잭션을 지원하는 DBMS가 제공하는 기능이다. 가장 큰 목적은 잠금을 사용하지 않는 일관된 읽기를 제공하는 데 있다. InnoDB는 언두 로그(undo log)를 이용해 이기능을 구현한다. 멀티 버전이라 함은 하나의 레코드에 대해 여러 개의 버전이 동시에 관리된다는 의미이다. CREATE TABLE member ( m_id INT NOT NULL. m_name VARCHAR(20) NOT NULL, m_area VARCHAR(100) NOT NULL, PRIMARY KEY (m_id), INDEX ix_area (m_area) ); INSERT INTO member (m_id, m_name, m_area) VALUES (12, '김민수', '서울'); COMMIT; . ![[Pasted image 20240418223535.png|400]] INSERT문이 실행되면 데이터베이스의 상태는 위 그림과 같은 상태로 바뀔 것이다. UPDATE member SET m_area='경기' WHERE m_id=12; . ![[Pasted image 20240418223701.png|400]] UPDATE문장이 실행되면 커밋 실행 여부와 관계없이 InnoDB의 버퍼 풀은 새로운 값인 ‘경기’로 업데이트된다. 아직 COMMIT이나 ROLLBACK이 되지 않은 상태에서 다른 사용자가 . SELECT * FROM member WHERE m_id=12; . 쿼리로 작업중인 레코드를 조회하면 어디에 있는 데이터를 조회할까? . 이 질문의 답은 시스템 변수 transaction_isolation에 설정된 격리 수준에 따라 다르다. READ_UNCOMMITTED InnoDB 버퍼 풀이 현재 가지고 있는 변경된 데이터를 읽어서 반환한다. READ_COMMITTED, REPEATABLE_READ, SERIALIZABLE 아직 커밋되지 않았기 때문에 InnoDB 버퍼 풀이나 데이터 파일에 있는 내용 대신 변경되지 이전의 내용을 보관하고 있는 언두 영역의 데이터를 반환한다. 잠금 없는 읽관된 읽기 (Non-Locking Consistent Read) . InnoDB 스토리지 엔진은 MVCC 기술을 이용해 잠금을 걸지 않고 읽기 작업을 수행한다. SERIALIZABLE이 아닌 READ_UNCOMMITTED, READ_COMMITTED, REPEATABLE_READ수준인 경우 INSERT와 연결되지 않은 순수한 읽기 작업은 다른 트랜잭션의 변경 작업과 관계없이 항상 잠금을 대기하지 않고 바로 실행된다. ![[Pasted image 20240418224628.png|400]] . 오랜시간 트랜잭션이 활성되어있다면, 이러한 일관된 읽기를 위해 언두 로그를 삭제하지 못하고 계속 유지해야하기 때문에 성능 저하가 발생할 수 있다. 가능한 빠르게 롤백이나 커밋을 통해 트랜잭션을 완료 하는것이 좋다. 자동 데드락 감지 . InnoDB 스토리지 엔진은 데드락 감지 스레드를 가지고 있어서 데드락 감지 스레드가 주기적으로 잠금 대기 그래프를 검사해 교착 상태에 빠진 트랙잭션들을 찾아서 그중 하나를 강제 종료한다. 어느 트랜잭션을 먼저 강제 종료할 것인지를 판단하는 기준은 트랜잭션의 언두 로그 양이며, 언두 로그 레코드를 더적게 가진 트랜잭션이 일반적으로 롤백의 대상이 된다. (롤백 코스트 때문) . InnoDB 스토리지 엔진은 상위 레이어인 MySQL엔진에서 관리되는 테이블 잠금은 볼 수가 없어서 데드락 감지가 불확실할 . 수있다. innodb_table_locks시스템 변수를 활성화하면 InnoDB 스토리지 엔진 내부의 레코드 잠금뿐만 아니라 테이블 레벨의 잠금까지 감지할 수 있다. 특별한 이유가 없다면 활성화 하는게 좋다. 동시 처리 스레드가 많은경우 데드락 감지 스레드가 느려진다. 데드락 감지 스레드는 잠금 목록을 검서해야 하기 때문에 잠금 상태가 변경되지 않도록 잠금 목록이 저장된 리스트에 새로운 잠금을 걸고 데드락 스레드를 찾게 된다. 이로인해 서비스를 처리하고 있는 스레드는 작업을 진행하지 못하고 대기하면서 서비스에 악영향을 미친다. 이를 위해 innodb_deadlock_detect 시스템 변수를 제공하며, innodb_deadlock_detect를 OFF로 설정하면 데드락 스레드는 작동하지 않는다. 대신 데드락이 발생하면 무한정 대기하게 될 것이다. 하지만 innodb_lock_timeout시스템 변수를 활성화 하면 일정 시간 이후 실패와 함께 메시지를 반환시킬 수 있다. innodb_lock_timeout는 초 단위로 설정 할 수 있다. 데드락 감지 스레드가 비활성 되어 있다면 50초 미만으로 사용할 것을 권장한다. 자동화된 장애 복구 . InnoDB에는 손실이나 장애로부터 데이터를 보호하기 위한 여러가지 메커니즘이 탑재돼 있다. MySQL 서버가 시작될 때 완료되지 못한 트랜잭션이나 디스크에 일부만 기록된 데이터 페이지 등에 대한 일련의 복구 작업이 자동으로 진행된다. InnoDB는 매우 견고한데, MySQL서버와 무관하게 디스크나 서버 하드웨어 이슈로 복구를 못할 수 있다. 이때 데이터를 가능한 만큼 백업하고 그 데이터로 복구해야 한다. InnoDB는 innodb_force_recovery 옵션을 1부터 6까지 설정하여 손상의 정도를 파악할 수 있다. 값이 커질수록 손상의 정도가 크다. InnoDB 버퍼 풀 . innoDB 스토리지 엔진에서 가장 핵심적인 부분이다. 디스크의 데이터 파일이나 인덱스 정보를 메모리에 캐시해 두는 공간이다. 쓰기 작업을 지연시켜 일괄 작업으로 처리할 수 있게 해주는 버퍼 역할도 같이한다. 일반적인 애플리케이션에서는 INSERT, UPDATE, DELETE처럼 데이터를 변경하는 쿼리는 데이터 파일의 이곳저곳에 위치한 레코드를 변경하기 때문에 렌덤한 디스크 작업을 발생시킨다. 하지만 버퍼 풀이 이러한 변경 데이터를 모아서 처리하면 랜덤한 디스크 작업의 횟수를 줄일 수 있다. 버퍼 풀의 크기 설정 . 일반적으로 전체 물리 메모리의 80% 정도를 InnoDB의 버퍼 풀로 설정하라는 내용의 게시물도 있는데, 운영체제와 각 쓰레드가 사용할 메모리도 충분히 고려해야한다. MySQL서버 내에서 메모리를 필요로하는 부분은 크게 없지만 드문 경우로 레코드 버퍼가 상당한 메모리를 사용하기도 한다. 레코드 버퍼공간은 별도로 설정할 수 없으며, 전체 커넥션 개수와 각 커넥션에서 읽고 쓰는 테이블 개수에 따라 결정된다. 레코드 버퍼는 각 클라이언트 세션에서 테이블의 레코드를 읽고 쓸 때 버퍼로 사용하는 공간이다. 커넥션이 많고 사용하는 테이블도 많다면 레코드 버퍼 용도로 사용되는 메모리 공간이 많이 필요해질 수 있다. 이러한 이유로 초기 설정시 80%가 아닌 50%부터 점진적으로 증가시켜 최적점을 찾는게 좋다. 버퍼 풀의 구조 . | LRU(Least Recently Used) : 한 번 읽어온 페이지를 최대한 오랫동안 버퍼 풀의 메모리에 유지하여 디스크 읽기를 최소화 함 | 플러시(Flush) : 변경 내역은 리두 로그와 더티 페이지에 기록되며 플러시는 더티 페이지를 관리한다. 두 곳 모두에 변경사항을 저장하는 이유는 실패시 복구를 위해 존재함 | 프리(Free) : 사용자 데이터로 채워지지 않은 비어있는 페이지 | . | ![[Pasted image 20240420180754.png | 350]] | . 버퍼 풀과 리두 로그 . 버퍼 풀의 버퍼링 기능까지 향상시키려면 InnoDB 버퍼 풀과 리두 로그의 관계를 먼저 이해해야 한다. ![[Pasted image 20240420181403.png|400]] 리두 로그는 1개 이상의 고정 크기 파일을 연결해서 순환 고리처럼 사용한다. 즉 리두 로그 파일에 기록됐던 로그 엔트리는 어느 순간 다른 엔트리로 덮어쓰인다. InnoDB스토리지 엔진은 주기적으로 체크포인트 이벤트를 발생시켜 리두 로그와 버퍼 풀의 더티 페이지를 디스크로 동기화한다. 체크포인트가 발생하면 체크포인트보다 작은 LSN(log sequence number) 리두 로그 엔트리와 관련된 더티 페이지는 모두 디스크로 동기화돼야 한다. 처음부터 리두 로그 파일의 크기를 적절히 선택하기 어렵다면 버퍼 풀의 크기가 100GB 이하의 MySQL서버에서는 리두 로그 파일의 크기를 대략 5~10GB 수준으로 선택하고 필요할 때마다 조금씩 늘려가면서 최적값을 선택하는 것이 좋다. 버퍼 풀 플러시 . InnoDB 스토리지 엔진은 버퍼 풀에서 아직 디스코로 기록되지 않은 더티 페이지들을 성능상의 악영향 없이 디스크에 동기화하기 위해 다음과 같이 2개의 플러시 기능을 백그라운드로 실행한다. | 플러시 리스트 플러시 | LRU 리스트 플러시 플러시 리스트 플러시 . 리두 로그의 공간 재활용을 위해 주기적으로 오래된 리두 로그 공간을 비워줘야한다. 이때 반드시 버퍼풀의 더티 페이지가 먼저 디스크로 동기화돼야 한다. 이를 위해 InnoDB는 주기적으로 플러시 리스트 플러시 함수를 호출한다. | . InnoDB에서 더티 페이지를 디스크로 동기화 하는 스레드를 클리너 스레드라고하는데, innodb_page_cleaners시스템 변수로 개수를 조절할 수 있다. innodb_page_cleaners는 버퍼풀 인스턴스 개수보다 적은경우 하나의 스레드가 여러 개의 버퍼 풀 인스턴스를 처리하므로 동일한 값을 설정하는것이 좋다. 그밖에도 아래와 같은 설정값들이 있다. | innodb_max_dirty_pages_pct_lwm : 일정 수준 이상의 더티 페이지가 발생하면 조금씩 더티 페이지를 디스크로 쓰기 | innodb_max_dirty_pages_pct : 더티 페이지 비율, 기본값 유지 | innodb_io_capacity : 어느 정도의 디스크 읽고 쓰기가 가능한지 설정 | innodb_io_capacity_max : 어느 정도의 디스크 읽고 쓰기가 가능한지 설정. | innodb_adaptive_flushing : on/off 위의 설정값들에 의존하지 않고 알고리즘을 사용한다. | innodb_adaptive_flushing_lwm : 기본값 10, 전체 리두 로그 공간에서 활성 리두 로그 공간이 10% 미만이면 알고리즘이 작동한다 | innodb_flush_neighbors : 더티 페이지를 디스크에 기록할 때 근접한 페이지중 더티 페이지가 있다면 함께 묶어 디스크 기록. 기본값인 비활성 모드 유지. | . LRU 리스트 플러시 . innodb_lru_scan_depth : 설정된 개수만큼의 페이지들을 스캔한다. 스캔할 때 더티페이지는 동기화 되고, 프리로 옮겨진다. 버퍼 풀 상태 백업 및 복구 . InnoDB의 버퍼 풀은 쿼리 성능에 밀접하게 연관되어있다. 초기화 되어있는 상태에서 쿼리를 하면 매우 느리다. 때문에 버퍼 풀 상태를 백업할 수 있는 기능을 지원한다. 버퍼 풀의 적재 내용 확인 . information_schema, innodb_buffer_page,cached_indexs테이블을 통해 버퍼 풀의 메모리에 어떤 테이블의 페이지들이 적재돼 있는지 확인할 수 있다. Double Write Buffer . InnoDB는 리두 로그 공간 낭비를 막기 위해 페이지의 변경된 내용만 기록한다. 이로 인해 문제 발생시 그 페이지의 내용을 복구할 수 없을 수 있다. 이를 위해 Double-Write기법을 사용한다. ![[Pasted image 20240420184622.png|400]] . InnoDB에서 더티 페이지를 디스크러 플러시 한다고 가정할때 A~E까지 일단 DoubleWrite 버퍼에 기록한다. 그다음 플러시를 실행한다. 플러시 도중 비정상적 종료가 일어난 경우, 재부팅시에 DoubleWrite 버퍼로부터 데이터를 페이지로 복사한다. SSD처럼 랜덤 IO나 순차 IO의 비용이 비슷한 저장 시스템에는 부담스러운 일이다. 하지만 무결성이 중요한 서비스의 경우에는 활성화를 고려하는 것이 좋다. 언두 로그 . InnoDB는 트랜잭션과 격리 수준을 보장하기 위해 DML로 변경되기 이전 버전의 데이터를 별도로 백업한다. 이렇게 백업된 데이터를 언두 로그라고한다. 언두 로그 레코드 모니터링 . SHOW ENGIEN INNODB STATUS \\G SELECT count FROM information_schema.innodb_metrics WHERE SUBSYSTEM='transaction' AND NAME='trx_rseg_history_len'; . 많은 양의 언두르고는 언두 로그의 이력을 필요한 만큼 스캔해야만 필요한 레코드를 찾을 . 수있기 때문에 쿼리의 성능이 전반적으로 떨어진다. 때문에 트랜잭션은 가능하면 빨리 끝내는것이 좋고, 모니터링이 필요하다. 언두 테이블스페이스 관리 . 언두 로그가 저장되는 공간을 언두 테이블스페이스라고 한다. 8.0버전부터는 언두 로그는 항상 시스템 테이블스페이스 외부의 별보 로그파일에 기록된다. InnoDB의 기본설정을 사용하면 131072(=16 * 1024 / 16 * 128 * 2 / 2)개 정도의 트랜잭션이 동시에 처리 가능해진다. 일반적으로 이정도까진 필요없지만 기본값으로 해서 크게 문제될 건 없으므로 가능하면 기본값을 유지하자. 언두 테이블스페이스 공간을 필요한 만큼만 남기고 불필요하거나 과도하게 할당된 공간을 운영체제로 반납하는 것을 ‘Undo tablespace truncate’라고 한다. | 자동 모드 : 트랜잭션이 커밋되면 더이상 언두 로그에 복사된 이전값이 필요가없다. 퍼지 스테드(purge thread)는 주기적으로 꺠어나서 언두 로그를 삭제한다. | 수동 모드 : 언두 테이블스페이스가 최소 3개이상은 되어야 작동하며, 언두 로그 파일의 잘라내기가 부진한 경우 퍼지 스레드가 작동한다 | . 체인지 버퍼 . RDBMS에서 레코드가 INSERT 되거나 UPDATE될 때는 데이터 파일을 변경하는 작업 뿐 아니라 해당 테이블에 포함된 인덱스를 업데이트하는 작업도 필요하다. 인덱스를 업데이트하는 작업은 랜덤하게 디스크를 읽는 작업이 필요하다. 테이블에 인덱스가 많다면 이 작업은 상당히 많은 자원을 소모하게 된다. 그래서 InnoDB는 변경해야 할 인덱스 페이지가 버퍼 풀에 있으면 바로 업데이트를 수행하지만 그렇지 않고 디스크로부터 읽어와서 업데이트해야 한다면 임시 공간에 저장해 두고 바로 사용자에게 결과를 반환하는 형태로 성능을 향상시킨다. 이때 사용하는 임시 메모리 공간을 체인지 버퍼라고한다. 중복 여부를 체크하는 유니크 인덱스는 체인지 버퍼를 사용할 수 없다. 체인지 버퍼에 임시로 저장된 인덱스 레코드는 백그라운드 스레드에 의해 병합된다. 체인지 버퍼는 기본 25%로 설정되어있다. 필요시 50%까지 늘릴 수 있다. 리두 로그 및 로그 버퍼 . InnoDB의 데이터 파일은 다음과 같은 두가지 종류의 일관되지 않은 데이터를 가질 수 있다. | 커밋됐지만 데이터 파일에 기록되지 않은 데이터 | 롤백됐지만 데이터 파일에 이미 기록된 데이터 1번의 경우 리두 로그에 저장된 데이터를 데이터 파일에 다시 복사하기만 하면 된다. 2번의 경우에는 리두 로그만으로는 해결할 수 없다. 이때는 변경되기 전 데이터를 가진 언두 로그의 내용을 가져와 데이터 파일에 복사하면 된다. | . 리두 로그 파일의 전체 크기가 InnoDB 버퍼 풀의 크기에 맞게 적절히 선택돼야 InnoDB가 적절히 변경된 내용을 버퍼 풀에 모았다가 한번에 디스크에 기록할 수 있다. 하지만 사용량이 많은 DBMS 서버의 경우 리두 로그의 기록 작업이 큰 문제가 되는데, 이러한 부분을 보완하기 위해 최대한 ACID 속성을 보장하는 수준에서 버퍼링한다. 이러한 리두 로그 버퍼링에 사용되는 공간이 로그 버퍼이다. 원자성(Atomicity), 일관성(Consistency), 격리성(Isolation), 지속성(Durability) . 리두 로그 아카이빙 . 데이터 파일을 복사하는 동안 추가된 리두 로그 엔트리가 같이 백업되지 않는다면 복사된 데이터 백업 파일은 일관된 상태를 유지하지 못한다. 그런데 MySQL서버에 유입되는 데이터 변경이 너무 많으면 리두 로그가 매우 빠르게 증가하고, 백업중 새로 추가되는 리두 로그내용을 복하기도 전에 덮어쓰일 수도 있다. 리두 로그 아카이빙 기능은 데이터 변경이 많아서 리두 로그가 덮어쓰인다고 하더라도 백업이 실패하지 않게 해준다. 리두 로그 활성화 및 비활성화 . 대용량의 데이터를 복구하거나 한번에 적재하는 경우 다음과 같이 리두 로그를 비활성화 해서 데이터의 적재 시간을 단축시킬 수 있다. ALTER INSTANCE DISABLE REDO_LOG; # 적재 쿼리 실행 ALTER INSTANCE ENABLE REDO_LOG; . 어댑티브 해시 인덱스 . 일반적으로 ‘인덱스’라고 하면 이는 테이블에 사용자가 생성해둔 B-Tree 인덱스를 의미한다. 어댑티브 해시 인덱스는 사용자가 수동으로 생성하는 인덱스가 아니라 InnoDB에서 사용자가 자주 요청하는 데이터에 대해 자동으로 생성하는 인덱스이다. B-Tree 인덱스에서 특정 값을 찾는 과정이 매우 빠르게 처리된다고 많은 사람들이 생각한다. 하지만 B-Tree도 동시에 몇천개의 스레드로 실행하면 컴퓨터의 CPU는 엄청난 프로세스 스케쥴링을 하게 되고 자연히 쿼리의 성능은 떨어진다. 어댑티브 해시 인덱스는 이러한 B-Tree의 검색 시간을 줄여주기 위해 도입된 기능이다. 자주 읽히는 데이터 페이지의 키 값을 이용해 해시 인덱스를 만들고, 필요할 때마다 어댑티브 해시 인덱스를 검색해서 레코드가 저장된 데이터 페이지를 즉시 찾아갈 수 있다. 어댑티브 해시 인덱스의 키 값은 ‘B-Tree 인덱스의 고유 번호와 B-Tree 인덱스의 실제 키 값’조합으로 생성된다. B-Tree 인덱스의 고유번호가 포함되는 이유는 InnoDB에서 어댑티브 해시 인덱스는 하나만 존재하기 때문이다. 어댑티브 해시 인덱스가 마냥 좋아보이지만, 실제 비활성화하는 경우도 많다. | 디스크 읽기가 많은 경우 | 특정 패턴의 쿼리가 많은 경우(조인 or Like) | 매우 큰 데이터를 가진 테이블의 레코드를 폭넓게 읽는 경우 | . 성능에 큰 도움이 되는경우는 . | 디스크의 데이터가 InnoDB 버퍼 풀 크기와 비슷한 경우(디스크 읽기가 많지 않은 경우) | 동등 조건 검색(동등 비교 IN 연산자)이 많은 경우 | 쿼리가 데이터 중에서 일부 데이터에만 집중되는 경우 | . 도움이 될지 판단하기 쉽지 않지만, 데이터 페이지를 디스크에서 읽어오는 경우가 빈번한 데이터베이스 서버에서는 아무런 도움이 되지 않는다. 하나 더 기억해야 할 것은 어댑티브 해시 인덱스는 공짜가 아니라 메모리를 사용한다는 것이다. 때로는 상당히 큰 메모리를 사용할 수도 있다. 또한 삭제나 변경에 대해서도 어댑티브 해시 인덱스에서 제거해야하므로 상당히 많은 자원을 소모할 수 있다. ",
    "url": "/docs/mysql/04.%20Real%20MySQL%208.0.html#mysql-%EC%97%94%EC%A7%84-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98",
    
    "relUrl": "/docs/mysql/04.%20Real%20MySQL%208.0.html#mysql-엔진-아키텍처"
  },"34": {
    "doc": "04. Real MySQL 8.0",
    "title": "04. Real MySQL 8.0",
    "content": " ",
    "url": "/docs/mysql/04.%20Real%20MySQL%208.0.html",
    
    "relUrl": "/docs/mysql/04.%20Real%20MySQL%208.0.html"
  },"35": {
    "doc": "04. 설계 품질과 트레이드오프",
    "title": "04. 설계 품질과 트레이드오프",
    "content": ". 설계는 변경을 위해 존재하고 변경에는 어떤 식으로든 비용이 발생한다. 훌륭한 설계란 합리적인 비용 안에서 변경을 수용할 수 있는 구조를 만드는 것이다. 객체지향 설계에서는 두 가지 방법은 이용해 시스템을 객체로 분할할 수 있다. 상태를 분할의 중심축으로 삼는 방법, 책임을 분할의 중심축으로 삼는 방법. 일반적으로 객체의 상태는 객체가 저장해야 하는 데이터의 집합을 의미하기 때문에 여기서는 상태와 데이터를 동일한 의미로 사용하겠다. 시스템을 분할하기 위해 데이터와 책임 중 어떤 것을 선택해야 할까? 결론부터 말하자면 훌륭한 객체지향 설계는 데이터가 아니라 책임에 초점을 맞춰야 한다. 데이터 기준으로 분할한 설계를 살펴보고, 책임 주도 설계방법보다 어떤 면에서 좋은지 살펴보자. 데이터 중심 설계는 객체가 내부에 저장해야 하는 데이터가 무엇인가를 묻는 것으로 시작한다. public class Movie { private String title; private Duration runningTime; private Money fee; private List&lt;DiscountCondition&gt; discountConditions; private MovieType movieType; private Money discountAmount; private double discountPercent; ｝ . 데이터 중심의 Movie 클래스 역시 책임 중심의 Movie 클래스와 마찬가지로 영화를 표현하는 가장 기본 적인 정보인 영화 제목(title), 상영시간(runningTime), 기본 요금(fee)을 인스턴스 변수로 포함한다. 하지만 기존의 설계와 동일한 부분은 여기까지다. 가장 두드러지는 차이점은 할인 조건의 목록(discountConditions)이 인스턴스 변수로 Movie 안에 직접 포함돼 있다는 것이다. 또한 할인 정책을 DiscountPolicy라는 별도의 클래스로 분리했던 이전 예제와 달리 금액 할인 정책에 사용되는 할인 금액(discountAmount)과 비율 할인 정책에 사용되는 할인 비율 (discountPercent)을 Movie 안에서 직접 정의하고 있다. 할인 정책은 영화별로 오직 하나만 지정할 수 있기 떄문에 movieType을 추가하여 discountAmount, discountPercent 둘 중 한가지 값만 사용한다. 객체의 책임을 결정하기 전에 이런 질문의 반복에 휩쓸려 있다면 데이터 중심의 설계에 매몰돼 있을 확률이 높다. Movie클래스 안에 종류를 저장하는 변수 (movieType)와 인스턴스 종류에 따라 배타적으로 사용될 인스턴스 변수를 하나의 클래스 안에 함께 포함시키는 방식은 데이터 중심의 설계안에서 흔히 볼 수 있는 패턴이다. 이와 같은 방식으로 영화 예매에 필요한 모든 데이터를 클래스로 구현했다. ![[Pasted image 20240527233825.png]] . 데이터 중심의 설계는 캡슐화를 위반하고 객체 내부 구현을 인터페이스의 일부로 만든다. 반면 책임 중심의 설계는 객체의 내부 구현을 안정적인 인터페이스 뒤로 캡슐화 한다. 데이터 중심으로 설계한 Movie 클래스는 getter setter를 사용하기 때문에 어떤 정보도 캡슐화하지 못한다. 또한 높은 결합도로 getter와 setter를 통해 내부 구현을 인터페이스의 일부로 만들기 때문에 캡슐화를 위반한다. 내부 구현이 드러난다는 것은 클라이언트가 구현에 강하게 결합된다는 것을 의미한다. ![[Pasted image 20240527234256.png]] . 낮은 응집도는 두 가지 측면에서 설계에 문제를 일으킨다. | 변경의 이유가 서로 다른 코드들을 하나의 모듈 안에 뭉쳐놓았기 때문에 변경과 아무 상관이 없는 코드들이 영향을 받게 된다. | 하나의 요구사항 변경을 반영하기 위해 동시에 여러 모듈을 수정해야 한다. | . public class Movie { private String title; private Duration runningTime; private Money fee; private List&lt;DiscountCondition&gt; discountConditions; private MovieType movieType; private Money discountAmount; private doublediscountPercent; public MovieType getMovieType () { return movieType; } public Money calculateAmountDiscountedFee () { if (movieType != MovieType .AMOUNT_DISCOUNT) { throw new IllegalArgumentException); } return fee.minus(discountAmount); } public Money calculatePercentDiscountedFee) { if (movieType != MovieType.PERCENT_DISCOUNT) { throw new IllegalArgumentException); } return fee.minus(fee.times(discountPercent)); } public Money calculateNoneDiscountedFee() { if (movieType != MovieType .NONE_DISCOUNT) { throw new IllegalArgumentException); } return fee: } } . ![[Pasted image 20240528002149.png]] . 이전보다 개선된것은 사실이지만 만족스러울 정도는 아니다. 첫 번째 설게에서 발생했던 대부분의 문제는 두 번째 설계에서도 여전히 발생한다. 캡슐화 위반 DiscountCondition에 구현된 두 개의 isDiscountable 메서드를 자세히 살펴보면 DiscountCondition에 포함된 DayofWeek 타입의 요일 정보와 LocalTime 타입의 시간 정보를 파라미터로 받는 것을 알 수 있다. 시간 정보가 인스턴스 변수로 포함돼 있다는 사실을 인터페이스를 통해 외부에 노출하고 있는 것이다. 높은 결합도 DiscountCondition의 내부 구현이 외부로 노출됐기 때문에 Movie와 DiscountCondition 사이의 결합도는 높을 수밖에 없다. 낮은 응집도 DiscountCondition이 할인 여부를 판단하는 데 필요한 정보가 변경된다면 Movie의 isDiscountable 메서드로 전달해야 하는 파라미터의 종류를 변경해 야 하고, 이로 인해 Screening에서 Movie의 isDiscountable 메서드를 호출하는 부분도 함께 변경해야 한다. ",
    "url": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/04.%20%EC%84%A4%EA%B3%84%20%ED%92%88%EC%A7%88%EA%B3%BC%20%ED%8A%B8%EB%A0%88%EC%9D%B4%EB%93%9C%EC%98%A4%ED%94%84.html",
    
    "relUrl": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/04.%20%EC%84%A4%EA%B3%84%20%ED%92%88%EC%A7%88%EA%B3%BC%20%ED%8A%B8%EB%A0%88%EC%9D%B4%EB%93%9C%EC%98%A4%ED%94%84.html"
  },"36": {
    "doc": "04. 처리율 제한 장치의 설계",
    "title": "04. 처리율 제한 장치의 설계",
    "content": ". 네트워크 시스템에서 처리율 제한 장치는 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치다. 예를들면 API요청 횟수가 제한 장치에 정의된 임게치를 넘어서면 추가로 도달한 모든 호출은 처리가 중단된다. | 사용자는 초당 2회 이상 새 글을 올릴 수 없다. | 같은 IP 주소는 하루에 10개 이상의 계정을 생성할 수 없다. | 같은 디바이스로는 주당 5회 이상 리워드를 요청할 수 없다. | . 이번 장에서는 이 처리율 제한 장치를 설계한다. 장점 . | DoS 공격에 의한 자원 고갈을 방지할 수 있다. | 비용을 절감한다. 또한 API횟수 를 확인하고 횟수를 제한하여 비용을 절감할 수 있다 | 서버 과부하를 막는다. 봇에서 오는 트래픽이나 사용자의 잘못된 이용 패턴으로 유발되는 트래픽을 걸러낼 수 있다. | . 폭넓게 채택된 기술인 클라우드 마이크로서비스의 경우, 처리율 제한 장치는 보통 API 게이트웨이라 불리는 컴포넌트에 구현된다. API 게이트웨이는 처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 관리 등을 지원하는 완전 위탁관리형 서비스, 즉 클라우드 업체가 유지 보수를 담당하는 서비스이다. 처리율 제한 장치를 서버에두는지 게이트웨이에 두는지 정답은 없다. 처리율 제한 장치를 직접 만드는 데는 시간이 든다. 충분한 인력이 없다면 사용 API게이트웨이를 쓰는 것이 바람직한 방법일 것이다. 처리율 제한 알고리즘 . | 토큰 버킷 | 누출 버킷 | 고정 윈도 카운터 | 이동 윈도 로그 | 이동 윈도 카운터 | . 토큰 버킷 토큰 버킷은 지정된 용량을 갖는 컨테이너이다. ![[Pasted image 20240802011623.png]] 각 요청은 처리될 때마다 하나의 토큰을 사용한다. 요청이 도착하면 토큰이 있는지 검사하고 있다면 토큰을 사용하여 요청 시스템에 전달한다. 토큰이 없다면 해당 요청은 버려진다. 장점 구현이쉽다 메모리 사용 측면에서도 효율적 짧은 시간에 집중되는 트래픽도 처리 가능하다. 단점 버킷 크기와 토큰 공급률이라는 두가지 값을 적절하게 튜닝하는 것이 까다롭다 . 누출 버킷 알고리즘 토큰 버킷과 비슷하지만 요청 처리율이 고정되어있다는 점이 다르다. FIFO 큐로 구현한다. | 요청이 도착하면 큐가 가득차있는지 본다. 빈자리가 있는 경우 큐에 요청을 추가한다. | 가득 차 있는 경우 새 요청은 버린다. | 지정된 시간마다 큐에서 요청을 꺼내어 처리한다. | . ![[Pasted image 20240802011935.png]] . 장점 큐의 크기가 제한되어 있어 메모리 사용량 측면에서 효율적 고정된 처리율로 안정적 출력 . 단점 단시간에 많은 트래픽이 몰리는 경우 요청을 제때 처리 못하면 최신 요청이 버려진다. 마찬가지로 튜닝이 까다롭다 . 고정 윈도 카운터 알고리즘 . | 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터를 붙인다. | 요청이 접수될 때마다 이 카운터의 값은 1씩 증가한다. | 이 카운터의 값이 사전에 설정된 임계치에 도달하면 새로운 요청은 새 윈도가 열릴 때까지 버려진다. | . ![[Pasted image 20240818171537.png]] . 이 알고리즘의 가장 큰 문제는 윈도의 경계 부근에 순간적으로 많은 트래픽이 집중될 경우 윈도에 할당된 양보다 더 많은 요청이 처리될 수 있다는 것이다. ![[Pasted image 20240818171914.png]] 예를 들어 분당 최대 5개의 요청만을 허용하는 시스템이 있다. 윈도우 카운트는 매분마다 초기화 된다. 2:00:00와 2:01:00 사이에 5개의 요청이 들어왔고 2:01:00과 2:02:00사이에 또 5개의 요청이 들어왔다. 윈도우 위치를 옮겨보면 2:00:30부터 2:01:30까지 10개를 처리한다. 허용 한도의 2배를 처리한것. 장점 . | 메모리 효율이 좋다 | 이해하기 쉽다 | 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다. 단점 | 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 된다. | . 이동 윈도 로깅 알고리즘 . 고정 윈도 카운터 알고리즘을 해결한 알고리즘이다. | 이 알고리즘은 요청 타임스탬프를 추적한다. | 새 요청이 오면 만료된 타임스탬프는 제거한다. | 새 요청의 타임스탬프를 로그에 추가한다. | 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다. 그렇지 않으면 처리를 거부한다. ![[Pasted image 20240818172445.png]] | . 장점 . | 이 알고리즘이 구현하는 처리율 제한 메커니즘은 아주 정교하다. 어느 순간의 윈도를 보더라도, 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다. 단점 | 이 알고리즘은 다량의 메모리를 사용하는데, 거부된 요청의 타임스탬프도 보관하기 때문이다. | . 이동 윈도 카운터 알고리즘 . 고정 윈도 카운터 알고리즘과 이동 윈도 로깅 알고리즘을 결합한 것이다. ![[Pasted image 20240818172621.png]] . 처리율 제한 장치가 한도가 분당 7개 요청으로 설정되어 있다고 하고, 이전 1분 동안 5개의 요청이, 그리고 현재 1분동안 3개의 요청이 왔다고 가정하자. 현재 1분의 30% 시점에 도착한 새 요청의 경우, 현재 윈도에 몇개의 요청이 온것으로 보고 처리해야할까? . 현재 1분간의 요청 수 + 직전 1분간의 요청 수 x 이동 윈도와 직전 1분이 겹치는 비율 공식에 따르면 3 + 5 x 70% = 6.5개다. 반올림하거나 반내림하여 쓸 수 있다. 장점 . | 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽도 잘 대응한다. | 메모리 효율이 좋다 | . 단점 . | 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨하다. (실험에 따르면 40억개 요청중 버려진것은 0.003%로 문제가 크지않음) | . 분산 환경에서의 처리율 제한 장치 구현 . 병렬 스레드를 지원하도록 시스템을 확장하는 것은 또다른 문제다. 다음 두가지 어려운 문제를 풀어야 한다. | 경쟁 조건 | 동기화 | . 경쟁 조건 . ![[Pasted image 20240818174120.png]] . 경쟁 조건 문제를 해결하는 가장 널리 알려진 해결책은 락이다. 하지만 락은 시스템의 성능을 상당히 떨어뜨린다는 문제가 있다. 락 대신 쓸 수 있는 해결책이 두 가지 있는데 . | 루아 스크립트 | 정렬 집합 이라는 레디스 자료구조를 쓰는 것이다. | . Lua 스크립트는 Redis 내에서 실행되는 작은 프로그램입니다. Redis에서 Lua 스크립트를 사용하면 여러 Redis 명령을 하나의 원자적 작업으로 실행할 수 있습니다. 다른 클라이언트가 중간에 끼어들 수 없어 race condition을 방지할 수 있습니다. 정렬 집합(Sorted Set)은 Redis의 자료구조 중 하나로, 각 요소가 점수(score)와 값(value)의 쌍으로 구성됩니다. 이 구조는 요소들을 점수에 따라 자동으로 정렬합니다. 이 작업은 원자적으로 수행되므로 race condition이 발생하지 않습니다. 원자성: ZINCRBY 명령은 원자적으로 실행되어 동시성 문제를 방지합니다. 동기화 이슈 . ![[Pasted image 20240818175134.png]] 분산환경에서 동기화는 중요한 요소이다. 처리율 제한 장치 서버를 여러대 두게 되면 동기화가 필요해진다. 하나의 레디스 서버를 두고 두개의 처리 장치가 하나의 레디스를 바라봄으로써 처리율 제한을 올바르게 수행할 수 있다. 모니터링 . 처리율 제한 장치를 설치한 이후에 효과적으로 동작하고 있는지 보기 위해 데이터를 모을 필요가 있다. | 채택된 처리율 제한 알고리즘이 효과적이다. | 정의한 처리율 제한 규칙이 효과적이다. | . ",
    "url": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/04.%20%EC%B2%98%EB%A6%AC%EC%9C%A8%20%EC%A0%9C%ED%95%9C%20%EC%9E%A5%EC%B9%98%EC%9D%98%20%EC%84%A4%EA%B3%84.html",
    
    "relUrl": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/04.%20%EC%B2%98%EB%A6%AC%EC%9C%A8%20%EC%A0%9C%ED%95%9C%20%EC%9E%A5%EC%B9%98%EC%9D%98%20%EC%84%A4%EA%B3%84.html"
  },"37": {
    "doc": "05. ELB 및 ASG",
    "title": "05. ELB 및 ASG",
    "content": ". ",
    "url": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html",
    
    "relUrl": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html"
  },"38": {
    "doc": "05. ELB 및 ASG",
    "title": "수직 확장성 Vertical scalability",
    "content": "인스턴스의 크기를 확장 데이터베이스와 같이 분산되지 않은 시스템에서 사용 하드웨어 용량 증가에 한계가 있다 . ",
    "url": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#%EC%88%98%EC%A7%81-%ED%99%95%EC%9E%A5%EC%84%B1-vertical-scalability",
    
    "relUrl": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#수직-확장성-vertical-scalability"
  },"39": {
    "doc": "05. ELB 및 ASG",
    "title": "수평 확장성 - 탄력성",
    "content": "시스템 수를 늘리는 방법 수평 확장을 했다는건 분배 시스템이 있다는것을 의미 . ",
    "url": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#%EC%88%98%ED%8F%89-%ED%99%95%EC%9E%A5%EC%84%B1---%ED%83%84%EB%A0%A5%EC%84%B1",
    
    "relUrl": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#수평-확장성---탄력성"
  },"40": {
    "doc": "05. ELB 및 ASG",
    "title": "고가용성",
    "content": "고가용성은 수평확장이랑 함께 사용되는 개념이지만 늘 그런것은 아니다 . 고가용성이란 애플리케이션 또는 시스템을 적어도 둘 이상의 aws의 az나 데이터 센터에서 가동중이라는것을 의미 . 고가용성의 목표는 데이터 센터에서의 손실에서 살아남는것으로 센터 하나가 멈춰도 계속 작동이 가능하게끔 하는것이다 . 스케일 아웃 -&gt; 늘림 스케일 인 -&gt; 줄임 . 고가용성은 다중 AZ가 활성화 된 자동 스케일러 그룹이나 로드밸런서에서도 사용된다 . ",
    "url": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#%EA%B3%A0%EA%B0%80%EC%9A%A9%EC%84%B1",
    
    "relUrl": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#고가용성"
  },"41": {
    "doc": "05. ELB 및 ASG",
    "title": "로드 밸런싱 Load Balancing",
    "content": "트래픽을 백엔드나 다운스트림 EC2 인스턴스 또는 서버들로 전달하는 역할을 한다 . 필요한 이유 . | 다운스트림 인스턴스 부하분산 | 다인 액세스 지점(DNS) 노출 | 인스턴스 실패 핸들링 | HTTPS 트래픽 사용 가능 | 쿠키로 고정도를 강화 | 고가용성 | 클라우드 내에서 개인 트래픽과 공공 트래픽을 분리 할 수 있다. | . 앨라스틱 로드밸런서는 무조껀 쓰는 편이 좋다 자체 로드 밸런서를 마련하는것 보다 저렴 관리와 확장성 측면에서도 손쉽다 다수의 aws 서비스와 통홥되어있다 . health check 정상 동작하는지를 체크 포트와 라우트에서 헬스체크가 이루어진다 . protocol : HTTP port : 4567 Endpoint : /health . 200을 반환하지않으면 상태가 좋지못한것으로 인식하고 로드밸런서는 해당 인스턴스에 요청을 보내지 않는다. ",
    "url": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#%EB%A1%9C%EB%93%9C-%EB%B0%B8%EB%9F%B0%EC%8B%B1-load-balancing",
    
    "relUrl": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#로드-밸런싱-load-balancing"
  },"42": {
    "doc": "05. ELB 및 ASG",
    "title": "로드밸런서 종류",
    "content": ". | CLB (classic load balancer) . | 구형 (2009년 출시) | HTTP, HTTPS, TCP, SSL | 권장하지 않음 | 사용은 가능함 | AWS에서 지원이 곧 끊길예정이며, 콘솔에서 사용할 수 없게된다 | . | ALB (application load balancer) . | 신형 (2016년에 출시) | HTTP, HTTPS, webSocket | . | NLB (network load balancer) . | 2017년 출시 | TCP, TLS, UDP | . | GWLB (gateway load balancer) . | 2020년 출시 | 네트워크 레이어에서 사용 | 3게층과 IP 프로토콜에서 작동 | . | . 더 많은 기능을 가진 신형 로드 밸런서를 사용하는것을 권장 . 일부 로드밸런서들은 내부에 설정될 수 있어 네트워크에 개인적 접근이 가능하고 웹사이트와 같이 모두에 사용 가능한 외부 공공 로드밸런서도 있다. ",
    "url": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#%EB%A1%9C%EB%93%9C%EB%B0%B8%EB%9F%B0%EC%84%9C-%EC%A2%85%EB%A5%98",
    
    "relUrl": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#로드밸런서-종류"
  },"43": {
    "doc": "05. ELB 및 ASG",
    "title": "로드 밸런서 보안 그룹",
    "content": "| 유저는 HTTP |   | HTTPS를 사용해 어디서든 로드 밸런서에 접근이 가능 | . 인스턴스는 로드밸런서로부터 곧장 들어오는 트래픽만 허용해야 하기 때문에 EC2의 보안그룹 규칙은 HTTP에 80포트만 허용하며 IP범위로 허용이 아니라 보안그룹을 허용하도록 설정해야한다 . ",
    "url": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#%EB%A1%9C%EB%93%9C-%EB%B0%B8%EB%9F%B0%EC%84%9C-%EB%B3%B4%EC%95%88-%EA%B7%B8%EB%A3%B9",
    
    "relUrl": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#로드-밸런서-보안-그룹"
  },"44": {
    "doc": "05. ELB 및 ASG",
    "title": "ALB",
    "content": ". | 7계층, 즉 HTTP 전요 로드 밸런서 | 머신 간 다수 HTTP 애플리케이션의 라우팅에 사용된다. 이런 머신들은 대상 그룹이라는 그룹으로 묶이게 된다 | HTTP/2 와 WebSocket을 지원한다 | 리다이렉트를 지원 (HTTP -&gt; HTTPS로 리다이렉트가 필요하다면 로드밸런서 영역에서 가능하다.) | 라우팅 . | 경로 라우팅 . | example.com/users |   | example.com/post | . | . | URL 라우팅 . | one.example.com |   | other.example.com | . | . | 쿼리 문자열과 헤더기반 라우팅 | example.com/users?id=123&amp;order=fasle | . | 마이크로 서비스나 컨테이너 기반 애플리케이션에 가장 좋은 로드밸런서이다 | 도커와 ECS의 경우 ALB가 가장 적합한 로드밸런서 | 동적 포트 리다이렉트 가능 | 클래식 로드밸런서의 경우는 인스턴수 갯수만큼 로드밸런서가 필요하다? but ALB는 1개로 처리 가능 | . ",
    "url": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#alb",
    
    "relUrl": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#alb"
  },"45": {
    "doc": "05. ELB 및 ASG",
    "title": "ALB의 대상 그룹",
    "content": ". | EC2 (auto scalㄴing group) - HTTP | ECS - HTTP | lambda - HTTP | ip주소들의 앞에도 위치할 수 있다. | 꼭 사설 ip만 가능 | . | 상태 확인은 대상 그룹 레벨에서 이뤄진다 | . ABL을 사용하는경우 로드밸런서에 고정 호스트 이름이 부여된다 애플리케이션 서버는 클라이언트의 ip를 직접 보지 못하며 클라이언트의 실제 ip는 X-Forwarded-For라고 불리는 헤더에 삽입된다. ",
    "url": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#alb%EC%9D%98-%EB%8C%80%EC%83%81-%EA%B7%B8%EB%A3%B9",
    
    "relUrl": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#alb의-대상-그룹"
  },"46": {
    "doc": "05. ELB 및 ASG",
    "title": "NLB",
    "content": ". | 네트워크 로드밸런서는 L4 로드밸런서이므로 TCP와 UDP 트래픽을 다룰 수 있다. | 성능이 매우 높다 | 초당 수백만건 처리 가능 | ALB 보다 지연시간 짧음 (alb 400 nlb 100) | 가용역역별로 하나의 고정 ip를 갖는다 | 탄력적 ip를 사용할 수도 있다 | 1~3개의 ip로만 액세스할 수 있는 애플리케이션을 만들라는 문제가 나오면 nlb 옵션 고려 | 프리티어에 미포함 | . 그룹 유형 . | ec2 | ip주소 (프라이빗) | alb 앞에도 가능 (nlb로 고정ip를 얻을 수 있음) | tcp, http, https 프로토콜 지원 | . GWLB . L3 계층에서 동작 배포 및 확장과 aws의 타사 네트워크 가상 어플라이언스의 플릿 관리에 사용된다 . 모든 트래픽이 방화벽을 통과하게 하거나 침입 탐지 및 방지 시스템에 사용 . IDPS나 심층 패킷 분석 시스템 또는 페이로드 조작 가능 (네트워크 수준에서) . 사용 예제 (중요) . | 사용자는 게이트웨이로 요청을한다 | 게이트웨이는 들어온 트래픽에 대해 검증을 하는 인스턴스로 보낸다 | 검증이 끝나면 인스턴스는 게이트웨이로 반환한다 (문제가 있는 트래픽은 드롭한다) | 게이트웨이는 원래 가야할 인스턴스로 트래픽을 전달한다 | . gwlb의 기능 2가지 . | 투명 네트워크 게이트웨이 (vpc의 모든 트래픽이 gwlb가 되는 단일 엔트리와 출구를 통과한다) | 대상 그룹의 가상 어플라이언스 집합에 전반적으로 트래픽을 분산해 로드 밸런서가 된다 | . 포트번호는 6081번을 사용한다 . ",
    "url": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#nlb",
    
    "relUrl": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#nlb"
  },"47": {
    "doc": "05. ELB 및 ASG",
    "title": "Sticky Session (고정 세션)",
    "content": ". | 로드 밸런서에 2가지(회) 요청을 수행하는 클라이언트가 요청에 응답하기 위해 동일한 백엔드 인스턴스에 요청을 보내도록하는것 | CLB와 ALB에서 설정 가능 | 원리는 쿠키 | 세션같은 중요한 정보를 잃지 않기 위해 동일한 인스턴스를 사용하도록 한다 | 고정을 활성화 하면 백엔드 ec2 인스턴스 부하에 불균형을 초래할 수 있다 | 일부 인스턴스는 고정 사용자를 갖게된다 | . 쿠키 . | 애플리케이션 . | 사용자 정의 쿠키 . | 애플리케이션에서 생성 | 타겟 그룹별로 이름이 생성 | ALB에서 사용하느 예약어는 사용하면 안됨 | AWSALB, AWSALBAPP, AWSALBTG | . | 애플리케이션 쿠키 . | 로드밸런서에서 생성 | 애플리케이션 쿠키는 애플리케이션에서 기간 설정 가능 | AWSALBAPP | . | . | 기간 . | 로드밸런서에서 생성 | AWSALB, AWSELB | . | . AWSALB같은 이름을 외울 필요는 없다 . ",
    "url": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#sticky-session-%EA%B3%A0%EC%A0%95-%EC%84%B8%EC%85%98",
    
    "relUrl": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#sticky-session-고정-세션"
  },"48": {
    "doc": "05. ELB 및 ASG",
    "title": "Cross-Zone Load Balancing",
    "content": "교차 영역 로드밸런싱 . 두개의 가용영역에 갯수가 다른 인스턴스가 존재할때 교차 영역 로드밸런싱을 사용하면 모든 인스턴스에 고르게 분산된다 . 좋은데? . | alb는 교차 영역 로드밸런서가 기본적으로 켜져있다 (alb의 교차 영역 로드밸런싱은 비용이 들지않는다) | 대상 그룹에서 비활성화 할 수 있다 | aws는 데이터를 다은 가용 역역으로 옮길때 비용이 청구되지만, alb는 교차 영역 로드밸런서가 기본 설정이기 때문에 AZ간의 데이터 이동에 비용이 들지 않는다 | nlb와 gwlb는 기본적으로 꺼져있기 때문에 교차 영역 로드밸런서를 사용하려면 비용이 든다 | clb는 기본 비활성이고 활성해도 비용이 들지 않는다 | . ",
    "url": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#cross-zone-load-balancing",
    
    "relUrl": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#cross-zone-load-balancing"
  },"49": {
    "doc": "05. ELB 및 ASG",
    "title": "SSL / TLS",
    "content": "개념 . | 클라이언트와 로드밸런서 사이에 통신하는동안 암호화를 해준다. 이를 in-flight(전송중)암호화 라고한다. | 송신자와 수신자 측에서만 복호화 할 수 있다 | SSL은 보안 소켓 계층을 으미하고 연결을 안호화 하는데 사용한다 | TLS는 새로운 버전의 SSL로 전송 계층 보안을 의미한다 | 최근에는 TLS 인증서가 주로 사용된다. 하지만 사람들은 여전히 SSL이라고 부른다 | 퍼블릭 인증서는 인증기관(CA : Certificate Authorities)에서 발급한다 | 퍼블릭 SSL인증서를 로드 밸런서에 추가하면, 클라이언트와 로드밸런서 사이의 연결을 암호화할 수 있다 | SSL인증서에는 만료 날짜가 있어서 주기적으로 갱신해 줘야한다 | HTTPS는 SSL인증서를 써서 암호화해 안전하다는 뜻 | 인터넷을 통해 우리 로드 밸런서로 접속하면, 로드밸런서에서는 내부적으로 SSL 종료를 수행한다 | 백엔드와는 HTTP로 통신한다 (암호화x) | 하지만 VPC로 이동하는 트래픽은 프라이빗 네트워크를 쓰기 때문에 로드밸런서는 x.509 인증서를 사용하는데, 이걸 SSL 또는 TLS 서버 인증서라고 부른다 | AWS에는 인증서들을 관리할 수 있는 ACM이라는게 있다 (aws 인증서 관리자를 의미) | HTTP리스너를 구성할 때 반드시 HTTPS 리스너로 해야한다 . | 기본 인증서를 지정해줘야한다 | 다중 도메인을 지원하기 위해 다른 인증서를 추가할 수 있다 | SNI(서버 이름 지정)라는 걸 써서 접속할 호스트의 이름을 알릴 수 있다 | . | . SNI . | 여러개의 SSL인증서를 하나의 웹 서버에 로드해 하나의 웹 서버가 여러개의 웹 사이트 지원할 수 있게 해준다 | 클라이언트가 대상 서버의 호스트 이름을 지정하도록 한다 | 클라이언트가 접속할 웹사이트를 말했을 때, 서버는 어떤 인증서를 로드해야 하는지 알 수 있다 | 모든 클라이언트가 지원하지 않는다. | ALB,NLB, CloudFront에서 동작한다 (CLB 지원x) | 인증서가 여러개라면 ALB or NLB | CLB를 이용해서 여러개의 인증서를 사용하려면 CLB를 여러개 둬야함 | . ",
    "url": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#ssl--tls",
    
    "relUrl": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#ssl--tls"
  },"50": {
    "doc": "05. ELB 및 ASG",
    "title": "Connection Draining",
    "content": "Deregistration Delay 연결 드레이닝 || 등록 취소 지연 . | 인스턴스를 등록 취소, 혹은 비정상 상태일\u001c 때 인스턴스에 어느정도 \b시간을 주어 in-flight 요청 (활성 요청)을 완료 할 수 있도록 하는 기능 | 설정값이 0이면 비활성과 같다 | 파일 업로드 다운로드와 같은 작업은 처리가 완료되기까지 오래걸리니 드레이닝 시간을 오래 주는것이 좋다 | 1~3600초 까지 가능 | . ",
    "url": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#connection-draining",
    
    "relUrl": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#connection-draining"
  },"51": {
    "doc": "05. ELB 및 ASG",
    "title": "ASG",
    "content": "오토 스케일링 그룹 . 웹사이트 방문자가 갈수록 많아지면서 로드가 바뀔 수 있다 이때 사용 . | asg는 스케일 아웃 스케일 인 한다 | 최대 최소 갯수를 지정할 수 있다 | 로드 밸런서와 페어링 하는경우 asg에 속한 모든 인스턴스가 로드 밸런서와 연결한다 | 한 인스턴스가 비정상이면 종료하고 새롭게 띄워 연결한다 | asg는 무료이다 | asg를 사용하려면 시작 템플릿을 구성해야한다 . | 시작 템플릿 구성 . | ami | 인스턴스 유형 | ec2사용자 데이터 | ebs 볼륨 | 보안 그룹 | SSH 키 페어 | ec2 인스턴스의 iam 역할 | 네트워크 및 서브넷 정보 | 로드밸런서 정보 등등 | asg 최대 최소 크기, 용량 스케일링 정책 | . | . | . CloudWatch 경보를 기반으로 asg를 스케일 인 아웃 할 수 있다 . ",
    "url": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#asg",
    
    "relUrl": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#asg"
  },"52": {
    "doc": "05. ELB 및 ASG",
    "title": "ASG 조정 정책",
    "content": "동적 . | 추적 스케일링 . | 평균 cpu 사용률을 추적 40%를 유지하도록 | . | 단순/단계 스케일링 . | 전체 asg에 대한 cpu 사용률이 70%를 초과하는 경우 용량은 두 유닛 추가하도록 설정 | cpu 사용률이 30% 이하로 떨어지면 유닛을 하나 제거 | cloudwatch를 사용하는 경우 한번에 추가되고 제거되는 유닛을 단계별로 설정하는게 좋다 | . | 예측 스케일링 . | 과거의 로드를 보고 예측이 생성된다 | 머신러닝 기반일것이다 | . | . cpu, 요청수, 평균 네트워크 in out 등등의 지표를 사용 . 스케일링 휴지 . 스케일링 작\b업이 끝날때마다 기본적으로 5분 또는 300초의 휴지기간을 갖는다. 이때는 asg가 추가 인스턴스를 실행 또는 종료할 수 없다 . ",
    "url": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#asg-%EC%A1%B0%EC%A0%95-%EC%A0%95%EC%B1%85",
    
    "relUrl": "/docs/aws/05.%20ELB%20%EB%B0%8F%20ASG.html#asg-조정-정책"
  },"53": {
    "doc": "05. Real MySQL 8.0",
    "title": "5장",
    "content": ". ",
    "url": "/docs/mysql/05.%20Real%20MySQL%208.0.html#5%EC%9E%A5",
    
    "relUrl": "/docs/mysql/05.%20Real%20MySQL%208.0.html#5장"
  },"54": {
    "doc": "05. Real MySQL 8.0",
    "title": "트랜잭션",
    "content": "트랜잭션은 DBMS커넥션과 동일하게 꼭 필요한 최소의 코드에만 적용하는 것이 좋다. 이는 프로그램 코드에서 트랜잭션 번위를 최소화하라는 의미이다. ",
    "url": "/docs/mysql/05.%20Real%20MySQL%208.0.html#%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98",
    
    "relUrl": "/docs/mysql/05.%20Real%20MySQL%208.0.html#트랜잭션"
  },"55": {
    "doc": "05. Real MySQL 8.0",
    "title": "MySQL 엔진의 잠금",
    "content": ". | 글로벌 락 : 한 세션에서 그로벌 락을 획득하면 다른 세션에서 SELECT를 제외한 대부분의 DDL DML은 대기 상태로 남는다. | 백업시 실패를 막기위해 사용 | . | 테이블 락 : 개별 테이블 단위로 설정되는 잠금이며 명시적, 묵시적 락이있다. | 묵시적 락은 테이블 변경시 해당 테이블에 잠금을 설정하고 데이터를 변경한 후 즉시 잠금을 해제한다. | . | 네임드 락 : GET_LOCK()함수를 이용해 임의의 문자열에 대해 잠금을 설정할 수 있다. | 대상이 테이블이나 레코드 또는 AUTO_INCREMENT와 같은 데이터베이스 객체가 아니라 단순히 사용자가 지정한 문자열에 대해 획득하고 반납하는 잠금이다. | 잘사용되지 않는다. | 데이터 동기화를 처리할때 사용? 동기화가 됐는지 확인용? | . | 메타데이터 락 : 데이터베이스 객체의 이름이나 구조를 변경하는 경우에 획득하는 잠금이다. | 명시적으로 획득하거나 해제할 수 없다. | RENAME TABLE tab_a TO tab_b같이 테이블의 이름을 변경하는 경우 자동으로 획득하는 잠금이다. | . | . ",
    "url": "/docs/mysql/05.%20Real%20MySQL%208.0.html#mysql-%EC%97%94%EC%A7%84%EC%9D%98-%EC%9E%A0%EA%B8%88",
    
    "relUrl": "/docs/mysql/05.%20Real%20MySQL%208.0.html#mysql-엔진의-잠금"
  },"56": {
    "doc": "05. Real MySQL 8.0",
    "title": "InnoDB 스토리지 엔진 잠금",
    "content": "InnoDB는 엔진 내부에서 레코드 기반의 잠금 방식을 탑재하고 있다. InnoDB는 MyISAM과 달리 트랜잭션을 지원하기 때문에 InnoDB엔진에서 사용되는 잠금에 대한 정보는 MySQL 명령을 이용해 접근하기가 까다롭다. 최근 버전에는 InnoDB의 트랜잭션 잠금, 잠금 대기 중인 트랜잭션의 목록을 조회할 수 있는 방법이 도입됐다. information_schema데이터베이스에 존재하는 . | INNODB_TRX | INNODB_LOCK | INNODB_LOCK_WAITS 라는 테이블을 조인해서 조회하면 현재 어떤 트랜잭션이 어떤 잠금을 대기하고 있고 해당 잠금을 어느 트랜잭션이 가지고 있는지 확인할 수 있다. 또한 장시간 잠금을 자지고 있는 클라이언트를 찾아서 종료시킬 수 있다. | . InnoDB 스토리지 엔진의 잠금 . InnoDB엔진은 레코드 기반의 잠금 기능을 제공하며, 잠금 정보가 상당히 작은 공간으로 관리되기 때문에 레코드 락이 페이지 락으로, 또는 테이블 락으로 레벨업되는 경우는 없다. 레코드 락 . 레코드 자체만 잠그는 것을 레코드 락이라고한다. 다른 DBMS의 레코드 락과 동일한 역할을 한다. 한가지 중요한 차이는 레코드 자체가 아니라 인덱스의 레코드를 잠근다는 점이다. 레코드 자체를 잠그느냐, 인덱스를 잠그느냐는 상당이 크고 중요한 차이를 만들어낸다. 갭 락 . 다른 DBMS와의 또 다른 차이가 바로 갭 락이다. 갭 락은 레코드 자체가 아니라 레코드와 바로 인접한 레코드 사이의 간격만 잠그는 것을 의미한다. 갭 락의 역할은 레코드와 레코드 사이의 간격에 새로운 레코드가 생성 되는것을 제어하는 것이다. 갭 락은 그 자체보다는 넥스트 키 락의 일부로 자주 사용된다. ![[Pasted image 20240422212720.png|400]] . 넥스트 키 락 . 레코드 락과 갭 락을 합쳐 놓은 형태의 잠금을 넥스트 키 락이라고 한다. InnoDB의 갭 락이나 넥스트 키 락은 바이너리 로그에 기록되는 쿼리가 레플리카 서버에 실행될 때 소스 서버에서 만들어 낸 결과와 동일한 결과를 만들어내도록 보장하는 것이 주목적이다. 그런데 넥스트 키 락과 갭 락으로 인한 데드락이 발생하거나 다른 트랜잭션을 기다리게 만드는 일이 자주 발생한다. 가능하다면 바이너리 로그 포맷을 row 형태로 바꿔서 넥스트 키 락이나 갭 락을 줄이는 것이 좋다. 자동 증가 락 . AUTO_INCREMENT컬럼이 사용된 테이블에 동시에 여러 레코드가 INSERT되는 경우, 저장되는 각 레코드는 중복되지 않고 저장된 순서대로 증가하는 일련번호 값을 가져야 한다. 이를 위해 InnoDB 내부적으로 AUTO_INCREMENT라고하는 테이블 수준의 잠금을 사용한다. InnoDB의 다른 잠금과는 달리 AUTO_INCREMENT 락은 트랜잭션과 관계없이 INSERT나 REPLACE 문장에서 AUTO_INCREMENT 값을 가져오는 순간만 락이 걸렸다가 즉시 해제된다. 아주 짧은시간 동안 걸렸다 해제되는 잠금이라 대부분의 경우 문제가 되지 않는다. MySQL5.0 이후 버전에서는 동작 방식을 변경할 수 있다. | innodb_autoinc_lock_mode=0 : 자동 증가 락 사용, 안전하지만 동시성이 제한된다. | innodb_autoinc_lock_mode=1: . | 행 수를 모를때는 0모드와 같이 동작한다. | 행 수를 알고있을때는 여러개의 자동 증가 값을 한번에 할당 받아서 insert되는 레코드에 사용한다. | 행 수를 알고있고 bulk insert 수행시 사용자가 bulk insert 행단위 갯수를 지정하므로 auto_increment값이 실제 들어가있는 row보다 클 수 있다. | . | innodb_autoinc_lock_mode=2: 자동 증가 락을 절대 걸지않는다. 이 설정에서는 자동증가 기능은 유니크한 값이 생성된다는 것만 보장한다. | . MySQL8.0부터는 기본값이 2이다. 인덱스와 잠금 . InnoDB의 잠금은 레코드를 잠그는 것이 아니라 인덱스를 잠그는 방식으로 처리된다. 특이한 점은 변경해야 할 레코드를 찾기 위해 검색한 인덱스의 레코드를 모두 락을 걸어야한다. -- first_name컬럼만 인덱스가 걸린 상태 -- count(first_name='Georgi') == 253 -- count(last_name='Klassen') == 1 UPDATE employees SET hire_date=NOW() WHERE first_name='Georgi' AND last_name='Klassen'; . 위의 쿼리를 실행시킬때 1명의 데이터를 업데이트 시키기 위해 253명 모두가 락에 걸린다. 만약 인덱스가 하나도 안걸려있다면, 테이블의 모든 레코드에 락이 걸린다. 이런 이유로 인덱스 설계가 중요하다. 레코드 수준의 잠금 확인 및 해제 . 레코드 수준의 잠금은 그 레코드가 자주 사용되지 않는다면 오랜 시간 동안 잠겨진 상태로 잘 발견되지 않을 수 있다. 강제로 잠금을 해제하려면 KILL명령어를 이용해 MySQL 서버의 프로세서를 강제로 종료하면 된다. MySQL 8.0 버전 부터는 performence_schema의 data_locks와 data_lock_waits테이블을 통해 정보를 확인할 수 있다. ![[Pasted image 20240422223416.png|400]] ![[Pasted image 20240422223428.png|400]] ![[Pasted image 20240422223441.png|400]] ![[Pasted image 20240422223726.png|400]] ![[Pasted image 20240422223745.png|400]] 위의 결과를 보면 employees 테이블에 대해 IX(intentional exclusive) 잠금을 가지고 있으며, 특정 레코드의 쓰기 잠금을 가지고 있다는 것을 확인할 수 있다. ‘IX’ 락 모드가 설정되어 있다면, 해당 자원에 대한 배타적인 쓰기 작업이 예약되어 있는 것을 나타냅니다. 이때 REC_NOT_GAP표시가 있으므로 레코드 잠금은 갭이 포함되지 않은 순수 레코드에 대해서만 잠금을 가지고 있음을 알 수 있다. 만약 이 상황에서 17번 스레드가 잠금을 가진 상태에서 오랜 시간 멈춰있다면 . KILL 17; . 명령어를 통해 문제를 해결할 수 있다. ",
    "url": "/docs/mysql/05.%20Real%20MySQL%208.0.html#innodb-%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80-%EC%97%94%EC%A7%84-%EC%9E%A0%EA%B8%88",
    
    "relUrl": "/docs/mysql/05.%20Real%20MySQL%208.0.html#innodb-스토리지-엔진-잠금"
  },"57": {
    "doc": "05. Real MySQL 8.0",
    "title": "MySQL의 격리 수준",
    "content": "트랜잭션의 격리 수준이란 여러 트랜잭션이 동시에 처리될 때 특정 트랜잭션이 다른 트랜잭션에서 변경하거나 조회하는 데이터를 볼 수 있게 허용할지 말지를 결정하는 것이다. 크게 . | READ UNCOMMITED | READ COMMITED | REPEATABLE READ | SERIALIZABLE 4가지로 나뉜다. 위에서부터 아래로 격리 수준이 높아진다. 격리 수준이 높아질수록 서버의 처리 성능이 많이 떨어질 것으로 생각할 수 있는데, SERIALIZABLE이 아니라면 크게 성능 저하가 발생하지 않는다. | . 데이터베이스 격리 수준을 이야기하면 항상 함께 언급되는 세가지 부정합의 문제가 있다. ![[Pasted image 20240424221727.png]] . Dirty Read (더티 리드): 트랜잭션이 아직 커밋되지 않은 다른 트랜잭션의 데이터를 읽는 것을 의미합니다. Non-Repeatable Read (비 반복 가능한 리드): 같은 트랜잭션 내에서 동일한 쿼리를 두 번 실행할 때, 첫 번째와 두 번째 리드 사이에 다른 트랜잭션이 커밋되어 데이터가 변경되는 상황을 가리킵니다. Phantom Read (팬텀 리드): 동일한 쿼리를 실행했을 때, 첫 번째와 두 번째 리드 사이에 다른 트랜잭션이 커밋되어 데이터가 추가되거나 삭제되는 상황을 가리킵니다. READ UNCOMMITTED . ![[Pasted image 20240424223123.png|400]] 사용자 A가 커밋하기도전에 B가 해당 값을 읽어간다. 이처럼 어떤 트랜잭션에서 처리한 작업이 완료되지 않았는데도 다른 트랜잭션에서 볼 수 있는 현상을 더티 리드라고하고, 더티 리드가 허용되는 격리 수준이 READ UNCCOMMITTED다. 최소한 READ COMMITTED 이상의 격리 수준을 사용할 것을 권장한다. READ COMMITTED . ![[Pasted image 20240424223357.png|400]] 조회하려는 테이블의 트랜잭션 작업이 완료되지 않은 경우 Undo log를 읽어간다. 위의 예제에서 사용자 B가 A의 커밋이 끝난 뒤에 다시 조회 한다면, 이전에 조회한 값과 다른 값이 출력된다. 이러한 경우를 Non-Repeatable Read라고 부른다. 또한 데이터가 추가 또는 삭제 된다면 Phantom Read가 발생한다. READ COMMITTED 격리 수준에서는 트랜잭션 내에서 실행되는 select 문장과 트랜잭션 외부에서 실행되는 select 문장의 차이가 별로 없다. 하지만 REPEATABLE READ의 경우는 기본적으로 select 쿼리 문장도 트랜잭션 범위 내에서만 작동한다. REPEATABLE READ . InnoDB는 기본적으로 REPEATABLE READ를 사용한다. 바이너리 로그를 가진 MySQL에서는 최소 REPEATABLE READ를 사용해야한다. InnoDB는 트랜잭션이 Rollback될 가능성에 대비해 변경되기 전에 레코드르 언두 공간에 백업해두고 실제 레크도 값을 변경한다. 이러한 변경 방식을 MVCC라고 한다. Multi-Version Concurrency Control 각 트랜잭션이 데이터를 읽을 때 해당 데이터의 버전을 기록합니다. 이 때문에 여러 트랜잭션이 동시에 데이터를 읽을 때, 각 트랜잭션은 서로 다른 버전의 데이터를 읽게 됩니다. 따라서 한 트랜잭션이 데이터를 수정할 때 다른 트랜잭션에게 영향을 주지 않고 동시에 데이터를 읽을 수 있습니다. 이러한 방식으로 MVCC는 동시성을 보장하면서도 데이터의 일관성을 유지할 수 있습니다. READ COMMITTEDD도 MVCC를 이용해 commit되기 전의 데이터를 보여준다. REPEATABLE READ의 차이는 언두 영역에서 백업된 레코드의 여러 버전 가운데 몇 번째 버전까지 찾아 들어가야 하느냐에 있다. 모든 InnoDB의 트랜잭션은 고유한 트랜잭션 번호를 가지며, 언두 영역에 백업된 모든 레코드에는 변경을 발생시킨 트랜잭션의 번호가 포함되어 있다. 그리고 언두 영역의 백업된 데이터는 불필요하다고 판단되는 시점에 주기적으로 삭제된다. REPEATABLE READ 격리 수준은 MVCC를 보장하기 위해 실행 중인 트랜잭션 가운데 가장 오래된 트랜잭션 번호보다 트랜잭션 번호가 앞선 언두 영역의 데이터는 삭제할 수 없다. | ![[Pasted image 20240424224717.png | 400]] | . REPEATABLE READ 격리 수준에서도 다음과 같은 부정합이 발생할 수 있다. 위에서 자신만만하게 ‘InnoDB는 없음’ 이래놓고..? . | ![[Pasted image 20240424225031.png | 400]] | . 마지막 쿼리는 SELECT … FOR UPDATE 라는 SQL문을 사용했는데, SELECT하는 레코드에 쓰기 잠금을 걸어야 하는데, 언두 레코드에는 잠금을 걸 수 없다. 그래서 SELECT … FOR UPDATE나 SELECT … LOCK IN SHARE MODE로 조회하는 레코드는 언두 영역의 변경 전 데이터를 가져오는 것이 아니라 현재 레코드의 값을 가져오게 되는 것이다. SERIALIZABLE . 가장 단순하면서 엄격한 격리 수준이다. 그만큼 동시 처리 성능도 다른 트랜잭션 격리 수준부도 떨어진다. InnoDB 테이블에서 기본적으로 순수한 SELECT 작업은 아무런 레코드 잠금도 설정하지 않고 실행된다. 하지만 트랜잭션의 격리 수준이 SERIALIZABLE로 설정되면 읽기 작업도 공유 잠금을 획득해야만 하며, 동시에 다른 트랜잭션은 그러한 레코드를 변경하지 못하게된다. 즉 트랜잭션이 동작중에는 다른 트랜잭션이 절대 접근할 수 없다. ",
    "url": "/docs/mysql/05.%20Real%20MySQL%208.0.html#mysql%EC%9D%98-%EA%B2%A9%EB%A6%AC-%EC%88%98%EC%A4%80",
    
    "relUrl": "/docs/mysql/05.%20Real%20MySQL%208.0.html#mysql의-격리-수준"
  },"58": {
    "doc": "05. Real MySQL 8.0",
    "title": "05. Real MySQL 8.0",
    "content": " ",
    "url": "/docs/mysql/05.%20Real%20MySQL%208.0.html",
    
    "relUrl": "/docs/mysql/05.%20Real%20MySQL%208.0.html"
  },"59": {
    "doc": "05. 안정 해시 설계",
    "title": "05. 안정 해시 설계",
    "content": ". 수평적 규모 확장성을 달성하기 위해서는 요청 또는 데이터를 서버에 균등하게 나누는 것이 중요하다. 해시 키 재배치 문제 . N개의 캐시 서버가 있다고 하다. 이 서버들에 부하를 균등하게 나누는 보편적 방법은 아래의 해시 함수를 사용하는 것이다. serverIndex = hash(key) % N (N은 서버의 갯수) . 4개의 서버에 저장한다고 가정하자. ![[Pasted image 20240818180309.png]] ![[Pasted image 20240818180316.png]] . 이때 서버1에 문제가 생긴다면 서버풀의 크기는 3으로 변한다. 그 결과로 ![[Pasted image 20240818180440.png]] 대부분의 키가 재분배된다. 1번 서버가 죽으면 대부분 캐시 클라이언트가 데이터가 없는 엉뚱한 서버에 접속하게 되는 것이다. 안정 해시는 이 문제를 효과적으로 해결하는 기술이다. 안정 해시 . 안정 해시는 해시 테이블크기가 조정 될 때 평균적으로 오직 k/n개의 키만 재배치하는 해시 기술이다. k : 키의 개수, n : 슬롯의 개수 . ![[Pasted image 20240818180709.png]] 해시 공간 . ![[Pasted image 20240818180725.png]] 해시 공간의 양쪽을 구부려 접으면 위와같은 해시 링이 만들어진다. ![[Pasted image 20240818181007.png]] ![[Pasted image 20240818181125.png]] . 어떤 키가 저장되는 서버는, 해당 키의 위치로부터 시계 방향으로 링을 탐색해 나가면서 만나는 첫 번째 서버다. 서버를 추가하더라도 키 가운데 일부만 재배치하면 된다. ![[Pasted image 20240818181217.png]] . 제거도 마찬가지이다. 기본 구현법의 두가지 문제 . 첫번째 문제는 서버가 추가되거나 삭제되는 상황을 감안하면 파티션의 크기를 균등하게 유지하는게 불가능하다. 여기서 파티션은 인접한 서버 사이의 해시 공간이다. 두번째 문재는 키의 균등 분포를 달성하기가 어렵다는 것이다. 이 문제를 해결하기 위해 제안된 기법이 가상노드 또는 복제노드라는 기법이다. 가상 노드 . 가상 노드는 실제 노드 또는 서버를 가리키는 노드로서, 하나의 서버는 링 위에 여러개의 가상 노드를 가질 수 있다. ![[Pasted image 20240818181522.png]] . 가상 노드의 개수를 늘리면 키의 분포는 점점 더 균등해진다. 표준 편차는 데이터가 어떻게 퍼져 나갔는지를 보이는 척도이다. 가상 노드의 개수를 더 늘리면 표준 편차의 값은 더 떨어진다. 시스템 요구사항에 맞도록 가상 노드 개수를 적절히 조정해야 한다. ",
    "url": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/05.%20%EC%95%88%EC%A0%95%20%ED%95%B4%EC%8B%9C%20%EC%84%A4%EA%B3%84.html",
    
    "relUrl": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/05.%20%EC%95%88%EC%A0%95%20%ED%95%B4%EC%8B%9C%20%EC%84%A4%EA%B3%84.html"
  },"60": {
    "doc": "05. 책임 할당하기",
    "title": "05. 책임 할당하기",
    "content": ". 데이터 중심의 설계는 행동보다 데이터를 먼저 결정하고 협력이라는 문맥을 벗어나 고립된 객체의 상태에 초점을 맞추기 때문에 캡슐화를 위반하기 쉽고, 요소들 사이의 결합도가 높아지며, 코드를 변경하기 어려워진다. 이를 해결할 수 있는 방법은 데이터가 아닌 책임에 초점을 맞추는 것이다. 책임에 초점을 맞춰 설계할 때 직면하는 가장 큰 어려움은 어떤 객체에게 어떤 책임을 할당할지를 결정하기가 쉽지 않다는 것이다. GRASP패터는 이를 위한 답을 제시해준다. 책임 중심 설계는 두가지 원칙은 따라야 한다. | 데이터보다 행동을 먼저 결정하라 | 협려깅라는 문맥 안에서 책임을 결정하라 | . 책임 주도 설계 . | 시스템이 사용자에게 제공해야 하는 기능인 시스템 책임을 파악한다 | 시스템 책임을 더 적은 책임으로 분할한다 | 분할된 책임을 수행할 수 있는 적절한 객체 또는 역할을 찾아 책임을 할당한다 | 객체가 책임을 수행하는 도중 다른 객체의 도움이 필요한 경우 이를 책임질 적절한 객체 또는 역할을 찾는다 | 해당 객체 또는 역할에게 책임을 할당함으로써 두 객체가 협력하게 한다 | . 책임 할당을 위한 GRASP 패턴 General Rsponsiblity Assignment Software Pattern 일반적인 책임 할당을 위한 소프트웨어 패턴 . 설계를 시작하기 전에 도메인에 대한 개략적인 모습을 그려 보는 것이 유용하다. ![[Pasted image 20240529125448.png]] . 설계를 시작하는 단계에서는 개념들의 의미와 관계가 정확하거나 완벽할 필요가 없다. 도메인 개념을 정리하는 데 너무 많은 시간을 들이지 말고 빠르게 설계와 구현을 진행하자 . 올바른 도메인 모델이란 존재하지 않는다 (접기/펼치기) ``` 올바른 도메인 모델이란 존재하지 않는다 그림 5.1은 도메인 모델이 2장에서 설명한 도메인 모델과는 약간 다르다. 2장에서는 할인 정책이라는 개념이 하나의 독립적인 개념으로 분리돼 있었지만 그림 5.1에서는 영화의 종류로 표현돼 있다. 어떤 쪽이 올바른 도메인 모델인가? 만약 두 도메인 모델 모두 올바른 구현을 이끌어낼 수만 있다면 정답은 '둘 다'다. 많은 사람들이 도메인 모델은 구현과는 무관하다고 생각하지만 이것은 도메인 모델의 개념을 오해한 것에 불과하다. 도메인 모델은 도메인을 개념적으로 표현한 것이지만 그 안에 포함된 개념과 관계는 구현의 기반이 돼야 한다. 이것은 도메인 모델이 구현을 염두에 두고 구조화되는 것이 바람직하다는 것을 의미한다. 반대로 코드의 구조가 도메인을 바라보는 관점을 바꾸기도 한다. 이번 장에서는 그림 5.1의 도메인 모델로 시작하기 때문에 실제로 구현된 코드는 2장과는 약간 다르다는 사실을 알게 될 것이다. 이것은 도메인 모델의 구조가 코드의 구조에 영향을 미치기 때문이다. 하지만 이번 장의 마지막에 이르면 도메인 모델이 2장과 동일하게 변경되는데 이것은 유연성이나 재사용성 등과 같이 실제 코드를 구현하면서 얻게 되는 통찰이 역으로 도메인에 대한 개념을 바꾸기 때문이다. 이것은 올바른 도메인 모델이란 존재하지 않는다는 사실을 잘 보여준다. 필요한 것은 도메인을 그대로 투영한 모델이 아니라 구현에 도움이 되는 모델이다. 다시 말해서 실용적이면서도 유용한 모델이 답이다. ``` 책임 주도 설계 방식의 첫 단계는 애플리케이션이 제공해야 하는 기능을 애플리케이션의 책임으로 생각하는 것이다. 객체는 자신의 상태를 스스로 처리하는 자율적인 존재여야 한다. 객체의 책임과 책임을 수행하는 데 필요한 상태는 동일한 객체 안에 존재해야 한다. GRASP에서는 이를 정보 전문가 패턴이라고 부른다. 정보 전문가 패턴에 따르면 예매하는데 필요한 정보를 가장 많이 알고있는 객체에게 예매하라 메시지를 처리할 책임을 할당해야 한다. 상영은 영화에 대한 정보와 상영 시간, 상영 순번처럼 영화 예매에 필요한 다양한 정보를 알고 있다. 따라서 영화 예매를 위한 전문가는 상영이다. 높은 응집도와 낮은 결합도 설계는 트레이드오프 활동이라는 것을 기억하라. 동일한 기능을 구현할 수 있는 무수히 많은 설계가 존재한다. 올바른 책임 할당을 위해 정보 전문가 패턴 이외의 다른 책임 할당 패턴을 함께 고려할 필요가 있다. 앞서 설계한 할인을 계산하라 는 Movie 객체를 통해 Movie가 DiscountCondition에게 할인 여부를 판단하라 메시지를 전송한다. 그렇다면 Movie가 아닌 Screeninig과 DiscountCondition가 협력하게 하는 것은 어떨까? 기능적 측면에서만 보면 차이가 없다. 하지만 응집도와 결합도 측면에서 차이가 있다. GRASP에서는 낮은 결합도 패턴과 높은 응집도 패턴이라고 부른다. 낮은 결합도 패턴은 의존성을 낮추고 변화의 영향을 줄이며 재사용성을 증가시키는데 필요하다. Movie는 이미 DiscountCondition과 결합되어있고, Screening은 추가를 해줘야한다. 때문에 낮은 결합도 측면에서는 Movie와 협력하는 것이 . 더나은 설계이다. 높은 응집도 패턴은 복잡성을 관리할 수 있는 수준으로 유지하는데 필요하다. Screening의 가장 중요한 책임은 예매를 생성하는 것이다. Screening이 DiscountCondition과 협력해야 한다면 요금 계산과 관련된 책임 일부를 떠안아야 한다. Screening은 DiscountCondition이 할인 여부를 판단할 수 있고 Movie가 할인 여부를 필요로 한다는 사실 역시 알고 있어야 한다. 반면 Movie의 주된 책임은 영화 요금을 계산하는 것이다. 따라서 요금을 계산하는데 할인 조건을 판단하기 위해 DiscountCondition과 현력하는 것이 . 더나은 설계 대안이다. 창조자에게 객체 생성 책임을 할당하라 . 영화 예매 협력의 최종 결과물은 Reservation 인스턴스를 생성하는 것이다. 이것은 협력에 참여하는 어떤 객체에게는 Reservation 인스턴스를 생성할 책임을 할당해야 한다는 것을 의미한다. GRASP의 창조자 패턴은 이같은 경우에 사용할 . 수있는 책임 할당 패턴이다. CREATOR 패턴 객체 A를 생성해야 할 때 어떤 객체에게 객체 생성 책임을 할당해야 하는가? 아래 조건을 최대한 많이 만족하는 B에게 객체 생성 책임을 할당하라. | ﻿﻿B가 A 객체를 포함하거나 참조한다 | ﻿﻿B가 A 객체를 기록한다. | ﻿﻿B가 A 객체를 긴밀하게 사용한다. | ﻿﻿B가 A 객체를 초기화하는 데 필요한 데이터를 가지고 있다(이 경우 B는 A에 대한 정보 전문가다) | . CREATOR 패턴의 의도는 어떤 방식으로든 생성되는 객체와 연결되거나 관련될 필요가 있는 객체에 해당 객체를 생성할 책임을 맡기는 것이다. 생성될 객체에 대해 잘 알고 있어야 하거나 그 객체를 사용해야 하는 객체는 어떤 방식으로든 생성될 객체와 연결될 것이다. 다시 말해서 두 객체는 서로 결합된다. 이미 결합돼 있는 객체에게 생성 책임을 할당하는 것은 설계의 전체적인 결합도에 영향을 미치지 않는다. 결과적으로 CREATOR 패턴은 이미 존재하는 객체 사이의 관계를 이용하기 때문에 설계가 낮은 결합도를 유지할 수 있게 한다. ![[Pasted image 20240529132355.png]] 따라서 Screening을 Reservation의 Creator로 선택하는 것이 적절해 보인다. public class Screening { public Reservation reserve(Customer customer, int audienceCount) { } } . 협력 관점에서 Screening은 예매하라 메시지에 응답할 수 있어야 한다. 책임이 결정뙛으므로 책임을 수행하는 . 데필요한 인스턴스 변수를 결정해야 한다. public class Screening { private Movie movie; private int sequence; private LocalDateTime whenScreened; public Reservation reserve(Customer customer, int audienceCount) { return new Reservation (customer, this, calculateFee(audienceCount), audienceCount) }; private Money calculateFee(int audienceCount) { return movie.calculateMovieFee(this).times (audienceCount); } ｝ . DiscountCondition 개선하기 . DiscountCondition은 변경에 취약하다. | 새로운 할인 조건 추가 . | isSatisfiedBy(Screening screening) {…} 메서드 안의 if else 구문을 수정해야 한다. 물론 새로운 할인 조건이 새로운 데이터를 요구한다면 DiscountCondition에 속성을 추가하는 작업도 필요하다. | . | 순번 조건을 판단하는 로직 변경 . | isSatisfiedBySequence 메서드 내부 구현을 수정해야 한다. 물론 순번 조건을 판단하는 . 데필요한 데이터가 변경된다면 DiscountCondition의 sequence속성 역시 변경해야 할 것이다. | . | 기간 조건을 판단하는 로직이 변경되는 경우 . | isSatisfiedByPeriod 메서드 내부의 구현을 수정해야한다. 물론 기간 조건을 판단하는 데 필요한 데이터가 변경된다면 DiscountCondition의 날짜 속성 역시 변경되어야 한다. | . | . 위 이유에 따라 클래스를 분리해야한다. ![[Pasted image 20240529133920.png]] 위와 같이 분리를 하게되면 Movie 클래스가 period class, sequence class 둘다 가지고있어야한다. public class Movie { private List&lt;PeriodCondition) periodConditions; private List&lt;SequenceCondition&gt; sequenceConditions; ... } . ![[Pasted image 20240529134057.png]] . public class PeriodCondition { private DayOfWeek dayOfWeek; private LocalTime startTime; private LocalTime endTime; ... } public class SequenceCondition { private int sequence; ... } . public class PeriodCondition implements DiscountCondition { ... } public class SequenceCondition implements DiscountCondition { ... } public class Movie { private List&lt;DiscountCondition&gt; discountConditions; public Money calculateMovieFee(Screening screening) { if (isDiscountable(screening)) { return fee.minus(calculateDiscountAmount()); } return fee; } private boolean isDiscountable(Screening screening) { return discountConditions.stream).anyMatch(condition -&gt; condition.isSatisfiedByscreening)); } ｝ . DB에 저장할때는 어떻게하지? Inheritance 사용 Joined or Single . Movie도 같은 방식으로 가능 . ![[Pasted image 20240529134823.png]] . 변경과 유연성 . 설계를 주도하는 것은 변경이다. 개발자로서 변경에 대비할 수 있는 두 가지 방법이 있다. | 코드를 이해하고 수정하기 쉽도록 최대한 단순하게 설계하는 것 | 코드를 수정하지 않고도 변경을 수용할 . 수있도록 코드를 더 유연하게 만드는 것 후자가 더 좋은 방법이다. | . 새로운 할인 정책이 추가될 때마다 인스턴스를 생성하고, 상태를 복사하고, 식별자를 관리하는 코드를 추가하는 일은 번거로울뿐만 아니라 오류가 발생하기도 쉽다. 이 경우 코드의 복잡성이 높아지더라도 할인 정책의 변경을 쉽게 수용할 . 수있게 코드를 유연하게 만드는 것이 더 좋은 방법이다. ![[Pasted image 20240529140007.png]] . 해결 방법은 상속 대신 합성을 사용하는 것이다. 이제 금액 할인 정책이 적용된 영화를 비율 할인 정책으로 바꾸는 일은 Movie에 연결된 DiscountPolicy의 인스턴스를 교체하는 단순한 작업으로 바뀐다. Movie movie = new Movie(\"타이타닉\", Duration.ofMinutes(120), Money wons (10000) , new AmountDiscountPolicy(...)); movie.changeDiscountPolicy(new PercentDiscountPolicy(...)); . 책임 주도 설계에 익숙해지기 위해서는 부단한 노력과 시간이 필요하다. 개인적으로 책임과 객체 사이에서 방황할 때 돌파구를 찾기 위해 선택하는 방법은 최대한 빠르게 목적한 기능을 수행하는 코드를 작성하는 것이다. 아무것도 없는 상태에서 책임과 협력에 관해 고민하기 보다는 일단 실행되는 코드를 얻고 . 난후에 코드 상에 명확하게 드러나는 책임들을 올바른 위치로 이동시키는 것이다. 주의점은 코드를 수정한 후에 겉으로 드러나는 동작이 바뀌어서는 안된다. 이처럼 이해하기 쉽고 수정하기 쉬운 소프트웨어로 개선하기 위해 겉으로 보이는 동작은 바꾸지 않은 채 내부 구조를 변경하는 것을 리팩터링이라고 부른다. 긴 메서드는 응집도가 낮기 때문에 이해하기 어렵고 재사용하기도 어려우며 변경하기도 어렵다. 이런 메서드를 몬스터 메서드라고 부른다. 작게 분리하자. 객체를 자율적으로 만들자 . 객체를 자율적으로 만들기 위해서는 메서드가 사용하는 데이터를 저장하고 있는 클래스로 메서드를 이동시키면 된다. ",
    "url": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/05.%20%EC%B1%85%EC%9E%84%20%ED%95%A0%EB%8B%B9%ED%95%98%EA%B8%B0.html",
    
    "relUrl": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/05.%20%EC%B1%85%EC%9E%84%20%ED%95%A0%EB%8B%B9%ED%95%98%EA%B8%B0.html"
  },"61": {
    "doc": "06. RDS",
    "title": "06. RDS",
    "content": ". 관계형 데이터베이스 서비스 . | Postgres | Mysql | MariaDB | Oracle | Microsoft SQL server | Aurora(AWS properietary database) . | rds는 데이터베이스 프로비저닝과 기본 운영체제 패치가 자동으로 되어있다 (완전 자동화) | 지속적으로 백업이 생성됨 | 성능을 대시보드로 확인 가능 | 읽기전용 복사를 통해 성능 향상 | 재해 복구 | 다중 AZ | 유지기간에 업그레이드 가능 | 수직 수평 스케일링 가능 | . 단점은 ssh액세스가 불가능 . | rds db를 만들때 스토리지를 설정하는데 공간이 부족하면 오토스케일링 기능으로 이를 감지해 스토리지를 확장한다. db를 다운시키는 작업따윈 필요없다 | 최대 스토리지를 정하는 작업이 필요하고 현재상태에서 10퍼센트가 남은경우 5분이 지났을때 (설정한지 6시간이 지났을때)오토스케일링이 동작한다 | 모든 엔진에서 지원한다 | . 읽기전용 복제본 . | 15개까지 가능 | 동일한 가용영역 또는 가용영역이나 리전을 결쳐서 생성 할 수 있다. | 비동기식 복제 | 읽기복제본은 db로 승격시킬수있다 | 비용 . | 데이터가 이동할떄 비용 발생 | 동일한 리전 내에 있을때는 비용이 발생하지 않는다 | . | . 다중 AZ . | 재해 복구에 사용 | 마스터 db는 대기 인스턴스에 동기식으로 복제 | 어플리케이션은 DNS를 통해 db에 접근한다 | 마스터 db에 문제가 생기면 동기식으로 연결된 db가 장애대응을 한다 | 스탠바이 db는 대기 목적으로만 사용한다 | 다중 az로 설정할 수 있다 | 단일 az에서 다중az로 바꿀때는 downtime이 없다 | 과정은 메인db에서 스냅샷을찍어 스탠바이db를 생성후 메인db와 스탠바이db가 싱크를 맞춘다 | . RDS custom . | 오라클, microsoft만 지원 | 데이터베이스와 운영체제 관리자 전체 권한을 갖게된다 | SSH SSM 접근할 수 있다 | 자동화를 꺼두는게 좋다 | SSH접근이 가능하기때문에 오류가 날 가능성이 많다 | 스냅샷을 찍어두는게 좋다 | . ",
    "url": "/docs/aws/06.%20RDS.html",
    
    "relUrl": "/docs/aws/06.%20RDS.html"
  },"62": {
    "doc": "06. RDS",
    "title": "오로라",
    "content": "시험에 잘나옴 자세히 알필요없음 동작 이해 필요 . | Postgres, Mysql 호환 | 클라우드 최적화 | mysql보다 5배 postgres의 3배 성능 | 스토리지를 자동 증가 (시작은 10GB 최대 128TB) | Sysops | 15개까지 읽기복사 | 복사속도도 빠름 | 가용성이 좋음 | rds에비해 20퍼 더비쌈 . | 높은가용성, 읽기 스케일링 | 3개의 az에 걸쳐 무언가 기록할때 6개의 사본 저장 | 복사시 쓰기는 4개 읽기는 3개만 필요 | 일부 데이터가 문제가있으면 백엔드에서 자가복구함 | 수백개의 볼륨을 사용하여 리스크 감소 | 오로라는 rds의 다중 az와 유사하다 | 오로라에도 마스터가 존재하고 여기서 쓰기를 받는다 | 마스터가 동작하지않으면 30초안에 장애조치가 발동 | 읽기복제는 15개까지 가능 | 마스터에 문제가생기면 다른db가 마스터가 된다 | 리전간 복제 제공 | . 오로라 클러스터 리드 엔드포인트 라이트 엔드포인드 라이트 엔드포인트는 마스터에만 연결 리드 엔드포인트는 복사된 리드 db에 로드밸런싱으로 연결 . 복제본 오토 스케일링 . 클라이언트 세개의 오로라 인스턴스 . | 1개의 라이터 엔드포인트를 통한 쓰기용 | 2개의 리더 엔드포인트를 통한 읽기용 | 많은 읽기 요청 발생 &amp; cpu 사용량 크게 증가 | 이때 읽기용 db 복제 오토스케일링 | 인스턴스가 증가할때 더 큰 스펙의 인스턴스를 생성한다 | 이렇게 하는 이유는 특정 복제본에 대해 분석 쿼리를 실행하는것이 더 좋을것 같아서이다 | 더 큰 스펙의 인스턴스를 생성한 이후 커스텀 엔드포인트를 만들어 이들을 연결한다 | 기존에 사용하던 엔드포인트는 사용하지않게된다 | 기존의 엔드포인트에 연결된 인스턴스는 사라지지않지만 사용하지않게된다 | (분석 쿼리는 뭔데?) | . 오로라 서버리스 . | 실제 사용량에 따라 자동화된 데이터베이스 인스턴스화 및 오토스케일링을 제공 | 워크로드가 드물거나 간헐적이거나 예측할 수 없는 경우에 유용 | 용량 계획을 세울 필요가 없다 | 초당 사용량으로 요금을 지불 (비용에 효율적) | 클라이언트는 오로라에서 관리하는 프록시 플릿과 대화하게 된다. | 백엔드에서는 서버리스 방식으로 워크로드에따라 많은 오로라 인스턴스가 생성된다 | 따라서 용량을 미리 프로비저닝 할 필요가 없다 | . 오로라 멀티 마스터 . | 라이터 노드에 대해 지속적인 쓰기 가용성을 원하는 경우 | 즉 오로라 클러스터에서 모든 오로라 인스턴스는 라이터 노드이다 | 하나의 새 마스터가 있고 그 마스터가 실패한경우 다른 인스턴스가 마스터가 된다 | 클라이언트는 여러개의 오로라 인스턴스에 대한 여러 데이터베이스 연결을 유지할 수 있다 | . 글로벌 오로라 . 리전간 읽기 복제본이 있는경우 재해복구용 설치가 간단 글로벌 데이터베이스 설정은 권장되는 방법이다 기본 리전에서 읽기 및 쓰기가 모두 일어난다 하지만 최대 5개의 보조 읽기 리전도 있다. 복제 지연이 1초 미만 보조 리전당 최대 15개의 읽기 복제본을 설정 할 수 있다. 전세계 읽기 워크로드 지연시간을 줄일 수 있다 재해가 일어난 경우 다른 리전으로 복구하는데 1분 미만이 걸린다 . 주의 오로라 글로벌 데이터베이스의 데이터 리전 간에 복제하는데 평균 1초 미만이 소요된다 해당 문장이 나오면 글로벌 오로라를 사용하라는 뜻 . 오로라 머신 러닝 . 머신러닝 서비스 간의 간단하고 최적화된 안전한 통합이다 . | SageMaker . | 백엔드에서 모든 종류의 머신러닝 모델을 사용할 수 있게 해준다 | . | Amazon Comprehend . | 감성 분석을 할 수 있다 | . | . 오로라가 이들과 통합되어있다 정도만 알면 된다 . 사용 사례 . | 사기 탐지 | 광고 타겟팅 | 감정 분석 | 제품 추천 | . 백엔드가 사용자의 데이터를 sagemaker에 데이터를 보내면, 이를 comprehend를 통해 분석해서 예측 데이터를 반환한다. ",
    "url": "/docs/aws/06.%20RDS.html#%EC%98%A4%EB%A1%9C%EB%9D%BC",
    
    "relUrl": "/docs/aws/06.%20RDS.html#오로라"
  },"63": {
    "doc": "06. RDS",
    "title": "백업",
    "content": ". | 자동화된 백업 . | rds서비스가 자동으로 매일 데이터베이스의 전체 백업을 수행한다. (데이터 베이스 백업 기간동안) | 5분마다 트랙잭션 로그가 백업된다 | 자동 백업을 통해 언제라도 5분전으로 복원할 수 있다 | 자동 백업 보존 기간은 1~35일 사이로 설정 가능 | 이 기능을 사용하지 않으려면 0으로 설정한다 | . | 수동 데이터베이스 스냅샷 . | 수동으로 한백업을 원하는 기간동안 유지 | 자동 백업은 만료되는 반명 수동 스냅샷은 원하는 기간동안 보관할 수 있다 | 백업은 비용을 절감하고싶을때도 진행한다 . | 사용한 데이터를 스냅샷으로 만든다음 원본 데이터베이스를 삭제하면 비용을 절감할 수 있다 | . | . | . 오로라 . | 자동화된 백업 . | 1~35일까지 가능, 하지만 비활성 불가능 | rds는 비활성이 가능하다 | 시점 복구 기능이 있다 | . | 수동 스냅샷 . | 사용자가 수동으로 트리거할 수 있으며, 원하는 기간동안 유지할 수 있다 | . | . rds백업과 오로라 백업은 매우 비슷하다 . 복원 옵션 . | 새 데이터배이스 | S3에서 mysql데이터베이스를 복원할 수 있다 . | 온프레미스 데이터베이스의 백업을 생성한 다음 객체 스토리지인 amazon S3에 배치 | S3에서 백업 파일을 복원 | . | mysql 오로라 클러스터로 복원하려는 경우 . | 온프레미스 데이터베이스를 다시 백업 | XtraBackup이란걸 사용해서 가능 | 백업 파일을 S3로 보내서 백업을 복원할 수 있다 | 차이점은 rds mysql로 복원할때는 데이터베이스 백업만 있으면 되지만 오로라는 XtraVackup으로 백업 한다음 S3에서 오로라 db 클러스터로 백업해야한다 | . | . 근데 복원 옵션이라면서 왜자꾸 백업백업 거림? . 온-프레미스는 무엇일까요? 기업이 자체적으로 IT 인프라를 소유, 관리 및 운영하는 경우를 ‘온-프레미스’라고 합니다. 오로라 데이터베이스 복제 . 기존 데이터베이스 클러스터에서 새로운 오로라 데이터베이스 클러스터를 생성할 수 있다 . copy on write 프로토콜을 사용한 복제는 매우 빠르다 . 처음 데이터베이스 복제본을 만들때는 원래 데이터베이스 클러스터와 동일한 데이터 볼륨을 사용하게 된다 데이터를 복사하지않는다 새로운 db클러스터가 생성되면 스토리지가 할당되고, 데이터가 복사 및 분리된다 . 데이터베이스 복제는 빠르고 비용 효율적이며, 프로덕션 데이터베이스에 영향을 주지 않는다 . 스냅샷 및 복원 기능도 필요없다 . ",
    "url": "/docs/aws/06.%20RDS.html#%EB%B0%B1%EC%97%85",
    
    "relUrl": "/docs/aws/06.%20RDS.html#백업"
  },"64": {
    "doc": "06. RDS",
    "title": "RDS Security",
    "content": ". | at-rest encryption . | RDS 및 오로라 데이터베이스에 저장된 데이터를 암호화 할 수 있다 | KMS를 사용해 마스터와 모든 복제본의 암호화가 이루어진다 | 마스터db가 암호화 되어있지 않다면 읽기 전용 복제본은 암호화 할 수 없다 | 암호화 되어있지 않은 기존 데이터베이스를 암호화 하려면 암호화 되지 않은 데이터베이스의 데이터베이스 스냅샷을 가지고 와서 암호화된 데이터베이스 형태로 데이터베이스 스냅샷을 복원해야 한다 | . | in-flight encryption . | 클라이언트와 데이터베이스 간의 전송중 데이터 암호화 | 클라이언트는 aws에서 제공하는 TLS 루트 인증서를 사용해야한다 | . | iam authentication . | rds와 오로라이므로 사용자 이름과 패스워드라는 전통적인 조합을 사용할 수도 있다 | aws이기도 하므로 iam역할을 사용해서 데이터베이스에 접속할 수도 있다 | . | security group . | 보안 그룹을 사용해서 데이터베이스에 대한 네트워크 액세스를 통제할 수도 있다 | 특정 포트, ip, 보안 그룹을 허용하거나 차단할 수 있다 | . | RDS와 오로라에는 SSH액세스가 없다 . | 다만 aws의 rds커스텀 서비스를 사용한다면 예외이다 | . | 감사로그 : 시간에 따라 rds및 오로라에서 어떤 쿼리가 생성되는지를 확인하려면 감사로그를 활성화 시키면 된다 . | 장기간 보관하고싶다면 cloudWatch Log에 전송해야한다 | . | . ",
    "url": "/docs/aws/06.%20RDS.html#rds-security",
    
    "relUrl": "/docs/aws/06.%20RDS.html#rds-security"
  },"65": {
    "doc": "06. RDS",
    "title": "Amazon RDS Proxy",
    "content": "VPC 내에 RDS 데이터베이스를 배포할 수 있다 완전 관리형 RDS 데이터베이스 프록시도 배포할 수 있다 . Amazon RDS 프록시를 사용하면 애플리케이션이 데이터베이스 내에서 데이터베이스 연결 풀을 형성하고 공유할 수 있다 . 애플리케이션을 RDS 데이터베이스 인스턴스에 일일이 연결하는 대신 프록시가 하나의 풀에 연결을 모아 RDS 데이터베이스 인스턴스로 가는 연결이 줄어든다 왜? . | RDS데이터베이스 인스턴스에 연결이 많은 경우 CPU와 RAM등 데이터베이스 리소스의 부담을 줄여 데이터베이스 효율성을 향상 시킬 수있다. 데이터베이스에 개방된 연결과 시간초과를 최소화할 수 있기 때문이다 (시험에 나온다) | . RDS프록시는 완전한 서버리스로 오토스케일링이 가능해 용량을 관리할 필요가 없고 가용성이 높다 다중 AZ지원 RDS에 장애조치가 발생하면 기본 인스턴스가 아니라 대기 인스턴스로 실행되며 RDS프록시 덕분에 RDS와 오로라의 장애 조치 시간을 66%까지 줄일 수 있다 - 메인 RDS 데이터베이스 인스턴스에 애플리케이션을 모두 연결하고 장애 조치를 각자 처리하게 하는 대신 장애 조치와 무관한 RDS 프록시를 연결한다 - RDS프록시가 장애 조치가 발생한 RDS 데이터베이스 인스턴스를 처리하므로 장애 조치 시간이 개선된다 . 프록시는 Mysql, PostgreSql, MariaDB용 RDS지원 Mysql, PostgreSQL용 오로라를 지원 . 데이터베이스에 IAM인증을 강제함으로써 IAM인증을 통해서만 RDS 데이터베이스 인스턴스에 연결하도록할 수 있다 자격증명은 AWS Secrets Manager 서비스에 안전하게 저장된다 . 데이터베이스에 IAM인증을 강제하고싶다면 프록시를 사용해라 . RDS는 퍼블릭 액세스가 절대로 불가능하다 VPC내에서만 액세스할 수 있다. 인터넷을 통해 RDS프록시에 연결할 수 없으니 보안이 훌륭하다 . 람다 함수와 RDS프록시를 함께 사용하면 좋다 . | 증식하는 람다가 RDS연결하게되면 개판날거다 | 개방된 연결에 시간초과도 발생하니 문제가 생긴다 | RDS프록시를 사용해서 해결할 수 있따 | 람다 함수의 연결 풀을 생성하면 람다 함수가 rds프록시를 오버로드한다 | rds프록시가 풀을 생성하면 rds 데이터베이스 인스턴스 연결이 줄어 문제를 해결할 수 있다 | . 엑셀도 파이썬으로 진행하는게 좋을까? db무는코드나 여타 다른코드는? 람다를 활용하면 카프카 필요없잖슴? 오케스트라 람다 필요함? 단일로 진행해도 될듯? 빠르면 좋잖슴? 그럼 마스터노드랑 서브노드로 구성해서 병합하는 방향도 좋을듯? . ",
    "url": "/docs/aws/06.%20RDS.html#amazon-rds-proxy",
    
    "relUrl": "/docs/aws/06.%20RDS.html#amazon-rds-proxy"
  },"66": {
    "doc": "06. RDS",
    "title": "Amazon ElastiCache",
    "content": "RDS가 관계형 데이터베이스를 관리하는 것과 같은 방식이다 . 엘라스틱 캐시는 캐싱 기술인 redis 또는 Memcached를 관리할 수 있도록 도와준다 . 캐시란? 캐시는 매우 높은 성능과 짧은 지연시간을 가진 인메모리 데이터베이스 . 캐시는 읽기 집약적인 워크로드에서 데이터베이스의 로드를 줄여준다 . 일반적인 쿼리는 캐시에 저장되므로, 매번 데이터베이스를 쿼리하지 않아도 된다 . 캐시만 사용하여 쿼리의 결과를 검색할 수 있다 . 애플리케이션의 상태를 엘라스틱캐시에 저장해서 애플리케이션을 상태 비저장형으로 할 수 있게 도와준다 . RDS와 동일한 이점이 있기 때문에, aws는 데이터베이스의 운영 체제를 유지 관리할 수 있다 . 패치, 최적화, 설정, 구성, 모니터링, 장애복구, 백업 등 . 엘라스틱캐시를 사용하는 경우 애플리케이션의 코드를 많이 바꿔야한다 그냥 캐시를 껐다 켰다 하면 되는 게 아니다 . 캐시를 쿼리하도록 애플리케이션을 변경해야 한다. 데이터베이스를 쿼리하기 전이나 후에 . 엘라스틱 캐시를 사용하기 위한 아키텍처 . 애플리케이션은 일단 앨라스틱 캐시로 요청을 한다. 이미 실행된 쿼리라면 캐시 히트라고한다. 캐시히트가 됐다면 앨라스틱 캐시에서 바로 답을 준다. db로 이동하는 시간 절약. 캐시 미스가 발생하면 db로 요청을 보내서 읽는다. 다른 애플리케이션이나 다른 인스턴스에서 같은 쿼리가 발생하면 데이터를 캐시에 다시 쓸 수 있다. 캐시 무효화 전략이 있어야한다 가장 최신 데이터만 사용되어야 하기떄문 . 또다른 아키텍처로는 세션을 저장한다 애플리케이션을 상태 비저장으로 만들기 위해 즉, 사용자가 어떤 애플리케이션에 로그인하면, 애플리케이션이 세션 데이터를 앨라스틱케시에 쓴다 사용자가 애플리케이션의 다른 인스턴스로 리디렉션되면, 애플리케이션은 그 세션의 세션 캐시를 앨라스틱 캐시에서 직접 검색할 수 있으므로, 사용자는 여전히 로그인 상태이다 . Redis vs Membcached . redis 자동 장애 조치기능이 있는 다중 az가 있다. 읽기 복제본이 있다 rds와 매우 유사 AOF 지속성을 이용한 데이터 내구성이 있다. 백업 및 복원 기능이 있다 .  AOF(Append On File) 방식은 redis의 모든 write/update 연산 자체를 모두 log 파일에 기록하는 형태이다. 캐시로서, set 및 정렬된set를 지원한다 . redis는 복제되는 캐시라고 생각하면 된다. 가용성과 내구성이 뛰어나다 . memCached 멀티노드 사용 (데이터 샤딩) 고가용성이 없고 복제가 일어나지 않으며 영구 캐시가 아니다 백업 및 복원도 없다 멀티스레드 아키텍처이다 memcached에서는 여러 인스턴스가 모두 샤딩을 통해 작동된다 memcached는 분산되어있는 순수한 캐시이다. 데이터가 손실되어도 괜찮은 경우 사용 . ",
    "url": "/docs/aws/06.%20RDS.html#amazon-elasticache",
    
    "relUrl": "/docs/aws/06.%20RDS.html#amazon-elasticache"
  },"67": {
    "doc": "06. RDS",
    "title": "ElasticCache Security",
    "content": "앨라스틱 캐시는 redis에서만 iam인증을 지원하며, 나머지 경우에는 사용자 이름과 비밀번호를 사용하면 된다 . 앨라스틱 캐시에서 iam정책을 정의하면 aws api 수준 보안에만 사용된다 . redis auth라는 redis내 보안을 통해 비밀번호와 토큰을 설정할 수 있다 (redis 클러스터를 만들때) . 또한 SSL 전송 중 암호화도 지원한다 . memcached는 SASL 기반 승인을 제공한다 상당히 고급 메커니즘이다 (이름만 기억하면 된다) . 앨라스틱 캐시에 데이터를 로드하는 패턴에는 세가지 종류가 있다 . | Lazy Loading . | 지연로딩 | 모든 데이터가 캐시되고 데이터가 캐시에서 지체될 수있다 | . | Write Through . | 데이터베이스에 데이터가 기록될 때마다 캐시에 데이터를 추가하더나 업데이트한다 | 데이터가 지체되지 않는다 | . | Session Store . | 유지 시간 기능을 사용해서 세션을 만료할 수 있다 | . | . 지연 로딩 전략 애플리케이션 히트가 있는 경우, 앨라스틱 캐시에서 데이터를 가져온다 캐시 미스의 경우 데이터베이스에서 읽고 캐시에 쓰게된다 지연로딩이라고 불리는 이유는 캐시 히트가 없는 경우에만 데이터를 앨라스틱케시에 로드하기 때문이다 . 사용 사례 . | 게이밍 리더보드 만들기 | 순위 정하기에 사용 | redis에는 정렬된 세트라는게 존재 | 고유성과 요소 순서를 모두 보장한다 | 요소가 추가될때마다 실시간으로 순서를 매긴다음 올바른 순서로 추가한다 | redis 클러스터가 있는 경우 실시간 리더보드를 만들 수 있다 | 모든 redis캐시는 동일한 리더보드를 사용할 수 있다 | 즉, 클라이언트가 redis를 사용하여 앨라스틱캐시와 대화할 때 이 실시간 리더보드에 액세스할 수 있으며, 애플리케이션 측에서 이 기능을 프로그래밍할 필요가 없다 | 정렬된 세트와 함께 redis를 활용하여 실시간 리더보드에 액세스할 수 있다 시험에 나올 수 있음 | . **중요한 포트:** - FTP: 21 - SSH: 22 - SFTP: 22 (SSH와 같음) - HTTP: 80 - HTTPS: 443 **vs RDS 데이터베이스 포트:** - PostgreSQL: 5432 - MySQL: 3306 - Oracle RDS: 1521 - MSSQL Server: 1433 - MariaDB: 3306 (MySQL과 같음) - Aurora: 5432 (PostgreSQL와 호환될 경우) 또는 3306 (MySQL과 호환될 경우) . ",
    "url": "/docs/aws/06.%20RDS.html#elasticcache-security",
    
    "relUrl": "/docs/aws/06.%20RDS.html#elasticcache-security"
  },"68": {
    "doc": "06. Real MySQL 8.0",
    "title": "6장",
    "content": ". InnoDB 버퍼풀은 디스크에서 데이터를 읽거나 쓸 때 사용되는 메모리 영역입니다. 이 영역은 InnoDB가 자주 액세스하는 데이터와 인덱스 페이지의 복사본을 보유하고 있어서 데이터베이스 작업을 더 빠르게 처리할 수 있습니다. ",
    "url": "/docs/mysql/06.%20Real%20MySQL%208.0.html#6%EC%9E%A5",
    
    "relUrl": "/docs/mysql/06.%20Real%20MySQL%208.0.html#6장"
  },"69": {
    "doc": "06. Real MySQL 8.0",
    "title": "페이지 압축",
    "content": "페이지 압축은 “Transparent Page Compression”이라고도 불린다. MySQL서버가 디스크에 저장하는 시점에 데이터 페이지가 압축되어 저장되고, 반대로 읽어올 때는 압축이 해제되기 떄문이다. 즉 버퍼 풀에 데이터 페이지가 한 번 적재되면 InnoDB 스토리지 엔진은 압축이 해제된 상태로만 데이터 페이지를 관리한다. 하나의 테이블 압축 결과가 어느정도 될지 예측이 불가능하지만, 적어도 하나의 테이블은 동일한 크기의 페이지로 통일된다. 페이지 압축 기능은 운영체제별로 특정 버전의 파일 시스템에서만 지원되는 펀치 홀(Punch hole)이라는 기능을 사용한다. 운영체제의 블록 사이즈가 512바이트인 경우, 페이지 압축이 작동하는 방식을 간단히 살펴보면 다음과 같다. 1. 16KB 페이지를 압축 (압축 결과를 7KB로 가정) 2. MySQL 서버는 디스크에 압축된 결과 7KB를 기록 (이때 MySQL서버는 압축 데이터 7KB에 9KB의 빈 데이터를 기록) 3. 디스크에 데이터를 기록한 후, 7KB 이후의 공간 9KB에 대해 펀치 홀을 생성 4. 파일 시스템은 7KB만 남기고 나머지 디스크의 9KB 공간은 다시 운영체제로 반납 . | ![[Pasted image 20240424231633.png | 400]] | . 문제는 펀치 홀 기능을 운영체제 뿐만 아니라 하드웨어 자체에서도 해당 기능을 지원해야 사용 가능하다는 점이다. 또 다른 문제는 아직 파일 시스템 관련 명령어가 펀치 홀을 지원하지 못하다는 것이다. 예를 들어 MySQL서버의 데이터 파일은 해당 서버에만 머무는 것이 아니라 백업 했다가 복구하는 과정에서 데이터 파일 복사 과정이 실행되고, 그 외에도 많은 파일 관련 유틸리티들을 사용한다. 펀치 홀이 적용되어 실제 데이터 파일의 크기가 1GB라고 하더라도 “cp” 같은 파일 복사 명령어 가 파일을 복사하면 펀치 홀이 다시 채워져 데이터 파일의 크기는 원본 크기인 10GB가 될 수도 있다. 이러한 이유로 실제 페이지 압축은 많이 사용되지 않는 상태이다. ",
    "url": "/docs/mysql/06.%20Real%20MySQL%208.0.html#%ED%8E%98%EC%9D%B4%EC%A7%80-%EC%95%95%EC%B6%95",
    
    "relUrl": "/docs/mysql/06.%20Real%20MySQL%208.0.html#페이지-압축"
  },"70": {
    "doc": "06. Real MySQL 8.0",
    "title": "테이블 압축",
    "content": "테이블 압축은 운영체제나 하드웨어에 대한 제약 없이 사용할 수 있기 때문에 일반적으로 더 활용도가 높은 편이다. 테이블 압축은 디스크의 데이터 파일 크기를 줄일 수 있다는 장점이 있지만 단점도 있다 . | 버퍼 풀 공간 활용률이 낮음 | 쿼리 처리 성능이 낮음 | 빈번한 데이터 변경 시 압축률이 떨어짐 이러한 단점들이 왜 발생하는지 알아보자 | . 압축 테이블 생성 . 테이블 압축을 사용하기 위해 테이블이 별도의 테이블 스페이스를 사용해야한다. 이를 위해서는 innodb_file_per_table 시스템 변수가 on으로 설정된 상태에서 테이블이 생성돼야 한다. 이제 테이블 압축을 사용하는 테이블은 다음과 같이 테이블을 생성할 때 ROW_FORMAT=COMPRESSED 옵션을 명시해야 한다. 추가로 KEY_BLOCK_SIZE옵션을 이용해 압축된 페이지의 타깃 크기를 명시하는데, 2n으로만 설정할 수 있다. InnoDB의 페이지 크기가 16KB라면 4KB또는 8KB만 설정할 수 있다. 그리포 페이지 크기가 32KB 또는 64KB인 경우에는 테이블 압축을 적용할 수 없다. 32KB 또는 64KB 페이지 크기를 갖는 InnoDB의 경우에는 테이블 압축을 적용할 수 없는 이유는 여러 가지가 있을 수 있습니다. 주요한 이유는 다음과 같습니다: 1. **압축 효율성**: 큰 페이지 크기는 작은 변경 사항에 대해 전체 페이지를 업데이트해야 하므로, 압축된 페이지의 크기를 효율적으로 관리하기 어려울 수 있습니다. 작은 페이지 크기를 갖는 경우에는 작은 변경 사항에 대한 압축 및 업데이트가 더 효율적으로 이루어집니다. 2. **메모리 사용량**: 큰 페이지 크기는 더 많은 메모리를 사용하게 되므로, 메모리 사용량이 증가할 수 있습니다. 작은 페이지 크기는 메모리 사용량을 줄일 수 있습니다. 3. **성능**: 큰 페이지 크기는 I/O 작업이 더 큰 덩어리로 처리되므로, 작은 변경 사항에 대해 디스크에 쓰기 작업을 더 자주 수행해야 할 수 있습니다. 이는 성능에 영향을 줄 수 있습니다. SET GLOBAL innodb_file_per_table=ON; CREATE TABLE compressed_table ( c1 INT PRIMARY KEY ) ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=8; CREATE TABLE compressed_table ( c1 INT PRIMARY KEY ) KEY_BLOCK_SIZE=8; . 두번째 생성 명령에서 ROW_FORMAT=COMPRESSED명령어가 생략됐지만 자동으로 기본옵션으로 들어간다. SIZE는 KB단위를 설정한다. 페이지 크기가 16KB, 그리고 KEY_BLOCK_SIZE가 8로 설정됐다고 가정할때, 데이터 페이지를 압축한 용량이 얼마가 될지 알 수 없는데, 무슨 자신감으로 8로 설정할 수 있을까? . | 16KB의 데이터 페이지를 압축 . | 압축된 결과가 8KB 이하이면 그대로 디스크에 저장 | 압축된 결과가 8KB를 초과하면 원본 페이지를 스플릿 해서 2개의 페이지에 8KB씩 저장 | . | 나뉜 페이지에 각각에 대해 “1”번 단계를 반복 실행 | . ![[Pasted image 20240427150211.png|400]] 이와 같은 작업으로 압축을 실행하기 때문에 목표 크기가 잘못 설정되면 처리 성능이 급격히 떨어질 수 있으니 주의하자. KEY_BLOCK_SIZE 결정 . 압축을 적용하기 전에 먼저 KEY_BLOCK_SIZE를 4KB또는 8KB로 테이블을 생성해서 샘플 데이터를 저장해보고 적절한지 판단하는 것이 좋다. (페이지가 10개정도는 생성되도록 테스트) . ![[Pasted image 20240427150613.png|400]] PRIMARY 키는 전체 18653번 압축을 실행했는데, 그중에서 13468번 성공했다. 즉 5175번 압축했는데, 압축의 결과가 4KB를 초과해서 데이터 페이지를 스플릿해서 다시 압축을 실행했다는 의미이다. 여기서 PRIMARY 키의 압출 실패율은 27.67%이며 나머지 인덱스 2개도 압축 실패율이 상대적으로 높게 나온 것을 알 수 있다. 일반적으로 압축 실패율은 3~5%미만으로 유지할 수 있게 KEY_BLOCK_SIZE를 선택하는 것이 좋다. 압축 실패율이 높다고 해서 압축을 사용하지 말아야 한다는 것은 아니다. 예를 들어 INSERT만 되는 로그 테이블의 경우에는 한번 INSERT되면 이후 다시 변경되지 않을 것이다. 그렇다면 한 번 정도는 압축 시도가 실패해서 페이지 스플릿 후 재압축 하더라도 전체 데이터 파일의 크기가 큰 폭으로 줄어든다면 큰 손해는 아닐 것이다. 압축 알고리즘은 많은 CPU자원을 소모한다는 것을 기억해두자. 압축된 페이지의 버퍼 풀 적재 및 사용 . InnoDB는 압축된 테이블의 데이터 페이지를 버퍼 풀에 적재하면 압축된 상태와 압축이 해제된 상태 2개 버전을 관리한다. InnoDB는 디스크에서 읽은 상태 그대로의 데이터 페이지 목록을 관리하는 LRU 리스트와 압축된 페이지들의 압축 해제 버전인 Unzip_LRU 리스트를 별도로 관리하게 된다. LRU는 “Least Recently Used”의 약자로, 메모리에서 가장 오랫동안 참조되지 않은 페이지를 대체하는 메커니즘 . InnoDB는 압축된 테이블에 대해서는 버퍼 풀의 공간을 이중으로 사용함으로써 메모리를 낭비하는 효과를 가진다. 또 다른 문제점은 압축된 페이지에서 데이터를 읽거나 변경하기 위해서는 압축을 해제해야 한다. 두 단점을 보완하기 위해 Unzip_LRU 리스트를 별도로 관리하고 있다가 MySQL서버로 유입되는 요청 패턴에 따라서 적절히 다음과 같은 처리를 수행한다. | 버퍼 풀의 공간이 필요한 경우 LRU 리스트에서 원본 데이터 페이지는 유지하고, Unzip_LRU 리스트에서 압축 해제된 버전은 제거해서 버퍼 풀의 공간을 확보한다. | 압축된 데이터 페이지가 자주 사용되는 경우 Unzip_LRU 리스트에 압축 해제된 페이지를 계속 유지하면서 압축 및 압축 해제 작업을 최소화한다. | 압축된 데이터 페이지가 사용되지 않아서 LRU 리스트에서 제거되는 경우에는 Unzip_LRU 리스트에서도 함께 제거된다. | . InnoDB는 버퍼 풀에서 압축 해제된 버전의 데이터 페이지를 적절한 수준으로 유지하기 위해 다음과 같은 어댑티브 알고리즘을 사용한다. | CPU 사용량이 높은 서버에서 가능하면 압축과 압축 해제를 피하기 위해 Unzip_LRU의 비율을 높여서 유지하고 | Disk IO 사용량이 높은 서버에는 가능하면 Unzip_LRU 리스트의 비율을 낮춰서 InnoDB 버퍼 풀의 공간을 더 확보하도록 작동한다. | . ",
    "url": "/docs/mysql/06.%20Real%20MySQL%208.0.html#%ED%85%8C%EC%9D%B4%EB%B8%94-%EC%95%95%EC%B6%95",
    
    "relUrl": "/docs/mysql/06.%20Real%20MySQL%208.0.html#테이블-압축"
  },"71": {
    "doc": "06. Real MySQL 8.0",
    "title": "06. Real MySQL 8.0",
    "content": " ",
    "url": "/docs/mysql/06.%20Real%20MySQL%208.0.html",
    
    "relUrl": "/docs/mysql/06.%20Real%20MySQL%208.0.html"
  },"72": {
    "doc": "06. 메시지와 인터페이스",
    "title": "06. 메시지와 인터페이스",
    "content": ". 협력과 메시지 . 클라이언트 - 서버 모델 . 협력은 어떤 객체가 다른 객체에게 무언가 요청할 때 시작된다. ![[Pasted image 20240529232145.png]] . 메시지와 메시지 전송 . 메시지는 객체들이 협력하기 위해 사용할 . 수있는 유일한 의사소통 수단이다. 한 객체가 다른 객체에게 도움을 요청하는 것을 메시지 전송 또는 메시지 패싱이라고 부른다. 이때 메시지를 전송하는 객체를 메시지 전송자 수신하는 객체를 메시지 수신자라고 부른다. 클라이언트 - 서버 모델 관점에서 클라이언트가 메시지 전송자 서버가 수신자로 . 볼수있다. ![[Pasted image 20240529233606.png]] . 메시지와 메서드 . 메시지를 수신했을 때 실제로 수행되는 함수 또는 프로시저를 메서드라고 부른다. 메시지와 메서드의 구분은 메시지 전송자와 메시지 수신자가 느슨하게 결합될 수있게 한다. 메시지 전송자는 자신이 어떤 메시지를 전송해야 하는지만 알면 된다. 수신자가 어떤 클래스의 인스턴스인지, 어떤 방식으로 요청을 처리하는지 몰라도 된다. 퍼블릭 인터페이스와 오퍼레이션 . 객체가 의사소통을 위해 외부에 공개하는 메시지의 집합을 퍼블릭 인터페이스라고 부른다. 퍼블릭 인터페이스에 포함된 메시지를 오퍼레이션이라고 부른다. 오퍼레이션은 수행 가능한 어떤 행동에 대한 추상화다. 내부의 구현 코드는 제외하고 단순히 메시지와 관련된 시그니처를 가리키는 경우가 대부분이다. ![[Pasted image 20240529235301.png]] . 시그니처 . 오퍼레이션(또는 메서드)의 이름과 파라미터 목록을 합쳐 시그니처라고 부른다. 오퍼레이션은 실행 코드 없이 시그니처만 정의한 것이다. 메서드는 이 시그니처에 구현을 더한 것이다. 인터페이스와 설계 품질 . 좋은 인터페이스는 최소한의 인터페이스와 추상적인 인터페이스라는 조건을 만족해야 한다. | 디미터 법칙 | 묻지 말고 시켜라 | 의도를 드러내는 인터페이스 | 명령 - 쿼리 분리 | . 디미터 법칙이란 협력하는 객체의 내부 구조에 대한 결합으로 인해 발상하는 설계 문제를 해결하기 위해 제안된 법칙이다. 요약하면 객체의 내부 구조에 강하게 결합되지 않도록 협력 경로를 제한하라는 것이다. “오직 인접한 이웃하고만 말하라” . 아래 조건을 만족하는 인스턴스에만 메시지를 전송하라는 한다라고 이해해도 무방하다 . | this 객체 | 메서드의 매개변수 | this의 속성 | \bthis의 속성인 컬렉션의 요소 | 메서드 내에서 생성된 지역 객체 ![[Pasted image 20240529235826.png]] ![[Pasted image 20240529235836.png]] | . 묻지말고 시켜라 . 메시지 전송자는 메시지 수신자의 상태를 기반으로 결정을 내린 . 후메시지 수신자의 상태를 바꿔선 안된다. 의도를 드러내는 인터페이스 . 메서드의 이름을 짓는 방법은 어떻게가 아니라 무엇을 하는지를 드러내는 것이다. 원칙의 함정 . 위 법칙은 절대적인 법칙은 아니다. 잊지 말아야 하는 사실은 설계가 트레이드오프의 산물이라는 것이다. 결합도와 응집도의 충돌 . 아니다. 모든 상황에서 맹목적으로 위임 메서드를 추가하면 같은 퍼블릭 인터페이스 안에 어울리지 않 는 오퍼레이션들이 공존하게 된다. 결과적으로 객체는 상관 없는 책임들을 한꺼번에 떠안게 되기 때문 에 결과적으로 응집도가 낮아진다. 클래스는 하나의 변경 원인만을 가져야 한다. 서로 상관없는 책임들이 함께 뭉쳐있는 클래스는 응집도 가 낮으며 작은 변경으로도 쉽게 무너질 수 있다. 따라서 디미터 법칙과 묻지 말고 시켜라 원칙을 무작 정 따르면 애플리케이션은 응집도가 낮은 객체로 넘쳐날 것이다. 명령 - 쿼리 분리 원칙 . 어떤 절차를 묶어 호출 가능하도록 이름을 부여한 기능 모듈을 루틴이라고 부른다. 루틴은 프로시저와 함수로 구분할 수 있다. | 프로시저는 부수 효과를 발생시킬 수 있지만 값을 반환할 수없다. | 함수는 값을 반환할 수 있지만 부수효과를 발생시킬 수 없다. 명령과 쿼리는 객체의 인터페이스 측면에서 프로시저와 함수를 부르는 또 다른 이름이다. | 객체의 상태를 변경하는 명령은 반환값을 가질 수 없다. | 객체의 정보를 반환하는 쿼리는 상태를 변경할 수 없다. | . ",
    "url": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/06.%20%EB%A9%94%EC%8B%9C%EC%A7%80%EC%99%80%20%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4.html",
    
    "relUrl": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/06.%20%EB%A9%94%EC%8B%9C%EC%A7%80%EC%99%80%20%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4.html"
  },"73": {
    "doc": "07. Real MySQL 8.0",
    "title": "7장",
    "content": ". ",
    "url": "/docs/mysql/07.%20Real%20MySQL%208.0.html#7%EC%9E%A5",
    
    "relUrl": "/docs/mysql/07.%20Real%20MySQL%208.0.html#7장"
  },"74": {
    "doc": "07. Real MySQL 8.0",
    "title": "데이터 암호화",
    "content": " ",
    "url": "/docs/mysql/07.%20Real%20MySQL%208.0.html#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%95%94%ED%98%B8%ED%99%94",
    
    "relUrl": "/docs/mysql/07.%20Real%20MySQL%208.0.html#데이터-암호화"
  },"75": {
    "doc": "07. Real MySQL 8.0",
    "title": "MySQL 서버의 데이터 암호화",
    "content": "![[Pasted image 20240429221226.png|400]] 데이터베이스 서버와 디스크 사이의 데이터를 읽고 쓰기 지점에서 암호화 또는 복호화를 수행한다. 그래서 MySQL 서버에서 디스크 입출력 이외의 부분에서는 암호화 처리가 전혀 필요치 않다. 데이터 암호화 기능이 활성화 돼 있다고 하더라도 사용자 입장에서는 아무런 차이가 없다. 이러한 방식을 TDE(Transparent Data Encryption)라고 한다. 또는 Data Rest Encryption이라고도 하는데, 데이터가 전송 단계가 아닌 저장 단계에서만 암호화된다는 의미로 사용된다. 2단께 키 관리 . MySQL TDE에서 암호화 키는 키링 플로그인에 의해 관리된다. | keyring_file File-Based 플러그인 (커뮤니티 에디션은 해당 플러그인만 가능) | keyring_encrypted_file Keyring | keyring_okv KMIP 플러그인 | keyring_aws Amazon Web Services Keyring 플러그인 | . 다양한 플러그인이 제공되지만 마스터 키를 관리하는 방법만 다르다. ![[Pasted image 20240429221815.png|400]] MySQL 서버의 키링 플러그인은 2단계 키 관리 방식을 사용한다. MySQL서버의 데이터 암호화는 마스터 키와 테이블 스페이스 키라는 두 종류의 키를 가지고 있는데, 테이블스페이스 키는 프라이빗 키 라고도 한다. MySQL서버는 외부 키 관리 솔루션 (그림의 HashiCrop 등)에서 마스터 키를 가져오고, 암호화된 테이블이 생성될 때마다 해당 테이블을 위한 임의의 테이블스페이스 키를 발급한다. 그리고 MySQL 서버는 마스터 키를 이용해 테이블스페이스키를 암호화해서 각 테이블의 데이터 파일 헤더에 저장한다. 이렇게 생성된 테이블 스페이스 키는 테이블이 삭제되지 않는 이상 절대 변경되지 않는다. (외부로 노출될 일이 없기 때문에 보안에 취약하지 않음) . 하지만 마스터 키는 외부로 노출될 가능성이 있기 때문에 주기적으로 변경해야 한다. 마스터키를 변경하려면 기존의 테이블 스페이스 키를 복호화 한 후에 새로운 마스터 키로 다시 암호화 한다. 이런 방식을 하는건 시스템 부하를 피하기 위해서이다. 테이블 스페이스 키를 바꿔야 한다면 테이블의 모든 데이터를 복호화 한 후에 스페이스 키를 새로 발급하여 다시 암호화 해야하는 엄청난 작업이 발생한다. 암호화와 성능 . 쿼리가 InnoDB 버퍼 풀에 존재하지 않는 데이터를 읽어야 하는 경우 복호화 과정을 거치기 때문에 복호화 시간동안 쿼리가 지연된다. 그리고 암호화된 테이블이 변경되면 다시 디스크로 동기화될 때 암호화 되어야하기 떄문에 처리가 지연된다. 하지만 데이터 페이지 저장은 백그라운드로 처리되기 때문에 실제 사용자 쿼리가 지연되는것이 아니다. AES암호화 알고리즘은 암호화하고자 하는 평문의 길이가 짧은 경우 암호화 키의 크기에 따라 암호화된 결과의 용량이 더 커질 수 있지만, 이미 데이터 페이지는 암호화 키보다 훨씬 크기 때문에 암호화 결과가 평문의 결과와 동인한 크기의 암호문을 반환한다. 같은 테이블에 암호화와 압축이 동시에 적용되면 서버는 압축 -&gt; 암호화를 적용한다 . 이유 . | 암호화된 결과문은 랜덤바이트를 가진다. 이는 압축률을 상당히 떨어트린다 | 암호화 먼저 실행되고 압축을 실행한다면 읽었을때 버퍼 풀의 데이터가 암호화 되어있어 사용할 때 마다 복호화를 해야한다 | . 암호화와 복제 . 서버 복제에서 레플리카 서버는 소스 서버와 데이터를 동기화 하기 때문에 실제 데이터 파일도 동일할 것이라 생각할 수 있다. 하지만 TDE를 이용한 암호화 사용시 마스터 키와 테이블스페이스 키는 그렇지 않다. 원격으로 키 관리 솔루션을 사용하느 경우에도 소스 서버와 레플리카 서버는 서로 다른 마스터키를 갖도록 설정해야 한다. 마스터 키 자체가 레플리카로 복제되지 않는다. 테이블스페이스 키 또한 마찬가지다. 때문에 복제 멤버들의 데이터 파일은 암호화 되기 전 값은 동일하더라도 암호화 된 데이터는 완전히 달라진다. ",
    "url": "/docs/mysql/07.%20Real%20MySQL%208.0.html#mysql-%EC%84%9C%EB%B2%84%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%95%94%ED%98%B8%ED%99%94",
    
    "relUrl": "/docs/mysql/07.%20Real%20MySQL%208.0.html#mysql-서버의-데이터-암호화"
  },"76": {
    "doc": "07. Real MySQL 8.0",
    "title": "테이블 암호화",
    "content": "키링 플러그인은 마스터 키를 생성하고 관리하는 부분까지만 담당하기 때문에 어떤 키링 플러그인을 사용하든 암호화된 테이블을 생성하고 활용하는 방법은 모두 같다. 테이블 생성 . TDE를 이용하는 테이블은 다음과 같이 생성할 수 있다. CREATE TABLE tab_encrypted ( id INT, data VARCHAR(100), PRIMARY KEY(id) ) ENCRYPTION='Y'; . 일반 테이블 생성 쿼리에 ENCRYPTION='Y'옵션만 추가해주면 된다. SELECT table_schema, table_name, create_options FROM infromation_schema.tables WHERE table_name='tab_encrpyted'; . 암호화 된 테이블만 검색할 때는 infromation_schema를 사용하면 된다. 응용 프로그램 암호화와의 비교 . 응용 프로그램에서 직접 암호화해서 MySQL 서버에 저장하는 경우도 있는데, 이 경우 저장되는 컬럼 값이 이미 암호화된 것인지 여부를 MySQL서버는 인식하지 못한다. 때문에 암호화된 컬럼은 인덱스를 생성하더라도 인덱스의 기능을 100% 활용할 수 없다. ![[Pasted image 20240429224556.png|400]] ![[Pasted image 20240429224608.png|400]] 날짜 범위 검색 등의 불편함 . 응용 프로그램의 암호화와 MySQL 서버의 암호화 기능중 선택해야 하는 상황이라면 고민할 필요 없이 MySQL 서버의 암호화 기능을 선택할 것을 권장한다. 테이블 스페이스 이동 . 테이블을 다른 서버로 복사해야 하는 경우 또는 특정 테이블의 데이터 파일만 백업했다가 복구하는 경우라면 테이블 스페이스 이동 기능이 레코드를 덤프했다가 복구하는 방식보다 훨씬 효율적이고 빠르다. MySQL서버에서 다음과 같이 FLUSH TABLES 명령으로 테이블스페이스를 익스포트할 수 있다. FLUSH TABLES source_table FOR EXPORT; . 해당 명령이 실행되면 다음과 같은 테이블 복사 과정을 거친다. | MySQL서버는 source_table의 저장되지 않은 변경 사항을 모두 디스크로 기록하고, 더이상 source_table에 접근할 수 없게 잠금을 건다. | 그와 동시에 source_table의 구조를 source_table.cfg파일로 기록해둔다. | 그러면 source_table.ibd 파일과 source_table.cfg 파일을 목적지 서버로 복사한다. | 복사가 완료되면 UNLOCK TABLES 명령을 실행해 source_table을 사용할 수 있게 하면 된다. | . 그런데 TDE가 적용되어 암호화된 테이블의 경우 원본 MySQL서버와 목적지MySQL 서버의 암호화 키가 다르기 때문에 하나 더 신경써야 할 부분이 있다. | 임시로 사용할 마스터 키를 발급해서 source_table.cfp라는 파일로 기록한다. | 그리고 암호화된 테이블의 테이블스페이스 키를 기존 마스터 키로 복호화한 후, 임시로 발급한 마스터 키를 이용해 다시 암호화해서 데이터 파일의 헤더 부분에 저장한다. | 그래서 암호화된 테이블의 경우 테이블스페이스 이동 기능을 사용할 때는 반드시 데이터 파일과 임시 마스터 키가 저장된 .cpf파일을 함께 복사해야 한다. 없다면 복구가 불가능하다 | . ",
    "url": "/docs/mysql/07.%20Real%20MySQL%208.0.html#%ED%85%8C%EC%9D%B4%EB%B8%94-%EC%95%94%ED%98%B8%ED%99%94",
    
    "relUrl": "/docs/mysql/07.%20Real%20MySQL%208.0.html#테이블-암호화"
  },"77": {
    "doc": "07. Real MySQL 8.0",
    "title": "언두 로그 및 리두 로그 암호화",
    "content": "테이블 암호화를 적용하더라도 디스크로 저장되는 데이터만 암호화되고 서버의 메모리에 존재하는 데이터는 복호화된 평문으로 관리된다. 리두 로그, 언두 로그, 그리고 복제를 위한 바이너리 로그에는 평문으로 저장되는데, innodb_undo_log_encrypt 시스템 변수와 innodb_redo_log_encrypt시스템 변수를 이용해 리두 로그와 언두 로그를 암호화된 상태로 저장할 수 있다. 옵션을 활성화 한다고 해서 기존에 사용하던 모든 리두 로그나 언두 로그의 데이터를 해당 시점에 한번에 암호화해서 다시 저장할 수 없다. 반대로 비활성화 한다고 해서 기존의 암호화 되어있던 로그들이 복호화되어 다시 저장되지 않는다. 때문에 암호화에 진행된 키는 상황에 따라 몇일 또는 몇달동안 필요할 수 있다. 리두 로그와 언두 로그 데이터 모두 각각의 테이블스페이스 키로 암호화된다. 테이블 스페이스 키는 마스터 키로 다시 암호화 되며 리두 로그 파일과 언두 로그 파일의 헤더에 저장된다. SHOW GLOBAL VARIABLES LIKE 'innodb_redo_log_encrypt'; . ",
    "url": "/docs/mysql/07.%20Real%20MySQL%208.0.html#%EC%96%B8%EB%91%90-%EB%A1%9C%EA%B7%B8-%EB%B0%8F-%EB%A6%AC%EB%91%90-%EB%A1%9C%EA%B7%B8-%EC%95%94%ED%98%B8%ED%99%94",
    
    "relUrl": "/docs/mysql/07.%20Real%20MySQL%208.0.html#언두-로그-및-리두-로그-암호화"
  },"78": {
    "doc": "07. Real MySQL 8.0",
    "title": "바이너리 로그 암호화",
    "content": "바이너리 로그와 릴레이 로그 파일 암호화 기능은 디스크에 저장된 로그 파일에 대한 암호화만 담당하고, 메모리 내부 또는 서버와 레플리카 서버간의 네트워크 구간에서 로그 데이터를 암호화 하지 않는다. 네트워크 구간 사이에서 암호화가 필요하다면 SSL을 사용한다. 바이너리 로그 암호화 키 관리 . ![[Pasted image 20240430222249.png|400]] . 바이너리 로그와 릴레이 로그 파일의 데이터는 파일 키(file key)로 암호화해서 디스크에 저장하고, 파일 키는 “바이너리 로그 암호화 키”로 암호화 해서 각 바이너리 로그와 릴레이 로그 파일의 헤더에 저장한다. 바이너리 로그 암호화 키 변경 . ALTER INSTANCE ROTATE BINLOG MASTER KEY; . 바이너리 로그 암호화 키가 변경되면 다음과 같은 과정을 거친다. | 증가된 시퀀스 번호와 함께 새로운 바이너리 로그 암호화 키 발급 후 키링 파일에 저장 | 바이너리 로그 파일과 릴레이 로그 파일 스위치 (새로운 로그 파일로 로테이션) | 새로 생성되는 바이너리 로그와 릴레이 로그 파일의 암호화를 위해 파일 키를 생성하고, 파일 키는 바이너리 로그 파일 키로 암호화해서 각 로그 파일에 저장 | 기존 바이너리 로그와 릴레이 로그 파일의 파일 키를 읽어서 새로운 바이너리 로그 파일 키로 암호화해서 다시 저장 | 모든 바이너리 로그와 릴레이 로그 파일이 새로운 바이너리 로그 암호화 키로 다시 암호화됐다면 기존 바이너리 로그 암호화 키를 키링 파일에서 제거 | . ",
    "url": "/docs/mysql/07.%20Real%20MySQL%208.0.html#%EB%B0%94%EC%9D%B4%EB%84%88%EB%A6%AC-%EB%A1%9C%EA%B7%B8-%EC%95%94%ED%98%B8%ED%99%94",
    
    "relUrl": "/docs/mysql/07.%20Real%20MySQL%208.0.html#바이너리-로그-암호화"
  },"79": {
    "doc": "07. Real MySQL 8.0",
    "title": "07. Real MySQL 8.0",
    "content": " ",
    "url": "/docs/mysql/07.%20Real%20MySQL%208.0.html",
    
    "relUrl": "/docs/mysql/07.%20Real%20MySQL%208.0.html"
  },"80": {
    "doc": "07. Route53",
    "title": "07. Route53",
    "content": ". ",
    "url": "/docs/aws/07.%20Route53.html",
    
    "relUrl": "/docs/aws/07.%20Route53.html"
  },"81": {
    "doc": "07. Route53",
    "title": "DNS",
    "content": "ip 주소를 사람들에게 친숙하게 변환 . | Domain Registrar . | Amazon Route 53, GoDaddy … | . | DNS Records . | A, AAAA, CNAME, NS | . | Zone File . | 모든 DNS 레코드를 포함하는 존 파일 | 호스트 이름과 ip주소를 일치시키는 방법 | . | Name Server . | DNS 쿼리를 실제로 해결하는 서버 | . | 최 상위 도메인 . | .com, .us, .in, .gov, .org … | . | 2단계 도메인 . | amazon.com, google.com | 단어사이에 . 존재 | . | http://api.www.example.com. | 마지막 .을 도메인 이름의 루트라고 한다 | .com은 TLD(최상위 도메인)이다 | example.com이 2단계 도메인이다 | www.example.com은 서브도메인 | api.www.example.com이 도메인 이름이다? | http == 프로토콜 | 전체를 FQDN이라고 부름 | Fully Qualified Domain Name | . | . ",
    "url": "/docs/aws/07.%20Route53.html#dns",
    
    "relUrl": "/docs/aws/07.%20Route53.html#dns"
  },"82": {
    "doc": "07. Route53",
    "title": "동작",
    "content": "1. Web Browser -(example.com)-&gt; Local DNS Server 로컬 DNS 서버는 보통 회사에 의해 할당되고 관리된다 또는 인터넷 서비스 제공자에 동적으로 할당된다 . 2. Local DNS Server -(example.com)-&gt; Root DNS server(ICANN) 로컬 DNS 서버가 이 쿼리를 전에 본적이 없다면 ICANN에 의해 관리된 DNS 서버의 루트에 물어본다 example.com 은 모르지만 .com은 알고있는 경우 NS(서버, 공인 IP 1.2.3.4) 레코드로 가보라고 알려준다 . 3. Local DNS Server -(example.com)-&gt; TLD DNS Server(.com의 정보 소유 Managed by IANA) TLD DNS Server는 example.com이라는 서브 도메인 정보를 가지고 있는 SLD DNS Server의 주소를 알려준다 . 4. Local DNS Server -(example.com)-&gt; SLD DNS Server(Amazon Registarar, ...) 해당 요청의 결과로 example.com 의 ip 주소를 얻게되어 example.com으로 요청할 수 있게 된다. Local DNS는 이제 example.com에대한 정보가 생겨 다시 요청하면 바로 대답해 줄 수 있다 . ",
    "url": "/docs/aws/07.%20Route53.html#%EB%8F%99%EC%9E%91",
    
    "relUrl": "/docs/aws/07.%20Route53.html#동작"
  },"83": {
    "doc": "07. Route53",
    "title": "Route53",
    "content": "(53은 DNS에 사용되는 포트를 의미) . 고가용성, 확장성을 갖춘 완전히 관리되며 권한있는 DNS이다 . 권한이란? 고객인 우리가 DNS 레코드를 업데이트 할 수 있다는 것 . 100% SLA 가용성을 제공하는 유일한 AWS 서비스이다. 레코드 설정 . | 도메인, 서브도메인 | Record Type . | A, AAAA, CNAME, NS | (고급) CAA / DS / MX / NAPTR / PTR / SOA / TXT / SPF / SRV | . | 레코드의 값 | 라우팅 정책 (쿼리에 응답하는 방식) | TTL (DNS 리졸버에 레코드가 캐싱되는 시간) | . Record Type . | A . | 호스트 이름과 IPv4 IP를 매핑 | example.com -&gt; 1.2.3.4 연결 | . | AAAA . | 호스트 이름을 IPv6 주소에 매핑 | . | CNAME . | 다른 호스트 이름과 매핑 | 대상 호스트 이름은 A 또는 AAAA가 될 수 있다 | 상위 노드 DNS에 대한 CNAMES를 생성할 수 없다? | 예를 들어 example.com에 CNAME을 만들 수 없지만, www.example.com에 대한 CNAME레코드는 만들 수 있다 | . | NS . | 서버의 DNS이름 또는 IP주소로 호스팅 존에대한 DNS쿼리에 응답할 수있다 | 또한 트래픽이 도메인으로 라우팅 되는 방식을 제어한다 | . | . Hosted Zones . 호스팅 존은 레코드의 컨테이너이다 도메인과 서브도메인으로 가는 트래픽의 라이팅 방식을 정의한다 . aws에서 만든 어떤 호스팅존이든 월에 50센트를 지불해야한다 . public hosted zones . 퍼블릭 도메인을 구매하면 퍼블릭 호스팅 존을 만들 수 있다 . 퍼블릭 호스팅 존은 공개된 클라이언트로부터 온 쿼리에 응답할 수 있다 웹브라우저에서 example.com을 요청하면 ip를 반환한다 . private hosted zones . 공개되지 않는 도메인 이름을 지원한다 가상 프라이빗 클라우드(VPC)만이 URL을 리졸브 할 수 있다 . ",
    "url": "/docs/aws/07.%20Route53.html#route53",
    
    "relUrl": "/docs/aws/07.%20Route53.html#route53"
  },"84": {
    "doc": "07. Route53",
    "title": "CNAME vs Alias",
    "content": "로드 밸런서나 CloudFront 등 AWS의 리소스를 사용하는 경우 호스트의 이름이 노출된다 lb-1234.us-east-2.elb.amazonaws.com 이를 myapp.mydomain.com에 매핑하고싶은경우 두가지 옵션이 있다 . CNAME . | 호스트 이름이 다른 호스트 이름으로 향하도록 할 수 있다 | 예를들어 app.mydomain.com이 blabla.anything.com으로 향하게끔 할 수 있다 | 루트 도메인 이름이 아닌 경우에만 가능해서 mydomain.com앞에 뭔가 붙어야한다 | . Alias . | Route53 한정 호스트 이름이 특정 AWS 리소스를 향하도록 할 수 있다 | app.mydoamin.com이 blabla.anyting.com으로 향하게 할 수 있다 (리소스라며 왜 예제를 도메인으로들어?) | 루트 및 비루트 도메인 모두에 작동한다 | 시험에 출제될 수 있다 | 무료이다 | 자체적으로 상태 확인이 가능하다 | AWS의 리소스에만 매핑이 되어있다 | CNAME과 달리 별칭 레코드는 Zone Apex라는 DNS 네임스페이스의 상위 노드로 사용될 수 있다 | AWS리소스를 위한 별칭 레코드의 타입은 항상 A또는 AAAA인데 별칭 레코드를 사용하면 TTL을 설정할 수 없다 -TTL (DNS 리졸버에 레코드가 캐싱되는 시간) . | 레코드 대상 . | ELB | CloudFront | API Gateway | Beanstalk | S3 websties (버킷은 안됨) | VPC interface endpoints | Global Accelerator | Route 53 Record | EC2의 DNS 이름에 대해서는 별칭 레코드를 설정할 수 없다 (중요) | . | . ",
    "url": "/docs/aws/07.%20Route53.html#cname-vs-alias",
    
    "relUrl": "/docs/aws/07.%20Route53.html#cname-vs-alias"
  },"85": {
    "doc": "07. Route53",
    "title": "Routing Policies",
    "content": "라우팅 정책 . DNS는 트래픽을 라우팅하지 않는다??? . 단순 라우팅 정책 . | 일반적으로 트래픽을 단일 리소스로 보내는 방식 | foo.example.com으로 가고자한다면 해당 IP주소를 알려줌. 이는 A레코드 | 동일한 레코드에 여러개의 값을 지정하는것도 가능하지만 반환은 랜덤이다 | 별칭과 함께 사용하면 하나의 AWS리소스만을 대상으로 지정할 수 있다 | 상태확인은 불가능하다 | . 가중치기반 라우팅 정책 . | 가중치를 활용해 일부 비율을 특정 리소스로 보내는 제어가 가능 | 비율은 합해서 100%가 아니여도 된다(그이상이여도 가능) | 서로 다른 지역들에 걸쳐 로드 밸런싱을 할때나 적은 양의 트래픽을 보내 새 어플리케이션을 테스트하는 경우에 사용 | 모든 리소스의 레코드 가중치가 0인경우 모든 레코드가 다시 동인한 가중치를 갖게된다 | . 지연 시간 기반 라우팅 정책 . | 지연 시간이 가장 짧은 리소스로 리다이렉팅 하는 정책 | 지연시간이 민감한 웹사이트나 애플리케이션에서 사용 | 유저가 레코드로 가장 가까운 식별된 AWS 리전에 연결하기까지 걸리는 시간을 기반으로 측정 | | . 지리적 위치 라우팅 정책 . 지연 시간 기반의 정책과 매우 다르게 사용자의 실제 위치를 기반으로 한다 . 일치하는 위치가 없는 경우 기본 레코드를 생성해야한다 . 지리 근접 라우팅 정책 . 사용자와 리소스의 지리적 위치를 기반으로 프래픽을 리소스로 라우팅한다 . 편향값을 사용해 특정 위치를 기반으로 리소스를 더 많은 트래픽을 이동한다 (편향값 증가 -&gt; 트래픽 증가) . IP기반 라우팅 정책 . 클라이언트 IP 주소를 기반으로 라우팅한다 . Route53에서 CIDR 목록을 정의해야한다 . CIDR에 따라 트래픽을 어느 로케이션으로 보내야하는지 정한다 . 네트워크 비용은 왜 절감되지? . 다중값 라우팅 정책 . 트래픽을 다중 리소스로 라우팅할 때 사용 . 클라이언트에서 다중 값 쿼리를 실행하면 최대 8개의 레코드가 반환된다 ELB와 유사해보이지만 ELB를 대체할 수 없다 . 클라이언트 측면에서 로드 밸런싱이다 . 최대 8개의 레코드를 수신한 클라이언트는 하나를 선택해서 요청하게된다 . 단순 라우팅정책은 상태 확인을 허용하지 않기 때문에 리소스가 비정상일 가능성이 있지만, 다중 값은 이 부분에대해서 더 보완할 수 있다 . ",
    "url": "/docs/aws/07.%20Route53.html#routing-policies",
    
    "relUrl": "/docs/aws/07.%20Route53.html#routing-policies"
  },"86": {
    "doc": "07. Route53",
    "title": "Route 53 상태 확인",
    "content": "주로 공용 리소스에 대한 상태를 확인하는 방법이다 개인 리소스의 상태 확인 방법 또한 존재 . 각 지역에 로드밸런서와 인스턴스가 떠있을떄 Route 53은 두개의 LB에 상황에 따라 요청을 보낼 수 있다 이때 한 지역이 사용 불가능이되면 그곳으로 유저의 요청을 보내지 말아야한다 그러기 위해서 Route 53에서 상태 확인을 생성해야한다 . 세가지의 상태확인이 가능하다 . | 공용 엔드포인트를 모니터링 (애플리케이션, 서버, 또다른 AWS리소스) | 계산된 상태 확인 (이게뭔데? 여러개의 상태 확인 결과를 하나로 합쳐주는기능) | CloudWatch 경보 상태 모니터링 | . 상태 확인들은 각자의 메트릭을 사용한다 . 메트릭이란? . AWS에서는 다양한 서비스에서 다양한 유형의 메트릭을 수집할 수 있습니다. 예를 들어, Amazon EC2 인스턴스의 CPU 사용률, Amazon S3 버킷의 객체 수, Amazon RDS 데이터베이스의 연결 수 등이 모두 메트릭의 예시입니다. Amazon CloudWatch는 AWS에서 제공하는 주요 메트릭 및 로그 관리 서비스 중 하나입니다. CloudWatch를 사용하면 AWS 리소스의 성능을 모니터링하고, 트랜잭션 및 이벤트 로그를 수집하며, 메트릭 데이터를 시각적으로 표시하고 경고를 설정할 수 있습니다. 상태 확인이 특정 엔드포인트에서 어떻게 작용하는지? ALB에 대한 eu-west-1의 상태 확인을 한다고 하면 aws의 상태 확인이 전 세계로부터 온다 이들은 우리가 루트를 설정한 공용 엔드 포인트로 모두 요청을 보낸다 200 OK 코드 또는 우리가 정의한 코드를 받으면 리소스는 정상으로 간주한다 . 시간 간격을 정기적으로 30초마다 또는 비용이 더들지만 10초마ㅏ다도 가능하다 HTTP, HTTPS와 TCP 등 많은 프로토콜을 지원한다 18% 이상의 상태 확인이 엔드포인트를 정상이라고 판단하면 Route53도 이를 정상이라고 간주한다 . 2xx 3xx의 코드를 받아야만 통과가 된다 . 텍스트 기반 응답일 경우 상태 확인은 응답의 처음 5120바이트를 확인한다. 응답 자체에 해당 텍스트가 있는지 보기 위해서이다 . 상태 확인이 애플리케이션 밸런서나 엔드포인트에 접근이 가능해야한다 . 계상된 상태 확인이란 여러개의 상태 확인 결과를 하나로 합쳐주는기능이다 EC2인스턴스가 3개있고 상태확인을 세개 생성할 수 있다 이 3개를 하위 상태 확인이라고 하고 하위 상태를 바탕으로 상위 상태 확인을 정의할 수 있다 합치기 위한 조건은 OR AND NOT이다 하위 상태는 256개까지 모니터링 할 수 있다 상태 확인을 통과해야 하는지도 지정할 수 있다 . 개인 리소스의 상태는 CloudWatch 지표를 만들어 알람을 할당하는 식으로 문제를 해결할 수 있따 . ",
    "url": "/docs/aws/07.%20Route53.html#route-53-%EC%83%81%ED%83%9C-%ED%99%95%EC%9D%B8",
    
    "relUrl": "/docs/aws/07.%20Route53.html#route-53-상태-확인"
  },"87": {
    "doc": "07. Route53",
    "title": "Domain Registar vs DNS Server",
    "content": "타사 도메인 및 Route 53 . Domain Registar를 통해 원하는 도메인 이름을 구매할 수 있다 매년 비용을 지불한다 . Domain Registar를 통해 도메인을 등록하면 DNS 레코드 관리를 위한 DNS 서비스를 제공한다 . Amazon 호스트 이름으로 DNS 이름을 등록했다면 DNS 레코드 관리를 위한 Route53 호스팅 존을 갖게된다. 하지만 Route53을 사용하지 않고 Amazon Registar를 사용해도된다 . GoDaddy(not Amazon Registar)에서 도메인을 등록하고 Amazon의 Route53으로 관리할수도있다 . ",
    "url": "/docs/aws/07.%20Route53.html#domain-registar-vs-dns-server",
    
    "relUrl": "/docs/aws/07.%20Route53.html#domain-registar-vs-dns-server"
  },"88": {
    "doc": "07. 객체 분해",
    "title": "07. 객체 분해",
    "content": ". ![[Pasted image 20240530001142.png]] 하향식 기능 분해의 문제점 . | 시스템은 하나의 메인 함수로 구성돼 있지 않다. | 기능 추가나 요구사항 변경으로 인해 메인 함수를 빈번하게 수정해야 한다. | 비즈니스 로직이 사용자 인터페이스와 강하게 결합된다. | 하향식 분해는 너무 이른 시기에 함수들의 실행 순서를 고정시키기 때문에 유연성과 재사용성이 저하된다. | 데이터 형식이 변경될 경우 파급효과를 예측할 수 없다. | . 비즈니스 로직과 사용자 인터페이스의 결합 . 하향식 접근법은 비즈니스 로직을 설계하는 초기 단계부터 입력 방법과 출력 양식을 함께 고민하도록 강요한다. 급여를 계산하는 기능의 경우 사용자로부터 소득세율을 입력받아 급여를 계산한 후 계산된 결과를 화면에 출력한다”라는 말에는 급여를 계산하는 중요한 비즈니스 로직과 관련된 관심사와 소득 세율을 입력받아 결과를 화면에 출력한다는 사용자 인터페이스의 관심사가 한데 섞여 있다는 것을 의 미한다. 결과적으로 코드 안에서 비즈니스 로직과 사용자 인터페이스 로직이 밀접하게 결합된다. 문제는 비즈니스 로직과 사용자 인터페이스가 변경되는 빈도가 다르다는 것이다. 그런데 로직을 한데 섞는다면 서로에 영향을 주기 때문에 불안정한 아키텍처를 낳는다. … 하향식으 문제점 계속 지적 … . 모듈 . 데이터 추상화와 추상 데이터 타입 . 추상 데이터 타입을 구현하려면 다음과 같은 특성을 위한 프로그래밍 언어의 지원이 필요하다. | ﻿﻿타입 정의를 선언할 수 있어야 한다. | ﻿﻿타입의 인스턴스를 다루기 위해 사용할 수 있는 오퍼레이션의 집합을 정의할 수 있어야 한다. | ﻿﻿제공된 오퍼레이션을 통해서만 조작할 수 있도록 데이터를 외부로부터 보호할 수 있어야 한다. | ﻿﻿타입에 대해 여러 개의 인스턴스를 생성할 수 있어야 한다. | . … 자바가 아니네,,, . 클래스 . 클래스는 추상 데이터 타입인가? . 명확한 의미에서 추상 데이터 타입과 클래스는 동일하지 않다. 가장 핵심적인 차이는 클래스는 상속과 다형성을 지원하는 데 비해 추상 데이터 타입은 지원하지 못한다는 점이다. ![[Pasted image 20240530002130.png]] . 이처럼 기존 코드에 아무런 영향도 미치지 않고 새로운 객체 유형과 행위를 추가할 수 있는 객체지향의 특성을 개방-폐쇄 원칙이라고 부른다. 이것이 객체지 향 설계가 전통적인 방식에 비해 변경하고 확장하기 쉬운 구조를 설계할 수 있는 이유다. ",
    "url": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/07.%20%EA%B0%9D%EC%B2%B4%20%EB%B6%84%ED%95%B4.html",
    
    "relUrl": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/07.%20%EA%B0%9D%EC%B2%B4%20%EB%B6%84%ED%95%B4.html"
  },"89": {
    "doc": "08. Real MySQL 8.0",
    "title": "8장",
    "content": ". ",
    "url": "/docs/mysql/08.%20Real%20MySQL%208.0.html#8%EC%9E%A5",
    
    "relUrl": "/docs/mysql/08.%20Real%20MySQL%208.0.html#8장"
  },"90": {
    "doc": "08. Real MySQL 8.0",
    "title": "인덱스",
    "content": "인덱스는 데이터베이스 쿼리의 성능을 언급하면서 빼놓을 수 없는 부분이다. ",
    "url": "/docs/mysql/08.%20Real%20MySQL%208.0.html#%EC%9D%B8%EB%8D%B1%EC%8A%A4",
    
    "relUrl": "/docs/mysql/08.%20Real%20MySQL%208.0.html#인덱스"
  },"91": {
    "doc": "08. Real MySQL 8.0",
    "title": "디스크 읽기 방식",
    "content": ". | 랜덤 읽기 | 순차 읽기 | . HDD와 SSD . 대략 SSD가 좋다 라는 내용. 디스크의 헤더를 움직이지 않고 한 번에 많은 데이터를 읽는 순자 I/O에서는 SSD가 HDD보다 조금 빠르거나 비슷한 성능을 보이기도 한다. 하지만 랜덤 읽기의 경우 SSD가 훨씬 빠르고 순차 읽기는 비중이 크지않으므로 SSD가 매우 좋다. 랜덤 IO 순차 IO . 디스크에서 3개의 페이지를 조회할때 순차의 경우 1번 시스템 콜을 요청하지만, 랜덤의 경우 3번의 시스템 콜을 요청한다. 순차는 랜덤보다 3배 빠르다고 할 수 있다. SSD의 경우 차이가 없을 것으로 예측하지만, 차이가 있긴하다. 쿼리 튜닝해서 랜덤 IO를 순차 IO로 바꿔서 실행할 방법이 많지 않다. 일반적으로 쿼리를 튜닝하는 것은 랜덤 IO 자체를 줄여주는 것이 목적이라고 할 수 있다. 랜덤 IO를 줄인다는 것은 쿼리를 처리하는데 꼭 필요한 데이터만 읽도록 쿼리를 개선하는 것을 의미한다. ",
    "url": "/docs/mysql/08.%20Real%20MySQL%208.0.html#%EB%94%94%EC%8A%A4%ED%81%AC-%EC%9D%BD%EA%B8%B0-%EB%B0%A9%EC%8B%9D",
    
    "relUrl": "/docs/mysql/08.%20Real%20MySQL%208.0.html#디스크-읽기-방식"
  },"92": {
    "doc": "08. Real MySQL 8.0",
    "title": "인덱스란?",
    "content": "책에 비유하자면 인덱스 - 책의 맨 끝에 있는 찾아보기 데이터 - 책의 내용 레코드 주소 - 페이지 번호 가 되겠다. 찾아보기와 인덱스의 공통점중 중요한점은 정렬이다. 찾아보기는 빠르게 검색어를 찾기위해 ‘ㄱ’,’ㄴ’,’ㄷ’,’ㄹ’… 과 같은 순서로 정렬돼 있다. DBMS의 인덱스도 마찬가지로 칼ㄹ머의 값을 주어진 순서대로 미리 정렬해서 보관한다. 자료구조 중에서 SortedList 와 ArrayList는 익숙할 정도로 많이 들어봤는데, 인덱스는 SortedList와 같은 자료구조이며, ArrayList는 데이터 파일과 같은 자료 구조를 사용한다. 인덱스는 SortedList와 마찬가지로 저장되는 칼럼의 값을 이용해 항상 정렬된 상태를 유지한다. 데이터 파일은 저장된 순서대로 별도의 정렬 없이 그대로 저장한다. 장단점 SortedList는 저장이 느리지만, 이미 정렬되어있어 아주 빨리 원하는 값을 찾아올 수 있다. 테이블의 인덱스를 하나 더 추가할지 말지는 데이터의 저장 속도를 어디까지 희생할 수 있는지, 읽기 속도를 얼마나 더 빨리 만들어야 하느냐에 따라 결정해야 한다. 저장 알고리즘은 대표적으로 B-Tree 인덱스와 Hash인덱스로 구분할 수 있다. 최근에는 Fractal-Tree나 Merge-Tree와 같은 알고리즘을 사용하는 DBMS도 개발되고 있다. Hash인덱스는 값을 변경해서 인덱싱하므로, like와 같이 일부만 검색하거나 범위를 검색할 때는 해시 인덱스를 사용할 수 없다. 유니크 인덱스는 단순이 값이 고유의 1개인지 아닌지를 나타내는것이지만, 옵티머이저에게는 더 찾지 않아도 된다는 중요한 정보이다. 때문에 유니크 인덱스로 인한 처리 방식의 변화나 차이점이 상당히 많다. ",
    "url": "/docs/mysql/08.%20Real%20MySQL%208.0.html#%EC%9D%B8%EB%8D%B1%EC%8A%A4%EB%9E%80",
    
    "relUrl": "/docs/mysql/08.%20Real%20MySQL%208.0.html#인덱스란"
  },"93": {
    "doc": "08. Real MySQL 8.0",
    "title": "B-Tree",
    "content": "가장 일반적으로 사용되고, 가장 먼저 도입된 알고리즘이다. 아직도 가장 범용적인 알고리즘으로 사용되는 알고리즘이다. B-Tree의 B는 Binary가 아니라 Balanced인 점 참고로 알아두자. 구조 및 특성 . B-Tree는 트리 구조의 최상위에 하나의 루트노드가 존재하고 그 하위에 자식 노드가 붙어 있는 형태다. 트리 구조의 가장 하위에 있는 노드를 리프 노드라고 한다. 루트도 리프도아닌 노드를 브랜치 노드라고 한다. 인덱스의 리프 노드는 항상 실제 데이터 레코드를 찾아가기 위한 주솟값을 가지고 있다. | ![[Pasted image 20240509222402.png | 400]] | . | ![[Pasted image 20240509222632.png | 400]] | . InnoDB 테이블은 프라이머리 키를 주소처럼 사용하기 때문에 논리적인 주소를 가진다고 볼 수 있다. 그래서 인덱스를 통해 읽을 때는 데이터 파일을 바로 찾아가지 못한다. 인덱스에 저장돼 있는 프라이머리 키 값을 이용해 프라이머리 키 인덱스를 한번 더 검색한 후, 프라이머리 키 인덱스의 리프 페이지에 저장돼 있는 레코드를 읽는다. B-Tree인덱스 키 추가 및 삭제 . 테이블의 레코드를 저장하거나 변경하는 경우 인덱스 키 추가나 삭제 작업이 발생한다. 인덱스 키 추가 . 새로운 키 값이 B-Tree에 저장될 때 테이블의 스토리지 엔진에 따라 새로운 키 값이 즉시 인덱스에 저장될 수도 있고 그렇지 않을 수 있다. B-Tree에 저장될 때는 저장될 키 값을 이용해 B-Tree상의 적절한 위치를 검색해야 한다. 리프 노드가 꽉차서 더는 저장할 수 없을 때는 리프 노드 분리돼야 하는데, 이는 상위 브랜치 노드까지 처리의 범위가 넓어진다. 이러한 작업 탓에 B-Tree는 상대적으로 쓰기 작업에 비용이 많이 드는것으로 알려졌다. 인덱스 키 삭제 . 키값이 삭제되는 경우는 상당히 간단하다. 해당 키 값이 저장된 B-Tree의 리프 노드를 찾아서 그냥 삭제 마크만 하면 작업이 완료된다. 이렇게 삭제 마킹된 인덱스 키 공간은 계속 그대로 방치하거나 재활용할 수 있다. 인덱스 키 삭제로 인한 마킹 작업 또한 디스크 쓰기가 필요하므로 이 작업 역시 디스크 IO가 필요한 작업이다. 삭제는 따로 진행하지않고 재활용하나봄 . 인덱스 키 변경 . 인덱스의 키 값은 그 값에 따라 저장될 리프 노드의 위치가 결정되므로 B-Tree의 키 값이 변경되는 경우 단순히 인덱스상의 키 값만 변경하는 것은 불가능하다. 키값이 변경된다면 키값을 삭제 후 다시 새로운 키 값을 추가하는 형태로 처리된다. 인덱스 키 검색 . 인덱스를 이용한 검색에서 키 값에 변형된 값은 B-Tree인덱스에 존재하는 값이 아니다. 따라서 함수나 연산을 수행한 결과로 정렬한다거나 검색하는 작업은 B-Tree의 장점을 이용할 수 없으므로 주의해야한다 . ? . InnoDB에서 지원하는 레코드 잠금이나 넥스트 키락이 검색을 수행한 인덱스를 잠근 후 테이블의 레코드를 잠그는 방식으로 구현돼 있다. 따라서 update나 delete문장이 실행될 때 테이블에 적절히 사용할 수 있는 인덱스가 없으면 불필요하게 많은 레코드를 잠근다. 심지어 테이블의 모든 레코드를 잠글 수도 있다. B-Tree 인덱스 사용에 영향을 미치는 요소 . 인덱스를 구성하는 칼럼의 크기와 레코드의 건수, 유니크한 인덱스 키값의 개수 등에 의해 검색이나 변경 작업의 성능이 영향을 받는다. 키값의 크기 . InnoDB는 디스크에 데이터를 저장하는 가장 기본 단위를 페이지 또는 블록이라고 하며, 디스크의 모든 읽기 및 쓰기 작업의 최소 작업 단위가 된다. 인덱스도 페이지 단위로 관리되며, 루트와 브랜치, 리프 노드를 구분한 기준도 페이지 단위이다. 일반적으로 DBMS의 B-Tree는 자식 노드의 개수가 가변적인 구조이다. 그러면 자식 노드를 몇개까지 가질 수 있을까? 인덱스의 페이지 크기와 키 값의 크기에 따라 결정된다. 페이지의 기본값은 16KB이며 4~64사이로 선택할 수 있다. 인덱스 페이지가 16KB라고 가정해보자 키값의 크기가 16바이트라고하면 16*1024/(16+12)=585개 저장할 수 있다. 32 바이트라고 가정한다면 16*1024/(32+12)=372개 저장할 수 있다. 쿼리가 500개의 레코드를 읽어야 하는경우라면 첫번째 경우는 한번으로 해결되지만, 후자는 최소 2번 이상 디스크로부터 읽어야한다. 결국 인덱스를 구성하는 키값이 커지면 디스크로부터 읽어야 하는 횟수가 늘어나고, 느려진다는 의미이다. 또한 인덱스 키값의 길이가 길어진다는 것은 전체적인 인덱스의 크기가 커지는것을 의미하고, 버퍼 풀의 크기는 제한적이기 때문에 하나의 레코드를 위한 인덱스 크기가 커질수록 캐시해둘 수 있는 레코드 수는 줄어든다. B-Tree 깊이 . 인덱스의 깊이는 상당히 중요하지만 직접 제어할 방법이 없다. 인덱스 키값의 평균 크기가 늘어나면 어떤 현상이 발생하는지 알아보자. 인덱스의 깊이가 3인 경우 최대 2억(585*585*585)개 정도의 키값을 담을 수 있지만, 키값이 32바이트로 늘어나면 (372*372*372)개로 줄어든다. B-Tree의 깊이는 MySQL에서 값을 검색할 때 몇번이나 랜덤하게 디스크를 읽어야 하는지와 직결되는 문제다. 여기서 언급한 내용은 인덱스 키 값의 크기는 가능하면 작게 만드는 것이 좋다는 것을 강조하기 위함이다. 선택도 . 인덱스에서 선택도 또는 기수성은 거의 같은 의미로 사용된다. 모든 인덱스 키 값 가운데 유니크한 값의 수를 의미한다. 전체 인덱스 키값은 100개인데, 그중에서 유니크한 값의 수는 10개라면 기수성은 10이다. 인덱스 키 값이 중복된 값이 많아지면 기수성은 낮아지고 동시에 선택도 또한 떨어진다. 인덱스는 선택도가 높을수록 검색 대상이 줄어들기 때문에 그만큼 빨리 처리된다. name컬럼에 김민수라는 이름이 100개있을때와 10개 있을때는 차이가 있다라는 뜻 . 읽어야 하는 레코드의 건수 . 인덱스를 통해 테이블의 레코드를 읽는 것은 인덱스를 거치지 않고 바로 테이블의 레코드를 읽는 것보다 높은 비용이 드는 작업이다. 일반적인 DBMS의 옵티마이저에서 인덱스를 통해 레코드 1건을 읽는 것이 테이블에서 직접 레코드 1건을 읽는 것보다 4~5배 정도 비용이 더 많이 드는 작업인 것으로 예측한다. 즉 인덱스를 통해 읽어야 할 레코드의 건수가 전체 테이블 레코드의 20% ~ 25%를 넘어 서면 인덱스를 이용하지 않고 테이블 모두 직접 읽어서 필요한 레코드만 가려내는 방식으로 처리하는 것이 효율적이다. B-Tree 인덱스를 통한 데이터 읽기 . 인덱스 레인지 스캔 . 인덱스의 접근 방법 가운데 가장 대표적인 접근 방식이다. 인덱스를 통해 레코드를 한 건만 읽는 경우와 한 건 이상을 읽는 경우를 각각 다른 이름으로 구분하지만, 이번 절에서는 묶어서 인덱스 레인지 스캔이라고 표현한다. 예제와 함께 살펴보자 . SELECT * FROM employees WHERE first_name BETEWEEN 'Ebbe' AND 'Gad'; . | ![[Pasted image 20240509231934.png | 400]] | . 인덱스 레인지 스캔은 검색해야 할 인덱스의 범위가 결정됐을 때 사용하는 방식이다. 루트 노드에서부터 비교를 시작해 브랜치 노드를 거치고 최종적으로 리프 노드까지 찾아 들어가야만 비로소 필요한 레코드의 시작 지점을 찾을 수 있다. 일단 시작해야 할 위치를 찾으면 이후 부터는 리프 노드의 레코드만 순서대로 읽으면 된다. 이처럼 차례대로 쭉 읽는 것을 스캔이라고 표현한다. 리프 노드의 끝까지 읽으면 리프 노드 간의 링크를 이용해 다음 리프 노드를 찾아서 다시 스캔한다. | ![[Pasted image 20240509232344.png | 400]] | . 한가지 또 중요한 것은 인덱스의 리프 노드에서 검색 조건에 일치하는 건들은 데이터 파일에서 레코드를 읽어오는 과정이 필요하다는 것이다. 이때 리프 노드에 저장된 레코드 주소로 데이터 파일의 레코드를 읽어오는데, 레코드 한 건 한건 단위로 랜덤 IO가 한번씩 일어난다. 위 그림에서는 최대 3번이 일어난다. 그래서 인덱스를 통해 데이터 레코드를 읽는 작업은 비용이 많이 드는 작업으로 분류된다. 종합하면 인덱스 레인지 스캔은 다음과 같은 작업을 진행한다. | 인덱스에서 조건을 만족하는 값이 저장된 위치를 찾는다. 이 과정을 인덱스 탐색이라고 한다. | 1번에서 탐색된 위치부터 필요한 인덱스를 차례대로 읽는다. 이 과정을 인덱스 스캔이라고 한다. | 2번에서 읽어들인 인덱스 키와 레코드 주소를 통해 레코드가 저장된 페이지를 가져오고, 최종 레코드를 읽어온다 | . ![[Pasted image 20240509232910.png|400]] 얼마나 열일했는지 확인할 수 있다. 인덱스 풀 스캔 . 인덱스 레인지 스캔과 달리 인덱스의 처음부터 끝까지 머두 읽는 방식을 인덱스 풀스캔이라고 한다. 대표적으로 쿼리의 조건절에 사용된 컬럼이 인덱스의 첫 번째 컬럼이 아닌 경우 인덱스 풀 스캔 방식이 사용된다. 예를 들어 인덱스는 (A,B,C)컬럼의 순서로 만들어 져 있지만 쿼리의 조건절은 B컬럼이나 C컬럼으로 검색하는 경우이다. ![[Pasted image 20240512161321.png|400]] 쿼리가 인덱스에 명시된 컬럼만으로 조건을 처리할 수 있는 경우 주로 이 방식이 사용된다. 인덱스 뿐만 아니라 레코드까지 모두 읽어야 한다면 절대 이방식으로 처리되지 않는다. 인덱스 레인지 스캔보다 빠르지 않지만, 테이블 풀 스캔보다 효율적이다. 루스 인덱스 스캔 . 말그대로 느슨하게 또는 듬성듬성하게 인덱스를 읽는것을 의미한다. ![[Pasted image 20240512161823.png|400]] 루스 인덱스 스캔은 인덱스 레인지 스캔과 비슷하게 동작하지만 중간에 필요치 않은 인덱스 키 값은 무시하고 다음으로 넘어가는 형태로 처리한다. 일반적으로 group by 또는 집합 함수 가운데 max()또는 min()함수에 대해 최적화를 하는 경우에 사용된다. SELECT dept_no, MIN(emp_no) FROM dept_emp WHERE dep_no BETWEEN 'd002' AND 'd004' GROUP BY dept_no; . 위 쿼리는 dept_no 와 emp_no라는 두개의 컬럼으로 인덱스가 생성돼 있다. 또한 (dept_no, emp_no)조합으로 정렬까지 돼 있어 위 그림과 같이 dept_no그룹별로 첫 번째 레코드의 emp_no값만 읽으면 된다. 즉 인덱스에서 where조건을 만족하는 범위 전체를 다 스캔할 필요가 없다는 것을 옵티마이저는 알고 있기 때문에 조건에 만족하지 않는 레코드는 무시하고 다음 레코드로 넘어간다. 인덱스 스킵 스캔 . 데이터베이스 서버에서 인덱스의 핵심은 값이 정렬돼 있다는 것이며, 이로 인해 인덱스를 구성하는 컬럼의 순서가 매우 중요하다. 예를 들어 employees 테이블에 다음과 같은 인덱스를 생성해보자. ALTER TABLE employees ADD INDEX ix_gender_birthdate (gender, bith_date); . 이 인덱스를 사용하려면 where 조건절에서 gender 칼럼에 대한 비교 조건이 필수였다. SELECT * FROM employees WHERE birth_date &gt;= '1965-02-01'; SELECT * FROM employees WHERE gender='M' AND birth_date &gt;= '1965-02-01'; . Mysql 8.0 버전 부터는 옵티마이저가 gender 컬럼을 건너 뛰어서 birth_date 컬럼만으로도 인덱스 검색이 가능하게 해주는 인덱스 스킵 스캔 최적화 기능이 도입됐다. \b이를 위해 옵티마이저는 gender컬럼에서 모든 값을 조회해서(distinct) 주어진 쿼리에 gender컬럼의 조건을 추가해서 쿼리를 다시 실행하는 형태로 처리한다. | ![[Pasted image 20240512163251.png | 400]] | . 결론적으로 아래 2개의 쿼리를 실행하는 것과 비슷한 형태의 최적화를 실행하게 된다. SELECT * FROM employees WHERE gender='M' AND birth_date &gt;= '1965-02-01'; SELECT * FROM employees WHERE gender='F' AND birth_date &gt;= '1965-02-01'; . 단점도 있다 . | WHERE 조건절에 조건이 없는 인덱스의 선행 칼럼의 유니크한 값의 개수가 적여야함 | 쿼리가 인덱스에 존재하는 컬럼만으로 처리 가능해야함 | . 선행 컬럼이 가진 유니크한 값의 개수가 소량일 때만 적용 가능한 최적화라는 것을 기억하자. 다중 컬럼 인덱스 . 지금까지 살펴본 인덱스들은 모두 1개의 컬럼만 포함된 인덱스였다. 하지만 실제 서비스용 데이터베이스에서는 2개 이상의 컬럼을 포함하는 인덱스가 더 많이 사용된다. 2개 이상의 컬럼으로 구성된 인덱스를 다중 컬럼 인덱스라고한다. ![[Pasted image 20240512164031.png|400]] 위 그림에서 중요한점은 인덱스의 두번째 컬럼은 첫번째 컬럼에 의존해서 정렬돼 있다는 것이다. 때문에 각 컬럼의 순서가 상당히 중요하며, 그것을 아주 신중히 결정해야 하는 이유가 이것이다. B-Tree 인덱스의 정렬 및 스캔 방향 . 인덱스를 생성할 때 설정한 규칙에 따라 인덱스의 키 값은 항상 오름차순이거나 내림차순으로 정렬되어 저장한다. 하지만 거꾸로 읽으면 되기 때 옵티마이저가 실행단계에서 결정한다 . 인덱스의 정렬 . MySQL 8.0 에서부터는 각 컬럼별로 오름 내림 차순을 선택할 수 있다. CREATE INDEX ix_teamname_userscore ON employees (team_name ASC, user_score DESC); . 내림차순 인덱스 . | ![[Pasted image 20240512164740.png | 400]] | . 요약하자면 정렬된 순서대로 읽는 쿼리와 역순으로 읽어야하는 경우 단순하게 역방향으로 읽는게 아니기 때문에 성능의 차이가 있다. (예제에서는 28.9%정도) . | ![[Pasted image 20240512164928.png | 400]] | . B-Tree 인덱스의 가용성과 효율성 . 쿼리의 where조건이나 group by 절이 어떤 경우에 인덱스를 사용할 수 있고 어떤 방식으로 사용할 수 있는지 식별할 수 있어야 한다. 비교 조건의 종류와 효율성 . 다중 컬럼 인덱스에서 각 컬럼의 순서와 그 컬럼에 사용된 조건이 동등비교 인지 아니면 크가 또는 작다 같은 범위 조건인지에 따라 각 인덱스 컬럼의 활용 형태가 달라지며, 그 효율 또한 달라진다. SELECT * FROM dept_emp WHERE dept_no='d002' AND emp_no &gt;= 10114; . 두가지 케이스로 인덱스 했다고 가정해보자 . | A : dept_no, emp_no | B : emp_no, dept_no A의 경우 꼭 필요한 작업만 한다. B의 경우는 dept_no에서 필요없는 값까지 모두 emp_no&gt;=10114에서 스캔한뒤 dept_no를 또한번 걸러낸다. ![[Pasted image 20240512165816.png|400]] 이처럼 인덱스를 통해 읽은 레코드가 나머지 조건에 맞는지 비교하는 취사선택 작업을 필터링이라고도 한다. 이러한 작업은 오히려 쿼리 실행을 더 느리게 만들때가 많다. | . 인덱스의 가용성 . B-Tree인덱스의 특징은 왼쪽 값에 기준해서 오른쪽 값이 정렬돼있다는 것이다. 여기서 왼쪽이란 하나의 컬럼 내에서 뿐만 아니라 다중 컬럼 인덱스의 컬럼에 대해서도 함께 적용된다. | A : first_name | B : dept_np, emp_no | . | ![[Pasted image 20240512170405.png | 400]] | . SELECT * FROM employees WHERE first_name LIKE '%mer'; . 이 쿼리는 인덱스 레인지 스캔 방식으로 인덱스를 이용할 수는 없다. 이유는 first_name 컬럼에 저장된 값의 왼쪽부터 한 글자씩 비교해 가면서 이맃하는 레코드를 찾아야하는데, 조건절에 주어진 상수값(‘%mer’)에는 왼쪽 부분이 고정되지 않았기 때문이다. 따라서 정렬 우선순위가 낮은 뒷부분의 값만으로는 왼쪽 기준 정렬 기반의 인덱스인 B-Tree에서는 인덱스의 효과를 얻을 수 없다. 예를 들어, `first_name`이라는 컬럼이 있다면, 이 인덱스는 이름의 첫 글자를 기준으로 정렬되어 있습니다. 하지만 여기서 `%mer`와 같이 와일드카드를 사용하여 검색하는 경우, 왼쪽에서부터 일치하는 값을 찾아야 합니다. 즉, 이름의 첫 글자가 `m`이고, 나머지는 어떤 문자든 상관 없는 경우에 해당합니다. 이런 경우 B-Tree 인덱스는 효과적으로 활용되지 않습니다. 왜냐하면 B-Tree는 일치하는 값의 시작점을 찾는 데 효과적이지만, 일치하는 값의 중간이나 끝을 찾는 데는 효과적이지 않기 때문입니다. SELECT * FROM dept_emp where emp_no &gt;= 10144; . 인덱스가 (dept_no, emp_no)컬럼 순서대로 생성돼 있다면 인덱스의 선행 컬럼인 dept_np 조건 없이 emp_no 값만으로 검색하면 인덱스를 효율적으로 사용할 수 없다. 가용성과 효율성판단 . 기본적으로 B-Tree 인덱스의 특성상 다음 조건에서는 사용할 수 없다. 경우에 따라서는 체크 조건으로 인덱스를 사용할 수는 있다 . | NOT-EQUAL로 비교된 경우(“&lt;&gt;”,”NOT IN”, “NOT BETWEEN”, “IS NOT NULL”) | LIKE ‘%??’(앞부분이 아닌 뒷부분 일치) 형태로 문자열 패턴이 비교된 경우 | 스토어드 함수나 다른 연산자로 인덱스 컬럼이 변형된 후 비교된 경우 . | WHERE SUBSTRING(column,1,1) = ‘X’ | WHERE DAYOFMONTH(column) = 1 | . | NOT-DETERMINISTIC 속성의 스토어드 함수가 비교 조건에 사용된 경우 . | WHERE column = deterministic_function() | . | 데이터 타입이 서로 다른 비교(인덱스 컬럼의 타입을 변환해야 비교가 가능한 경우) . | WHERE char_column = 10 | . | 문자열 데이터 타입의 콜레이션이 다른 경우 . | WHERE utf-8_bin_char_column = euckr_bin_char_column 다른 일반적인 DBMS에서는 NULL 값이 인덱스에 저장되지 않지만 MySQL에서는 NULL값도 인덱스에 저장된다. | . | . 다중 컬럼으로 만들어진 인덱스는 어떤 조건에서 사용될 수 있고, 어떤 경우에 절대 사용할 수 없는지 알아보자. INDEX ix_test (column_1,column_2,column_3,... column_n) . | 작업 범위 결정 조건으로 인덱스를 사용하지 못하는 경우 . | column_1 컬럼에 대한 조건이 없는 경우 | column_1 컬럼의 비교 조건이 위의 인덱스 사용 불가 조건중 하나인 경우 | . | 작업 범위 결정 조건으로 인덱스를 사용하는 경우(i는 2보다 크고 n보다 작은 임의의 값을 의미) . | column_1 ~ column(i-1) 컬럼까지 동등 비교 형태(“=” 또는 “IN”)로 비교 | column_i 컬럼에 대해 다음 연산자 중 하나로 비교 . | 동등 비교 (“=” 또는 “IN”) | 크다 작다 형태(“&gt;”또는”&lt;”) | LIKE로 좌측 일치 패턴 (LIKE ‘승환$’) | . | . | . 위 두 조건을 만족하는 쿼리는 column_1 부터 column_i 까지는 작업 범위 결정 조건으로 사용 되고, column(i+1)부터 column_n까지의 조건은 체크 조건으로 사용된다. 인덱스를 사용하는 경우와 그렇지 않은 상황에 해당하는 쿼리 조건 예제를 살펴보자. -- 다음 쿼리는 인덱스를 사용할 수 없음 WHERE column_1 &lt;&gt; 2 -- 다음 쿼리는 column_1과 column_2까지 범위 결정 조건으로 사용됨 WHERE column_1 = 1 AND column_2 &gt; 10 -- 다음 쿼리는 column_1, column_2, column3까지 범위 결정 조건으로 사용됨 WHERE column_1 IN (1,2) AND column_2 - 2 AND column_3 &lt;= 10 -- 다음 쿼리는 column_1, column_2, column_3까지 범위 결정 조건으로, column_4는 체크 조건으로 사용됨 WHERE column_1 = 1 AND column_2 = 2 AND column_3 IN (10,20,30) AND column_4 &lt;&gt; 100 -- 다음 쿼리는 column_1, column_2, column_3, column_4까지 범위 결정 조건으로 사용됨 -- 좌측 패턴 일치 LIKE 비교는 크다 또는 작다 비교와 동금으로 생각하면 됨 WHERE column_1 = 1 AND column_2 IN (2,4) AND column_3 = 30 column_4 LIKE '김승%' -- 다음 쿼리는 column_1, column_2, column_3, column_4, column_5 컬럼까지 모두 범위 결정 조건으로 사용됨 WHERE column_1 = 1 AND column_2 = 2 AND column_3 = 30 column_4 LIKE '김승환' AND column_5 = '서울' . ",
    "url": "/docs/mysql/08.%20Real%20MySQL%208.0.html#b-tree",
    
    "relUrl": "/docs/mysql/08.%20Real%20MySQL%208.0.html#b-tree"
  },"94": {
    "doc": "08. Real MySQL 8.0",
    "title": "R-Tree 인덱스",
    "content": "내부 메커니즘은 B-Tree와 흡사하다. 차이는 B-Tree는 1차원 스칼라 값인 반면 R-Tree는 2차원 공간 개념 값이라는 것이다. 최근 GPS나 지도 서비스를 내장하는 스마트 폰이 대중화되면서 SNS 서비스가 GIS와 GPS에 기반을 둔 서비스로 확장되고 있다. 이러한 위치 기반 서비스를 구현하는 방법은 여러 가지가 있겠지만 MySQL의 공간 확장을 이용하면 간단하게 이러한 기능을 구현할 수 있다. MySQL의 공간 확장에는 다음과 같이 크게 3가지 기능이 포함돼 있다. | 공간 데이터를 저장할 수 있는 데이터 타입 | 공간 데이터의 검색을 위한 공간 인덱스(R-Tree 알고리즘) | 공간 데이터의 연상 함수(거리 또는 포함 관계의 처리) | . 구조 및 특성 . MySQL은 공간 정보의 저장 및 검색을 위해 여러 가지 기하학적 도형 정보를 관리할 수 있는 데이터 타입을 제공한다. ![[Pasted image 20240512212917.png|400]] . 마지막의 GEOMETRY타입은 나머지 3개 타입의 슈퍼 타입으로, POINT와 LINE, POLYGON 객체를 모두 저장할 수 있다. -- 각 타입 조회 SELECT ST_AsText(ST_GeomFromText('POINT(30 10)')); SELECT ST_AsText(ST_GeomFromText('LINESTRING(0 0, 1 1, 2 2)')); SELECT ST_AsText(ST_GeomFromText('POLYGON((0 0, 0 1, 1 1, 1 0, 0 0))')); . 저장된 값 POINT 0101000000000000000000F03F0000000000000040 LINE 01020000000300000000000000000000000000000000000000000000000000000000000000000F03F000000000000004000000000000000400800000000000004001000000000000040 POLYGON 01030000000100000005000000000000000000000000000000000000000000000000000000000000000000F03F00000000000000000000000000000000F03F0000000000000040000000000000000000000000000000F03F0000000000000040000000000000000000000000000000F03F000000000000004000000000000000000000000000000000 . 공간 정보의 검색을 위한 R-Tree 알고리즘을 이해하려면 MBR이라는 개념을 알고 있어야 한다. 그림 8.20은 그림 8.19에서 예시로 든 도형들의 MBR을 보여주는데, MBR이란 “Minimum Bounding Rectangle”의 약자로 해당 도형을 감싸는 최소 크기의 사각형을 의미한다. | ![[Pasted image 20240512214708.png | 400]] | . ![[Pasted image 20240512215729.png|400]] 위 그림은 MBR을 3개의 레벨로 나눠서 그려본 것이다. | 최상위 레벨 : R1, R2 | 차상위 레벨 : R3, R4, R5, R6 | 최하위 레벨 : R7 ~ R14 | . 최하위 레벨의 MBR은 각 도형 데이터의 MBR을 의미한다. 그리고 차상위 레벨의 MBR은 중간 크기의 MBR이다. 그림 8.22의 예제에서 최상위 MBR은 R-Tree의 루트 노드에 저장되는 정보이며, 차상위 그룹 MBR은 R-Tree의 브랜치 노드가 된다. 마지막으로 각 도형의 객체는 리프 노드에 저장되므로 그림 8.23과 같이 R-Tree 인덱스 내부를 표현할 수 있다. ![[Pasted image 20240512220132.png|400]] . R-Tree 인덱스의 용도 . R-Tree는 각 도형의 포함 관계를 이용해 만들어진 인덱스다. 따라서 ST_Contains()등과 같은 포함 관계를 비교하는 함수로 검색을 수행하는 경우에만 인덱스를 이용할 수 있다. 대표적으로는 ‘현재 사용자의 위치로부터 반경 5km이내의 음식점 검색’등과 같은 검색에 사용할 수 있다. 현재 출시되는 버전의MySQL에서는 거리를 비교하는 ST_Distance()와 ST_Distance_Sphere() 함수는 공간 인덱스를 효율적으로 사용하지 못하기 때문에 공간 인덱스를 사용할 수 있는 ST_Contains()또는 ST_Within()을 이용해 거리 기반의 검색을 해야한다. | ![[Pasted image 20240512220928.png | 400]] | . 그림에서 P6는 반경에 포함되지 않지만 ST_Contains()또는 ST_Within() 조회시 포함되어 나온다. 뺴고 결과를 조회하려면 조금 더 복잡한 비교가 필요하다. 무방하다면 아래와 같은 쿼리를 수행하면 된다. SELECT * FROM tb_location WHERE ST_Contains(사각상자, px); SELECT * FROM tb_location WHERE ST_within(px, 사각상자); . P6를 반드시 제거해야 한다면 다음과 같이 ST_Contains()비교의 결과에 대해 ST_Distance_Sphere()함수를 이용해 다시한번 필터링 해야한다. SELECT * FROM tb_location WHERE ST_Contains(사각상자, px) AND ST_Distance_Sphere(p,px)&lt; 5*1000 -- 5km . ",
    "url": "/docs/mysql/08.%20Real%20MySQL%208.0.html#r-tree-%EC%9D%B8%EB%8D%B1%EC%8A%A4",
    
    "relUrl": "/docs/mysql/08.%20Real%20MySQL%208.0.html#r-tree-인덱스"
  },"95": {
    "doc": "08. Real MySQL 8.0",
    "title": "전문 검색 인덱스",
    "content": "이전까지 살펴본 인덱스 알고리즘은 크지 않은 데이터에 대한 인덱싱 알고리즘이였다. 문서의 내용 전체를 인덱스화해서 특정 키워드가 포함된 문서를 검색하는 전문(full text) 검색에는 일반적인 용도의 B-Tree인덱스를 사용할 수 없다. 인덱스 알고리즘 . 전문 검색에서는 문서 본문의 내용에서 사용자가 검색하게 될 키워드를 분석해 내고, 빠른 검색용으로 사용할 수 있게 이러한 키워드로 인덱스를 구축한다. 어근 분석 알고리즘 . 전문 검색 인덱스는 다음과 같은 두 가지 중요한 과정을 거쳐서 색인 작업이 수행된다. | 불용어 처리 | 어근 분석 불용어 처리는 검색에서 별 가치가 없는 단어를 모두 필터링해서 제거하는 작업을 의미한다. 개수는 많지 않기 때문에 알고리즘을 구현한 코드에 모두 상수로 정의해서 사용하는 경우가 많고, 데이터베이스화해서 사용자가 추가하거나 삭제할 수 있게 구현하는 경우도 있다. | . 어근 분석은 검색어로 선정된 단어의 뿌리인 원형을 찾는 작업이다. 한글이나 일본어의 경우 영어와 같이 단어의 변형 자체는 거의 없기 때문에 어근 분석보다는 문장의 형태소를 분석해서 명사와 조사를 구분하는 기능이 더 중요한 편이다. 분석과 처리를 위해 MeCab라는 플러그인이 필요하며, 플러그인 설치로 끝나는것이 아닌 단어 사전이 필요하다. 또한 문장을 해체해서 각 단어의 품사를 식별할 수 있는 문장의 구조 인식이 필요하다. 이는 샘플을 이용해 학습과정이 필요한데, 이 과정은 상당한 시간이 필요한 작업이다. n-gram 알고리즘 . MeCab을 위한 형태소 분석은 매우 전문적인 전문 검색 알고리즘이어서 만족할 만한 결과를 내기 위해서는 많은 노력과 시간이 필요로 하낟. 이런 담점을 보완하기 위한 방법으로 n-gram 알고리즘이 도입됐다. 형태소 분석이 문장을 이해하는 알고리즘이라면, n-gram은 단순히 키워드를 검색해내기 위한 인덱싱 알고리즘이라고 할 수 있다. n-gram이란 본문을 무조건 몇 글자씩 잘라서 인덱싱하는 방법이다. 형태소 분석보다는 알고리즘이 단순하고 국가별 언어에 대한 이해와 준비 작업이 필요 없는 반면, 만들어진 인덱스의 크기는 상당히 큰 편이다. n-gram에서 n은 인덱싱할 키워드의 최소 글자 수를 의미한다. 일반적으로 2글자 방식을 많이 사용한다. To be or not to be. That is the question . 각 단어는 다음과 같이 띄어쓰기(공백)와 마침표(.)를 기준으로 10개의 단어로 구분되고, 2글자씩 중첩해서 토큰으로 분리된다. 주의해야 할 것은 각 글자가 중첩해서 2글자씩 토큰으로 구분됐다는 것이다. 그래서 10글자 단어라면 그 단어는 2-gram알고리즘에서는 (10-1)개의 토큰으로 구분된다. 이렇게 구분된 각 토큰을 인덱스에 저장하기만 하면 된다. | ![[Pasted image 20240512232238.png | 400]] | . MySQL에서는 이렇게 생성된 토큰들에 대해 불용어를 걸러내는 작업을 수행하는데, 불용어와 동일하거나 포함하는 경우 걸러서 버린다. MySQL서버에 내장된 불용어를 사용하지 않고 사용자가 별도로 정의하는 방법도 있다. 전문 검색 인덱스의 가용성 . 전문 검색 인덱스를 사용하려면 반드시 두가지 조건을 갖춰야 한다 . | 쿼리 문장이 전문 검색을 위한 문법 (MATCH … AGAINST …)을 사용 | 테이블이 전문 검색 대상 컬럼에 대해서 전문 인덱스 보유 | . ",
    "url": "/docs/mysql/08.%20Real%20MySQL%208.0.html#%EC%A0%84%EB%AC%B8-%EA%B2%80%EC%83%89-%EC%9D%B8%EB%8D%B1%EC%8A%A4",
    
    "relUrl": "/docs/mysql/08.%20Real%20MySQL%208.0.html#전문-검색-인덱스"
  },"96": {
    "doc": "08. Real MySQL 8.0",
    "title": "함수 기반 인덱스",
    "content": "일반적인 인덱스는 컬럼의 값 일부 또는 전체에 대해서만 인덱스 생성이 허용된다. 하지만 때로는 컬럼의 값을 변형해서 만들어진 값에 대해 인덱스를 구축해야 할 때도 있다. 함수 기반 인덱스를 구현하는 방법은 두가지로 구분할 수 있다 . | 가상 컬럼을 이용한 인덱스 | 함수를 이용한 인덱스 | . 가상 컬럼을 이용한 인덱스 . 아래와 같은 테이블이 있다고 가정하자. CREATE TABLE user ( user_id BIGINT, first_name VARCHAR (10), last_name VARCHAR (10), PRIMARY KEY (user_id) } . first_name과 last_name을 합쳐서 검색하는 요건이 생겼다면 full_name이라는 컬럼을 추가하고 모든 레코드에 full_name을 업데이트하는 작업을 거쳐야 했다. 8.0버전 부터는 다음과 같이 가상 컬럼을 추가하고 그 가상 컬럼에 인덱스를 생성할 수 있게 됐다. ALTER TABLE user ADD full_name VARCHAR(30) AS (CONCAT (first_name,' ' ,last_name)) VIRTUAL, ADD INDEX ix_fullname (full_name); . 이제부터는 full_name 컬럼에 대한 검색도 새로 만들어진 ix_fullname인덱스를 이용해 실행 계획이 만들어지는 것을 확인할 수 있다. | ![[Pasted image 20240512234025.png | 400]] | . 함수를 이용한 인덱스 . CREATE TABLE user ( user_id BIGINT, first_name VARCHAR (10), last_name VARCHAR (10) , PRIMARY KEY (user_id), INDEX ix_ fullname ((CONCAT(first_name,' ' ,last_name))) ) . 함수를 직접 사용하는 인덱스는 테이블의 구조는 변경하지 않고, 계산된 결과값의 검색을 빠르게 만들어 준다. 함수 기반 인덱스를 활용하려면 반드시 조건절에 함수 기반 인덱스에 명시된 표현식이 그대로 사용돼야 한다. ",
    "url": "/docs/mysql/08.%20Real%20MySQL%208.0.html#%ED%95%A8%EC%88%98-%EA%B8%B0%EB%B0%98-%EC%9D%B8%EB%8D%B1%EC%8A%A4",
    
    "relUrl": "/docs/mysql/08.%20Real%20MySQL%208.0.html#함수-기반-인덱스"
  },"97": {
    "doc": "08. Real MySQL 8.0",
    "title": "멀티 밸류 인덱스",
    "content": "전문 검색 인덱스를 제외한 모든 인덱스는 레코드 1건이 1개의 인덱스 키 값을 가진다. 하지만 멀티 밸류 인덱스는 하나의 데이터 레코드가 여러 개의 키 값을 가질 수 있는 형태의 인덱스다. 하지만 최근 RDBMS들이 json 데이터 타입을 지원하기 시작하면서 json의 배열 타입의 필드에 저장된 원소들에 대한 인덱스 요건이 발생한 것이다. CREATE TABLE user ( user_ id BIGINT AUTO_INCREMENT PRIMARY KEY, first__name VARCHAR (10), last_name VARCHAR (10), credit_info JSON, INDEX mx_creditscores ( (CAST(credit_info-&gt;'$.credit_scores' AS UNSIGNED ARRAY)); ) INSERT INTO user VALUES (1, 'Matt', 'Lee', '{\"credit_scores\":[360, 353, 351]}'); . 멀티 밸류 인덱스를 활용하기 위해서는 일반적인 조건 방식을 사용하면 안되고, 반드시 다음 함수들을 이용해서 검색해야 옵티마이저가 인덱스를 활용한 실행 계획을 수립한다. 이제 신용 점수를 검색하는 쿼리를 살펴보자 . | MEMBER OF() | JSON_CONTAINS() | JSON_OVERLAPS() ![[Pasted image 20240512234749.png|400]] 이 예제에서는 MEMBER OF() 연산자를 사용했지만 나머지 두 연산자도 모두 멀티 밸류 인덱스를 활용해 실행 계획이 만들어진다. | . ",
    "url": "/docs/mysql/08.%20Real%20MySQL%208.0.html#%EB%A9%80%ED%8B%B0-%EB%B0%B8%EB%A5%98-%EC%9D%B8%EB%8D%B1%EC%8A%A4",
    
    "relUrl": "/docs/mysql/08.%20Real%20MySQL%208.0.html#멀티-밸류-인덱스"
  },"98": {
    "doc": "08. Real MySQL 8.0",
    "title": "클러스터링 인덱스",
    "content": "클러스터링이란 여러 개를 하나로 묶는다는 의미로 주로 사용되는데, 지금 설명하고자 하는 인덱스의 클러스터링도 그 의미를 크게 벗어나지 않는다. 클러스터링 인덱스 . 클러스터링 인덱스는 테이블의 프라이머리 키에 대해서만 적용되는 내용이다. 즉 프라이머리 키 값이 비슷한 레코드끼리 묶어서 저장하는 것을 클러스터링 인덱스라고 표현한다. 중요한 것은 프라이머리 키 값에 의해 레코드의 저장 위치가 결정된다는 것이며, 키값이 바뀌면 물리적인 저장 위치가 바뀌어야 한다는 것을 의미한다. 사실 클러스터링 인덱스 알고리즘이라기 보단 저테이블 레코드 저장 방식이라고 볼 수 있다. 그래서 클러스터링 테이블 이라고 부르기도 한다. | ![[Pasted image 20240513000732.png | 400]] | . | ![[Pasted image 20240513000808.png | 400]] | . 그러면 프라이머리 키가 없는 테이블은 어떻게 클러스터링 테이블로 구성될까? . | 프라이머리 키가 있으면 기본적으로 프라이머리 키를 클러스터링 키로 선택 | NOT NULL 옵션의 유니크 인덱스 중에서 첫 번째 인덱스를 클러스터링 키로 선택 | 자동으로 유니크한 값을 가지도록 증가되는 컬럼을 내부적으로 추가한 후 클러스터링 키로 선택 | . 세컨더리 인덱스에 미치는 영향 . 프라이머리 키가 데이터 레코드의 저장에 미치는 영향을 알아봤다. 이제 프라이머리 키가 세컨더리 인덱스에 어떤 영향을 미치는지 알아보자 . InnoDB의 세컨더리 인덱스는 해당 레코드가 저장된 주소가 아니라 프라이머리 키 값을 저장하도록 구현되어있다. 클러스터링 인덱스의 장점과 단점 . | 장점 | • 프라이머리 키&lt;클러스터링 키)로 검색할 때 처리 성능이 매우 빠름(특히, 프라이머리 키를 범위 검색하는 경우 매 우 빠름)• 테이블의 모든 세컨더리 인덱스가 프라이머리 키를 가지고 있기 때문에 인덱스만으로 처리될 수 있는 경우가 많 음(이를 커버링 인덱스라고 한다. 더 자세한 내용은 10장 ‘실행 계획’에서 다시 설명) | . | 단점 | • 테이블의 모든 세컨더리 인덱스가 클러스터링 키를 갖기 때문에 클러스터링 키 값의 크기가 클 경우 전체적으로 인덱스의 크기가 커짐• 세컨더리 인덱스를 통해 검색할 때 프라이머리 키로 다시 한번 검색해야 하므로 처리 성능이 느림- INSERT할 때 프라이머리 키에 의해 레코드의 저장 위치가 결정되기 때문에 처리 성능이 느림• 프라이머리 키를 변경할 때 레코드를 DELETE하고 INSERT하는 작업이 필요하기 때문에 처리 성능이 느림 | . 클러스터링 테이블 사용 시 주의사항 . 클러스터링 인덱스 키의 크기 . 프라이머리 키는 AUTO-INCREMENT 보다는 업무적인 컬럼으로 생성(가능한 경우) . 프라이머리 키는 반드시 명시할 것 . ",
    "url": "/docs/mysql/08.%20Real%20MySQL%208.0.html#%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%EB%A7%81-%EC%9D%B8%EB%8D%B1%EC%8A%A4",
    
    "relUrl": "/docs/mysql/08.%20Real%20MySQL%208.0.html#클러스터링-인덱스"
  },"99": {
    "doc": "08. Real MySQL 8.0",
    "title": "유니크 인덱스",
    "content": "유니크는 사실 인덱스라기 보단 제약조건에 가깝다. 프라이머리 키는 클러스터링 키 역할도 하므로 유니크 인덱스와는 근본적으로 다르다 . 유니크 인덱스와 일반 세컨더리 인덱스 비교 . 인덱스 구조상 아무런 차이점이 없다. 인덱스 읽기 . 유니크가 더 빠르다고 생각하지만 사실이 아니다. 인덱스 쓰기 . 유니크는 중복 값이 있는지 체크하기 때문에 더 느리다. 유니크 인덱스 사용 시 주의사항 . 꼭 필요한 경우라면 유니크 인덱스를 생성하는 것은 당연하다. 하지만 성능이 좋아질 것으로 생각하고 불필요하게 유니크 인덱스를 생성하지 않는 것이 좋다. ",
    "url": "/docs/mysql/08.%20Real%20MySQL%208.0.html#%EC%9C%A0%EB%8B%88%ED%81%AC-%EC%9D%B8%EB%8D%B1%EC%8A%A4",
    
    "relUrl": "/docs/mysql/08.%20Real%20MySQL%208.0.html#유니크-인덱스"
  },"100": {
    "doc": "08. Real MySQL 8.0",
    "title": "외래키",
    "content": "외래키 관리에는 중요한 두 가지 특징이 있다. | 테이블의 변경(쓰기 잠금)이 발생하는 경우에만 잠금 대기가 발생한다. | 외래키와 연관되지 않은 컬럼의 변경은 최대한 잠금 대기을 발생시키지 않는다. | . CREATE TABLE tb_parent ( id INT NOT NULL, fd VARCHAR (100) NOT NULL, PRIMARY KEY (id) ) ENGINE=InnoDB; CREATE TABLE tb_child ( id INT NOT NULL, pid INT DEFAULT NULL,-- 1/ parent.id 칼럼 참조 Fa VARCHAR(100) DEFAULT NULL, PRIMARY KEY (id), KEY ix parentid (pid), CONSTRAINT Child ibfk 1 FOREIGN KEY (pid) REFERENCES to parent (id) ON DELETE CASCADE ) ENGINE=InnoDB; INSERT INTO tbparent VALUES (1, 'parent-1'), (2, 'parent-2'); mysal&gt; INSERT INTO tb_child VALUES (100, 1, 'child-100'); . 자식 테이블의 변경이 대기하는 경우 . | 작업 번호 | 커넥션-1 | 커넥션-2 | . | 1 | BEGIN; |   | . | 2 | UPDATE tb_parentSET fd=’changed-2’ WHERE id=2; |   | . | 3 |   | BEGIN; | . | 4 |   | UPDATE tb_ childSET pid=2 WHERE id=100; | . | 5 | ROLLBACK; |   | . | 6 |   | Query OK, 1 row affected (3.04 sec) | . 이 작업에서는 1번 커넥션에서 먼저 트랜잭션을 시작하고 부모 테이블에서 id가 2인 레코드에 update를 실행한다. 이 과정에서 1번 커넥션이 tb_parent 테이블에서 id가 2인 레코드에 대해 쓰기 잠금을 획득한다. 그리고 2번 커넥션에서 자식 테이블의 외래키 컬럼인 pid를 2로 변경하는 쿼리를 실행해보자. 이 쿼리(작업 번호 4)는 부모 테이블의 변경 작업이 완료될 때까지 대기한다. 다시 1번 커넥션에서 ROLLBACK이나 COMMIT으로 트랜잭션을 종료하면 2번 커넥션의 대기 중이던 작업이 즉시 처리되는 것을 확인할 수 있다. 이는 첫번째 특징에 해당한다. 자식 테이블의 외래키가 아닌 컬럼의 변경은 외래키로 인한 잠금 확장이 발생하지 않는다. 이는 두번째 특징에 해당한다. 부모 테이블의 변경 작업이 대기하는 경우 . | 작업 번호 | 커넥션-1 | 커넥션-2 | . | 1 | BEGIN; |   | . | 2 | UPDATE to_childSET fd=’ changed-100’WHERE id=100; |   | . | 3 |   | BEGIN; | . | 4 |   | DELETE FROM to_parentWHERE id=1; | . | 5 | ROLLBACK; |   | . | 6 |   | Query OK, 1 row affected (6.09 sec) | . 변경하는 테이블 순서만 변경한 예제이다. 첫번째 커넥션에서 부모 키 “1”을 참조하는 자식 테이블의 레코드를 변경하면 tb_child 테이블의 레코드에 대해 쓰기 잠금을 획득한다. 이 상태에서 2번 커넥션이 tb_parent테이블에서 id가 1인 레코드를 삭제하는 경우 이 쿼리는 tb_child테이블의 레코드에 대한 쓰기 잠금이 해제될 때까지 기다려야 한다. 외래키 특성 때문에 부모 레코드가 삭제되면 자식 레코드도 동시에 삭제되는 식으로 작동하기 때문이다. ",
    "url": "/docs/mysql/08.%20Real%20MySQL%208.0.html#%EC%99%B8%EB%9E%98%ED%82%A4",
    
    "relUrl": "/docs/mysql/08.%20Real%20MySQL%208.0.html#외래키"
  },"101": {
    "doc": "08. Real MySQL 8.0",
    "title": "08. Real MySQL 8.0",
    "content": " ",
    "url": "/docs/mysql/08.%20Real%20MySQL%208.0.html",
    
    "relUrl": "/docs/mysql/08.%20Real%20MySQL%208.0.html"
  },"102": {
    "doc": "08. 의존성 관리하기",
    "title": "08. 의존성 관리하기",
    "content": ". 잘 설계된 객체지향 애플리케이션은 작고 응집도 높은 객체들로 구성된다. 작고 응집도 높은 객체란 책임의 초점이 명확하고 한 가지 일만 잘 하는 객체를 의미한다. 이런 작은 객체들이 단독으로 수행할 수있는 작업은 거의 없기 때문에 일반적인 애플리케이션의 기능을 구현하기 위해서는 다른 객체에게 도움을 요청해야 한다. 이런 요청이 객체 사이의 협력을 낳는다. 어떤 객체가 협력하기 위해 다른 객체를 필요로 할 때 두 객체 사이에 의존성이 존재하게 된다. 두가지 시점이 있다. | ﻿﻿실행 시점: 의존하는 객체가 정상적으로 동작하기 위해서는 실행 시에 의존 대상 객체가 반드시 존재해야 한다. | ﻿﻿구현 시점: 의존 대상 객체가 변경될 경우 의존하는 객체도 함께 변경된다. | . ![[Pasted image 20240530002548.png]] 의존성은 방향성을 가지며 항상 단방향이다. Screening이 변 경될 때 Periodcondition이 영향을 받게 되지만 그 역은 성립하지 않는다. 이 경우 PeriodCondition은 Screening에 의존한다. ![[Pasted image 20240530002704.png]] . Movie 클래스에서 AmountDiscountPolicy 클래스와PercentDiscountPolicy 클래스로향하는 어떤 의존성도 존재하지 않는다. Movie 클래스는 오직 추상 클래스인 DiscountPolicy클래스에만 의존한다. Movie 클래스의 코드를 살펴보면 AmountbiscountPolicy나 PercentbiscountPolicy에 대해서는 언급조차 하지 않는다는 것을 알 수 있다. new 는 해롭다 . 대부분의 언어에서는 클래스의 인스턴스를 생성할 수 있는 new 연산자를 제공한다. 하지만 안타깝게도 new를 잘못 사용하면 클래스 사이의 결합도가 극단적으로 높아진다. 결합도 측면에서 new가 해로운 이 유는 크게 두 가지다. | ﻿﻿new 연산자를 사용하기 위해서는 구체 클래스의 이름을 직접 기술해야 한다. 따라서 new를 사용하는 클라이언트는 추상화 가 아닌 구체 클래스에 의존할 수밖에 없기 때문에 결합도가 높아진다. | ﻿﻿new 연산자는 생성하려는 구체 클래스뿐만 아니라 어떤 인자를 이용해 클래스의 생성자를 호출해야 하는지도 알아야 한 다. 따라서 new를 사용하면 클라이언트가 알아야 하는 지식의 양이 늘어나기 때문에 결합도가 높아진다. | . 해결 방법은 인스턴스를 생성하는 로직과 생성된 인스턴스를 사용하는 로직을 분리하는 것이다. AmountDiscountPolicy를 사용하는 Movie는 인스턴스를 생성해서는 안 된다. 단지 해당하는 인스턴스를 사용하기만 해야 한다. 이를 위해 Movie는 외부로부터 이미 생성된 AmountDiscountPolicy의 인스턴스를 전달받아야 한다. 그렇다면 누가 AmountDiscountPolicy를 생성할까? ![[Pasted image 20240530003329.png]] 생성의 책임을 클라이언트로 옮겨 결합도를 낮춘다. 설계는 트레이드 오프라는것을 기억하라 가끔은 생성해도 괜찮다. public class Movie { private DiscountPolicy discountPolicy; public Movie(String title, Duration runningTime, Money fee) { this(title, runningTime, fee, new AmountDiscountPolicy(...)); ｝ public Movie(String title, Duration runningTime, Money fee, DiscountPolicy discountPolicy) { ... this.discountPolicy = discountPolicy; ｝ ｝ . 추가된 생성자 안에서 AmountoiscountPolicy 클래스의 인스턴스를 생성한다는 것을 알 수 있다. 여 기서 눈여겨볼 부분은 첫 번째 생성자의 내부에서 두 번째 생성자를 호출한다는 것이다. 다시 말 해 생성자가 체인처럼 연결된다. 이제 클라이언트는 대부분의 경우에 추가된 간략한 생성자를 통해 AmountoiscountPolicy의 인스턴스와 협력하게 하면서도 컨텍스트에 적절한 DiscountPolicy의 인스턴스 로 의존성을 교체할 수 있다. 의존성이 불편한 이유는 변경에 대한 영향때문이다. 변경이 될 확률이 거의 없는 클래스라면 의존성이 문제가 되지 않는다. ",
    "url": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/08.%20%EC%9D%98%EC%A1%B4%EC%84%B1%20%EA%B4%80%EB%A6%AC%ED%95%98%EA%B8%B0.html",
    
    "relUrl": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/08.%20%EC%9D%98%EC%A1%B4%EC%84%B1%20%EA%B4%80%EB%A6%AC%ED%95%98%EA%B8%B0.html"
  },"103": {
    "doc": "08. 클래식 솔루션 아키텍처 토론",
    "title": "08. 클래식 솔루션 아키텍처 토론",
    "content": ". 애플리케이션을 실행하는데 매우 긴 시간이 걸린다 . 속도를 높이기 위해서는? 클라우드의 장점을 사용할 수 있다 . AMI에 종속성 등 모든것을 사전에 설치하고 이후로는 EC2인스턴스들을 AMI로부터 직접 실행하면 된다 . 부트스트래핑은 기본적으로 인스턴스가 처음 시작할 때 구성하는것을 의미한다. 이것은 매우 느리다 . ",
    "url": "/docs/aws/08.%20%ED%81%B4%EB%9E%98%EC%8B%9D%20%EC%86%94%EB%A3%A8%EC%85%98%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%86%A0%EB%A1%A0.html",
    
    "relUrl": "/docs/aws/08.%20%ED%81%B4%EB%9E%98%EC%8B%9D%20%EC%86%94%EB%A3%A8%EC%85%98%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%86%A0%EB%A1%A0.html"
  },"104": {
    "doc": "08. 클래식 솔루션 아키텍처 토론",
    "title": "Elastic Beanstalk",
    "content": "하나의 인터페이스에서 앞에서 본 EC2, ASG, ELB, RDS 등 모든 컴포넌트를 재사용한다는 개념 . 즉 용량 프로비저닝, 로드 밸런서 설정, 스케일링, 애플리케이션 상태 모니터링, 인스턴스 설정 등을 처리한다 . Elastic Beanstalk는 무료이다 Beanstalk의 컴포넌트는 환경, 버전, 설증 등 Beanstalk컴포넌트 컬렉션인 애플리케이션으로 구성된다. 때문에 버전1, 버전2 등등을 가질 수 있다 . Web Server Tier vs Worker Tier . | web server tier . | 로드 밸런서가 있고 그게 트래픽을 오토 스케일링 그룹에 전송하고 거기엔 웹 서버가 될 다수의 EC2 인스턴스가 있는 아키텍처 | . | worker tier . | 여기서는 EC2 인스턴스에 직접적으로 액세스하는 클라이언트가 없다 | 메시지 대기열인 SQS Queue를 사용한다 | EC2 인스턴스는 워커가 된다 | 워커 환경은 SQS 메시지 수의 따라 스케일링이 달라진다 | . | 웹 환경의 메시지를 워커환경으 SQS에 푸시하게 함으로써 웹 환경과 워커 환경을 하나로 모을 수 있다 | . ",
    "url": "/docs/aws/08.%20%ED%81%B4%EB%9E%98%EC%8B%9D%20%EC%86%94%EB%A3%A8%EC%85%98%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%86%A0%EB%A1%A0.html#elastic-beanstalk",
    
    "relUrl": "/docs/aws/08.%20%ED%81%B4%EB%9E%98%EC%8B%9D%20%EC%86%94%EB%A3%A8%EC%85%98%20%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%20%ED%86%A0%EB%A1%A0.html#elastic-beanstalk"
  },"105": {
    "doc": "09. Real MySQL 8.0",
    "title": "9장",
    "content": ". ",
    "url": "/docs/mysql/09.%20Real%20MySQL%208.0.html#9%EC%9E%A5",
    
    "relUrl": "/docs/mysql/09.%20Real%20MySQL%208.0.html#9장"
  },"106": {
    "doc": "09. Real MySQL 8.0",
    "title": "옵티마이저",
    "content": "옵티마이저는 가장 복잡한 부분으로 알려져 있으며, 옵티마이저가 만들어 내는 실행 계획을 이해하는 것 또한 상당히 어려운 부분이다. 쿼리 실행 절차 . 쿼리가 실행되는 과정은 크게 세 단계로 나눌 수 있다. | 사용자로부터 요청된 SQL문장을 잘게 쪼개서 MySQL서버가 이해할 수 있는 수준으로 분리 한다. | SQL의 파싱 정보를 확인하면서 어떤 테이블부터 읽고 어떤 인덱스를 이용해 테이블을 읽을지 선택한다. | 두 번째 단계에서 결정된 테이블의 읽기 순서나 선택된 인덱스를 이용해 스토리지 엔진으로부터 데이터를 가져온다. | . 첫번째 단계를 파싱 이라고 하며 SQL파서 라는 모듈러 처리한다. SQL문장이 문법적으로 잘못됐다면 이 단계에서 걸러진다. 또한 이 단계에서 SQL파스 트리가 만들어진다. MySQL은 SQL문장 그 자체가 아니라 SQL파스 트리를 이용해 쿼리를 실행한다. 두번째 단계에서 파스 트리를 참조하여 다음과 같은 내용을 처리한다 . | 불필요한 조건 제거 및 복잡한 연산의 단순화 | 여러 테이블의 조인이 있는 경우 어떤 순서로 테이블을 읽을지 결정 | 각 테이블에 사용된 조건과 인덱스 통계 정보를 이용해 사용할 인덱스를 결정 | 가져온 레코드들을 임시 테이블에 넣고 다시 한번 가공해야 하는지 결정 | . 두 번째 단계는 최적화 및 실행 계획 수립 단계이며 옵티마이저에서 처리한다. 두 번째 단계가 완로되면 실행 계획 이 만들어진다. 세 번째 단계는 수립된 실행 계획대로 스토리지 엔진에 레코드를 읽어오도록 요청하고, MySQL은 스토리지 엔진으로 부터 받은 레코드를 조인하거나 정렬하는 작업을 수행한다. 첫 번째 단계와 두 번째 단계는 거의 MySQL엔진에서 처리하며, 세 번째 단계는MySQL엔진과 스토리지 엔진이 동시에 참여해서 처리한다. 옵티마이저의 종류 . 옵티마이저는 크게 2가지로 나뉜다 . | 비용 기반 최적화 방법 . | 쿼리를 처리하기 위한 여러 가지 가능한 방법을 만들고, 각 단위 작업의 비용 정보와 대상 테이블의 예측된 통계 정보를 이용해 실행 계획별 비용을 산출한다. 이렇게 산출된 실행 방법별로 비용이 최소로 소요되는 처리 방식을 선택해 최종적으로 쿼리를 실행한다. | . | 규칙 기반 최적화 방법 . | 기본적으로 대상 테이블의 레코드 건수나 선택도 등을 고려하지 않고 옵티마이저에 내장된 우선순ㅟ에 따라 실행 계획을 수립하는 방식ㅡㄹ 의미한다. 이 방식에서는 통계 정보를 조사지 않고 실행 계획이 수립되기 떄문에 같은 쿼리에 대해서는 거의 항상 같은 실행 방법을 만들어 낸다.. 하지만 사용자의 데이터는 분포도가 매우 다양하기 때문에 규칙 기반의 최적화는 오래전부터 많은 BDMS에서 사용되지 않는다. | . | . ",
    "url": "/docs/mysql/09.%20Real%20MySQL%208.0.html#%EC%98%B5%ED%8B%B0%EB%A7%88%EC%9D%B4%EC%A0%80",
    
    "relUrl": "/docs/mysql/09.%20Real%20MySQL%208.0.html#옵티마이저"
  },"107": {
    "doc": "09. Real MySQL 8.0",
    "title": "기본 데이터 처리",
    "content": "MySQL 서버를 포함한 모든 RDBMS는 데이터를 정렬하거나 그루핑하는 등의 기본 데이터 가공 기능을 가지고있다. MySQL 서버가 어떤 알고리즘을 사용하는지 간단히 살펴보자. 풀 테이블 스캔과 풀 인덱스 스캔 . 풀 테이블 스캔은 인덱스를 사용하지 않고 테이블의 데이터를 처음부터 끝까지 읽어서 요청된 작업을 처리하는 작업을 의미한다. 다음과 같은 조건이 일치할때 주로 풀 테이블 스캔이 일어난다. | 테이블의 레코드 건수가 너무 작아서 인덱스를 통해 읽는 것보다 풀 테이블 스캔을 하는 편이 더 빠른 경우(일반적으로 테이블이 페이지 1개로 구성된경우) | WHERE절이나 ON절에 인덱스를 이용할 수 있는 적절한 조건이 없는 경우 | 인덱스 레인지 스캔을 사용할 수 있는 쿼리라고 하더라도 옵티마이저가 판단한 조건 일치 레코드 건수가 너무 많은 경우 | . 일반적으로 테이블의 전체 크기는 인덱스보다 훨씬 크기 때문에 테이블을 처음부터 끝까지 읽는 잘업은 상당히 많은 디스크 읽기가 필요하다. MySQL은 풀 테이블 스캔을 실행할때 디스크로부터 페이지를 가져와야 하는데, InnoDB는 특정 테이블의 연속된 데이터 페이지가 읽히면 백그라운드 스레드에 의해 리어 헤드 작업이 자동으로 시작된다. 리어 헤드란 어떤 영역의 데이터가 앞으로 필요해지리라는 것을 예측해서 요청이 오기 전에 미리 디스크에서 읽어 InnoDB의 버퍼 풀에 가져다 두는것을 의미한다. 즉 풀 테이블 스캔이 실행되면 처음 몇개의 데이터 페이지는 포그라운드 스레드가 페이지 읽기를 실행하지만 특정 시점부터는 읽기 작업을 백그라운드 스래드로 넘긴다. 백그라운드 스레드가 읽기를 넘겨받는 시점부터는 한 번에 4개 또는 8개씩의 페이지를 읽으면서 계속 그 수를 증가시킨다. (64개까지) 리어 헤드는 풀 테이블 스캔에서만 사용되는 것이 아니라 풀 인덱스 스캔에서도 동일하게 사용된다. SELECT COUNT(*) FROM employees; . 이 쿼리는 아무런 조건 없이 employees 테이블의 레코드 건수를 조회하고 있으므로 당연히 풀 테이블 스캔을 할 것 처럼 보인다. 하지만 실제 실행 계획은 풀 인덱스 스캔을 하게 될 가능성이 높다. 단순히 레코드의 건수만 필요로 하는 쿼리라면 용량이 작은 인덱스를 선택하는 것이 디스크 읽기 횟수를 줄일 수 있기 때문이다. 병렬 처리 . 시스템 변수를 이용해 하나의 쿼리를 최대 몇 개의 스레드를 이용해 처리할지 변경할 수 있다. SET SESSION innodb_parallel_read_threads=1; mysql&gt; SELECT COUNT(*) FROM salaries; 1 row in set (0.32 sec) SET SESSION innodb_parallel_read_threads=2; mysql&gt; SELECT COUNT(*) FROM salaries; 1 row in set (0.20 sec) SET SESSION innodb_parallel_read_threads=4; mysal&gt; SELECT COUNT(*) FROM salaries; 1 row in set (0.18 sec) SET SESSION innodb_parallel_read_threads=8; mysql&gt; SELECT COUNT(*) FROM salaries; 1 row in set (0.13 sec) . ORDER BY 처리 . 정렬을 처리하는 방법은 인덱스를 이용하는 방법과 쿼리가 실행될 때 Filesort라는 별도의 처리를 이용하는 방법으로 나눌 수 있다. |   | 장점 | 단점 | . | 인덱스 이용 | INSERT, UPDATE, DELETE 쿼리가 실행될 때 이미 인 덱스가 정렬돼 있어서 순서대로 읽기만 하면 되므로 매 우 빠르다. | INSERT, UPDATE, DELETE 작업 시 부가적인 인덱 스 추가/삭제 작업이 필요하므로 느리다.인덱스 때문에 디스크 공간이 더 많이 필요하다.인덱스의 개수가 늘어날수록 InnoDB의 버퍼 풀을 위한 메모리가 많이 필요하다. | . | Filesort 이용 | 인덱스를 생성하지 않아도 되므로 인덱스를 이용할 때 의 단점이 장점으로 바뀐다.정렬해야 할 레코드가 많지 않으면 메모리에서 Filesort가 처리되므로 충분히 빠르다. | 정렬 작업이 쿼리 실행 시 처리되므로 레코드 대상 건수가 많아질수록 쿼리의 응답 속도가 느리다. | . 정렬을 하기 위해 항싱 Filesort라는 정렬 작업을 거쳐야 하는 것은 아니다. 하지만 다음과 같은 이유로 모든 정렬을 인덱스를 이용하도록 튜닝하기란 거의 불가능하다 . | 정렬 기준이 너무 많아서 요건별로 모두 인덱스를 생성하는 것이 불가능한 경우 | GROUP BY의 결과 또는 DISTINCT 같은 처리의 결과를 정렬해야 하는 경우 | UNION의 결과와 같이 임시 테이블의 결과를 다시 정렬해야 하는 경우 | 랜덤하게 결과 레코드를 가져와야 하는 경우 뭔가 읽어온 테이블의 결과가 예측 불가능하게 재가공하거나 랜덤한경우들이네 . | . 인덱스를 이용하지 않고 별도의 정렬 처리를 수행했는지는 실행 계획의 Extra컬럼에 using filesort 메시지가 표시되는지 여부로 판단할 수 있다. 소트 버퍼 . 정렬을 수행하기 위해 별도의 메모리 공간을 할당받아서 사용하는데, 이 메모리 공간을 소트 버퍼라고 한다. 소트 버퍼는 정렬이 필요한 경우에만 할당되며, 버퍼의 크기는 정렬해야 할 레코드의 크기에 따라 가변적으로 증가한다. 최대 사용 가능한 버퍼공간은 시스템 변수로 설정할 수 있다. 쿼리의 실행이 완료되면 즉시 시스템으로 반납된다. 소트 버퍼에 따라 문제가 발생할 수 있는데 작게 설정한다면, 그보다 큰 레코드들을 읽어올 경우 메모리 소트 버퍼에서 정렬을 수행하고, 그 결과를 임시로 디스크에 저장. 이 과정을 반복해서 마지막에 병합 작업을 수행하면서 다시 정렬을 수행해야한다. 이 작업들이 모두 디스크의 쓰기와 읽기를 유발하며, 레코드의 건수가 많을수록 반복 횟수가 많아진다. 크기를 크게 설정하면 디스크를 사용하지 않아엇 더 빨라질 것으로 생각할 수 도 있지만, 실제 벤치마크 결과로는 큰 차이를 보이지 않았다. ![[Pasted image 20240519195532.png|400]] . 큰 메모리 공간 할당 때문에 성능이 훨씬 떨어질 수도 있다. 소트 버퍼는 세션 메모리 영역에 해당한다. 즉 소트 버퍼는 여러 클라이언트가 공유해서 사용할 수 있는 영역이 아니다. 커넥션이 많으면 많을수록, 정렬 작업이 많으면 많을수록 소트 버퍼로 소비되는 메모리 공간이 커짐을 의미한다. 정렬 알고리즘 . 레코드를 정렬할 때 레코드 전체를 소트 버퍼에 담을지 또는 정렬 기준 컬럼만 소트 버퍼에 담을지에 따라 싱글 패스 와 투 패스 2가지 정렬모드로 나눌 수 있다. -- 1/ 옵티마이저 트레이스 활성화 SET OPTIMIZER_TRACE=\"enabled=on\", END_MARKERS_IN_JSON=on; SET OPTIMIZER_TRACE_MAX_MEM_SIZE=1000000; -- // 쿼리 실행 SELECT * FROM employees ORDER BY last_name LIMIT 100000, 1; -- 1/ 트레이스 내용 확인 SELECT * FROM INFORMATION_SCHEMA. OPTIMIZER_TRACE \\G ・・・ \"filesort_priority_queue_optimization\": { \"limit\": 100001 } /* filesort_priority_queue_optimization */, \"filesort_execution\": [ ] /* filesort_execution */, \"filesort_summary\": { \"memory_available\": 262144, \"key_size\": 32, \"row_size\": 169, \"max_rows_per_buffer\": 1551, \"num_rows_estimate\": 936530, \"num_rows_found\": 300024, \"num_initial_chunks_spilled_to_disk\": 82, \"peak memory _used\": 262144, \"sort_algorithm\": \"std: :stable_sort\", \"sort_mode\": \"{fixed_sort_key, packed_additional_fields›\" } /* filesort_summary */ . filesort_summary의 sort_algorithm필드에 정렬 알고리즘이 표시된다. \"sort_mode\": \"{fixed_sort_key, packed_additional_fields›\" . MySQL서버의 정렬 방식은 당므과 같이 3가지가 있다. | &lt;sort_key, rowid&gt; : 정렬 키와 레코드의 로우 아이디만 가져와서 정렬하는 방식 | &lt;sort_key, additional_fields&gt; : 정렬 키와 레코드 전체를 가져와서 정렬하는 방식으로, 레코드의 컬럼들은 고정 사이즈로 메모리 저장 | &lt;sort_key, packed_addtional_fields&gt; : 정렬 키와 레코드 전체를 가져와서 정렬하는 방식으로, 레코드의 컬럼들은 가변 사이즈로 메모리 저장 | . 첫 번째 방식을 투 패스 정렬 방식이라 명명하고, 두 번째와 세 번째 방식을 싱글 패스 정렬 방식이라 명명하겠다. 싱글 패스 정렬 방식 . ![[Pasted image 20240519200451.png|400]] 그림에서 알 수 있듯이, 처음에 employees 테이블을 읽을 때 정렬에 필요하지 않은 last_name컬럼까지 전부 읽어서 소트 버퍼에 담고 정렬을 수행하낟. 그리고 정렬이 완료되면 클라이언트로 넘겨주는 과정을 볼 수 있다. 투 패스 정렬 방식 . 정렬 대상 컬럼과 프라이머리 키 값만 소트 버퍼에 담아서 정렬을 수행하고, 정렬된 순서대로 다시 프라이머리 키로 테이블을 읽어서 select할 컬럼을 가져오는 방식이다. ![[Pasted image 20240519200731.png|400]] . MySQL의 예전 방식인 투 패스 방식은 테이블을 두번 읽어야 하기 때문에 불합리하지만, 새로운 정렬 방식인 싱글 패스는 이런 불합리가 업삳. 하지만 싱글 패스는 소트 버퍼 공간이 필요하다. 즉 대략 128KB의 정렬 버퍼를 사용한다면 이 쿼리는 투 패스 정렬 방식에서는 대량 7,000건의 레코드를 정렬할 수 있지만 싱글 패스 정렬 방식에서는 그것의 반 정도밖에 정렬할 수 없다. 물론 이것은 소트 버퍼 공간의 크기와 레코드의 크기에 의존적이다. 최신 버전에서는 일반적으로 싱글 패스 정렬 방식을 주로 사용한다. 특정 경우에는 투 패스 방식을 사용한다 . | 레코드의 크기가 max_length_for_sort_data시스템 변수에 설정된 값보다 클 때 | BLOB이나 TEXT타입의 컬럼이 SELECT 대상에 포함일 때 | . 싱글 패스 방식은 정렬 대상 레코드의 크기나 건수가 작은 경우 빠른 성능을 보이며, 투 패스 방식은 정렬 대상의 레코드의 크기가 상당히 많은 경우 효율적이라고 볼 수 있다. 정렬 처리 방벙 . ORDER BY가 사용되면 반드시 3가지 처리 방법 중 하나로 정렬이 처리된다. 아래쪽에 있는 정렬 방법으로 갈수록 처리 속도는 떨어진다. | 정렬 처리 방법 | 실행 계획의 Extra 칼럼 내용 | . | 인덱스를 사용한 정렬 | 별도 표기 없음 | . | 조인에서 드라이빙 테이블만 정렬 | “Using filesort” 메시지가 표시됨 | . | 조인에서 조인 결과를 임시 테이블로 저장 후 정렬 | “using temporary; Using filesort” 메시지가 표시됨 | . 먼저 인덱스를 사용할 수 있을지 확인하고 그럴 수 없다면 filesort를 사용할 것이다 이때 레코드를 최소화 하기 위해 다음 2가지 방법중 하나를 선택한다 . | 조인 드라이빙 테이블만 정렬한 다음 조인을 수행 | 조인이 끝나고 일치하는 레코드를 모두 가져운 후 정렬을 수행 | . 일반적으로 조인이 수행되면서 레코드 건수와 레코드의 크기는 거의 배수로 불어나기 때문에 가능하다면 드라이빙 테이블만 정렬한 다음 조인을 수행하는 방법이 효율적이다. 인덱스를 이용한 정렬 . 인덱스를 이용한 정렬을 위해서는 반드시 ORDER BY에 명시된 컬럼이 제일 먼저 읽는 테이블에 속하고, ORDER BY의 순서대로 생성된 인덱스가 있어야 한다. 또한 WHERE절에 첫 번째로 읽는 테이블의 컬럼에 대한 조건이 있다면 그 조건과 ORDER BY는 같은 인덱스를 사용할 수 있어야 한다. 그리고 B-Tree 계열의 인덱스가 아닌 해시 인덱스나 전문 검색 인덱스 등에서는 인덱스를 이용한 정렬을 사용할 수 없다. R-Tree도 불가능 . 여러 테이블이 조인되는 경우 네스티드 루프 방식의 조인에서만 이 방식을 이용할 수 있다. | ![[Pasted image 20240519202049.png | 400]] | . 네스티드 루프(Nested Loop) 방식은 루프(반복문) 안에 또 다른 루프가 중첩되어 있는 형태를 말합니다. for i in range(outer_limit): for j in range(inner_limit): # 내부 루프의 코드 pass # 외부 루프의 코드 pass . B-Tree가 가능한 이유는 키값으로 정렬돼 있기 때문이다. 조인이 사용된 쿼리의 실행 계획에 조인 버퍼가 사용되면 순서가 흐트러 질 수 있기 때문에 주의해야한다. 조인 드라이빙(Join Driving)이란 데이터베이스에서 조인을 수행할 때, 어느 테이블을 기준으로 조인을 실행할지를 결정하는 과정을 말합니다. 이는 특히 대규모 데이터셋에서 효율적인 쿼리 성능을 위해 매우 중요합니다. 조인 드라이빙의 목표는 최소한의 리소스를 사용하여 최적의 성능을 내는 것입니다. 조인의 드라이빙 테이블만 정렬 . 일반적으로 조인이 수행되면 결과 레코드의 건수가 몇 배로 불어나고, 레코드 하나하나의 크기도 늘어난다. 그래서 조인을 싱행하기 전에 첫 번째 테이블의 레코드를 먼저 정렬한 다음 조인을 실행하는 것이 정렬의 차선책이 될 것이다. 이 방법으로 정렬이 처리되려면 조인에서 첫 번째로 읽히는 테이블의 컬러만으로 ORDER BY절을 작성해야 한다. ![[Pasted image 20240519202751.png|400]] order by employees.last_name . 임시 테이블을 이용한 정렬 . 쿼리가 어려 테이블을 조인하지 않고, 하나의 테이블로부터 select해서 정렬하는 경우라면 임시 테이블이 필요하지 않다. 하지만 2개 이상의 테이블을 조인해서 그 결과를 정렬해야 한다면 임시 테이블이 필요할 수도 있다. 앞에서 살펴본 조인의 드라이빙 테이블만 정렬은 2개 이상의 테이블이 조인되면서 정렬이 실행되지만 임시 테이블을 사용하지 않는다. 하지만 그 외 패턴의 쿼리에서는 항상 조인의 결과를 임시 테이블에 저장하고, 그 결과를 다시 정렬하는 과정을 거친다. 3가지 방법중 가장 느린 정렬 방법이다. | ![[Pasted image 20240519204703.png | 400]] | . 정렬 처리 방법의 성능 비교 . 주로 웹 서비스용 쿼리에서는 ORDER BY와 함께 LIMIT이 거의 필수로 사용되는 경향이 있다. 일반적으로 LIMIT은 테이블이나 처리 결과의 일부만 가져오기 때문에 작업량을 줄이는 역할을 한다. 그런데 ORDER BY나 GROUP BY 같은 작업은 WHERE조건을 만족하는 레코드 LIMIT 건수 만큼만 가져와서는 처리할 수 없다. 우선 조건을 만족하는 레코드를 모두 가져와서 정렬을 수행하거나 그루핑 작업을 실행해야만 비로소 LIMIT으로 건수를 제한할 수 있다. WHERE조건이 아무리 인덱스를 잘 활용하도록 튜닝해도 잘못된 ORDER BY나 GROUP BY때문에 쿼리가 느려지는 경우가 자주 발생한다. 느려지는 이유에 대해 알아보자 . 스트리밍 방식 . 서버 쪽에서 처리할 데이터가 얼마인지 관계없이 조건에 일치하는 레코드가 검색될 때마다 바로바로 클라이언트로 전송해주는 방식을 의미한다. 빠른 응답시간을 보장해준다. LIMIT 처럼 결과 건수를 제한하는 조건들은 쿼리의 전체 실행 시간을 상당히 줄여줄 수 있다. 버퍼링 방식 . ORDER BY GROUP BY같은 처리는 쿼리의 결과가 스트리밍 되는것을 불가능하게 한다. 모든 레코드를 검색하고 정렬하는 작업을 하는 동안 클라이언트는 아무것도 하지 않고 기다려야 하기 떄문에 응답속도가 느려진다. 그렇기 때문에 스트리밍의 반대인 버퍼링이라고 표현한 것이다. 정렬 처리 방법에서 소개한 order by 의 3가지 처리 방법 가운데 인덱스를 사용한 정렬 방식만 스트리밍 형태의 처리이며 나머지는 모두 벌퍼링된 후에 정렬된다. 각 차이를 살펴보자 . | test1 테이블 레코드가 100건이고,test2테이블 레코드가 1000건으로 가정 | 두 테이블의 조인 결과는 전체 1000건이라고 가정 SELECT * FROM to_ test1 t1, tb_test2 t2 WHERE t1.co11=t2.col1 ORDER BY t1 .col2 LIMIT 10; . | . 왜 join on 형태가 아니라 where를 쓰지? 레거시. | ![[Pasted image 20240519205803.png | 400]] | . | ![[Pasted image 20240519205814.png | 400]] | . 어느 테이블이 먼저 드라이빙 되어 조인되는지도 중요하지만 어떤 정렬 방식으로 처리되는지 더 큰 성능 차이를 만든다. GROUP BY 처리 . group by 또한 order by와 같이 쿼리가 스트리밍된 처리를 할 수 없게 하는 처리중 하나이다. group by 에 사용된 조건은 인덱스를 사용해서 처리될 수 없으므로 having 절을 튜닝하려고 인덱스를 생성하거나 다른 방법을 고민할 필요는 없다. group by 작업도 인덱스를 사용하는 경우와 그렇지 못한 경우로 나눠 볼 수 있다. 인덱스를 이용할 때는 인덱스를 차례대로 읽는 인덱스 스캔 방법 인덱스를 건너뛰면서 읽는 루스 인덱스 스캔이라는 방법 으로 나뉜다. 그리고 인덱스를 사용하지 못하는 쿼리에서 group by작업은 임시 테이블을 사용한다. 인덱스 스캔을 이용하는 group by . 조인의 드라이빙 테이블에 속한 컬럼만 이용해 그루핑할 때 group by 컬럼으로 이미 인덱스가 있다면 그 인덱스를 차례대로 읽으면서 그루핑 작업을 수행하고 그 결과로 조인을 처리한다. 루스 인덱스 스캔을 이용하는 group by . 실행 계획의 extra 컬럼에 using index for group by 코멘트가 표시된다. EXPLAIN SELECT emp_no FROM salaries WHERE from_date='1985-03-01' GROUP BY emp_no; . salaries 테이블의 인덱스는 (emp_no, from_data)로 생성돼 있으므로 위의 쿼리 문장에서 where조건은 인덱스 레인지 스캔 접근 방식으로 이용할 수 없는 쿼리이다. 하지만 extra 컬럼의 메시지를 보면 group By처리 까지 인덱스를 사용했다는 것을 알 수 있다. 쿼리 실행 순서를 살펴보자 . | ﻿﻿﻿(emp_no, from_date) 인덱스를 차례대로 스캔하면서 emp_no의 첫 번째 유일한 값(그룹 키) 10001”을 찾아낸다. | ﻿﻿﻿(emp_no, from_date) 인덱스에서 emp_no가 10001’인 것 중에서 from_date 값이 1985-03-01’인 레코드만 가져온다. 이 검색 방법은 1번 단계에서 알아낸 10001’ 값과 쿼리의 WHERE 절에 사용된 “from_date=’1985-03-01•” 조건을 합쳐서 “emp_no=10001 AND from_date=’1985-03-01” 조건으로 (emp_ no, from_date) 인덱스 를 검색하는 것과 거의 흡사하다 | ﻿﻿﻿(emp_no, from_date) 인덱스에서 emp_no의 그다음 유니크한(그룹 키) 값을 가져온다. | ﻿﻿﻿3번 단계에서 결과가 더 없으면 처리를 종료하고, 결과가 있다면 2번 과정으로 돌아가서 반복 수행한다. | . 루스 인덱스 스캔 방식은 단일 테이블에 대해 수행되는 GROUP BY 처리에만 사용할 수 있다. 또한 프리픽스 인덱스 (컬럼값의 앞쪽 일부만으로 생성된 인덱스)는 루스 인덱스 스캔을 사용할 수 없다. 루스 인덱스 스캔은 유니크한 값의 수가 적을수록 성능이 향상된다. 별도의 임시 테이블은 필요없다. 다음은 루스 인덱스 스캔을 사용할 수 없는 경우이다 . -- 1/ MIN()과 MAX() 이외의 집합 함수가 사용됐기 때문에 루스 인덱스 스캔은 사용 불가 SELECT col1, SUM(col2) FROM tb_test GROUP BY col1; -- 1/ GROUP BY에 사용된 칼럼이 인덱스 구성 칼럼의 왼쪽부터 일치하지 않기 때문에 사용 불가 SELECT col1, co12 FROM tb_test GROUP BY co12, col3; -- // SELECT 절의 칼럼이 GROUP BY와 일치하지 않기 때문에 사용 불가 SELECT col1, col3 FROM to_test GROUP BY cOl1, col2; . 임시 테이블을 사용하는 GROUP BY . 인덱스를 전혀 사용하지 못할 때는 이 방식으로 처리된다. DISTINCT처리 . 특정 컬럼의 유니크한 값만 조회하려면 select 쿼리에 distinct를 사용한다. distinct는 MIN(), MAX() 또는 COUNT() 같은 집합 함수와 함께 사용되는 경우와 집합 함수가 없는 경우 2가지로 구분해서 살펴보자. select distinct … . 단순 select 되는 레코드중 유니크한 레코드만 가져오고자 하면 GROUP BY와 동일한 방식으로 처리된다. 집합 함수와 함께 사용된 DISTINCT . MIN(), MAX() 또는 COUNT()같은 집합 함수 내에서 DISTINCT 키워드가 사용될 수 있는데, 이 경우에는 일반적으로 SELECT DISTINCT와 다른 형태로 해석된다. 집합 함수가 없는 SELECT 쿼리에서 DISTINCT는 조회하는 모든 컬럼의 조합이 유니크한 것들만 가져온다. 하지만 집합 함수내에서 사용된 DISTINCT는 그 지합 함수의 인자로 전달된 컬럼의 유니크한 것들을 가져온다. SELECT COUNT(DISTINCT s.salary) FROM employees e, salaries s WHERE e. emp_no=s. emp_no AND e.emp_no BETWEEN 100001 AND 100100; . 이 쿼리는 SELECT COUNT(DISTINCT s.salary)를 처리하기 위해 임시 테이블을 사용한다. SELECT COUNT(DISTINCT s.salary), COUNT(DISTINCT e. last_name) FROM employees e, salaries s WHERE e.emp_no=s.emp_no AND e.emp_no BETWEEN 100001 AND 100100; . 위 쿼리는 2개의 임시 테이블을 사용한다. 하지만 다음 쿼리와 같이 인덱스된 컬럼에 대해 DISTINCT 처리를 수행할 때는 인덱스를 풀 스캔하거나 레인지 스캔하면서 임시 테이블 없이 최적화된 처리를 수행할 수 있다. SELECT COUNT(DISTINCT emp_no) FROM employees; SELECT COUNT(DISTINCT emp_no) FROM dept_emp GROUP BY dept_no; . 내부 임시 테이블 활용 . 엔진이 내부적인 가공을 위해 생성하는 임시 테이블은 다른 세션이나 다른 쿼리에서는 볼 수 없으며 사용하는것도 불가능하다. 사용자가 생성하는 (CREATE TEMPORARY TABLE)과는 달리 내부적인 임시 테이블은 쿼리의 처리가 완료되면 자동으로 삭제된다. 메모리 임시 테이블과 디스크 임시 테이블 . 임시테이블의 크기가 1GB(기본값, 바꿀수있음)보다 커지는 경우 메모리의 임시 테이블을 디스크로 기록하게 되는데, 2가지 디스크 저장 방식중 하나를 선택한다. | MMAP 파일로 디스크에 기록 . | 기본값 innodb 테이블로 전환하는 것 보다 오버헤드가 적기 떄문에 | . | InnoDB 테이블로 기록 | . 임시 테이블이 필요한 쿼리 . | ﻿﻿ORDER BY와 GROUP BY에 명시된 칼럼이 다른 쿼리 | ﻿﻿ORDER BY나 GROUP BY에 명시된 칼럼이 조인의 순서상 첫 번째 테이블이 아닌 쿼리 | ﻿﻿DISTINCT와 ORDER BY가 동시에 쿼리에 존재하는 경우 또는 DISTINCT가 인덱스로 처리되지 못하는 쿼리 | ﻿﻿UNIONOI나 UNION DISTINCT가 사용된 쿼리(select_type 칼럼이 UNION RESULT인 경우) | ﻿﻿쿼리의 실행 계획에서 select_type이 DERIVED인 쿼리 | . 임시 테이블이 디스크에 생성되는 경우 . 내부 임시 테이블은 기본적으로는 메모리상에 만들어지지만 다음과 같은 조건을 만족하면 메모리 임시 테이블을 사용할 수 없게 된다. | UNIONOI나 UNION ALL에서 SELECT되는 칼럼 중에서 길이가 512바이트 이상인 크기의 칼럼이 있는 경우 | GROUP BYL DISTINCT 칼럼에서 512바이트 이상인 크기의 칼럼이 있는 경우 | 메모리 임시 테이블의 크기가 (MEMORY 스토리지 엔진에서) tmp_table_size 또는 max_heap_table_size 시스템 변수보다 크거나 (TempTable 스토리지 엔진에서) temptable_max_ram 시스템 변수 값보다 큰 경우 | . ",
    "url": "/docs/mysql/09.%20Real%20MySQL%208.0.html#%EA%B8%B0%EB%B3%B8-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%B2%98%EB%A6%AC",
    
    "relUrl": "/docs/mysql/09.%20Real%20MySQL%208.0.html#기본-데이터-처리"
  },"108": {
    "doc": "09. Real MySQL 8.0",
    "title": "고급 최적화",
    "content": "옵티마이저 옵션은 크게 조인 관련된 옵티마이저 옵션과 옵티마이저 스위치로 구분할 수 있다. 옵티마이저 스위치 옵션 . MRR과 배치 키 액세스 . mysql에서 지금까지 지원하던 조인 방식은 드라빙 테이블(조인되는 테이블에서 제일 먼저 읽는 테이블)의 레코드를 한 건 읽어서 드리븐 테이블(조인되는 테이블에서 드라이빙이 아닌 테이블들)의 일치하는 레코드를 찾아서 조인을 수행하는 것이었다. 이를 네스티드 루프 조인 이라고 한다. mysql 내부 구조상 조인 처리는 mysql엔진이 처리 하지만, 실제 레코드를 검색하고 읽는 부분은 스토리지 엔진이 담당한다. 이때 드라이빙 테이블의 레코드 건별로 드리븐 테이블의 레코드를 찾으면 레코드를 찾고 읽는 스토리지 엔진에서는 아무런 최적화를 수행할 수 없다. 이같은 단점을 보완하기 위해 조인 대상 테이블 중 하나로부터 레코드를 읽어서 조인 버퍼에 버퍼링한다. 즉 조인을 즉시 실행하지 않고 조인 대상을 버퍼링하는 것이다. 조인 버퍼에 레코드가 가득 차면 버퍼링된 레코드를 스토리지 엔진으로 한번에 요청한다. 이렇게 함으로써 스토리지 엔진은 읽어야 할 레코드들을 데이터 페이지에 정렬된 순서로 접근해서 디스크의 데이터 페이지 읽기를 최소화할 수 있는 것이다. 물론 데이터 페이지가 메모리에 있다고 하더라도 버퍼 풀의 접근을 최소화할 수 있는 것이다. 이러한 읽기 방식을 MRR이라고 하며, MRR을 응용해 실행되는 조인 방식을 BKA 조인이라고 한다. 블록 네스티드 루프 조인 . MySQL 에서 사용되는 대부분의 조인은 네스티드 루프 조인 인데, 조인의 연결 조건이 되는 컬럼에 모두 인덱스가 있는 경우 사용되는 조인 방식이다. 네스티드 루프 조인과 블록 네스티드 루프 조인의 가장 큰 차이는 조인 버퍼가 사용되는지 여부와 조인에서 드라이빙 테이블과 드리븐 테이블이 어떤 순서로 조인되느냐다. 조인 알고리즘에서 block이라는 단어가 사용되면 조인용으로 별도 버퍼가 사용됐다는 것을 의미한다. 조인은 드라이빙 테이블에서 일치하는 레코드의 건수만큼 드리븐 테이블을 검색하면서 처리된다. 즉 드라이빙 테이블은 한번에 쭉 읽지만, 드리븐 테이블은 여러 번 읽는다는 것을 의미한다. 드라이빙 테이블에서 일치하는 레코드가 1000건이라면 드리븐 테이블의 조인 조건이 인덱스를 용할 수 없었다면 1000번의 테이블 풀스캔을 해야한다. 그래서 옵티마이저는 최대한 드리븐 테이블의 검색이 인덱스를 사용할 수 있도록 실행계획을 세운다. 그런데 어떤 방식으로도 드리븐 테이블의 풀 테이블 스캔이나 인덱스 풀 스캔을 피할 수 없다면, 드라이빙 테이블에서 읽은 레코드를 메모리에 캐시한 후 드리븐 테이블과 이 메모리 캐시를 조인하는 형태로 처리한다. 이때 사용되는 메모리의 캐시를 조인 버퍼라고 한다. mysql &gt; SELECT * FROM dept_emp de, employees e WHERE de. from_date&gt;'1995-01-01' AND e.emp_no&lt;109004; . | dept_emp 테이블의 ix_fromdate 인덱스를 이용해(from_date〉’1995-01-01’) 조건을 만족하는 레코드를 검색한다 | 조인에 필요한 나머지 칼럼을 모두 dept_emp 테이블로부터 읽어서 조인 버퍼에 저장한다. | ﻿﻿﻿employees 테이블의 프라이머리 키를 이용해 (emp_no&lt;109004) 조건을 만족하는 레코드를 검색한다. | ﻿﻿﻿3번에서 검색된 결과(employees)에 2번의 캐시된 조인 버퍼의 레코드(dept_emp)를 결합해서 반환한다. | . ![[Pasted image 20240519221744.png]] . 중요한 점은 조인 버퍼가 사용되는 쿼리에서는 조인의 순서가 거꾸로인 것 처럼 실행된다. 위에서 설명한 4번 단계가 employees 테이블의 결과를 기준으로 dept_emp 테이블의 결과를 병합 한다는 것을 의미한다. 실제 이 쿼리의 실행 계획상으로는 dept_emp 테이블이 드라이빙 테이블이 되고, employees 테이블이 드리븐 테이블이 된다. 하지만 실제 드라이빙 테이블의 결과는 조인 버퍼에 담아두고, 드리븐 테이블을 먼저 읽고 조인 버퍼에서 일치하는 레코드를 찾는 방식으로 처리된다. 조인 버퍼가 사용되는 조인에서는 결과의 정렬 순서가 흐트러질 수 있음을 기억해야한다. 인덱스 컨디션 푸시다운 . mysal &gt; SELECT * FROM employees WHERE last_name='Acton' AND first_name LIKE '%sal'; . first_name LIKE ‘%sal’; 조건은 인덱스 레인지 스캔으로는 검색해야할 인덱스를 좁힐 수 없다. ![[Pasted image 20240519222636.png]] Action을 먼저 읽고 그다음 %sql을 탐색한다. 만약 Action의 레코드가 10만건인데 %sql 조건이 일치하는 레코드가 1개라면? 99,999건의 레코드 읽기가 불필요한 작업이 된다. ![[Pasted image 20240519222813.png]] On을 할 경우 인덱스를 이용해 최대한 필터링까지 완료 해서 꼭 필요한 레코드 1건에 대해서 테이블 읽기를 수행할 수 있다. 인덱스 확장 . InnoDB스토리지 엔진을 사용하는 테이블에서 세컨더리 인덱스에 자동으로 추가된 프라이머리 키를 활용할 수 있게 할지 결정하는 옵션이다. 세컨더리 인덱스에 자동으로 추가된 프라이머리 키로인해 어떤 성능상 장점이 있는지 살펴보자 . CREATE TABLE dept_emp ( emp_no INT NOT NULL, dept_no CHAR(4) NOT NULL, from_date DATE NOT NULL, to_date DATE NOT NULL, PRIMARY KEY (dept_no, emp_no), KEY ix_fromdate (from_date) ) ENGINE=InnoDB; . dept_emp 테이블에서 프라이머리 키는 (dept_no, emp_no)이며, 세컨더리 인덱스는 from_date컬럼만 포함한다. 그런데 세컨더리 인덱스는 데이터 레코드를 찾아가기 위해 프라이머리 키인 dept_no와 emp_no 컬럼을 순서대로 포함한다. 최종적으로 ix_fromdata인덱스는 (from_data, dept_no, emp_no)조합으로 인덱스를 생성한 것과 흡사하게 동작할 수 있게된다. from_date 칼럼은 DATE 타입입니다. MySQL에서 DATE 타입은 내부적으로 3바이트를 사용합니다. dept_no 칼럼은 CHAR(4) 타입이며, 이는 고정 길이 문자열로 4바이트를 사용합니다. 그러나 인덱스에서 CHAR 타입의 길이를 계산할 때는 가변 길이와 비교하여 더 많은 공간이 필요할 수 있습니다. CHAR(4) 타입의 경우, MySQL에서는 추가적인 바이트를 포함하여 16바이트로 계산할 수 있습니다. ![[Pasted image 20240520221758.png]] 예제를 보면 19바이트가 표시되어있다. from_data 컬럼(3바이트)과 dept_no 컬럼 (16바이트)까지 사용 했다는 것을 알 수 있다. ![[Pasted image 20240520221850.png]] dept_no 컬럼을 사용하지 않으니, from_data 컬럼을 위한 3바이트만 표시된 것을 확인할 수 있다. ![[Pasted image 20240520221933.png]] 뿐만아니라, 세컨더리 인덱스에 포함되어 있으므로 다음과 같이 정렬 작업에도 인덱스를 활용해서 처리하는 장점도 있다. 인덱스 머지 . 인덱스를 이용해 쿼리를 실행하는 경우, 대부분 테이블별로 하나의 인덱스만 사용하도록 실행 계획을 수립한다. 쿼리에 사용된 각각의 조건이 서로 다른 인덱스를 사용할 수 있고 그 조건을 만족하는 레코드 건수가 많을 것으로 예상 될때 서버는 인덱스 머지 실행 계획을 선택한다. 머시 실행 계획을 사용하면 하나의 테이블에 대해 2개 이상의 인덱스를 이용해 쿼리를 처리한다. 인덱스 머지 실행 계획은 다음과 같이 3개의 세부 실행 계획으로 나누어 볼 수 있다. | index_merge_intersection | index_merge_sort_union | index_merge_union | . 인덱스 머지 - 교집합 (index_merge_intersection) . ![[Pasted image 20240520223537.png|400]] ![[Pasted image 20240520223507.png|400]] 인덱스 머지 실행 계획이 아니였다면 다음 2가지 방식으로 처리해야 했을 것이다. | “first_name=’Georgi’” 조건만 인덱스를 사용했다면 일치하는 레코드 253건을 검색한 다음 데이터 페이지에서 레코드를 찾고 emp_no 컬럼의 조건에 일치하는 레코드들만 반환하는 형태로 처리돼야 한다. | “emp_no BETWEEN 10000 AND 20000” 조건만 인덱스를 사용했다면 프라이머리 키를 이용해 10000건을 읽어와 “first_name=’Georgi’” 조건에 일치하는 레코드만 반환하는 형태로 처리돼야 한다. | . 실제 두 조건을 만족하는 레코드 건수는 14건밖에 안된다. 두 작업 모두 비효율이 매우 큰 상황이어서 옵티마이저는 각 인덱스를 검색해 두 결과의 교집합만 찾아서 반환한 것이다. ix_firstname인덱스는 프라이머리 키인 emp_no를 자동으로 포함하고 있기 때문에 그냥 ix_firstname인덱스만 사용하는것이 더 좋다고 생각할 수 있다. 이때는 최적화를 비활성화 하면된다. 현재 쿼리에 대해서만 비활성화 할 수 있다. 인덱스 머지 - 합집합(index_merge_union) . WHERE 절에 사용된 2개 이상의 조건이 각각의 인덱스를 사용하되 OR 연산자로 연결된 경우에 사용되는 최적화다. ![[Pasted image 20240520225453.png]] . first_name=’Matt’이면서 hire_date=’1987-03-31’인 사원이 있었다면 그 사원의 정보는 ix_firstname 인덱스를 검색한 결과에도 포함돼 있을 것이며, ix_hiredate 인덱스를 검색한 결과에도 포함돼 있을 것이다. 하지만 이 쿼리의 결 과에서는 그 사원의 정보가 두 번 출력되지는 않는다. 그렇다면 MySQL 서버는 두 결과 집합을 정렬해 서 중복 레코드를 제거했다는 것인데, 두 결과 집합에서 중복을 제거하기 위해서는 정렬 작업이 필요했 을 것이다. 실제 실행 계획에는 정렬했다는 표시는 없다. MysQL 서버는 이 같은 중복 제거를 위해 내부적으로 어떤 작업을 수행했을까? . ![[Pasted image 20240520225615.png|400]] 검색 결과는 프라이머리 키로 각가 정렬되어 있다는걸 안다. 이를 이용해 두 집합에서 하나씩 가녀와서 서로 비교하면서 프라이머리 키인 emp_no컬럼의 값이 중복된 레코드들을 정렬 없이 걸러낼 수 있다. 인덱스 머지 - 정렬 후 합집합(index_merge_sort_union) . 하지만 모든 경우 그렇지 않는데, 만약 인덱스 머지 작업을 하는 도중에 결과의 정렬이 필요한 경우 Sort Union알고리즘을 사용한다. 세미 조인 쿼리 ![[Pasted image 20240520230208.png]] . 세미 조인 . 다른 테이블과 실제 조인을 수행하지는 않고, 단지 다른 테이블에서 조건에 일치하는 레코드가 있는지 없는지만 체크하는 형태의 쿼리를 세미조인 이라고한다. 테이블 풀 아웃(Table Pull -out) . 세미 조인의 서브쿼리에 사용된 테이블을 아우터 쿼리로 끄집어낸 후에 쿼리를 조인 쿼리로 재작성하는 형태의 최적화이다 ![[Pasted image 20240520231626.png]] ![[Pasted image 20240520231636.png]] 모든 형태의 서브 쿼리에서 사용될 수 있는것은 아니다. 특정 조건이 있다는 점 알아두자. 퍼스트 매치(firstmatch) . IN(subquery) 형태의 세미 조인을 EXISTS(subquery) 형태로 튜닝한 것과 비슷한 방법으로 실행된다. ![[Pasted image 20240520231918.png]] ![[Pasted image 20240520232152.png]] “FirstMatch(e)”문구는 employees 테이블의 레코드에 대해 titles 테이블에 일치하는 레코드 1건만 찾으면 더이상의 titles 테이블 검색을 하지 않는다는 것을 의미한다. ![[Pasted image 20240520231953.png]] . 루스 스캔(loosescan) . Group BY 최적화 방법에서 살펴본 Using index for group-by의 루스 인덱스 스캔과 비슷한 방식을 사용한다. ![[Pasted image 20240520232352.png]] department테이블의 레코드 건수는 9건밖에 안되지만dept_emp 테이블의 레코드 건수는 무려 33만 건 가까이 저장돼 있다. dept_emp 테이블에는 (dept_no + emp_no) 컬럼의 조합으로 프라이머리 키 인덱스가 만들어져 있다. 프라이머리 키를 루스 인덱스 스캔으로 유니크한 dept_no만 읽으면 효율적으로 서브쿼리 부분을 실행할 수 있다. ![[Pasted image 20240520232544.png]] . 구체화(Materialization) . 세미 조인에 사용된 서브쿼리를 통째로 구채화해서 쿼리를 최적화한다는 의미이다. 구체화는 쉽게 표현하면 내부 임시 테이블을 생성한다는 것을 의미한다. ![[Pasted image 20240520232909.png]] 이 쿼리는 FirstMatch 최적화를 사용하면 employees 테이블에 대한 조건이 서브 쿼리 이외에는 아무것도 없기 때문에 employees테이블을 풀 스캔해야 할 것이다. 그래서 이런 형태의 세미 조인에서는 FirstMatch 최적화가 성능 향상에 별로 도움이 되지 않는다. 때문에 이런 형태에서는 서브 쿼리 구체화 최적화를 사용한다. 중복 제거(Duplicated Weed-out) . 세미 조인 쿼리를 일반적인 INNER JOIN 쿼리로 바꿔서 실행하고 마지막에 중복된 레코드를 제거하는 방법으로 처리되는 최적화 알고리즘이다. ![[Pasted image 20240520235126.png]] . salaries 테이블의 프라이머리 키가(emp_no + from_date)이므로 salary가 150000 이상인 레코드를 salaries 테이블에서 조회하면 그 결과에는 중복된 emp_no가 발생할 수 있다. 그래서 이 쿼리를 다음과 같이 재작성해서 GROuP BY 절을 넣어 주면 위의 세미 조인 서브쿼리와 동일한 결과를 얻을 수 있다. ![[Pasted image 20240520235312.png]] . 아래는 중복 제거 동작 방식이다. ![[Pasted image 20240520235348.png]] . 컨디션 팬아웃(condition_fanout_filter) . 조인을 실행할 때 테이블의 순서는 쿼리의 성능에 매우 큰 영향을 미친다. 그래서 옵티마이저는 여러 테이블이 조인되는 경우 일치하는 레코드 건수가 적은 순서대로 조인을 실행한다. 인덱스 통계 분석: 각 인덱스에 대한 통계 정보를 분석하여 인덱스 열의 값 분포를 파악한다. 예를 들어, 특정 열의 값이 균일하게 분포되어 있는지, 아니면 특정 값에 집중되어 있는지 등을 분석한다. 인덱스 통계 정보만 사용하는것이 아니라 다음 순서대로 사용 가능한 방식을 선택한다. | ﻿﻿﻿레인지 옵티마이저(Range optimizer)를 이용한 예측 | ﻿﻿﻿히스토그램을 이용한 예측 | ﻿﻿﻿인덱스 통계를 이용한 예측 | ﻿﻿﻿추측에 기반한 예측(Guesstimates3) | . 이러한 과정을 통해 컨디션 팬아웃 필터는 가장 효율적인 인덱스 조합을 선택하여 쿼리 성능을 향상시킨다. 파생 테이블 머지 . - . 인비저블 인덱스 . MySQL 8.0 버전부터는 인덱스의 가용 상태를 제어할 수 있는 기능이 추가됐다. MySQL 8.0 이전 버 전까지는 인덱스가 존재하면 항상 옵티마이저가 실행 계획을 수립할 때 해당 인덱스를 검토하고 사용 했다. 하지만 MySQL 8.0 버전부터는 인덱스를 삭제하지 않고, 해당 인덱스를 사용하지 못하게 제어하 는 기능을 제공한다. 스킵 인덱스 . 값이 정렬되있다는것이 핵심이며, 이로 인해 인덱스를 구헝하는 컬럼의 순서가 매우 중요하다. 예를 들어, (A, B, C) 칼럼으로 구성된 인덱스가 있을 때 쿼리의 WHERE 절에 A와 B 칼럼에 대한 조건 이 있다면 이 쿼리는 A 칼럼과 B 칼럼까지만 인덱스를 활용할 수 있고, WHERE 절에 A 칼럼에 대한 조건만 가지고 있다면 A 칼럼까지만 인덱스를 활용할 수 있다. 그런데 WERE 절에 B와 C 칼럼에 대한 조건을 가 지고 있다면 이 쿼리는 인덱스를 활용할 수 없다. 인덱스 스킵 스캔은 제한적이긴 하지만 인덱스의 이런 제약 사항을 뛰어넘을 수 있는 최적화 기법이다. 해시 조인(hash_join) . 해시 조인 기능을 기대하는 이유가 기존의 네스티드 루프 조인(Nested Loop Join)보다 해시 조인이 빠르다고 생각하기 때문이다. 하지만 이는 항상 옳은 이야기는 아니다. ![[Pasted image 20240521001004.png]] 화살표의 길이는 전체 쿼리 실행시간을 의미한다. 해시 조인은 첫 번째 레코드를 찾는 데는 시간이 많이 걸리지만 최종 레코드를 찾는 데까지는 시간이 많이 걸리지 않음을 알 수 있다. ![[Pasted image 20240521001235.png]] 위 그림은 해시 조인 과정을 그림으로 표현한 것이다. ![[Pasted image 20240521001304.png]] 해시 테이블이 조인 버퍼 메모리보다 큰 경우 적당한 크기로 분리한 다음 청크별로 조인과 동일한 방식으로 해시 조인을 처리한다. ![[Pasted image 20240521001419.png]] . | 1차 조인이 완료되면 MySQL 서버는 디스크에 저장된 “빌드 테이블 청크”에서 첫 번째 청크를 읽어서 다시 “메모리 해시 테이블”을 구축한다. | “프로브 테이블 청크”에서 첫 번째 청크를 읽으면서 새로 구축된”메모리 해시 테이블”과 조인을 수행해 2차 결과를 가져온다. | . 빌드 테이블 청크”와 “프로브 테이블 청크”에서 첫 번째 청크만 처리하는 그림을 보여주지만 디스크에 저장된 청크 개수만큼 이 과정을 반복 처리해서 완성된 조인 결과를 만들어낸다. 이렇게 청크 단위로 조인을 수행하기 위해 2차 해시 함수를 이용해 빌드 테이블과 프로브 테이블을 동일 개수의 청크로 쪼개어 디스크로 저장한다 . 인덱스 정렬 선호(prefer_ordering_index) . 옵티마이저는 order by 또는 group by를 인덱스를 사용해 처리 가능한 경우 쿼리의 실행계획에서 가중치를 높이 설정해서 실행된다. 조인 최적화 알고리즘 . Exhaustive 검색 알고리즘 . | ![[Pasted image 20240521001718.png | 400]] | . FROM 절에 명시된 모든 테이블의 조합에 대해 실행 계획의 비용을 계산해서 최적의 조합 1개를 찾는 방법이다. 테이블이 20개라면 이 방법으로 처리했을 때 가능한 조인 조합은 모두 20!(Factorial, 3628800)개가 된다. 이전 버전에서 사용되던 Exhaustive 검색 알고리즘에서는 사실 테이블이 10개만 넘어도 실행 계획을 수립하는 데 몇 분이 걸린다. 그리고 테이블이 10개에서 1개만 더 늘어나도 11배의 시간이 더 걸린다. Greedy 검색 알고리즘 . Greedy 검색 알고리즘은 Exhaustive 검색 알고리즘의 시간 소모적인 문제점을 해결하기 위해 도입된 조인 최적화 기법이다. | ![[Pasted image 20240521001857.png | 400]] | . ",
    "url": "/docs/mysql/09.%20Real%20MySQL%208.0.html#%EA%B3%A0%EA%B8%89-%EC%B5%9C%EC%A0%81%ED%99%94",
    
    "relUrl": "/docs/mysql/09.%20Real%20MySQL%208.0.html#고급-최적화"
  },"109": {
    "doc": "09. Real MySQL 8.0",
    "title": "쿼리 힌트",
    "content": "MysQL 서버는 우리가 서비스하는 비즈니 스를 100% 이해하지는 못한다. 그래서 서비스 개발자나 DBA보다 MySQL 서버가 부족한 실행 계획을 수립할 때가 있을 수 있다. 이런 경우에는 옵티마이저에게 쿼리의 실행 계획을 어떻게 수립해야 할지 알려주기 위해 다양한 옵티마이저 힌트를 제공한다. 인덱스 힌트 . STRAIGHT_JOIN과 USE INDEX 등을 포함한 인덱스 힌트들은 옵티마이저 힌트가 도입되기 전에 사용되던 기능들이다. 그래서 ANSI-SQL 표준 문법을 준수하지 못하게 되는 단점이 있다. MySQL 5.6 버전부터 추가되기 시작한 옵티마이저 힌트들은 모두 MySQL 서버를 제외한 다른 RDBMS에서는 주석으로 해석하기 때문에 ANSI-SQL 표준을 준수한다고 볼 수 있다. 그래서 가능하다면 인덱스 힌트보다는 옵티마이저 힌트를 사용할 것을 추천한다. 또한 인덱스 힌트는 SELECT 명령과 UPDATE 명령에서만 사용할 수 있다. STRAIGHT_JOIN . STRAIGHT_JOIN은 옵티마이저 힌트인 동시에 조인 키워드이기도 하다. STRAIGHT_JOIN은 SELECT, UPDATE, DELETE 쿼리에서 여러 개의 테이블이 조인되는 경우 조인 순서를 고정하는 역할을 한다. 다음 쿼리는 3개의 테이블을 조인하지만 어느 테이블이 드라이빙 테이블이 되고 어느 테이블이 드리븐 테이블이 될지 알 수 없다. 옵티마이저가 그때그때 각 테이블의 통계 정보와 쿼리의 조건을 기반으로 가장 최적이라고 판단되는 순서로 조인한다. ![[Pasted image 20240521002735.png]] ![[Pasted image 20240521002919.png]] 이 쿼리의 조인 순서를 변경하려는 경우에는 STRAIGHT_JOIN힌트를 사용할 수 있다. 다음 두 쿼리는 힌트의 표기법만 다를 뿐 동일한 쿼리다. ![[Pasted image 20240521002801.png]] 두 예제 모두 STRAIGHT_JOIN 키워드가 SELECT 키워드 바로 뒤에 사용됐다는 것에 주의하자. 이처럼 인덱스 힌트는 사용해야 하는 위치가 이미 결정됐으므로 그 이외의 다른 위치에서는 사용하지 않도록 주의하자. STRAIGHT_JOIN 힌트는 옵티마이저가 FRON 절에 명시된 테이블의 순서대로 조인을 수행하도록 유도 하는데, 이 쿼리의 실행 계획을 보면 FROM 에 명시된 테이블의 순서대로(employees -&gt; dept_emp -&gt; departments) 조인을 수행한다는 것을 알 수 있다. ![[Pasted image 20240521003113.png]] . 옵티마이저 힌트 . 힌트의 종류 . | 인덱스 : 특정 인덱스의 이름을 사용할 수 있는 옵티마이저 힌트 | 테이블 : 특정 테이블의 이름을 사용할 수 있는 옵티마이저 힌트 | 쿼리 블록 : 특정 쿼리 블록에 사용할 수 있는 옵티마이저 힌트로서, 특정 쿼리 블록의 이름을 명시하는 것이 아니라 힌트가 명시된 쿼리 블록에 대해서만 영향을 미치는 옵티마이저 힌트 | 글로벌(쿼리 전체) : 전체 쿼리에 대해서 영향을 미치는 힌트 | . 이 구븐으로 인해 힌트의 사용 위치가 달라지는 것은 아니다. 힌트에 인덱스 이름이 명시될 수 있는 경우를 인덱스 수준의 힌트로 구분하고, 테이블 이름까지만 명시될 수 있는 경우를 테이블 수준의 힌트로 구분한다. 둘 다 할 수 있지만 테이블 이름만 명시한 경우는 인덱스와 테이블 수준의 힌트가 된다. 그 외의 다양한 힌트는 필요한 경우 찾아보자. | MAX_EXECUTION_TIME | SET_VAR | SEMIJOIN &amp; NO_SEMIJOIN | SUBQUERY | BNL &amp; NO_BNL &amp; HASHJOIN &amp; NO_HASHJOIN | JOIN_FIXED_ORDER &amp; JOIN_ORDER &amp; JOIN_PREFIX &amp; JOIN_SUFFIX | MERGE &amp; NO_MERGE | INDEX_MERGE &amp; NO_INDEX_MERGE | NO_ICP(Index Condition Pushdown) | SKIP_SCAN &amp; NO_SKIP_SCAN | INDEX &amp; NO_INDEX | . ",
    "url": "/docs/mysql/09.%20Real%20MySQL%208.0.html#%EC%BF%BC%EB%A6%AC-%ED%9E%8C%ED%8A%B8",
    
    "relUrl": "/docs/mysql/09.%20Real%20MySQL%208.0.html#쿼리-힌트"
  },"110": {
    "doc": "09. Real MySQL 8.0",
    "title": "09. Real MySQL 8.0",
    "content": " ",
    "url": "/docs/mysql/09.%20Real%20MySQL%208.0.html",
    
    "relUrl": "/docs/mysql/09.%20Real%20MySQL%208.0.html"
  },"111": {
    "doc": "09. S3",
    "title": "09. S3",
    "content": ". ",
    "url": "/docs/aws/09.%20S3.html",
    
    "relUrl": "/docs/aws/09.%20S3.html"
  },"112": {
    "doc": "09. S3",
    "title": "소개",
    "content": "무한하게 확장할 수 있는 스토리지 백업과 스토리지로 사용한다 . 재해 복구 용도로도 사용한다. 예를들어 리전이 다운되는 경우 데이터를 다른 리전으로 이동시켜야 한다. 이런 경우 데이터는 어딘가에 백업되어야하는데 이때 사용한다? . 아카이브용으로도 사용한다. S3에 파일을 아카이브해 두면 추후 매우 손쉽게 검색할 수 있다. 애플리케이션을 호스팅하고 동영상 파일이나 이미지 등 미디어를 호스팅할 수 있다. 데이터 레이크를 보유하여 다량의 데이터를 저장하고 빅 데이터 분석을 수행하기 위해서도 사용한다. 데이터 레이크(Data Lake) 정형, 반정형, 비정형 데이터를 저장하는 중앙 집중식 저장소입니다. 데이터 레이크는 데이터를 기본 형식으로 저장할 수 있으며, 크기 제한을 무시하고 다양한 데이터를 처리할 수 있습니다. 정적 웹사이트를 호스팅하기 위해서도 사용할 수 있다. 이게 cloudFront 인건가? . S3는 파일을 버킷에 저장하는데, 버킷은 상위 레벨 디렉토리로 표시된다. ???? . S3 버킷의 파일은 객체라고한다. 버킷의 이름은 계정에 있는 모든 리전과 AWS에 존재하는 모든 계정에서 고유해야한다. 하지만 버킷은 리전 수준에서 정의된다. S3 버킷에는 명명 규칙이있는데 기억할 필요는 없지만 알아두면 좋다. S3 그 자체로는 디렉토리의 개념이 없다. 핵심은 키 . S3 최대 객체 크기는 5TB이다 . 파일 업로드시 5GB보다 크다면 나눠서 업로드해야한다. 5TB의 경우는 1000개로 나눠서 업로드 필요. 객체에는 메타데이터도 있어서 필요에 따라 사용할 수 있다. ",
    "url": "/docs/aws/09.%20S3.html#%EC%86%8C%EA%B0%9C",
    
    "relUrl": "/docs/aws/09.%20S3.html#소개"
  },"113": {
    "doc": "09. S3",
    "title": "보안 (S3 버킷 정책)",
    "content": "User-Based . | 사용자 기반 (IAM 사용) Resource-Based | 리소스 기반 | S3 버킷 정책 사용하여 전체 버킷 규칙을 세울 수 있다. | 특정 사용자가 들어올 수 있게 하거나 다른 계정의 사용자를 허용할수 있게 설정하는것을 교차 계정이라고한다 | 이는 S3버킷을 공개로 만드는 방법이기도 하다 | ACL . | object Access Control List . | 객체 액세스 제어 목록 | 세밀한 보안이며 비활성화할 수 있다 | . | Bucket Access Control List . | 훨씬 덜 일반적이다. | 비활성화할 수 있다. | . | . | . S3 버킷의 보안관리는 일반적으로 버킷 정책을 사용하는것이다. 보안을 관리할 수 있는 방법은 암호화 키를 사용하여 객체를 암호화 하는것이다. JSON기반 보안 정책 작성 . Principal이 * 인 경우 모든 사용자를 허용한다 . S3 버킷 정책을 설정하여 공개로 만들더라도 보안키 설정이 되어있다면 버킷은 결코 공개되지않는다. ",
    "url": "/docs/aws/09.%20S3.html#%EB%B3%B4%EC%95%88-s3-%EB%B2%84%ED%82%B7-%EC%A0%95%EC%B1%85",
    
    "relUrl": "/docs/aws/09.%20S3.html#보안-s3-버킷-정책"
  },"114": {
    "doc": "09. S3",
    "title": "S3 정적 웹사이트",
    "content": "버킷에서 공개 읽기가 활성화 되지 않은경우 이것은 동작하지않는다. (403 FOrbidden 오류가 나는경우 해당 케이스) . 웹사이트 URL은 버킷이름과 AWS리전에 따라 달라진다 . ",
    "url": "/docs/aws/09.%20S3.html#s3-%EC%A0%95%EC%A0%81-%EC%9B%B9%EC%82%AC%EC%9D%B4%ED%8A%B8",
    
    "relUrl": "/docs/aws/09.%20S3.html#s3-정적-웹사이트"
  },"115": {
    "doc": "09. S3",
    "title": "S3 버전관리",
    "content": "S3는 파일을 버전 관리할 수 있다 버킷 수전에서 활성화 해야한다 사용자가 파일을 업로드할 때마다 선택키에서 해당 파일의 버전이 생성된다 동일한 키를 업로드하고 해당 파일을 덮어쓰는 경우 버전 2 버전 3 등을 생성하게 된다 . 버전 관리를 활성화하기 전에 버전 관리가 적용되지 않은 모든 파일은 null버전을 갖게된다 또 버전 관리르 중단해도 이전 버전을 삭제하지는 않는다 . ",
    "url": "/docs/aws/09.%20S3.html#s3-%EB%B2%84%EC%A0%84%EA%B4%80%EB%A6%AC",
    
    "relUrl": "/docs/aws/09.%20S3.html#s3-버전관리"
  },"116": {
    "doc": "09. S3",
    "title": "S3 복제",
    "content": ". | 교차 리전 복제 CRR | 같은 리전으로 복제 SRR | . 소스 버킷과 복제 대상 버킷 둘 모두 버전 관리 기능이 활성화되어야한다 CRR은 이름 그대로 두 리전이 달라야 하고, SRR은 같은 리전이여야한다 복제는 비동기식으로 이루어진다 복제 과정은 백그라운드에서 이루어진다 복제 기능이 정상적으로 실행되려면 , S3에 올바른 IAM권한 (읽기 쓰기)를 부여해야한다. CRR은 컴플라이언스(법규나 내부 체제 관리), 다른 리전에 있어 발생할 수 있는 지연시간을 줄이는 경우 에 사용한다 . SRR은 버킷간의 로그를 통합할때나 개발 환경이 별도로 있어 운영 환경과 개발 환경간의 실시간 복제를 필요로 할 떄 사용한다 . 복제를 활성화한 후에는 새로운 객체만 복제 대상이 된다. 기존의 객체를 복제하려면 S3 배치 복제 기능을 사용해야한다. 기존 객체부터 복제에 실패한 객체까지 복제할 수 있는 기능이다 . 작업을 삭제하려면?? 이게뭔소리임 소스 버킷에서 대상 버킷으로 삭제 마커를 복제하면 된다 버전 ID로 삭제하는 경우 버전 ID는 복제되지 않는다 . 체이닝 복제는 불가능하다 1번 버킷이 2번에 복제되어있고, 2번 버킷이 3번에 복제돼있는 경우 1번 버킷의 객체가 3번 버킷으로 복제되지 않는다. ????? . S3 Storage Classes . | Amazon S3 Standard . | 지연시간이 짧고 처리량이 높음 | AWS에서 두개의 기능장애를 동시에 버틸 수 있다 | 빅데이터 분석, 모바일, 게임 애플리케이션, 콘텐츠 배포에 사용 | 가용성은 99.99% | . | Amazon S3 Infrequent Access . | 자주 액세스하지는 않지만 필요한 경우 빠르게 액세스해야 하는 데이터 | standard보다 비용이 적게 들지만 검색 비용이 발생 | 가용성은 99.9% | 사용 사례는 재해복구와 백업 | . | Amazon S3 One Zone - Infrequent Access . | 단인 AZ 내에서는 높은 내구성을 갖지만 AZ가 파괴된 경우 데이터를 잃게 된다. | 가용성은 99.5% | 사용 사례는 온프레미스 데이터를 2차 백업하거나 재생성 가능한 데이터를 저장하는데 쓴다. | . | Amazon S3 Intelligent Tiering . | 사용자 패턴에 따라 액세스된 티어 간에 객체를 이동할 수 있게 해준다 | 소액의 월별 모니터링 비용과 티어링 비용이 발생한다 | 검색 비용이 없다 | FrequentAccess 티어 . | 자동?, 기본 티어 | . | InfrequestAccess 티어 . | 30일 동안 액세스 하지 않는 객체 전용 티어 | . | Archive Instant Access 티어 . | 자동?, | 90일 동안 액세스 하지 않는 티어 | . | Archive Access 티어 . | 선택 사항 | 90일에서 700일 이상까지 구성할 수 있다 | . | Deep Archive Access 티어 . | 180일에서 700일 이상 액세스 하지 않는 객체 티어 | . | 알아서 객체를 이동시켜주기 떄문에 편하게 스토리지를 관리할 수 있다. (위의 자동이란건 자동으로 파일을 옮겨준다는 뜻이구나..!) | | . | . Glacier 종류 . | Glacier 는 콜드 스토리지이다 | 아카이빙과 백업을 위한 저비용 객체 스토리지 . | Glacier Instant Reterieval | . | 밀리초 단위로 검색 가능 | 분기에 한번 액세스하는 데이터에 아주 적합 | 최소 보관 기간이 90일 이내 | 백업이지만 밀리초 이내에 액세스 하는경우에 적합 . | Glacier Flexible Retrieval | . | 3가지 옵션 | Expedited . | 데이터를 1~5분 이내에 받을 수 있다 | . | Standard . | 데이터를 돌려받는데 3~5시간 소요 | . | Bulk . | 무료이지만 데이터를 돌려받는데 5~12시간 소요 | . | 최소 보관 기간 90일 . | Glacier Deep Archive | . | 장기보관을 위해 사용 | 데이터 검색 시간 . | standard - 12시간 | bulk - 48시간 | . | 가장 저렴한 비용 | 최소 보관 기간 180일 | . | . 스토리지 클래스 간에 객체를 자동으로 이동할 수도 있다 . 내구성 . | S3로 인해 객체가 손실되는 획수 | 99.99999999% 보장 가용성 | 서비스가 얼마나 용이하게 제공되는지를 나타냄 | 스토리지 클래스마다 다름 | standard는 1년에 53분정도만 서비스를 사용할 수 없다 | . 다른 스토리지 클래스 간에 객체를 옮기는 방법 . Amazon S3 Standard Amazon S3 Infrequent Access Amazon S3 Intelligent Tiering Amazon S3 One Zone - Infrequent Access Glacier Instant Reterieval Glacier Flexible Retrieval Glacier Deep Archive . 위에서 아래 로 클래스 간 객체를 옮길 수 있다. 수작업으로 옮길 수도 있지만, 라이프사이클 규칙을 이용해서 자동으로 옮길 수도있다 . 라이프사이클 룰 . Transition Action 다른 스토리지 클래스로 이전하기 위해 객체를 설정 예를들어 생성된지 60일 후에 Standard 클래스로 이전 또는 6개월 후에 Glacier로 이전하여 아카이브화 Expiration actions 일정 시간뒤에 만료되어서 객체를 삭제할 수 있다 . 특정 접두어에 대해 지정도 가능하다 태그 또한 가능 . ",
    "url": "/docs/aws/09.%20S3.html#s3-%EB%B3%B5%EC%A0%9C",
    
    "relUrl": "/docs/aws/09.%20S3.html#s3-복제"
  },"117": {
    "doc": "09. S3",
    "title": "요청자 지불",
    "content": "스토리지 비용은 버킷 소유자가 지불하고 다운로드시 발생하는 네트워킹 비용은 요청자에게 청구할 수 있다 이를위해서는 요청자는 익명이여서는 안된다 요청자가 AWS에서 인증을 받아야한다 . ",
    "url": "/docs/aws/09.%20S3.html#%EC%9A%94%EC%B2%AD%EC%9E%90-%EC%A7%80%EB%B6%88",
    
    "relUrl": "/docs/aws/09.%20S3.html#요청자-지불"
  },"118": {
    "doc": "09. S3",
    "title": "이벤트 알림",
    "content": "이벤트는 예를 들어 객체가 생성되었거나 객체가 삭제되었거나 객체가 복구되었거나 복제되는 것 등을 말한다 . 이벤트들은 필터링 될 수 있다 . 이벤트를 만들고 그걸 몇몇 대상에 전송할 수 있다 . 대상은 SNS토픽이나 SQS Queue, 람다 함수 등이 될 수 있다 . 이벤트 알림이 작동하려면 IAM권한을 갖고 있어야 한다 (SNS토픽에 전송하려고 한다면 SNS 리소스 정책이라는것을 첨부해야함, 람다를 호출하려면 람다 호출 권한을 가져야함) . 이벤트는 S3 버킷으로 갈것이고, 모든 이벤트는 결국 Amazon EventBridge로 가게된다 . 이벤트 브릿지에서는 규칙을 설정할 수 있다 이 규칙들로 18가지 AWS 서비스에 전송할 수 있다 . ",
    "url": "/docs/aws/09.%20S3.html#%EC%9D%B4%EB%B2%A4%ED%8A%B8-%EC%95%8C%EB%A6%BC",
    
    "relUrl": "/docs/aws/09.%20S3.html#이벤트-알림"
  },"119": {
    "doc": "09. S3",
    "title": "성능",
    "content": "S3는 요청이 아주 많을 때 자동으로 확장된다 . S3로부터 첫 번째 바이트를 수신하는데 지연시간도 100~200밀리초 사이로 아주 짧다 . 초당 3,500개의 PUT/COPY/POST/DELETE 초당 5,500개의 GET/HEAD 요청을 지원한다 . 접두사당 초당 의미 첫 번째 객체의 위치는 bucket/folder1/sub1/file입니다 bucket과 file 사이에 있는 것이 접두사가 됩니다 /folder1/sub1이 되겠죠 . 성능 최적화 . 100MB가 넘는 파일은 멀티파트 업로드를 사용하는것이 좋다 5GB가 넘는 파일은 반드시 사용해야한다 . 멀티파트 업로드는 업로드를 병렬화 하여 전송속도를 높여 대역폭을 최대화할 수 있다. 전송 가속화 . 파일을 AWS 엣지 로케이션으로 전송해서 전송 속도를 높이고 데이터를 대상 리전에 있는 S3 버킷으로 전달한다 . 엣지 로케이션은 리전수보다 많다 . 파일을 수신하고 파일을 읽는 가장 효율적인 방법은? S3 바이트 범위 가져오기 . 파일에서 특정 바이트 범위를 가져와서 GET요청을 병렬화 하는 방법 . 특정 바이트 범위에서 가져오는데 실패하는 경우 더 작은 바이트 범위에서 재시도하여 실패의 경우 복원력이 높다 . ",
    "url": "/docs/aws/09.%20S3.html#%EC%84%B1%EB%8A%A5",
    
    "relUrl": "/docs/aws/09.%20S3.html#성능"
  },"120": {
    "doc": "09. S3",
    "title": "Select &amp; Glacier Select",
    "content": "S3에서 파일을 검색할 때 검색한 다음에 필터링하면 너무 많은 데이터를 검색하게된다 . 대신 서버 측 필터링을 수행하면 비용을 줄일 수 있다 SQL문에서 간단히 행과 열을 사용해 필터링할 수 있다 네트워크 전송이 줄어들기 때문에 데이터 검색과 필터링에 드는 클라이언트 측의 CPU 비용도 줄어든다 . select로 CSV파일을 가져오는 방법도 있다 데이터 크기가 훨씬 작아 저렴하다 . ",
    "url": "/docs/aws/09.%20S3.html#select--glacier-select",
    
    "relUrl": "/docs/aws/09.%20S3.html#select--glacier-select"
  },"121": {
    "doc": "09. S3",
    "title": "Batch Operations",
    "content": "단일 요청으로 S#객체에서 대량 작업을 수행하는 서비스 . 한번에 많은 S3 객체의 메타 데이터와 프로퍼티를 수정할 수 있다 . S3버킷 간에 객체를 복사할 수 있다 . S3 버킷 내 암호화되지 않은 모든 객체를 암호화할 수 있다 . ACL이나 태그를 수정할 수 있다 . S3 Clacier에서 한번에 많은 객체를 복원할 수 있다 . Lambda 함수를 호출해서 S3 Batch Operations의 모든 객체에서 사용자 지정 작업을 수행할 수 있다 . S3 Batch Operations를 사용하면 재시도를 관리할 수 있다 진행 상황을 추적하고 작업 완료 알림을 보내고 보고서 생성 등을 할 수 있다 . 배치에 전달할 객체 목록은 S3 Inventory라는 기능을 사용하여 객체 목록을 가져오고 S3 Select를 사용하여 객체를 필터링한다 객체 목록을 얻은 다음 S3 Batch Operations에 수행할 작업, 매개 변수와 함께 객체 목록을 전달한다 . ",
    "url": "/docs/aws/09.%20S3.html#batch-operations",
    
    "relUrl": "/docs/aws/09.%20S3.html#batch-operations"
  },"122": {
    "doc": "09. S3",
    "title": "보안",
    "content": "4가지 방법 . SSE (Server Side Encryption) . | SSE-S3 : S3에서 관리하는 키를 이용한 서버측 암호회 . | AWS가 처리하고 관리하는 소유키를 사용해서 암호화 | 키에 절대 접근 불가능하다 | AWS에 의해 서버측에서 암호화 적용 | 보안유형 AES-256 | SSE-S3 메커니즘을 이용하기 위해 객체를 암호화 하도록 헤더를 “x-amz-server-side-encrytion”:”AES256”이라고 설정해야한다 | . | SSE-KMS : KMS키를 이용해서 암호화 키를 관리 . | 키 관리 서비스를 이용해 직접 키를 관리한다 | KMS의 장점은 사용자가 키를 통제할 수 있다는것 | CloudTrail을 이용해서 키 사용을 검사할 수 있다 | CloudTrail AWS안에서 일어나는 모든걸 로깅하는 서비스 | 헤더를 “x-amz-server-side-encrytion”:”aws:kms”이라고 설정해야한다 | KMS 키에도 접근 권한이 있어야 암호를 해제할 수 있다 | 제약사항 . | 복호화를 위해 KMS api를 호출해야한다. | 처리량이 아주 많고 모든게 KMS키로암호회 되어있다면 스로틀링이 걸릴 수 있다 | . | . | SSE-C : 고객이 제공한 키를 사용 . | 파일과 키를 함께 업로드한다 CSE (Client Side Encryption) | . | 암호화 라이브러리를 사용하면 쉽게 구현 | 클라이언트가 직접 암호화 한다음 S3에 업로드한다 | . 기본값 암호화는 SSE-S3로 제공하지만 버킷 정책으로 암호화를 강제할 수 있다. 전송중 암호화 . S3 버킷은 기본적으로 2개의 엔드포인트가 존재한다 암호화가 되지 않는 HTTP 암호화가 제공되는 HTTPS S3는 HTTPS를 권고한다 . 전송 중 암호화를 강제하는방법 . | 버킷 정책 사용 | S3 버킷에 버킷 정책 첨부하고 | aws:SecureTransport가 false라면 GetObject 작업을 거부한다 | 해당 옵션으로 암호화 연결을 사용하지 않는다면 차단된다 | . ",
    "url": "/docs/aws/09.%20S3.html#%EB%B3%B4%EC%95%88",
    
    "relUrl": "/docs/aws/09.%20S3.html#보안"
  },"123": {
    "doc": "09. S3",
    "title": "CORS",
    "content": "오리진은 체계(프로토콜)와 호스트(도메인)와 포트로 구성된다 . https://www.example.com:443 프로토콜 도메인 포트의 예 . CORS는 웹 브라우저 기반 보안 메커니즘이다 메인 오리진을 방문하는 동안 다른 오리진에 대한 요청을 허용하거나 거부한다 오리진이 같다는건 프로토콜 도메인 포트가 같다라는 뜻 . S3에 적용 . 클라이언트가 S3버킷에서 교차 오리진 요청을 하면 정확한 CORS 헤더를 활성화 해야한다 . 시험에 나옴 이 작업을 빠르게 수행하려면 특정 오리진을 허용하거나 *를 붙여 모든 오리진을 허용한다 . MFA . 멀티팩터 인증 . 사용자가 장치에서 코드를 생성하도록 강제한다 . MFA는 객체 버전을 영구적으로 삭제할 때 필요하다 영구 삭제에 대한 보호 설정 . 버킷에서 버저닝을 중단할 때도 필요하다 . 루트 계정만이 MFA delete를 활성화하거나 비활성화할수있다 . S3 Access Logs . 어떤 계정이든 S3로 보낸 모든 요청은 승인 또는 거부 여부와 관계없이 기록된다 . 해당 데이터는 Amazon Athena 같은 데이터 분석 도구로 분석할 수 있다 . 로깅 버킷은 같은 AWS리전에 있어야한다 . 액세서 로그를 활성화 하면 모든 요청이 로깅 버킷에 기록된다 . 특정 로그 형식이 있다 . 주의사항 . | 절대 로깅 버킷을 모니터링하는 버킷과 동일하게 설정하면 안된다. | 동일하게 설정하면 로깅 루프가 생성되고 무한이 반복되어 버킷의 크기가 기하급수적으로 증가한다 | . ",
    "url": "/docs/aws/09.%20S3.html#cors",
    
    "relUrl": "/docs/aws/09.%20S3.html#cors"
  },"124": {
    "doc": "09. S3",
    "title": "Pre-Signed URLs",
    "content": "URL에는 만료 기한이 있다 S3 콘솔을 사용하면 최대 12시간 CLI를 하면 168시간까지 사용할 수 있다 . 서명된 URL을 생성할때 URL을 받는 사용자는 URL을 생성한 사용자의 GET 또는 PUT에 대한 권한을 상속한다 . S3 Glacier Vault Lock . 볼트 잠금 . WORM모델을 채용하기 위해 Clacier 볼트를 잠근다 . WORM은 한번 쓰고 여러번 읽는다는 뜻이다 . 객체를 가져와서 S3 Clacier에 넣은다음 수정하거나 삭제할 수 없도록 잠그는것 . 잠금 정책을 설정하고 잠근 후에는 누구도 변경하거나 삭제할 수 없다 . 유사한 옵션으로 . S3 객체 잠금 . 이 있다 . 조금더 복잡하다 . S3 객체 잠금을 활성화 하려면 먼저 버저닝을 활성화 해야한다 . 잠금은 전제가 아닌 버킷 내의 모든 객체에 각각 적용할 수 있다 . 특정 객체 버전이 특정 시간동안 삭제되는걸 차단할 수 있다 . 객체 잠금에는 보존 모드가 있다 . 보존모드 . 규정 준수 모드 . | S3 Glacier 볼트 잠금과 매우 유사 | 사용자를 포함한 누구도 객체 버전을 덮어쓰거나 삭제할 수 없다 | 규정 준수 모드에서는 누구도 객체를 변경할 수 없다 | 보존 모드 자체도 변경할 수 없다 | 보돈 기간도 단축할 수 없다 | . 거버넌스 보존 모드 . | 좀 더 유연하다 | 객체 버전을 덮어쓰거나 삭제하거나 로그 설정을 변경할 수 없다 | 하지만 관리자 같은 일부 사용자는 IAM을 통해 부여받은 특별한 권한으로 보존기간을 변경하거나 객체를 바로 삭제할 수 있다 | . 객체에 법적 보존 상태를 설정할 수 있다 . | S3 버킷 내 모든 객체를 무기한으로 보존한다 | s3:putObjectLegalHold IAM권한을 가진 사용자는 어떤 객체든 법전 보존을 설정하거나 제거할 수 있다 | . 엑세스 포인트 . 사용자의 데이터가 많아질수록 관리하기 어렵다 . 해소방법은? 엑세스 포인트 . 예를들어 재무 관련된 파일들을 /finance 라는 접두어에 읽기와 쓰기 액세스 권한을 부여한다 . 엑세스 포인트=에는 각자의 보안을 갖고있다 . 특정 사람들만 재무 부문에 접속할 수 있도록 하게된다 . 이렇게 해서 실제로 S3 버킷에 대한 엑세스를 스케일링 할 수 있따 . 엔드포인트는 각자의 DNS 이름을 갖게 된다 . ",
    "url": "/docs/aws/09.%20S3.html#pre-signed-urls",
    
    "relUrl": "/docs/aws/09.%20S3.html#pre-signed-urls"
  },"125": {
    "doc": "09. S3",
    "title": "S3 Object Lambda",
    "content": "액세스 포인트에는 또 다른 활용 사례가 있다. S3 객체 람다 . S3버킷이 있는데 호출자 애플리케이션이 객체를 받기 직전에 객체를 수정하려는 경우 . 버킷을 복제해서 버킷에 각 객체의 다른 버전을 갖는 대신에 S3 객체 람다를 사용할 수 있다 . 람다를 거치는 과정에서 요청자에게 데이터를 전달하고 객체를 삭제하거나 수정한다 . 이를 위해 S3 액세스 포인트가 필요하다 . ",
    "url": "/docs/aws/09.%20S3.html#s3-object-lambda",
    
    "relUrl": "/docs/aws/09.%20S3.html#s3-object-lambda"
  },"126": {
    "doc": "09. 유연한 설계",
    "title": "09. 유연한 설계",
    "content": ". 개방 폐쇄 원칙 소프트웨어 개체는 확장에 대해 열려 있어야 하고, 수정에 대해서는 닫혀 있어야 한다. | 확장에 대해 열려 있다. 애플리케이션의 요구사항이 변경될 때 이 변경에 맞게 새로운 ‘동장’과 ‘코드’의 관점을 반영한다. | 수정에 대해 닫혀 있다. 기존의 ‘코드’를 수정하지 않고도 애플리케이션의 동작을 추가하거나 변경할 수 있다. | . 컴파일타임 의존성을 고정시키고 런타임 의존성을 변경하라 ![[Pasted image 20240601141147.png]] . 추상화가 핵심이다 개방 - 폐쇄 원칙의 핵심은 추상화에 의존하는 것이다. 추상화는 핵심적인 부분만 남기고 필요한 부분은 생략함으로써 복잡성을 극복하는 기법이다. 개방 - 폐쇄 원칙은 관점에서 생략되지 않고 남겨지는 부분은 다양한 상황에서의 공통점을 반영한 추상화의 결과물이다. 공통적인 부분은 문맥이 바뀌더라도 변하지 않아야 한다. 주의할점은 추상화를 했다고 해서 모든 수정에 대해 설계가 폐쇄되는 것이 아니라는 것이다. 추상화가 수정에 대해 닫혀있을 수 있는 이유는 변경되지 않을 부분을 신중하게 결정하고 올바른 추상화를 주의 깊에 선택했기 때문이라는 사실을 기억하라. 생성 사용 분리 . ![[Pasted image 20240601141814.png]] 유연하고 재사용 가능한 설계를 원한다면 객체와 관련된 두 가지 책임을 서로 다른 객체로 분리해야 한다. 하나는 객체를 생성하는 것이고, 다른 하나는 객체를 사용하는 것이다. 생성을 분리하는데 사용되는 가장 보편적인 방법은 책임을 클라이언트로 옮기는 것이다. public class Client { public Money getAvatarFee () { Movie avatar = new Movie(\"아바타\" Duration.ofMinutes (120), Money wons (10000), new AmountDiscountPolicy(...)); return avatar.getFee; } } . ![[Pasted image 20240601142058.png]] . FACTORY 추가하기 . Client의 코드를 다시 살펴보면 Movie를 생성하는 동시에 getFee 메시지도 함께 전송한다. 역시 생성과 사용의 책임을 함께 지니고있다. 이 경우 객체 생성과 관련된 책임만 전담하는 별도의 객체를 추가하고 Client는 이 객체를 사용하도록 만들 수 있다. 이처럼 생성과 사용을 분리하기 위해 객체 생성에 특화된 객체를 FACTORY라고 부른다. ![[Pasted image 20240601142401.png]] . 순수한 가공물에게 책임 할당하기 시스템을 객체로 분해하는데 크게 두 가지 방식이 존재한다고 한다. | 표현적 분해 : 도메인에 존재하는 사물 또는 개념을 표현하는 객체들을 이용해 시스템을 분해하는 것 | 행위적 분해 : 도메인 개념을 표현한 객체가 아닌 설계자가 편의를 위해 임의로 만들어낸 가공의 객체 | . 이런 측면에서 객체지향이 실세계의 모방이라는 말은 옳지 않다. 의존성 주입 . 생성과 사용을 분리하면 Movie에는 오로지 인스턴스를 사용하는 책임만 남게 된다. 이것은 외부의 다른 객체가 Movie에게 생성된 인스턴스를 전달해야 한다는 것을 의미한다. 객체를 생성한 후 이를 전달해서 의존성을 해결하는 방법을 의존성 주입이라고 부른다. | 생성자 주입 : 객체를 생성하는 시점에 생성자를 통한 의존성 해결 | setter주입 : 객체 생성 후 setter 메서드를 통한 의존성 해결 | 메서드 주입 : 메서드 실행시 인자를 이용한 의존성 해결 | . 숨겨진 의존성은 나쁘다. 이외에도 의존성을 해결할 수 있는 다양한 방법이 존재한다. SERVICE LOCATOR 패턴 SERVICE LOCATOR 패턴은 서비스를 사용하는 코드로부터 서비스가 누구인지(서비스를 구현한 구체 클래스의 타입이 무엇인지), 어디에 있는지(클래스 인스턴스를 어떻게 얻을지)를 몰라도 되게 해준다. public class ServiceLocator { private static ServiceLocator soleInstance = new ServiceLocator); private DiscountPolicy discountPolicy; public static DiscountPolicy discountPolicy) { return soleInstance.discountPolicy; } public static void provide (DiscountPolicy discountPolicy) { soleInstance.discountPolicy = discountPolicy; } private ServiceLocator () { } . ServiceLocator.provide(new AmountDiscountPolicy (...)); Movie avatar = new Movie(\"아바타\", Duration.ofMinutes (120), Money wons (10000)); . SERVICE LOCATOR 패턴의 가장 큰 단점은 의존성을 감춘다는 것이다. Movie는 DiscountPolicy에 의존하고 있지만 어디에도 표시돼 있지 않다. 감춰진 의존성은 문제를 런타임에 가서야 발견할 수 있다. 단위 테스트 작성 또한 어렵다. 일반적인 단위 테스트는 고립되어야 하는데 그렇지 못한다. 원인은 캡슐화를 위반했기 때문이다. 가장 큰 문제는 의존성을 이해하기 위해 코드의 내부 구현을 이해할 것을 강요한다. 어쩔수 없이 객체를 계속해서 전달해야 하는 고통을 견디기 어려운 경우에는 어쩔수 없이 SERVICE LOCATOR 패턴을 사용하는 것을 고려하자 . 의존성 역전 원칙 . 변경에 취약한 설계는 상위 클래스가 하위 클래스에 의존하는 설계이다. ![[Pasted image 20240601144150.png]] . 이 경우에도 해결사는 역시 추상화다. Movie와 AmountDiscountPolicy 모두 추상화에 의존하도록 수정하면 하위 수준 클래스의 변경으로 인해 상위 수준의 클래스가 영향을 받는 것을 방지할 수 있다. ![[Pasted image 20240601144751.png]] . 의존성 역전 원칙에 따라 상위 수준의 협력 흐름을 재사용하기 위해서는 추상화가 제공하는 인터페이스의 소유권 역시 역진시켜야 한다. ![[Pasted image 20240601145001.png]] . 유연성에 대한 조언 . 유연한 설계는 유연성이 필요할 때만 옳다. 유연하고 재사용 가능한 설계가 항상 좋은 것은 아니다.설계의 미덕은 단순함과 명확함으로부터 나온다. 단순하고 명확한 설계를 가진 코드는 읽기 쉽고 이해하기도 편하다. 유연한 설계라는 말의 이면에는 복잡한 설계라는 의미가 숨어 있다. 설계가 유연할수록 클래스 구조와 객체 구조 사이의 거리는 점점 멀어진다. 따라서 유연함은 단순성과 명확성의 희생 위에서 자라난다. 복잡성이 필요한 이유와 합리적인 근거를 제시하지 않는다면 어느 누구도 설계를 만족스러운 해법으로 받아들이지 않을 것이다. ",
    "url": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/09.%20%EC%9C%A0%EC%97%B0%ED%95%9C%20%EC%84%A4%EA%B3%84.html",
    
    "relUrl": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/09.%20%EC%9C%A0%EC%97%B0%ED%95%9C%20%EC%84%A4%EA%B3%84.html"
  },"127": {
    "doc": "10. CloudFront",
    "title": "10. CloudFront",
    "content": ". cloud front란 CDN, 즉 컨텐츠 전송 네트워크라는 뜻 . 서로 다른 엣지 로케이션에 미리 캐싱하여 읽기 성능을 높이는 것이다 . 전세계의 총 216개의 엣지 로케이션이 구성되어 있어 낮은 레이턴시로 접근할 수 있게된다. 컨텐츠가 전체적으로 분산되어 있으므로 DDoS 공격에서 보호 받을 수 있다 . 버킷에는 CloudFront만 접근할 수 있게 보장하는데, 이를 가능하게하는것은 OAC라 불리는 Origin Access Control로 기존의 OAI를 대체한다. OAI (Origin Access Identity)란 CloudFront가 S3에 저장된 Private 객체에 액세스 할 수 있도록 하는 특별한 식별자다. OAS Origin Access Control + S3 Bucket Policy . Ingress . CloudFront를 통해 버킷 데이터를 보내는 방법도 가능하다 . HTTP 백엔드와 같은 사용자 정의 원본을 쓸수있다???? . 예시로, 어플리케이션 로드 밸런서나 EC2인스턴스, 또는 S3 웹사이트 . CloudFront와 CRR(교차 리전 복제)간의 차이점? . CloudFront는 전세계를 대상으로 한정적 컨텐츠를 사용하고자 할때 사용 . 교차 리전은 각 리전에 설정이 되어 있어야한다. 즉 전세계를 대상으로 한것이 아니다 그리고 파일은 거의 실시간으로 갱신되고 캐싱되지 않는다. ",
    "url": "/docs/aws/10.%20CloudFront.html",
    
    "relUrl": "/docs/aws/10.%20CloudFront.html"
  },"128": {
    "doc": "10. CloudFront",
    "title": "어플리케이션 로드밸런서를 원본으로 사용할경우",
    "content": "EC2인스턴스를 통해 HTTP백엔드를 개발한다고 가정 . 그리고 사용자들이 CloudFront를 통해 접근하기를 원한다. CloudFront는 가상 프라이빗 클라우드(VPC)가 없기 때문에 CloudFront, 백엔드 애플리케이션 둘달 퍼블릭으로 설정하지 않으면 EC2(백엔드)에 접근 할 수 없다. 따라서 모든 엣지 로케이션의 모든 공용 IP가 EC2에 접근할 수 있도록 설정이 필요하다 . 두번째 방식으로느는 어플리케이션 로드 밸런서이다 . 마찬가지로 공용으로 설정되어있어야 한다 . 반면 EC2의 인스턴스는 프라이빗으로 설정해도 된다. 로드밸런서가 이를 해결해줄것이다 . ",
    "url": "/docs/aws/10.%20CloudFront.html#%EC%96%B4%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EB%A1%9C%EB%93%9C%EB%B0%B8%EB%9F%B0%EC%84%9C%EB%A5%BC-%EC%9B%90%EB%B3%B8%EC%9C%BC%EB%A1%9C-%EC%82%AC%EC%9A%A9%ED%95%A0%EA%B2%BD%EC%9A%B0",
    
    "relUrl": "/docs/aws/10.%20CloudFront.html#어플리케이션-로드밸런서를-원본으로-사용할경우"
  },"129": {
    "doc": "10. CloudFront",
    "title": "CloudFront 지리적 제한 기능",
    "content": "접근이 가능한 국가 목록을 만들어 설정할 수 있다. 반대도 가능 . 이런케이스는 저작권법으로 인한 제한 등이 있다 . ",
    "url": "/docs/aws/10.%20CloudFront.html#cloudfront-%EC%A7%80%EB%A6%AC%EC%A0%81-%EC%A0%9C%ED%95%9C-%EA%B8%B0%EB%8A%A5",
    
    "relUrl": "/docs/aws/10.%20CloudFront.html#cloudfront-지리적-제한-기능"
  },"130": {
    "doc": "10. CloudFront",
    "title": "비용",
    "content": "시험에 나올 수 있다 엣지 로케이션마다 비용이 다르다 . 비용 절감을 위해 CloudFront를 분살할 엣지 로케이션 수를 줄이는 방법이 있다 . Price Class All . | 최고 성능 Price Class 200 | 대부분의 리전은 사용 가능하지만 가장 비싼 리전은 제외 Price class 100 | 가장 저렴한 리전만 사용 | . ",
    "url": "/docs/aws/10.%20CloudFront.html#%EB%B9%84%EC%9A%A9",
    
    "relUrl": "/docs/aws/10.%20CloudFront.html#비용"
  },"131": {
    "doc": "10. CloudFront",
    "title": "캐시 무효화",
    "content": "TTL(타임 투 리브)를 하루로 설정하면 하루 24시간 안에 엣지 로케이션이 파일을 캐시로 다시 가져온다 . 더빨리 반영하고싶다면 index.html파일과 모든 이미지를에대한 경로 /images/* 파일을 무효화 하도록 엣지 로케이션에 지시하면 된다. 그러면 엣지 로케이션은 캐시로부터 파일을 지우고, 사용자가 요청할때 새로 캐싱하게 된다 . ",
    "url": "/docs/aws/10.%20CloudFront.html#%EC%BA%90%EC%8B%9C-%EB%AC%B4%ED%9A%A8%ED%99%94",
    
    "relUrl": "/docs/aws/10.%20CloudFront.html#캐시-무효화"
  },"132": {
    "doc": "10. CloudFront",
    "title": "AWS Global Accelerator",
    "content": "멀리 떨어져있는 지역에서 서버가 있는 리전으로 오기까지 딜레이가 걸릴 수 있다. 이를위해 Global Accelerator를 사용한다 . 유니캐스트IP 하나의 서버가 하나의 IP주소를 가진다 . 애니캐스트IP 모든 서버가 동일한 IP주소를 가지며 클라이언트는 가장 가까운 서버로 라우팅된다 . Global Accelerator는 애니캐스트를 사용한다 . 인도에 서버가 있고 미국에서 접근한다면 엣지 로케이션에 먼저 연결되고, 엣지 로케이션은 안정적이고 지연시간이 적은 사설 AWS네트워크를 거쳐 인도 로드벨런서로 트래픽을 전달한다. 이를 통해 지연시간을 줄일 수 있다 . 아무것도 캐시하지 않기에 클라이언트 캐시와도 문제가 없다 . 상태 확인 . Global Accelerator가 애플리케이션에 대해 상태확인을 실행한다 . 애플리케이션이 글로벌한지 확인한다 . 한 리전에 있는 한 ALB에 대해 상태 확인을 실패하면 자동화 된 장애조치가 1분안에 정상 엔드포인트로 실행된다 . CloudFront와의 차이 . 둘 다 동일한 글로벌 네트워크를 사용하고있고, 둘 다 AWS가 생성한 전세계의 엣지 로케이션을 사용한다. 둘 다 DDoS 보호를 위해 AWS Shield와 통합되어있다. CloudFront는 이미지나 비디오처럼 캐싱 가능한 내용과 API가속 및 동적 사이트 전달 같은 동적 내용 모두에 대해 성능을 향상시킨다. 반면에 Global Accelerator는 TCP나 UDP상의 다양한 애플리케이션 성능을 향상시킨다 그러나 패킷은 엣지 로케이션으로부터 하나 이상의 AWS리전에서 실행되는 애플리케이션으로 프록시된다. 이 경우 모든 요청이 애플리케이션으로 전달된다. 캐싱은 불가능 . 따라서 게임이나 IoT또는 Voice Over Ip같은 비 HTTP를 사용할 경우 매우 적합하다 . 글로벌하게 고정 IP를 요구하는 HTTP를 사용할때도 매우 유용하다 . ",
    "url": "/docs/aws/10.%20CloudFront.html#aws-global-accelerator",
    
    "relUrl": "/docs/aws/10.%20CloudFront.html#aws-global-accelerator"
  },"133": {
    "doc": "10. 상속과 코드 재사용",
    "title": "10. 상속과 코드 재사용",
    "content": ". 객체지향 프로그래밍의 장점 . 중하나는 코드를 재사용하기가 용이하다는 것이다. 가장 대표적인 기법인 상속 그리고 새로운 클래스의 인스턴스 안에 기존 클래스의 인스턴스를 포함시키는 방법인 합성에 대해 알아보자. 상속과 중복 콛, . DRY 원칙 중복 코드는 변경을 방해한다. 이것이 중복 코드를 제거해야 하는 가장 큰 이유다. 하지만 코드는 작성하고나면 언젠간 변경될 것이라고 생각하는 것이 현명하다. 중복 코드가 가지는 가장 큰 문제는 코드를 수정하는 데 필요한 노력을 몇 배로 증가시킨다는 것이다. 모양이 유사하다는 것은 단지 중복의 징후일 뿐이다. 중복 여부를 결정하는 기준은 코드가 변경에 반응하는 방식이다. DRY원칙은 Dont Repeat yourself의 첫글자로 모아 만든 용어이다. 타입코드 사용하기 두 클래스 사이의 중복 코드를 제거하는 한 가지 방법은 클래스를 하나로 합치는 것이다. 하지만 계속 강조했던 것처럼 타입 코드를 사용하는 클래스는 낮은 응집도와 높은 결합도라는 문제에 시달리게 된다. 타입 클래스를 사용하지 않고 중복 코드를 관리할 수 있는 효과적인 방법은 상속이다. 하지만 상속을 사용하면 부모객체와 자식객체간의 강결합이라는 문제가 발생한다. 취약한 기반 클래스 문제 부모 클래스의 작은 변경에도 자식 클래스는 컴파일 오류와 실행 에러에 시달려야 할 수 있다. 불필요한 인터페이스 상속 문제 . 메서드 오바리이딩 오작용 문제 . 부모 클래스와 자식 클래스의 동시 수정 문제 자식 클래스가 부모 클래스의 메서드를 오버라이딩 하거나 불필요한 인터페이스를 상속받지 않았음에도 부모 클래스를 수정할 때 자식 클래스를 함께 수정해야 수 있다. 상속은 코드 재사용과 관련된 대부분의 경우에 우아한 해결 방법이 아니다. 객체지향에 능숙한 개발자들은 상속의 단점을 피하면서도 코드를 재사용할 수 있는 더 좋은 방법이 있다는 사실을 알고 있다. 바로 합성이다. ",
    "url": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/10.%20%EC%83%81%EC%86%8D%EA%B3%BC%20%EC%BD%94%EB%93%9C%20%EC%9E%AC%EC%82%AC%EC%9A%A9.html",
    
    "relUrl": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/10.%20%EC%83%81%EC%86%8D%EA%B3%BC%20%EC%BD%94%EB%93%9C%20%EC%9E%AC%EC%82%AC%EC%9A%A9.html"
  },"134": {
    "doc": "11. AWS 스토리지 추가 기능",
    "title": "11. AWS 스토리지 추가 기능",
    "content": ". AWS Snow Family 안전한 휴대 기기를 가르킨다 데이터를 수집하고 처리하거나 데이터를 AWS안팎으로 마이그레이션 하는데 사용한다 . 데이터 마이그레이션에 사용되는 기기에는 Snowcone, Snowball Edge, SnowMobile 등 세가지 종류가 있다 . 엣지 컴퓨팅에는 Snowcone과 Snowball Edge가 있다 . 왜 마이그레이션하는데 snow family를 사용하는걸까? snow family는 데이터 마이그레이션을 할 수 있게 해주는 오프라인 기기이다 너무 큰 데이터라 데이터를 전송하는데 일주일 이상 걸린다면 snowball기기를 사용해야한다 기기는 우편을 통해 전달받는다 로컬에서 데이터를 직접 기기에 로딩하고 기기를 다시 aws로 반송한다 . snowcone은 아주 작은 휴대 기기이다 snowball이 적합하지 않은경우 snowcone을 사용한다 예를들면 공간 제약이 있는 환경 . snowmobile은 실제 트럭이다 snowmobile은 엑사바이트급 데이터를 옮길 수 있다 . Snowcone, Snowball Edge, Snowmobile 각각 8TB, 80TB, 100PB . 엣지 컴퓨팅은 엣지 위치에서 데이터를 생성하는 중에 그 데이터를 처리하는것을 말한다 . 엣지 위치란 도로위 또는 바다 등등 이곳에서는 데이터를 생성하지만 인터넷이 없어 통신을 못할 수 있다 . 머신러닝을 위해 gpu 옵션이 제공된다 . OpsHub . 컴퓨터나 노트북에 설치하는 소프트웨어이다 snow family기기에서 실행되는 인스턴스를 시작하고 관리할 수 있다. 또 기기와 메트릭을 모니터링한다 . snowball은 glacier에 데이터를 직접 끌어올 순 없다 . 그렇게 하려면 먼저 amazon s3를 사용해서 수명 주기 정책을 생성해서 amazon glacier로 객체를 전환할 수 있다 시험에 나온다 . 절차 snowball -&gt; s3 -&gt; glacier . ",
    "url": "/docs/aws/11.%20AWS%20%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80%20%EC%B6%94%EA%B0%80%20%EA%B8%B0%EB%8A%A5.html",
    
    "relUrl": "/docs/aws/11.%20AWS%20%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80%20%EC%B6%94%EA%B0%80%20%EA%B8%B0%EB%8A%A5.html"
  },"135": {
    "doc": "11. AWS 스토리지 추가 기능",
    "title": "Amazon FSx",
    "content": "AWS에서 완전 관리형 서비스로 타사 고성능 파일 시스템을 실행시킨다 . rds에서 aws에 mysql이나 postgres를 실행하는것과 같은 개념이다 . 으악 보기싫어 . ",
    "url": "/docs/aws/11.%20AWS%20%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80%20%EC%B6%94%EA%B0%80%20%EA%B8%B0%EB%8A%A5.html#amazon-fsx",
    
    "relUrl": "/docs/aws/11.%20AWS%20%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80%20%EC%B6%94%EA%B0%80%20%EA%B8%B0%EB%8A%A5.html#amazon-fsx"
  },"136": {
    "doc": "11. AWS 스토리지 추가 기능",
    "title": "스토리지 gateway",
    "content": "aws에서는 하이브리드 클라우드를 권장한다 이는 일부 인프라는 aws클라우드에 있고 나머지는 그대로 온프레미스에 두는 방식이다 . S3는 독점 스토리지 기술이다 (자랑?) S3데이터를 온프레미스에 두려면 어떻게 해야할까? . AWS strage Gateway가 S3와 온프레미스 인프라를 이어주는 가교 역할을 한다 . S3파일 게이트웨이 . | S3 버킷에는 원하는 스토리지 클래스를 임의로 사용할 수 있다 | S3 Standard, S3 Standard-IA. S3 One Zone-IA, S3 Intelligent-Tiering 모두 되지만 Glacier는 안 된다 | 객체를 아카이브 하고자하는 경우 S3버킷에 수명 주기 정책을 생성하여 이후 Glacier로 객체를 옮겨 아카이브한다 FSx 파일 게이트웨이 | 비슷하다 | 근데 번거롭게 사용하는 이유는? | 게이트웨이를 생성하면 자주 액세스하는 데이터의 로컬 캐시를 확보할 수 있다 | 즉 중요한 파일의 로컬 캐시가 회사 데이터 센터에 쌓이고, 액세스 시 지연시간을 단축 시킬 수 있다 볼륨 게이트웨이 | 블록 스토리지로 amazon s가 백업하는 iSCSI 프로토콜을 사용한다 | 필요에 따라 온프레미스 볼륨을 복구할 수 있다 | 캐시볼륨, 저장볼륨 두가지가 있다 테이프 게이트웨이 | 물리적으로 테이프를 사용하는 백업 시스템이 있는 회사가 백업에 테이프 대신 클라우드를 활용해 데이터를 백업할 수 있게 해준다 | . ",
    "url": "/docs/aws/11.%20AWS%20%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80%20%EC%B6%94%EA%B0%80%20%EA%B8%B0%EB%8A%A5.html#%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80-gateway",
    
    "relUrl": "/docs/aws/11.%20AWS%20%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80%20%EC%B6%94%EA%B0%80%20%EA%B8%B0%EB%8A%A5.html#스토리지-gateway"
  },"137": {
    "doc": "11. AWS 스토리지 추가 기능",
    "title": "AWS 전송 제품군",
    "content": "S3 또는 EFS의 안팎으로 데이터를 전송하려는 경우 . 대신 S3 API는 사용하고 싶지 않을 때 EFS 네트워크 파일 시스템도 사용하지않고, FTP프로토콜만 사용하려는 경우 전송 제품군을 사용한다 . FTP FTPS SFTP . 시간당 프로비저닝된 엔드 포인트 비용에 전송 제품군 안팎으로 전송된 데이터의 gb당 요금을 더한다 . 또 서비스 내에서 사용자 자격증명을 저장 및 관리할 수 있다 . 전송 제품군 서비스 보안을 위해 외부 인증 시스템을 통해서사용자를 인증할 수 있다 . ",
    "url": "/docs/aws/11.%20AWS%20%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80%20%EC%B6%94%EA%B0%80%20%EA%B8%B0%EB%8A%A5.html#aws-%EC%A0%84%EC%86%A1-%EC%A0%9C%ED%92%88%EA%B5%B0",
    
    "relUrl": "/docs/aws/11.%20AWS%20%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80%20%EC%B6%94%EA%B0%80%20%EA%B8%B0%EB%8A%A5.html#aws-전송-제품군"
  },"138": {
    "doc": "11. AWS 스토리지 추가 기능",
    "title": "Data Snyc",
    "content": "시험에 자주 출제 . 데이터를 동기화하며 대용량의 데이터를 한곳에서 다른곳으로 옮길 수 있다 . 온프레미스나 aws의 다른 클라우드로 데이터를 옮길 수 있다 . NFS, SMB, HDFS 또는 다른 프로토콜을 연결해야한다 . 옮길 위치에는 에이전트가 있어야한다 . 한aws 서비스에 다른 aws서비스로 데이터를 옮길 수도 있다 . 이 경우에는 에이전트가 필요 없다 . glacier를 포함해 모든 스토리지 클레스에 동기화할 수 있다 . 복제 작업은 계속 이루어지지 않고 일정을 지정하여 datasync가 매 시간 매일 혹은 매주 실행되도록할 수 있다 . 파일을 한곳에서 다른곳으로 옮길 때 이를 이용하여 파일의 메타데이터를 보존할 수 있다 . 에이전트 하나의 테스크가 초당 10gb까지 사용할 수 있다 . 성능을 초과하고싶지 않다면 대역폭에 제한을 걸 수 있다 . ",
    "url": "/docs/aws/11.%20AWS%20%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80%20%EC%B6%94%EA%B0%80%20%EA%B8%B0%EB%8A%A5.html#data-snyc",
    
    "relUrl": "/docs/aws/11.%20AWS%20%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80%20%EC%B6%94%EA%B0%80%20%EA%B8%B0%EB%8A%A5.html#data-snyc"
  },"139": {
    "doc": "11. 합성과 유연한 설계",
    "title": "11. 합성과 유연한 설계",
    "content": ". 상속과 합성은 객체지향 프로그래밍에서 가장 널리 사용되는 코드 재사용 기법이다. 상속 관계는 is-a관게, 합성관계는 has-a관계 라고 부른다. 합성은 구현에 의존하지 않는다는 점에서 상속과 다르다. 합성은 내부에 포함되는 객체의 구현이 아닌 퍼블릭 인터페이스에 의존한다. 상속은 부모 클래스 안에 구현된 코드 자체를 재사용하지만 합성은 포함되는 객체의 퍼블릭 인터페이스를 재사용한다. 합성을 이용하면 포함된 객체의 내부 구현이 변경되더라도 영향을 최소하할 수있기 때문에 변경에 더안정적인 코드를 얻을 수있다. 상속의 문제 . | 불필요한 인터페이스 상속 문제 | 메서드 오버라이딩의 오작용 문제 | 부모 클래스와 자식 클래스의 동시 수정 문제 | . 상속으로 인한 조합의 폭발적인 증가 . | 하나의 기능을 추가하거나 수정하기 위해 불필요하게 많은 수의 클래스를 추가하거나 수정해야 한다. | 단일 상속만 지원하는 언어에서는 상속으로 인해 오히려 중복 코드의 양이 늘어날 수 있다. | . 기본 정책과 부가 정책 조합하기 . ![[Pasted image 20240529141852.png]] . | 기본 정책의 계산 결과에 적용된다 . | 세금 정책은 기본 정책인 RegularPhone이나 NightlyDiscountPhone의 계산이 끝난 결과에 세금을 부과한다. | . | 선택적으로 적용할 수 있다 . | 기본 정책의 계산 결과에 세금 정책을 적용할 수도 있고 적용하지 않을 수도 있다. | . | 조합 가능하다 . | 기본 정책에 세금 정책만 적용하는 것도 가능하고, 기본 요금 할인 정책만 적용하는 것도 가능하다. 또한 세금 정책과 기본 요 금 할인 정책을 함께 적용하는 것도 가능해야 한다. | . | 부가 정책은 임의의 순서로 적용 가능하다 . | 기본 정책에 세금 정책과 기본 요금 할인 정책을 함께 적용할 경우 세금 정책을 적용한 후에 기본 요금 할인 정책을 적용할 수 도 있고, 기본 요금 할인 정책을 적용한 후에 세금 정책을 적용할 수도 있다. ![[Pasted image 20240529141947.png]] | . | . ![[Pasted image 20240529142203.png]] . 합성 관계로 변경하기 . Phone의 경우처럼 다양한 종류의 객체와 협력하기 위해 합성 관계를 사용하는 경우에는 합성을 객체의 타입을 인터페이스나 추상 클래스로 선언하고 의존성 주입을 사용해 런타임에 필요한 객체를 설정할 . 수있도록 구현하는 것이 일반적이다. ![[Pasted image 20240529142501.png]] . 일반 요금제의 규칙에 따라 통화 요금을 계산하고 싶다면 다음과 같이 Phone과 BasicRatePolicy의 인스 턴스를 합성하면 된다. Phone phone = new Phone new RegularPolicy (Money wons (10), Duration.ofSeconds (10))); . 심야 할인 요금제의 규칙에 따라 통화 요금을 계산하고 싶다면 다음과 같이 Phone과 NightlyDiscount Policy의 인스턴스를 합성하면 된다. Phone phone = new Phone(new NightlyDiscountPolicy (Money.wons(5), Money.wons (10), Duration.ofSeconds (10))); . 현재 설계에 부가 정책을 추가하여 합성의 강력함을 실감해보자. ![[Pasted image 20240529142857.png]] ![[Pasted image 20240529142904.png]] 이를 위해 부가 정책이라는 AdditionalRatePolicy가 필요하다. public abstract class AdditionalRatePolicy implements RatePolicy { private RatePolicy next; public AdditionalRatePolicy(RatePolicy next) { this.next = next; } @Override public Money calculateFee (Phone phone) { Money fee = next.calculateFee (phone); return afterCalculated (fee) ; } abstract protected Money afterCalculated Money fee); . ![[Pasted image 20240529162508.png]] . ![[Pasted image 20240529162710.png]] . 객체 합성이 클래스 상속보다 더 좋은 방법이다. 합성이 상속과 같은 문제점(부모-자식 강결합)을 초래하지 않는 이유는 클래스의 구체적인 구현이 아니라 객체의 추상적인 인터페이스에 의존하기 때문이다. 상속과 클래스를 기반으로 하는 재사용 방법을 사용하면 클래스의 확장과 수정을 일관성 있게 표현할 수 있는 추상화의 부족으로 인해 변경하기 어려운 코드를 얻게 된다. 믹스인 . 믹스인은 객체를 생성할 때 코드 일부를 클래스 안에 섞어 넣어 재사용하는 기법을 가르키는 용어이다. 합성이 실행 시점에 객체를 조합하는 재사용 방법이라면 믹스인은 컴파일 시점에 필요한 코드 조각을 조합하는 재사용 방법이다. 예제는 스칼라의 트레이트를 사용한다. 스칼라 트레이트란? 스칼라 트레이트는 클래스 간에 인터페이스와 필드를 공유하는 데 사용되는 강력한 도구입니다. 자바 8의 인터페이스와 유사하지만, 트레이트는 더 많은 기능을 제공합니다. abstract class BasicRatePolicy { def calculateFee (phone: Phone): Money = phone.calls.map(calculateCallFee(_).reduce(_ + _) protected def calculateCallFee(call: Call): Money; } . class RegularPolicy(val amount: Money, val seconds: Duration) extends BasicRatePolicy { override protected def calculateCallFee(call: Call): Money = amount * (call.duration.getSeconds / seconds.getSeconds) } . 표준 요금제를 구현하는 RegularPolicy는 BasicRatePolicy를 상송받아 개별 call의 요금을 계산하는 calculateCallFee 메서드를 오바리이딩한다. calculateCallFee를 오버라이딩 함으로써 컴파일 시점에 필요한 코드 조각을 조합한다. trait TaxablePolicy extends BasicRatePolicy { def taxRate: Double override def calculateFee (phone: Phone): Money = { val fee = super.calculateFee (phone) return fee + fee * taxRate } } . 위 코드에서 TaxablePolicy 트레이트가 BasicRatePolicy를 확장한다는 점에 주목하자. 이것은 상속의 개념이 아니라 TaxablePolicy가 BasicRatePolicy나 BasicRatePolicy의 자식에 해당하는 경우에만 믹스인될 수 있다는 것을 의미한다. 기본 정책에 부가 정책을 적용하기 원하기 때문에 이 제약 코드로 표현하는 것은 의미를 명확하게 전달할 뿐만 아니라 TaxablePolicy를 사용하는 개발자의 실수를 막을 수 있다는 장점이 있다. 앞서 상속은 결합도를 높이기 때문에 좋지한다고했다. 상속은 정적이지만 믹스인은 동적이다. TaxablePolicy는 BasicRatePolicy를 상속받은 경우에만 믹스인될 수 있다. 따라서 RegularPolicy와 NightlyDiscountPolicy에 믹스인될 수 있으며 심지 어 미래에 추가될 새로운 BasicRatePolicy의 자손에게도 믹스인될 수 있지만 다른 클래스나 트레이트에 는 믹스인될 수 없다. TaxablePolicy는 어떤 코드에 믹스인될 것인지 알 수 없다. 부가 정책과 기본 정책을 부모 클래스와 자식 클래스라는 관계로 결합시켜야 했던 상속과 달리 부가 정책과 기본 정책을 구현한 코드 사이에 어떤 관계도 조재하지 않는다. ",
    "url": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/11.%20%ED%95%A9%EC%84%B1%EA%B3%BC%20%EC%9C%A0%EC%97%B0%ED%95%9C%20%EC%84%A4%EA%B3%84.html",
    
    "relUrl": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/11.%20%ED%95%A9%EC%84%B1%EA%B3%BC%20%EC%9C%A0%EC%97%B0%ED%95%9C%20%EC%84%A4%EA%B3%84.html"
  },"140": {
    "doc": "12. SQS,SNS,Kinesis, Active MQ",
    "title": "12. SQS,SNS,Kinesis, Active MQ",
    "content": ". 대기열 모델 - SQS pub/sub - SNS 실시간 스트리밍 - Kinesis . ",
    "url": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html",
    
    "relUrl": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html"
  },"141": {
    "doc": "12. SQS,SNS,Kinesis, Active MQ",
    "title": "SQS",
    "content": "시험에서 애플리케이션 분리에 대한 문제가 보이면 SQS를 떠올려라 . 무제한 처리량을 얻을 수 있다 . 처리량에 제한이 없고 대기열에 있는 메시지 수에도 제한이 없다 . 각 메시지는 수명이 짧다 메시지는 기본값으로 4일 동안 대기열에 남아 있고, 대기열에 있을 수 있는 최대 시간은 14일이다 . 지연시간이 매우 짧다. 보내거나 읽는경우 10밀리초 이내 . 전송된 메시지당 256KB 미만이여야 한다 . SQS에는 중복 메시지가 있을 수 있다 애플리케이션에서는 이를 고려해야한다 . SQS는 메시지를 처리할 소비자를 여럿 둘 수 있다 각 소비자는 poll 함수를 호출하여 다른 메시지를 수신한다 메시지가 소비자에 의해 빠르기 처리되지 않으면 다른 소비자가 수신한다. 그래서 적어도 한번은 전송된다 라는것 . 소비자는 메시지를 처리하면 메시지를 삭제해야한다. 안그러면 다른 소비자가 메시지를 처리한다. 더 많은 메시지량을 처리하려면 소비자를 추가하고 수평확장을 수행하면서 개선할 수 있다. (ASG : auto scaling groups) . SQS보안 . HTTPS API를 사용하여 메시지를 보내고 생성함으로써 전송 중 암호화를 하고 KMS키를 사용하여 미사용 암호화를 얻고 ㅜ언한다면 클라리언트 측 암호화를 할 수 있다 . 액세스 제어를 위해 IAM 정책은 SQS API에 대한 액세스를 규제할 수 있고, S3 버킷 정책과 유사한 SQS 액세서 정책도 있다 . ",
    "url": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#sqs",
    
    "relUrl": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#sqs"
  },"142": {
    "doc": "12. SQS,SNS,Kinesis, Active MQ",
    "title": "Message Visibility Timeout",
    "content": "메시지 가시성 시간 초과 . 소비자가 메시지를 폴링하면 다른 소비자들에게 보이지 않게된다 . 기본값으로 메시지 가시성 시간초과는 30초이다 그 말은 이 30초 동안 메시지가 처리되어야한다 라는뜻 그리고 그 가시성 시간 초과 기간 내에서는 그 메시지가 다른 소비지한테 보이지 않는다. 소비자가 메시지를 처리하는데 시간이 더 필요하다는 것을 알리는 방법으로는 ChangeMessageVisibility라는 API가 있다 . ",
    "url": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#message-visibility-timeout",
    
    "relUrl": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#message-visibility-timeout"
  },"143": {
    "doc": "12. SQS,SNS,Kinesis, Active MQ",
    "title": "Long Polling",
    "content": "소비자가 대기열에 메시지 요청을 하는데 대기열에 아무것도 없다면 메시지 도착을 기다린다 이것이 롱 폴링 . | 지연시간을 줄이기 위해 | SQS로 보내는 api 호출 숫자를 줄이기 위해 | . 대기열 레벨에서 구성하여 폴링하는 아무 소비자로부터 롱 폴링을 활성화하는 방법과 소비자 측에서 wait time seconds를 지정해서 하는 방법이 있다 . ",
    "url": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#long-polling",
    
    "relUrl": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#long-polling"
  },"144": {
    "doc": "12. SQS,SNS,Kinesis, Active MQ",
    "title": "FIFO Queue",
    "content": "순서보장 대기열의 처리량에는 제한이 있다. 묶음이 아닐 경우 초당 300개의 메시지를 처리하고, . 메시지를 묶음으로 보낸다면 처리량은 초당 3000개가 된다. 또한 중복을 제거하도록 해주는 기능이 있어 정확히 한번만 보낼 수 있게 해준다 . ",
    "url": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#fifo-queue",
    
    "relUrl": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#fifo-queue"
  },"145": {
    "doc": "12. SQS,SNS,Kinesis, Active MQ",
    "title": "SQS with Auto Scaling Group",
    "content": "CloudWatch 지표인 대기열 길이를 보고 결정할 수 있다 . ApproximateNumberOfMessage라고 하는 지표로 대기열에 몇개의 메시지가 남아 있는지 표시한다 . 특정 행사로 인해 주문이 밀리는 경우 쓰기 대상 데이터베이스에서 SQS를 버퍼로 사용할 수 있다 데이터 베이스에 바로 요청을 쓰는 대신 애플리케이션이 SQS대기열에 먼저 쓰는 방법이다. 이 패턴은 클라이언트에게 따로 데이터베이스에 쓰였다는 확인을 전송할 필요가 없을때만 가능하다 . ",
    "url": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#sqs-with-auto-scaling-group",
    
    "relUrl": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#sqs-with-auto-scaling-group"
  },"146": {
    "doc": "12. SQS,SNS,Kinesis, Active MQ",
    "title": "SNS",
    "content": "메시지 하나를 여러 수신자에게 보낼때 사용 . 주제별로 최대 1200만 이상의 구독자까지 가능 . 계정당 가질 수 있는 주제 수는 최대 10만개이고 더 늘릴 수 있다 이런건 시험에 안나옴 . SNS를 통해 이메일도 보낼 수 있고, 모바일 알림도 보낼 수 있다 또한 지정된 HTTP 또는 HTTPS엔드 포인트로 직접 데이터를 보낼 수도 있다 . SQS와 통합하여 메시지를 대기열로 직접 보낼수도 있고 메시지를 수신한 후 함수가 코드를 수행하도록 lambda에 보내거나 firehose를 통해 데이터를 S3나 Redshift로 보낼 수 있다 . SNS는 다양한 AWS서비스에서 데이터를 수신하기도한다 CloudWatch 경보 Auto Scaling 그룹 알림 CloudFormation State Changes Budgets, S3 버킷 DMS, Lambda, DynamoDB RDS 이벤트 등 서비스명은 시험에 안나온다 . SNS 수신 가능 대상은 Google, GCM, Apple APNS 또는 Amazon ADM 구독자이다 . 기본적으로 전송 중 암호화와 KMS키를 사용한 저장 데이터 암호화가 있다 . 엑세스 제어는 IAM 정책 중심이다 모든 SNS API가 IAM 정책으로 규제된다 . SNS 주제에 교차 계정 액세스 권한을 갖고너 S3이벤트와 같은 서비스가 SNS 주제에 작성할 수 있도록 허용하려는 경우 매우 유용 . ",
    "url": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#sns",
    
    "relUrl": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#sns"
  },"147": {
    "doc": "12. SQS,SNS,Kinesis, Active MQ",
    "title": "SNS + SQS",
    "content": "Fan Out 패턴 . 메시지를 여러 SQS 대기열로 보내고 싶은데 개별적으로 보내면 애플리케이션이 중간에 비정상적으로 종료된 경우 특정 SQS에 전달이 실패하거나 SQS대기열이 더 추가될 수 있다. SNS 주제에 메시지를 전송한 후 원하는 수의 SQS대기열이 이 SNS주제를 구독하는것으로 해결할 수 있다 . 리전 간 전달도 가능하다 . Kinesis Data Firehose 이거 뭔데? . SNS에도 FIFO를 적용할 수 있다 . SNS의 기능중 메시지 필터링이 있다 이는 SNS 주제를 구독할 때 전송되는 메시지를 필터링하는데 사용되는 JSON 적책이다 구독에 어떤 필터링 정책도 없다면 모든 메시지를 받아들이는 것이 기본값이다 . ",
    "url": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#sns--sqs",
    
    "relUrl": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#sns--sqs"
  },"148": {
    "doc": "12. SQS,SNS,Kinesis, Active MQ",
    "title": "Kinesis",
    "content": "키네시스를 활용하면 실시간 스트리밍 데이터를 손쉽게 수집하고 처리하여 분석할 수 있다 . 애플리케이션 로그, 계측, 웹사이트 클릭 스트림, IoT원격 측정 데이터 등 . Kinesis Data Stream . 시스템에서 큰 규모의 데이터 흐름을 다루는 서비스 . 여러개의 샤드로 구성되어 있고 이 샤드는 1번,2번에서 N번까지 번호가 매겨진다 이건 사전에 프로비저닝해야한다 . 애플리케이션과같은 데이터 생성자는 kinesis에 레코드를 전달한다 . 레코드는 근복적으로 두가지 요소로 구성된다 파티션 키와 최대 1MB크기의 데이터 블롭 . 파티션 키는 레코드가 이용할 샤드를 결정하는데 사용, 데이터 블롭은 값 자체를 의미 . 생상자는 데이터를 스트림으로 보낼때 초당 1MB를 전송하거나 샤드당 1초에 천개의 메시지를 전송할 수 있다 . 샤드에 저장된 데이터를 처리하는 소비자에게 전송되는 레코드에는 파티션 키, 샤드에서 레코드의 위치를 나타내는 시퀀스 번호, 데이터 자체를 의미하는 데이터 블롭이 있다 . 소비자마다 샤드당 1초에 2MB씩 받을 수도 있다 . 정리하면 생산자가 Kinesis에 데이터를 전송하고 데이터는 잠시 거기에 머물면서 여러 소비자에게 읽힌다 . 보존기간은 1일에서 365사이로 설정할 수 있다 이 말은 데이터를 다시 처리하거나 확인할 수 있다는 뜻 . 일단 Kinesis로 들어오면 삭제할 수 없으며 불변성이다 데이터는 파티션키가 같은 메시지들은 같은 샤드로 들어가게 되어 키를 기반으로 데이터를 정렬할 수 있다 . 용량은 두가지가 있는데 . 프로비저닝 유형 샤드 수를 정하고 Api를 활용하거나 수동으로 조정한다 . 온디맨드형 프로비저닝을 하거나 용량관리를 할 피룡가 없다 시간에 따라 언제든 용량이 조정된다 기본적으로 초당 4MB 또는 4천개의 레코드를 처리 이 용량은 지난 30일동안 관측한 최대 처리량에 기반하여 자동으로 조정된다 시간당 송수신 데이터량(GB)에 따라 비용이 부과된다 . 이것은 리전 배포된다 . IAM정책을 사용하여 샤드를 생성하거나 샤드에서 읽어들이는 접근 권한을 제어할 수 있다 . 모든 API요청은 CludTrail로 감시할 수 있다 . Kinesis Data Firehose . 생산자에서 데이터를 가져올 수 있는 유용한 서비스 . 애플리케이션, 클라이언트, SDK, KPL, Kinesis Agent 모두 Kinesis Data Firehose로 데이터를 보낼 수 있다 . 데이터를 전송하면 람다 기능을 활용해 데이터를 변환할지 선택이 가능하다 . 수신처는 세가지 종류가 있다 . | AWS 수신처 모든 데이터를 아마존 S3에 쓸수있다 데이터 웨어하우스인 아마존 레드시프트도있다 아마존 ElasticSearch 도 있다 . | 써드 파티 파트너 수신처도 있다 데이터독, 스플렁크, 뉴렐릭, 몽고DB . | HTTP엔드포인트가 있는 자체 API를 보유하고있다면 커스텀 수신처로 데이터를 보낼 수 있다 . | . 데이터가 수신처로 전송되고나면 두가지 선택지가 있다 모든 데이터를 백업으로 S3에 저장 실패한 케이스만 S3에 저장 . 근 실시간으로 이루어진다 이유는 배치로 처리되기 때문에 적어도 1MB데이터가 있을때까지 기다린다 . 데이터 전환, 변환, 압축이 필요하다면 람다를 사용할수있다 . 스토리지가 따로 없어 반복하는 기능은 없다 . ",
    "url": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#kinesis",
    
    "relUrl": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#kinesis"
  },"149": {
    "doc": "12. SQS,SNS,Kinesis, Active MQ",
    "title": "정렬",
    "content": "Kinesis 파티션키 . SQS 전송 순서대로 처리 . 브로커가 한개란소리? 맞네 . ",
    "url": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#%EC%A0%95%EB%A0%AC",
    
    "relUrl": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#정렬"
  },"150": {
    "doc": "12. SQS,SNS,Kinesis, Active MQ",
    "title": "Amazon MQ",
    "content": "RabbitMQ와 ActiveMQ 두 가지 기술을 위한 관리형 메시지 브로커 서비스 . MQ는 무한 확장이 가능한 SQS나 SNS처럼 확장성이 크지 않다 . MQ는 서버에서 실행되므로 서버 문제가 있을 수 있다 . 고가용성을 위해 장애 조치와 함께 다중 AZ설정을 할 수 있다 . MQ는 EFS에 마운드된다 . ",
    "url": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#amazon-mq",
    
    "relUrl": "/docs/aws/12.%20SQS,SNS,Kinesis,%20Active%20MQ.html#amazon-mq"
  },"151": {
    "doc": "12. 다형성",
    "title": "12. 다형성",
    "content": ". 상속을 이용해 자식 클래스를 추가하려 한다면 스스로에게 다음과 같은 질문을 해보기 바란다. 상속을 사용하려는 목적이 단순히 코드를 재사용하기 위해서인가? 아니면 클라이언트 관점에서 인스턴스들을 동일하게 행동하는 그룹으로 묶기 위해서인가? . 첫 번째 질문에 답한 답이 ‘예’라면 상속을 사용하지 말아야 한다. ![[Pasted image 20240601202848.png]] 다형성은. 위 그림과 같이 분류할 수 있다. 일반적으로 하나의 클래스 안에 동일한 이름의 메서드가 존재하는 경우 오버로딩 다형성 이라고 부른다. 강제 다형성은 언어가 지원하는 자동적인 타입 변환이나 사용자가 직접 구현한 타입 변환을 이용해 동일한 연산자를 다양한 타입에 사용할 수 있는 방식을 가르킨다. (자바에서 ‘+’는 피연산자가 모두 정수일 경우에 덧셈, 문자열인 경우에는 연결 연산자로 사용) . 매개변수 다형성은 제네릭 프로그래밍과 관련이 높은데 클래스의 인스턴스 변수나 메서드의 매개변수 타입을 임의의 타입으로 선언한 후 사용하는 시점에 구체적인 타입으로 지정하는 방식을 가리킨다. (자바의 List 인터페이스는 타입을 T로 지정하고 있으며 인스턴스 생성 시점에 구체적인 타입으로 지정하게 함) . 포함 다형성은 메시지가 동일하더라도 수신한 객체의 타입에 따라 실제로 수행되는 행동이 달라지는 능력을 의미한다. 서브타입 다형성이라고도 부른다. (일반적인 상속을 통해 메서드 오버라이딩 됐을때의 경우) . 상속 메커니즘을 이해하는데 필요한 몇가지 개념 . | 업캐스팅 | 동적 메서드 탐색 | 동적 바인딩 | self 참조 | super 참조 | . 같은 메시지 다른 메서드 코드 안에서 선언된 참조 타입과 무관하게 실제로 메시지를 수신하는 객체의 타입에 따라 실행 되는 메서드가 달라질 수 있는 것은 업캐스팅과 동적 바인딩이라는 메커니즘이 작용하기 때문이다. 정적 바인딩 컴파일 타임에 함수 호출이 어떤 함수와 연결될지 결정됩니다. 주로 함수 오버로딩, 컴파일러가 호출할 메서드를 명확히 알 수 있을 때 사용됩니다 동적 바인딩 실행 시간에 함수 호출이 어떤 함수와 연결될지 결정됩니다. 주로 상속과 오버라이딩을 통해 다형성을 구현할 때 사용됩니다. 부모 클래스 타입으로 선언된 변수에 자식 클래스의 인스턴스를 할당하는 것이 가능한것을 업캐스팅이라 부른다. 반대로 부모 클래스의 인스턴스를 자식 클래스 타입으로 변환하기 위해서는 명시적인 타입 캐스팅이 필요한데 이를 다운캐스팅이라 부른다. ![[Pasted image 20240601210148.png]] . 동적 메서드 탐색과 다형성 객체지향 시스템은 다음 규칙에 따라 실행할 메서드를 선택한다. | 메시지를 수신한 객체는 먼저 자신을 생성한 클래스에 적합한 메서드가 존재하는지 검사한다. 존재하면 메서드를 실핸하고 탐색을 종료한다 | 메서들르 찾지 못했다면 부모 클래스에서 메서드 탐색을 계속한다. 이 과정은 적합한 메서드를 찾을 때 까지 상속 계측을 따라 올라가며 계속된다. | 상속 계층의 가장 최상위 클래스에 이르렀지만 메서드를 발견하지 못한 경우 예외를 발생시키며 탐색을 중단한다. | . 객체가 메시지를 수신하면 컴파일러는 self참조라는 임시 변수를 자동으로 생성한 후 메시지를 수신한 객체를 가리키도록 설정한다. 동적 메서드 탐색은 self가 가르키는 객체의 클래스에서 시작해서 상속 계층의 역방향으로 이뤄지며 종료되는 순간 self참조는 자동으로 소멸된다. ![[Pasted image 20240601210508.png]] 위 그림은 메시지를 수신한 시점의 GradeLecuture 인스턴스 상태이다. 메서드 탐색은 자식 -&gt; 부모 방향으로 진행된다. self참조가 동적 문잭을 결정한다는 사실은 종종 어떤 메서드가 실행될지를 예상하기 어렵게 만든다. 대표적인 경우가 자신에게 다시 메시지를 전송하는 self전송이다. ![[Pasted image 20240601211004.png]] . stat메서드를 실행하던 중에 getEvaluationMethod메서드 호출 구문을 발견하면 시스템은 self 참조가 가르키는 현재 객체에게 메시지를 전송해야 한다고 판단한다. 이런 self의 특성과 대비해서 언급할만한 가치가 있는것이 바로 super참조이다. super.evaluate()라는 문장은 단순히 부모 클래스의 evaluate메서드를 호출하는 것이 아니다. 더 상위에 위치한 조상 클래스의 메서드일 수 있다. ![[Pasted image 20240601211624.png]] super참조는 부모 클래스에 정의된 메서드를 실행하기 위한 것이 아니다. 지금 이클래스의 부모 클래스에서 부터 메서드 탐색을 시작하세요다. ",
    "url": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/12.%20%EB%8B%A4%ED%98%95%EC%84%B1.html",
    
    "relUrl": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/12.%20%EB%8B%A4%ED%98%95%EC%84%B1.html"
  },"152": {
    "doc": "13. ECS, Fargate, ECR 및 EKS",
    "title": "13. ECS, Fargate, ECR 및 EKS",
    "content": ". 도커란? 앱 배포를 위한 소프트웨어 개발 플랫폼 컨테이너 기술 . 온프레미스에서 클라우드로 앱을 리프트-앤-시프트 . 도커와 가상 머신의 차이점 도커는 순전히 가상화 기술은 아니다 리소스가 호스트와 공유되어 한 서버에서 다수의 컨테이너를 공유할 수 있다 . 가상 머신의 아키텍처를 살펴보면 인프라와 호스트 운영체제가 있으며 그 위에 하이퍼바이저가 있고 앱과 guest운영체제가 있다 . 반면 도커 컨테이너의 경우 인프라와 ec2인스턴스 같은 호스트 os가 있고 도커 Daemon위에 많은 컨테이너가 있다 . 가상머신보다 덜 안전하지만 하나의 서버에 많은 컨테이너를 실행할 수 있다 . AWS에서 도커 컨테이너를 관리하는 방법은 ECS이다 (Elastic Container Service) . ",
    "url": "/docs/aws/13.%20ECS,%20Fargate,%20ECR%20%EB%B0%8F%20EKS.html",
    
    "relUrl": "/docs/aws/13.%20ECS,%20Fargate,%20ECR%20%EB%B0%8F%20EKS.html"
  },"153": {
    "doc": "13. ECS, Fargate, ECR 및 EKS",
    "title": "ECS",
    "content": "aws에서 컨테이너를 실행하면 ecs클러스터에서 ecs테스크를 실핸하는것이다 . ecs클러스터에는 ec2 인스턴스가 들어있다 . 즉 ecs 클러스터는 여러 ec2 인스턴스로 구성된다는 뜻 . ecs클러스터는 ec2내부의 ecs agent를 실행한다 그럼 ecs 에이전트가 각각의 ec2인스턴스를 amazon ecs 서비스와 지정된 ecs클러스터에 등록한다 . 이후에 ecs 테스크를 수행하기 시작하면 aws가 컨테이너를 시작하거나 멈춘다 . 도커 컨테이너는 미리 프로저닝한 ec2 인스턴스에 위치한다 . Fargate . 마찬가지로 aws에 도커 컨테이너를 실행하는데, . 이번에는 인프라를 프로비저닝 하지 않아 관리할 ec2인스턴스가 없다 . 서버리스이다 . 서버를 관리하지 않아 서버리스라고 부르는데 서버가 없는건 아니ㄷ . 필요한 cpu나 ram에 따라 ecs테스크를 aws가 대신 실행한다 . 관리가 필요 없다 . ecs 테스크의 iam 역할 . ec2인스턴스 프로파일 역할과 ecs테스크 역할의 차이점 기억 . ??? . ecs를 사용할때 ec2와 fargate 모두 사용한다면 efs를 사용해서 데이터를 공유하는게 좋다 . s3는 ecs테스크에 파일 시스템으로 마운트 될 수 없다 . ",
    "url": "/docs/aws/13.%20ECS,%20Fargate,%20ECR%20%EB%B0%8F%20EKS.html#ecs",
    
    "relUrl": "/docs/aws/13.%20ECS,%20Fargate,%20ECR%20%EB%B0%8F%20EKS.html#ecs"
  },"154": {
    "doc": "13. ECS, Fargate, ECR 및 EKS",
    "title": "오토스케일링",
    "content": "aws Auto Scaling 서비스가 있다 . CPU, RAM, ALB의 타겟당 요청수 위 세개의 지표에 대해 사용률을 확장할 수 있다 . 특정 타겟을 추적하는 대상 추척 스케일링이나 단계 스케일링 혹은 미리 ECS서비스 확장을 설정하는 예약 스케일링이 있다 . EC2 시작 유형이라면 태스크 레벨에서의 ECS 서비스 확장이 EC2 인스턴스 클러스터의 확장과 다르다는것 인지 필요 -&gt; ECS클러스터 용량 공급자 새 테스크를 실행할 용량이 부족하면 자동으로 ASG를 확장한다 . ",
    "url": "/docs/aws/13.%20ECS,%20Fargate,%20ECR%20%EB%B0%8F%20EKS.html#%EC%98%A4%ED%86%A0%EC%8A%A4%EC%BC%80%EC%9D%BC%EB%A7%81",
    
    "relUrl": "/docs/aws/13.%20ECS,%20Fargate,%20ECR%20%EB%B0%8F%20EKS.html#오토스케일링"
  },"155": {
    "doc": "13. ECS, Fargate, ECR 및 EKS",
    "title": "ECR",
    "content": "Elastic Container Registry . aws에 도커 이미지를 저장하고 관리하는데 사용한다 . Docker Hub등의 온라인 저장소를 사용해도되지만, amazon ecr에도 저장할 수 있다 . 옵션 계정에 한해 이미지를 비공개로 저장 . 혹은 퍼블릭 저장소를 사용해 Amazon ECR Public Gallery에 게시 . ",
    "url": "/docs/aws/13.%20ECS,%20Fargate,%20ECR%20%EB%B0%8F%20EKS.html#ecr",
    
    "relUrl": "/docs/aws/13.%20ECS,%20Fargate,%20ECR%20%EB%B0%8F%20EKS.html#ecr"
  },"156": {
    "doc": "13. ECS, Fargate, ECR 및 EKS",
    "title": "EKS",
    "content": "Elastic Kubernetes Service . 관리형 Kubernetes 클러스터를 실행할 수 있는 서비스 . Docker로 컨테이너화한 애플리케이션의 자동 배포, 확장, 관리를 지원한다 . 컨테이너를 실행한다는 목적은 ECS와 비슷하지만 사용하는 API가 다르다 . ECS는 오픈소스가 아닌 반면 Kubernetes는 오픈소스이고 여러 클라우드 제공자가 사용함로 표준화를 기대할 수 있다 . EKS에는 두가지 실행 모드가 있다 . EC2 시작 모드는 ec2 인스턴스에서 처럼 작업자 모드를 배포할 때 사용하고, . Fargate모드는 EKS클러스터에 서버리스 컨테이너를 배포할 때 사용한다 . EKS클러스터에 데이터 볼륨을 연결하려면 EKS 클러스터에 스토리지 클래스 매니페스트를 지정해야한다 . ",
    "url": "/docs/aws/13.%20ECS,%20Fargate,%20ECR%20%EB%B0%8F%20EKS.html#eks",
    
    "relUrl": "/docs/aws/13.%20ECS,%20Fargate,%20ECR%20%EB%B0%8F%20EKS.html#eks"
  },"157": {
    "doc": "13. ECS, Fargate, ECR 및 EKS",
    "title": "App Runner",
    "content": "완전 관리형 서버스로 규모에 따라 웹 애플리케이션, api 배포를 돕는다 . 인프라나 컨테이너 소스 코드 등을 알 피룡가 전혀 없다 . 먼저 소스코드나 docker컨테이너 이미지를 가지고 원하는 구성을 설정한다 . cpu의 수나 컨테이너 메모리의 크기 오토스케일링 여부 상태 확인을 설정하면 된다 . 다음 작업은 자동으로 이뤄진다 . app runner서비스가 웹 앱을 빌드하고 배포한다 컨테이너가 생성되고 배포된다 . api나 웹 앱이 배포된 다음엔 url을 통해 바로 액세스할 수 있다 . 장점 오토 스케일링이 가능하고 가용성이 높으며 로드 밸런싱 및 암호화 기능을 지원한다 . 컨테이너가 vpc에 애세스할 수 있어서 데이터베이스와 캐시 메시지 대기열 서비스에 연결할 수 있다 . 사용 사례로는 빨리 배포해야하는 웹 앱 api 그리고 마이크로 서비스가 있다 . ",
    "url": "/docs/aws/13.%20ECS,%20Fargate,%20ECR%20%EB%B0%8F%20EKS.html#app-runner",
    
    "relUrl": "/docs/aws/13.%20ECS,%20Fargate,%20ECR%20%EB%B0%8F%20EKS.html#app-runner"
  },"158": {
    "doc": "13. 서브클래싱과 서브타이핑",
    "title": "13. 서브클래싱과 서브타이핑",
    "content": ". 상속의 첫 번째 용도는 타입 계층을 구현하는 것이다. 타입 계층 안에서 부모 클래스는 일반적인 개념을 구현하고 자식 클래스는 특수한 개념을 구현한다. 타입 계층의 관점에서 부모 클래스는 자식 클래스의 일반화 일고 자식 클래스는 부모 클래스의 특수화이다. 상속의 두 번째 용도는 코드 재사용이다. 하지만 재사용을 위해 상속을 사용할 경우 부모 클래스와 자식 클래스가 강하게 결합되기 때문에 변경하기 어려운 코드를 얻게 될 확률이 높다. 상속을 사용하는 일차적인 목표는 코드 재사용이 아니라 타입 계층을 구현하는 것이여야 한다. 올바른 타입 계층을 구성하는 원칙을 살펴보도록 하자. 객체지향 프로그래밍에서 타입의 의미를 이해하려면 프로그래밍 언어 관점에서의 타입과 개념 관점에서의 타입을 함께 살펴볼 필요가 있다. 개념 관점의 타입 . 우리가 인지하는 세상의 사물의 종류를 의미한다. 어떤 대상이 타입으로 분류될 때 그 대상을 타입의 인스턴스라고 부른다. 일반적으로 타입의 인스턴스를 객체라고 부른다. 타입은 세가지 요소로 구성된다. 심볼, 내연, 외연 . | 심볼 : 타입에 이름을 붙인 것이다. | (ex 프로그래밍 언어) | . | 심볼 : 타입의 정의로서 타입에 속하는 객체들이 가지는 공통적인 속성이나 행동을 가르킨다. | (ex 컴퓨터에게 특정한 작업을 지시하기 위한 어휘와 문법적 규칙의 집합) | . | 외연 : 타입에 속하는 객체들의 집합이다. | (ex 자바, 루비, 자바스크립트, C) 프로그래밍 언어 관점의 타입 . 연속적인 비트에 의미와 제약을 부여하기 위해 사용된다. 비트에 담긴 데이터를 문자열로 다룰지, 정수로 다룰지는 전적으로 데이터를 사용하는 애플리케이션에 의해 결정된다. 따라서 프로그래밍 언어의 관점에서 타입은 비트 묶음에 의미를 부여하기 위해 정의된 제약과 규칙을 가리킨다. | . | . 객체지향 패러다임 관점의 타입 . 객체지향에서는 객체가 수신할 수 있는 메시지를 기준으로 타입을 분류하기 때문에 동일한 퍼블릭 인터페이스를 가지는 객체들은 동일한 타입으로 분류할 수 있다. 타입 계층 . 수학에서 집합은 다른 집합을 포함할 수 있다. 타입 역시 객체들의 집합이기 때문에 다른 타입을 포함하는 것이 가능하다. ![[Pasted image 20240602132114.png]] . ![[Pasted image 20240602132135.png]] 타입계층을 구성하는 두 타입 간의 관계에서 더 일반적인 타입을 슈퍼타입이라고 부르고 더 특수한 타입을 서브타입이라고 부른다. 서브클래싱과 서브타이핑 . 어떤 타입이 다른 타입의 서브타입이 되기 외해서는 어떤 조건을 만족해야 할까? . 언제 상속을 사용해야 하는가? 반복 강조하지만 상속의 올바른 용도는 타입 계층을 구현하는 것이다. | 상속 관계가 is - a 관계를 모델링하는가? . | 자식 클래스는 부모 클래스다 라고말해도 이상하지 않다면 상속을 사용할 후보로 간주할 수 있다. | . | 클라이언트 입장에서 부모 클래스의 타입으로 자식 클래스를 사용해도 무방한가? . | 상속 계층을 사용하는 클라이언트의 입장에서 부모 클래스와 자식 클래스의 차이점을 몰라야 한다. 이를 행동 호환성이라고 부른다. | . | . \b 펭귄은 새다 새는 날 수 있다 . 위 두가지 조건에 따르면 펭귄은 날 수 없기 때문에 상속관계여서는 안된다. 타입의 이름 사이에 개념적으로 어떤 연관성이 있다고 하더라도 행동에 연관성이 없다면 is-a 관계를 사용하지 말아야 한다. 결론은 두 타입 사이에 행동이 호환될 경우에만 타입 계층으로 묶어야 한다는 것이다. 행동의 호환 여부를 판단하는 기준은 클라이언트의 관점이다. 클라이언트가 두 타입이 동일하게 행동할 것이라고 기대한다면 두 타입을 타입 계층으로 묶을 수 있다. ![[Pasted image 20240602132911.png]] . ![[Pasted image 20240602132932.png]] . 만약 펭귄이 새의 코드를 재사용해야 한다면 어떻게 해야할까? 합성을 사용하는 것이다. 만약 새의 퍼블릭 인터페이스를 통해 재사용하기 어렵다면 새를 약간 수정해야할 수도 있을것이다. 대부분의 경우에 불안정한 상속 계층을 계속 껴안고 가는 것보다는 새를 재사용 가능하도록 수정하는 것이 더 좋은 방법이다. ![[Pasted image 20240602133210.png]] . 이처럼 인터페이스를 클라이언트의 기대에 따라 분리함으로써 변경에 의해 영향을 제어하는 설계 원칙을 인터페이스 분리 원칙이라고 부른다. 서브클래싱과 서브타이핑 . 상속을 사용하는 두 가지 목적에 특별한 이름을 붙였는데, 서브클래싱과 서브타이핑이 그것이다. | 서브클래싱 : 다른 클래스의 코드를 재사용할 목적으로 상속을 사용하는 경우를 가리킨다. 구현상속 또는 클래스 상속이라고 부르기도 한다. | 서브타이핑 : 타입 계층을 구성하기 위해 상속을 사용하는 경우를 가르킨다. 인터페이스 상속이라고 부르기도 한다. | . 서브타입이 리스코프 치환 원칙을 만족시키기 위해서는 클라이언트와 슈퍼타입 간에 체결된 계약을 준수해야 한다. | 사전 조건 : 클라이언트가 정상적으로 메서드를 실행하기 위해 만족시켜야 하는 조건 | 사후 조건 : 메서드가 실행된 후에 서버가 클라이언트에게 보장해야 하는 조건 | 클래스 불변식 : 메서드 실행 전과 실행 후에 인스턴스가 만족시켜야하는 조건 | . 하지만 오버라이딩이라는게 존재한다. 자식 객체에서 오버라이딩 할때 더 강력한 사전 조건을 거는 경우 기존 코드에서는 이 사실을 모른다. 때문에 서브타입에 더 강력한 사전 조건을 정의할 수 없다. 하지만 사후 조건은 슈퍼타입과 같거나 더 강한 사후 조건을 걸어도 기존 코드에는 영향이 없다. ",
    "url": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/13.%20%EC%84%9C%EB%B8%8C%ED%81%B4%EB%9E%98%EC%8B%B1%EA%B3%BC%20%EC%84%9C%EB%B8%8C%ED%83%80%EC%9D%B4%ED%95%91.html",
    
    "relUrl": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/13.%20%EC%84%9C%EB%B8%8C%ED%81%B4%EB%9E%98%EC%8B%B1%EA%B3%BC%20%EC%84%9C%EB%B8%8C%ED%83%80%EC%9D%B4%ED%95%91.html"
  },"159": {
    "doc": "14. 서버리스",
    "title": "14. 서버리스",
    "content": ". 서버리스 서비스를 사용하는 개발자는 서버를 관리할 필요가 없다. 서버리스는 서버가 보이지 않거나 서버를 프로비저닝 하지 않는것이다. Lambda, DynamoDB, Cognito, API Gateway, S3, SNS, SQS, Aurora, Fargate(ECS) 등 . ",
    "url": "/docs/aws/14.%20%EC%84%9C%EB%B2%84%EB%A6%AC%EC%8A%A4.html",
    
    "relUrl": "/docs/aws/14.%20%EC%84%9C%EB%B2%84%EB%A6%AC%EC%8A%A4.html"
  },"160": {
    "doc": "14. 서버리스",
    "title": "Lambda",
    "content": "최대 15분 온디맨드 (함수가 실행되는 동안만 청구) 스케일링이 자동화 . 장점 . | 쉬운 가격책정 | 다양한 aws 서비스와 통합 가능 | 여러가지 프로그래밍 언어 지원 | 쉬운 cloudwatch와의 모니터링 통합 | 함수당 최대 10gb의 램을 프로비저닝 할 수 있다만약 함수의 ram을 증가시키면 cpu 및 네트워크의 품질과 성능도 함께 향상된다 | 컨테이너 이미지 지원 . | 해당 컨테이너가 lambda 런타임 api를 구현하지 않으면 ecs나 fargate에서 컨테이너를 실행해야한다 | . | . 서버리스 섬네일 생성시 lambda와 s3를 사용해서 해결할 수 있다 . 제한 . 한도는 리전당 존재 메모리 할당량은 128mb ~ 10gb 메로리는 1mb씩 증가한다 최대 실행시간은 15분이다 환경변수는 4kb까지 가질 수 있다 /tmp 폴더에 용량이 있으며 크기는 최대 10gb이다 람다 함수는 최대 1000개까지 동시 실행이 가능하다 . 배포한도 압축 시 최대 크기는 50mb 압축하지 않았을 때는 250mb이다 이 용량이 넘는경우 /tmp 공간을 사용해야한다. Customization At The Edge . 엣지에서의 사용자 지정 . 보통은 함수와 애플리케이션을 특정 리전에서 배포하지만, CloudFront를 사용할 때는 엣지 로케이션을 통해 배포한다 . 애플리케이션에 도달하기 전에 엣지에서 로직을 실행하도록 하는것을 엣지 함수라고함 CloudFront배포에 연결하는 코드이다 . 사용자 근처에서 실행하여 지연시간을 최소화하는 것이 목적이다 . 두가지 종류 CloudFront Lambda@Edge . 엣지함수 -&gt; 서버 관리가 필요없다 전역으로 배포되기 때문 . \u001fCloudFront 함수의 활용과 원리 . 클라이언트는 클라우드 프론트에 뷰어 요청을 하고 클라우드 프론트는 오리진에 요청하여 그 응답을 클라이언트로 보낸다. 클라우드프론트는 뷰어(클라이언트)에게 응답하기전에 응답을 수정할 수 있다. 뭐라는거야? 그래서 왜있는건데? . Lambda@Edge 기능이 더 많다 Node.js 나 Python으로 작성 초당 수천개의 요청을 처리 모든 CloudFront요청 및 응답을 변경할 수 있다 함수는 us-east-1리전에서만 작성 가능 함수를 작성하면 모든 로케이션에 해당 함수를 복사한다 . 차이는 런타임 지원 cloudfront는 js lambda@edge는 node.js 와 python 지원 . cloudfront는 수백만개의 요청 처리 lambda@edge는 수천개 수준 . cloudfront 함수의 최대 실행시간은 1밀리초 미만 lmbda@edge는 실행에 5~10초 소요 . cloudfront는 캐시 키를 정규화 요청 속성을 변환하여 최적의 캐시 키를 생성 요청이나 응답에 http헤더를 삽입, 수정, 삭제 조작 url을 다시 쓰거나 리디렉션 jwt를 생성하거나 검증하는 요청 인증 및 권한 부여 . lmbda@edge는 cpu와 메모리가 증가하므로 여러 라이브러리를 로드할 수 있다 타사 라이브러리에 코드를 의존시킬 수 있다 대규모 데이터 통합도 수행가능 파일 시스템이나 http요청 본문에도 바로 엑세스 가능하다 . Lambda 네트워킹 . 람다 함수를 시작하면 vpc외부에서 시작된다. 그래서 람다는 redis, elastiCache, ELB 에 접근 할 수 없다 . 해결하려면 vpc에서 lambda 함수를 시작하면된다 이를 위해서 vpc id lambda 함수를 시작하려는 서브넷을 지정하고 lambda함수에 보안 그룹을 추가해야한다. 람다에는 rds프록시를 연결해야한다 . 람다 호출 및 이벤트 알림 . 데이터베이스 인스턴스 안의 람다를 호출 할 수 있다!? 그래서 데이터베이스 안에서 일어나는 데이터 이벤트를 처리할수있다?! RDS 인스턴스로부터 람다 함수로 오는 인바운드 트래픽을 허용해 줘야한다 RDS는 람다 호출에 필요한 권한을 갖고있어야한다 DB안의 데이터에 관한 정보는 보내지 않는다 . RDS이벤트 알림을 사용하는 것과 아주 다르다 . 뭐더라? . DynamoDB . 완전 관리형 DB이다 데이터가 다중 az간에 복제되므로 가용성이 높다 NoSQL 관계형은 아니지만 트랜잭션 지원 기능이 있다 비용이 적게 들고 오토 스케일링 기능이 탑제 유지 관리나 패치 없이도 항상 사용 가능 프로비저닝 필요 없음 테이블의 용량만 설정하면됨 엑세스가 빈번한것과 그렇지 않은것으로 클래스를 나누어 저장함 DynamoDB 항목의 최대 크기는 400kb이므로 큰 객체를 저장할 때는 적합하지 않다 . 다양한 데이터 유형을 지원한다 문자열, 숫자 등등 일반적인것 목록, 지도와 같은 문서 유형과 세트 유형도 지원한다 . DynamoDB를 사용하려면 읽기/쓰기 용량모드도 설정 해야한다 . 기본 프로비저닝된 모드는 미리 용량을 프로비저닝한다. 해당 기능은 로드를 예측 할 수 있고 비용 절감을 원할때 사용 . 온디맨드 모드는 읽기 / 쓰기 용량이 워크로드에 따라 자등으로 확장된다 로드가 급격히 증가하는 경우에 유용하다 . 수천개의 상태에서 수백만개의 트랙잭션으로 1분내로 확장해야하는 경우 프로비저닝은 적합하지않다 . DAX . DynamoDB Accelerator . 고가용성의 완전 관리형 무결절 인메모리 캐시 테이블에 읽기 작업이 많을때 dax클러스터를 생성하고 데이터를 캐싱하여 읽기 혼잡을 해결한다 . dax클러스터는 기존 dynamoDB api와 호환되므로 애플리케이션 로직을 변경할 필요가 없다 . ElastiCache가 아니라 DAX를 사용하는 이유는? 쿼리와 스캔캐시를 처리하는데 유용 . 예를들어 집계 결과는 ElastiCache가 좋고 대용량의 연산을 저장할때는 DynamoDB가 좋다 DynamoDB에 캐싱 솔루션을 추가할때는 DAX를 사용한다 . DynamoDB Stream . 보존 기간이 24시간이고 소비자 수가 제한된다. ?? . lambda 트리거와 함께 사용하면 좋다 . 으악 듣기싫어 . 222. Amazon DynamoDB 심화기능 . 나중에 다시 듣자 . ",
    "url": "/docs/aws/14.%20%EC%84%9C%EB%B2%84%EB%A6%AC%EC%8A%A4.html#lambda",
    
    "relUrl": "/docs/aws/14.%20%EC%84%9C%EB%B2%84%EB%A6%AC%EC%8A%A4.html#lambda"
  },"161": {
    "doc": "14. 서버리스",
    "title": "API Gateway",
    "content": "클라이언트가 직접 lambda 함수를 지연 호출할 수 있게 하려면 클라이언트에게 IAM권한이 있어야 한다 . 클라이언트와 Lambda 함수 사이에 애플리케이션 로드밸런서 배치 필요 혹은 API Gateway를 사용한다 . API Gateway를 사용하는 이유는 HTTP엔드포인트 뿐만아니라 인증 사용량계획, 개발 단계 등의 기능을 제공한다 . API Gateway + Lambda = 완전 서버리스 애플리케이션 . Websocket 프로토콜도 지원하므로 실시간 스트리밍이 가능하다 . 인증, 권한부여 등 보안 기능을 api gateway에 활성화 할 수 있다 . 과도한 요청에 대해 스로틀링 가능 . 스웨거와 같은 api 정의 가능 . api 응답 캐싱 가능 . 속도 제한 기능 . API Gateway 배포 방법 . | 엣지 최적화 . | 글로벌 클라이언트용 | 전세계 누구나 접근 가능 | 모든 요청이 cloudFront엣지 로케이션을 통해 라우팅되므로 지연시간 개선 | . | 자체 CloudFront배포 . | 엣지 최적화와 동일한 결과 | 캐싱 전략과 CloudFront설정에 더많은 권한을 가질 수 있다 | . | 프라이빗 배포 . | VPC내에서만 액세스 가능 | ENI같은 인터페이스 VPC엔드포인트를 사용한다 ENI가 뭐더라? 엘라스틱 네트워크 인스턴스? . | . | . 보안 . | IAM 사용 | Amazon Cognito | HTTPS . | 사용자 지정 도메인 이름을 aws certificate manager(ACM)과 통합할수있다. | . | . Route53에 CNAME이나 A-별칭 레코드를 설정해 도메인 및 api gateway를 가리키도록 해야한다 . ",
    "url": "/docs/aws/14.%20%EC%84%9C%EB%B2%84%EB%A6%AC%EC%8A%A4.html#api-gateway",
    
    "relUrl": "/docs/aws/14.%20%EC%84%9C%EB%B2%84%EB%A6%AC%EC%8A%A4.html#api-gateway"
  },"162": {
    "doc": "14. 서버리스",
    "title": "Step Functions",
    "content": "서버리스 워크플로를 시작적으로 구성할 수 있는 기능 . 람다 함수를 오케스트레이션 하는데 활용 . 그래프를 통해 단계별로 다음 수행하는 작업을 정의 . 시퀀싱, 병행 실행, 조건 설정, 타임아웃, 에러 처리 등 기능이있다 . 람다 뿐 아니라 ec2, ecs, 온프레미스 서버, api gateway, sqs 등 다양한 aws서비스를 워크플로에 넣을 수 있다 . ",
    "url": "/docs/aws/14.%20%EC%84%9C%EB%B2%84%EB%A6%AC%EC%8A%A4.html#step-functions",
    
    "relUrl": "/docs/aws/14.%20%EC%84%9C%EB%B2%84%EB%A6%AC%EC%8A%A4.html#step-functions"
  },"163": {
    "doc": "14. 서버리스",
    "title": "Amazon Cognito",
    "content": "사용자에게 웹 및 모바일 앱과 상호작용 할 수 있는 자격 증명을 부여한다 . 두 종류의 하위 서비스 . | 가입 기능을 제공하는 사용자 풀 . | API Gateway 및 애플리케이션 로드 밸런서와 원활히 통합 된다 | . | 페더레이션 자격 증명 자격 증명 풀 . | 앱에 등록된 사용자에게 임시 aws자격 증명을 제공 | 일부 aws리소스에 직접 액세스 할 수 있도록 해준다 | 사용자 풀과 원활히 통합된다 | . | . 수백명의 사용자, 모바일 사용자, SAML을 통한 인증과 같은 키워드가 나오면 Cognito를 설명하는 것이다 . Congnito 사용자 풀 (CUP) . 웹 및 모바일 앱을 대상으로 하는 서버리스 사용자 데이터베이스이다 . 멀티팩터 인증이 가능하다 facebook or google과 통합할수있어 소셜 로그인 가능하다 . Cognito 사용자 풀은 api gateway나 애플리케이션 로드 밸런서와 통합된다 . api gateway를 예로 들면 사용자는 congnito 사용자 풀에 접속해서 토큰을 받고 검증을 위해 토큰을 api gateway에 전달한다. 확인이 끝나면 사용자 자격 증명으로 변환되어 백엔드의 lambda 함수로 전달된다 . 다른 방법으로 애플리케이션 로드밸런서를 사용해서 로그인 여부를 확인 후 백엔드로 리다이렉트 하는 방법도 있다 . 자격증명 풀 (페더레이션 자격증명) . 사용자에게 자격증명을 제공하지만 api gateway나 로드밸런서를 액세스하지 않고 임시 aws 자격증명을 사용해 aws계정에 직접 액세스한다 . 직접 또는 api gateway를 통해 서비스에 액세스할 수도 있다 . 원한다면 iam역할을 정의할 수도 있다 . ",
    "url": "/docs/aws/14.%20%EC%84%9C%EB%B2%84%EB%A6%AC%EC%8A%A4.html#amazon-cognito",
    
    "relUrl": "/docs/aws/14.%20%EC%84%9C%EB%B2%84%EB%A6%AC%EC%8A%A4.html#amazon-cognito"
  },"164": {
    "doc": "14. 일관성 있는 협력",
    "title": "14. 일관성 있는 협력",
    "content": ". 객체는 협력을 위해 존재한다. 객체지향 패러다임의 장점은 설계를 재사용할 수 있다는 것이다.하지만 재사용은 공짜로 얻어지지 않는다. 재사용을 위해서는 객체들의 협력 방식을 일관성 있게 만들어야 한다. 가능하면 유사한 기능을 구현하기 위해 유사한 협력 패턴을 사용하라. 일관성 있는 협력 패턴을 적용하면 여러분의 코드가 이해하기 쉽고 직관적이며 유연해진다는 것이 이번 장의 주제이다. 일관성 있는 설계를 만드는데 가장 훌륭한 조언은 다양한 설계 경험을 익히라는 것이다. 두번째 조언은 널리 알려진 디자인 패턴을 학습하고 변경이라는 문맥 안에서 디자인 패턴을 적용해 보라는 것이다. | 변하는 개념을 변하지 않는 개념으로부터 분리하라 | 변하는 개념을 캡슐화하라 이 두가지 지침은 훌륭한 구조를 설계하기 위해 따라야 하는 기본적인 원칙이기도 하다. | . 조건 로직 대 객체 탐색 . 4장의 할인 조건과 할인 정책의 종류를 판단하는 두 개의 if문이 존재하며 새로운 조건이 필요하면 우리는 if문들에 새로운 else를 추가하게 될 것이다. 객체지향은 조금 다른 접근 방법을 취한다. 조건 로직을 객체 사이의 이동으로 바꾸는 것이다. 이전에 작성한 Movie는 할인 정책이 어떤 종류인지 확인하지 않는다. 단순히 discountPolicy에 필요한 메시지를 전송할 뿐이다. ![[Pasted image 20240602173628.png]] . 캡슐화 다시 살펴보기 . 캡슐화는 클래스의 모든 인스턴스 변수는 private으로 선언해야 하고 오직 해당 클래스의 메서드만 인스턴스 변수에 접근할 수 있어야 한다는 것이다. 캡슐화는 단순히 데이터를 감추는것이 아니며, 소프트웨어 안에서 변할 수 있는 어떤 개념이라도 감추는 것이다. ![[Pasted image 20240602173746.png]] . 일관성 있는 기본 정책 구현하기 . 변경 분리하기 첫번째 단계는 변하는 개념과 변하지 않는 개념을 분리하는 것이다. ![[Pasted image 20240602174132.png]] 시간대별, 요일별, 구견별 방식의 공통점은 각 기본 정책을 구성하는 방식이 유사하다는 점이다. | 기본 정책은 한 개 이상의 규칙으로 구성된다. | 하나의 규칙은 적용조건과 단위요금의 조합이다. ![[Pasted image 20240602174443.png]] | . 따라서 변하지 않는 규칙으로부터 변하는 적용조건을 분리해야한다. 변경 캡슐화하기 여기서 변하지 않는 부분은 규칙, 변하는 것은 조건이다 따라서 규칙으로부터 적용조건을 분리해서 추상화한 후 시간대별, 요일별, 구간방식을 이 추상화의 서브타입으로 만든다. ![[Pasted image 20240602174649.png]] . Feerule은 규칙을 담당하며 Feecondition은 조건을 담당한다 . 협력 패턴 설계하기 ![[Pasted image 20240602174737.png]] 변하지 않는 추상화만 남겨 재사용 가능한 협력 패턴을 선명하게 드러낸다. ![[Pasted image 20240602174803.png]] . 규칙의 적용 조건을 만족하는 구간들로 나누는 작업은 이를 잘 알고있는 feeCondition에게 책임을 맡긴다. 이렇게 분리된 통화구간에 단위 요금을 적용해서 요금을 적용하는 계산은 FeeRule이 담담한다. ![[Pasted image 20240602175024.png]] . 협력 패턴에 맞추기 . 이제 고정요금 정책이 남있다. 고정 요금 정책을 어떻게 하면 기존 협력에 맞출 수 있을까? FeeCondition타입을 추가하는 것 뿐이다. 개념적으로 불필요한 FixedFeeCondition클래스를 추가하고 findTimeIntervals메서드의 반환 타입이 List임에도 항상 단 하나의 DateTimeInterval인스턴스를 반환한다는 사실이 조금 걸리지만 개념적 무결성을 무너뜨리는 것보다는 약간의 부조화를 수용하는 편이 더 낫다. ![[Pasted image 20240602175520.png]] . 지금까지 살펴본 것 처럼 일관성 있는 협력의 핵심은 변경을 분리하고 캡슐화하는 것이다. ",
    "url": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/14.%20%EC%9D%BC%EA%B4%80%EC%84%B1%20%EC%9E%88%EB%8A%94%20%ED%98%91%EB%A0%A5.html",
    
    "relUrl": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/14.%20%EC%9D%BC%EA%B4%80%EC%84%B1%20%EC%9E%88%EB%8A%94%20%ED%98%91%EB%A0%A5.html"
  },"165": {
    "doc": "15. DB",
    "title": "15. DB",
    "content": ". Neptune은 완전 관리형 그래프 데이터베이스입니다 . 소셜 네트워크입니다 . Keyspaces는 AWS의 관리형 Apache Cassandra를 보조합니다 . Cassandra는 오픈 소스 NoSQL 분산 데이터베이스이고 . Keyspaces를 사용하면 클라우드에서 AWS가 Cassandra를 직접 관리해 줍니다 . 서버리스 서비스이며 . 확장성과 가용성이 높으며 AWS 완전 관리형입니다 . 이번에는 Amazon QLDB에 대해 이야기해 봅시다, 퀀텀 레저 데이터베이스의 약자인데요 . 무슨 뜻일까요? . 원장은 금융 트랜잭션을 기록하는 장부입니다 . 따라서 QLDB는 금융 트랜잭션 원장을 갖게 됩니다 . 완전 관리형 데이터베이스이며, 서버리스고요, 가용성이 높고요, 3개의 가용 영역에 걸쳐 . 데이터를 복제할 수 있습니다 . 또한 애플리케이션 데이터의 시간에 따른 모든 변경 내역을 검토하는 데 사용됩니다 . 따라서 장부라고 하는 거죠 . 그리고 불변 시스템입니다 . Amazon Timestream을 살펴보겠습니다 . 이름에서 알 수 있듯이 시계열 데이터베이스입니다 . 완전 관리형이며 빠르고 확장성 있는 서버리스 서비스예요 . 시계열이란 무엇일까요? . 시계열은 시간 정보를 포함하는 포인트의 모음을 말합니다 . 화면에 보이는 연도별 그래프가 시계열의 예입니다 . Timestream를 사용하면 . 데이터베이스의 용량을 자동으로 확장, 축소할 수 있고 . 매일 수조 건의 이벤트를 저장 및 분석할 수 있습니다 . 시계열 데이터가 있을 때는 . 관계형 데이터베이스보다 시계열 데이터베이스를 사용하는 것이 . 훨씬 빠르고 저렴합니다 . ",
    "url": "/docs/aws/15.%20DB.html",
    
    "relUrl": "/docs/aws/15.%20DB.html"
  },"166": {
    "doc": "15. 디자인 패턴과 프레임워크",
    "title": "15. 디자인 패턴과 프레임워크",
    "content": ". 애플리케이션을 설계하다 보면 어떤 요구사항을 해결하기 위해 과거에 경험했던 유사한 해결 방법을 다시 사용하는 경우가 있다. 이처럼 반복적으로 발생하는 문제에 대해 반복적으로 적용할 수 있는 해결 방법을 디자인 패턴이라고 부른다. 디자인 패턴이 설계를 재사용하기 위한 것이라면 프레임워크는 설계와 코드를 함께 재사용하기 위한것이다. 디자인 패턴과 프레임워크 모두 14장에서 사라펴본 일관성 있는 협력과 관련이 있다. 디자인 패턴은 특정한 변경을 일관성 있게 다룰 수 있는 협력 템플릿을 제공한다. 프레임워크는 일관성 있는 협력을 제공하는 확장 가능한 코드라고 할 수 있다. 디자인 패턴과 설계 재사용 . 패턴이란 무엇인가를 논의할 때면 반복적으로 언급되는 몇 가지 핵심적인 특징이 있다. | 패턴은 반복적으로 발생하는 문제와 해법의 쌍으로 정의된다. | 패턴을 사용함으로써 이미 알려진 문제와 이에대한 해법을 문서로 정리할 수 있으며, 이 지식을 다른사람과 의사소통할 수 있다. | 패턴은 추상적인 원인과 실제 코드 작성 사이의 간극을 메워주며 실질적인 코드 작성을 돕는다. | 패턴의 요점은 패턴이 실무에서 탄생했다는 점이다. | . 패턴은 홀로 존재하지 않는다. 특정 패턴 내에 포함된 컴포넌트와 컴포넌트 간의 관계는 더 작은 패턴에 의해 서술될 수 있다. 패턴 분류 패턴의 범위나 적용 단계에 따라 아키텍처 패턴, 분석 패턴, 디자인 패턴, 이디엄 의 4가지로 분류하는 것이다. 4가지 중 가장 널리 알려진 것은 디자인 패턴이다. 디자인 패턴은 특정 정황 내에서 일반적인 설계 문제를 해결하며, 협력하는 컴포넌트 사이에서 반복적으로 발생하는 구조를 서술한다. 디자인 패턴은 중간 규모의 패턴으로, 특정한 설계 문제를 해결하는 것을 목적으로 하며, 프로그래밍 언어나 프로그래밍 패러다임에 독립적이다. 디자인 패턴 상위에는 소프트웨어의 전체적인 구조를 결정하기 위해 사용할 수 있는 아키텍쳐 패턴이 위치한다. 아키텍처 패턴은 미리 정의된 서브 시스템들을 제공하고, 각 서브 시스템들의 책임을 정의하며, 서브 시스템들 사이의 관계를 조직화하는 규칙과 가이드라인을 포함한다. 디자인 패턴의 하위에는 이디엄이 위치한다. 이디엄은 특정 프로그래밍 언어에만 국한된 하위 레밸 패턴으로, 주어진 언어의 기능을 사용해 컴포넌트, 혹은 컴포넌트 간의 특정 측면을 구현하는 방법을 서술한다. 이디엄은 언어에 종속적이기 때문에 특정 언어의 이디엄이 다른 언어에서는 무용지물이 될 수 있다. 분석 패턴은 도메인 내의 개념적인 문제를 해결하는 데 초점을 맞춘다. 분석 패턴은 업무 모델링 시에 발견되는 공통적인 구조를 표현하는 개념들의 집합이다. 패턴과 책임-주도 설계 패턴은 공통으로 사용할 수 있는 역할, 책임, 협력의 템플릿이다. STRATEGY패턴은 다양한 알고리즘을 동적으로 교체할 수 있는 역할과 책임의 집합을 제공한다. BRIDGE패턴은 추상화의 조합으로 인한 클래스의 폭발적인 증가 문제를 해결하기 위해 역할과 책임을 추상화와 구현의 두 개의 커다란 집합으로 분해함으로써 설계를 확장 가능하게 만든다. OBSERVER패턴은 유연한 통지 메커니즘을 구축하기 위해 객체간의 결합도를 낮출 수 있는 역할과 책임의 집합을 제공한다. 패턴의 구성 요소는 클래스가 아니라 역할이다. 개별 객체와 복합 객체를 동일하게 취급할 수 있는 COMPOSITE패턴을 살펴보자 ![[Pasted image 20240602200339.png]] . 패턴을 구성하는 요소가 클래스가 아니라 역할이라는 사실은 패턴 템플릿을 구현할 수 있는 방법이 다양하다는 것이다. ![[Pasted image 20240602201143.png]] ![[Pasted image 20240602201151.png]] 두 방법 모두 COMPOSITE패턴에서 제공하는 기본적인 역할과 책임, 협력 관계를 준수한다. 이것은 패턴을 적용하기 위해서는 패턴에서 제시하는 구조를 그대로 표현하는 것이 아니라 패턴의 기본 구조로부터 출발해서 현재의 요구에 맞게 구조를 수정해야 한다는 것을 의미한다. 캡슐화와 디자인 패턴 몇 가지 이례적인 경우를 제외하면 널리 알려진 대부분의 디자인 패턴은 협력을 일관성 있고 유연하게 만드는 것을 목적으로 한다. STRAGTEGY패턴은 알고리즘의 변경을 캡슐화하는 것이고 이를 구현하기 위해 객체 합성을 이용한다. 물론 변경을 캡슐화하는 방법이 합성만 있는 것은 아니다. 상속을 이용할 수도 있다. ![[Pasted image 20240602201446.png]] 이처럼 변경하지 않는 부분은 부모 클래스로, 변경하는 부분은 자식 클래스로 분리함으로써 변경을 캡슐화한다. 알고리즘을 캡슐화 하기 위해 합성 관계가 아닌 상속 관계를 사용하는 것을 TEMPlATE METHOD 패턴이라고 부른다. ![[Pasted image 20240602201559.png]] . 다만 합성보다는 결합도가 높은 상속을 사용했기 때문에 STRATEGY패턴 처럼 런타임에 객체의 알고리즘을 변경하는 것은 불가능하다. 하지만 알고리즘 교체와 같은 요구사항이 없다면 상대적으로 STRATEGY패턴보다 복잡도를 낮출 수 있다는 면에서는 장점이라고 할 수 있다. 핸드폰과 과금 시스템 설계는 DECORATOR 패턴을 기반으로 한다.DECORATOR 패턴은 객체의 행동을 동적으로 추가할 수 있게 해주는 패턴으로서 기본적으로 객체의 행동을 결합하기 위해 객체 합성을 사용한다. ![[Pasted image 20240602202006.png]] . 디자인 패턴에서 중요한 것은 디자인 패턴의 구현 방법이나 구조가 아니다. 어떤 디자인 패턴이 어떤 변경을 캡슐화 하는지를 이해하는 것이 중요하다. 객체의 수를 캡슐화 하는 COMPOSITE 패턴 COMPOSITE 패턴은 개별 객체와 복합 객체라는 객체의 수와 관련된 변경을 캡슐화하는 것이 목적이다. Movie는 자신과 협력해야 하는 DiscountPolicy인스턴스가 단일 객체인지 복합 객체인지 알 필요가 없다. 다시 말해서 협력하는 객체의 수를 변경하더라도 Movie에 영향을 미치지 않는다. 프레임워크와 코드 재사용 . 디자인 패턴을 적용하기 위해서는 설계 아이디어를 프로그래밍 언어의 특성에 맞춰 가공해야 하고 매번 구현 코드를 재작성해야 한다는 단점이 있다. 재사용 관점에서 설계 재사용보다 더 좋은 방법은 코드 재사용이다. 오랜 시간 동안 개발자들은 부품을 조립해서 제품을 만드는 것처럼 별도의 프로그래밍 없이 기존 컴포넌트를 조립해서 애플리케이션을 구축하는 방법을 추구해왔다. 아쉽게도 컴포넌트 기반의 재사용 방법이라는 아이디어 자체는 이상적이지만 실제 적용하는 과정에서 현실적이지 않다는 사실이 드러났다. 가장 이상적인 형태의 재사용 방법은 설계 재사용과 코드 재사용을 적절한 수준으로 조합하는 것이다. 코드만 재사용하는 컴포넌트는 실패했다. 유사한 코드를 반복적으로 구현하는 문제를 피하는 방법 -&gt; 프레임워크 . 프레임워크란 추상 클래스나 인터페이스를 정의하고 인스턴스 사이의 상호작용을 통해 시스템 전체 혹은 일부를 구현해 놓은 재사용 가능한 설계이다. 프레임워크는 코드를 재사용함으로써 설계 아이디어를 재사용한다. 상위 정책과 하위 정책으로 패키지 분리하기 . 프레임워크의 핵심은 추상 클래스나 인터페이스와 같은 추상화라고 할 수 있다. ![[Pasted image 20240602202847.png]] 그림에서 알 수 있는 것처럼 구체적인 클래스들은 RatePolicy, AdditionalRatePolicy, FeeCondition에 의존하지만 추상화들의 구체 클래스에 의존하지 않는다는 것을 알 수 있다. 상위 정책은 상대적으로 변경에 안정적이지만 세부 사항은 자주 변경된다. 만약 변하지 않는 상위 정책이 자주 변하는 세부 사항에 의존한다면 변경에 대한 파급 효과로 인해 상위 정책이 불안정해질 것이다. 변하는 것과 변하지 않는 것을 서로 분리해야한다. 이를 위한 첫 걸음은 변하는 부분과 변하지 않는 부분을 별도의 패키지로 분리하는 것이다.![[Pasted image 20240602203133.png]] . 제어 역전 원리 . 상위 정책을 재사용한다는 것은 결국 도메인에 존재하는 핵심 개념들 사이의 협력 관계를 재사용한다는 것을 의미한다. 객체지향 설계의 재사용성은 개별 클래스가 아니라 객체들 사이의 공통적인 협력 흐름으로부터 나온다. 그리고 그 뒤에는 항상 의존석 역전 원리라는 강력한 지원군이 존재한다. 의존성 역전 원리(Dependency Inversion Principle, DIP)는 객체 지향 설계의 중요한 원칙 중 하나로, 상위 모듈이 하위 모듈에 의존하지 않도록 하여 시스템의 유연성과 유지보수성을 높이는 것을 목표로 합니다. DIP는 다음 두 가지 규칙을 따릅니다 . | 상위 모듈은 하위 모듈에 의존해서는 안 된다. 둘 다 추상화에 의존해야 한다. | 추상화는 구체적인 것에 의존해서는 안 된다. 구체적인 것이 추상화에 의존해야 한다. | . 의존성을 역전시킨 객체지향 구조에서는 프레임워크가 애플리케이션에 속하는 서브 클래스의 메서드를 호출한다. 따라서 프레임워크를 사용할 경우 개별 애플리케이션에서 프레임워크로 제어 흐름의 주체가 이동한다. 즉 의존성을 역전시키면 제어 흐름의 주체 역시 역전된다. 이를 제어 역전원리, 또는 할리우드 원리라고 한다. ![[Pasted image 20240602203805.png]] 핸드폰 과금 시스템의 프레임워크의 요소들을 이용해 기본 정책의 협력을 나타낸 것이다. 그림에서 전체적인 협력 흐름은 프레임워크에 정의돼 있다. 특정한 기본 정책을 구현하는 개발자는 FeeCondition을 대체할 서브타입만 개발하면 프레임워크에 정의된 플로우에 따라 요금이 계산된다. 프레임워크에서는 일반적인 해결책만 제공하고 애플리케이션에 따라 달라질 수 있는 특정한 동작은 비워둔다. 그리고 이렇게 완성되지 않은 채로 남겨진 동작을 훅 이라고 부른다. 우리의 코드는 수동적인 존재다. 프레임워크가 우리의 코드를 호출해줄 때까지 그저 넋 놓고 기다리고 있을 수밖에 없다. 할리우드에서 캐스팅 담당자가 오디션을 보러 온 배우에게 “먼저 연락하지 마세요. 저희가 연락 드리겠습니다”라고 말하는 것처럼 프레임워크는 자신을 찾지 말라고 이야기한다. ",
    "url": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/15.%20%EB%94%94%EC%9E%90%EC%9D%B8%20%ED%8C%A8%ED%84%B4%EA%B3%BC%20%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC.html",
    
    "relUrl": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/15.%20%EB%94%94%EC%9E%90%EC%9D%B8%20%ED%8C%A8%ED%84%B4%EA%B3%BC%20%ED%94%84%EB%A0%88%EC%9E%84%EC%9B%8C%ED%81%AC.html"
  },"167": {
    "doc": "16. 데이터 분석",
    "title": "16. 데이터 분석",
    "content": ". ",
    "url": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html",
    
    "relUrl": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html"
  },"168": {
    "doc": "16. 데이터 분석",
    "title": "Athena",
    "content": "S3 버킷에 저장된 데이터 분석에 사용하는 서버리스 쿼리 서비스 . Presto엔진에 빌드됨 . S3에 저장하면 데이터를 이용하지않고 S3에서 데이터를 쿼리하고 분석할 수 있다 . CSV, JSON, ORC, Avro Parquet 등의 형식 지원 . 가격책정 - 스캔된 데이터의 TB당 고정 가격을 지불 . 서비스리여서 데이터베이스 프로비저닝 필요 없다 . Amazon QuickSight라는 도구와 함께 사용하는 일이 많다 강의에서 나중에 알아볼 예정 . Athena는 임시 쿼리 수행이나 비즈니스 인텔리전스 분석 및 보고에 사용된다 . AWS에서 발행하는 모든 로그를 쿼리하고 분석 할 수 있다 VPC흐름 로그, 로드 밸런서 로그 CloudTaril 추적 등 . Athena도 성능향상이 가능하다 열 기반 데이터 유형을 사용하면 된다. 필요한 열만 스캔하므로 비용 절감이 가능 따라서 권장 형식은 Apache Parquet과 ORC . Glue는 CSV와 Parquet간의 데이터를 변환하는데 매우 유용하다 . 적은 데이터를 스캔해야하므로 데이터를 압축해 더 적게 검색해야한다. 예 S3://athena-example/flight/parquet/year=1991/month=1/day=1/ . Athena를 사용할 때 S3의 파일이 너무 작게 나눠져있으면 성능이 떨어진다. 128MB이상의 파일을 사용해야한다. Athena는 S3뿐만아니라 관계형 데이터베이스나 비관계형 데이터베이스 객체, 사용자 지정 데이터 원본을 쿼리할 수 있다 Athena를 앞에 람다를 두어 다양한 데이터베이스와 연결하여 쿼리를 실행할 수 있다. 쿼리 결과는 사후 분석을 위해 S3에 저장할 수 있다 . ",
    "url": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#athena",
    
    "relUrl": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#athena"
  },"169": {
    "doc": "16. 데이터 분석",
    "title": "Redshift",
    "content": "데이터베이스이자 분석 엔진 . PostgreSQL 기술 기반 . 온라인 트랜잭션 처리에 사용되지 않는다? (OLTP) . 온라인 분석 처리를 의미하는 OLAP유형의 데이터베이스이다 . 분석과 데이터 웨어하우징에 사용한다 데이터가 PB규모로 확장 가능 . 열 기반 데이터 스토리지를 사용하기 때문에 성능 향상이 가능하다 . 행 기반이 아니라 병렬 쿼리 엔진이 있는 것이다? . Redshift클러스터에서 프로비저닝한 인스턴스에 대한 비용만 지불하면 된다 . 쿼리를 수행할때 SQL문을 사용할 수 있다 . Amazon Quicksight 같은 BI 도구나 Tableea같은 도구도 Redshift와 통합할 수 있다 . Redshift vs Atehna . Redshift는 S3에서 모든 데이터를 로드해와야한다. 로드하고 나면 Redshift의 쿼리가 더 빠르다 . 조인과 통합을 훨씬 더 빠르게 할 수 있다 . Athena에는 인덱스가 없는데 Redshift에는 있다 . 쿼리가 많고 복잡하며 조인이나 집계하는 등 집중적인 데이터 웨어하우스라면 Redshift가 좋다. (Athena는 임시쿼리) . Redshift 클러스터에는 두 노드가 있다. 리더 노드, 컴퓨팅 노드 . 리더노드는 쿼리르 계획하고 결과를 집계 . 컴퓨팅노드는 실제로 쿼리를 실행하고 결과를 리더에게 보냄 . Redshift는 노드의 크기를 미리 프로비저닝해야함 . 비용 절감하려면 예약 인스턴스를 사용하면됨 . 재해복구 스냅샷 . 대부분은 단일 AZ이지만 일부에서 다중 AZ를 지원한다 . 다중 AZ의경우 재해복구전략이 적용되지만 단일의 경우 스냅샷을 사용해야한다 . 스냅샷은 지정시간에 백업으로 S3내부에 저장되며 증분한다 . 변경사항만 저장되므로 공간을 절약한다 . 스냅샷이 8시간 또는 5GB마다 자동으로 생성되도록 예약할 수 있다 . 보존기간 또한 설정할 수 있다 . 수동스냅샷의 경우 직접 삭제하지 않으면 유지된다 . 원본의 Redshift클러스터와 다른 리전이 있을때 스냅샷을 생성하면 새로운 리전에 자동으로 복사되고 복사딘 스냅샷에서 새 Redshift클러스터를 복원할 수 있다 . 데이터 주입 방법 . Amazon Kinesis Data Firehose firehose가 다양한 소스로부터 데이터를 받아서 Redshift로 보내는 방법 . firehose -&gt; s3 -&gt; redshift . JDBC드라이버를 사용해 Redshift클러스터에 데이터를 삽입하는 방법 . ??? . Spectrum . S3dp 있는 데이터를 Redshift를 사용해 분석은 하지만 로드는 하지않는 방법 . 쿼리에 From S3. 으로 시작하는 명령어를 실행하면 Specttrum이 자동으로 시작되고 쿼리는 Redshift Spectrum노드에서 제출된다. 제출이 완료되면 Amazon Redishift클러스터를 통해 쿼리를 시작한곳으로 전송된다 . ",
    "url": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#redshift",
    
    "relUrl": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#redshift"
  },"170": {
    "doc": "16. 데이터 분석",
    "title": "Amazon OpenSearch",
    "content": "ElasticSearch의 후속작 라이선싱문제때문에 이름이 바뀜 . DynamoDB는 기본키 또는 인덱스만을 이용해서 쿼리할 수 있다 . 하지만 OpenSearch는 모든 필드를 검색할 수 있다 . 검색에 사용하지만 분석에도 사용한다 . 프로비저닝은 두가지 모드가 있다 관리형 클러스터 모드 : 실제 물리적인 인스턴스가 프로비저닝 되고 그걸 볼 수 있게된다 . 서버리스 클러스터 : 서버리스 경로를 설정해 서버리스 클러스터를 가질 수 있다 . OpenSearch는 자체 쿼리가 있다 . SQL을 지원하지 않지만 플러그인으로 호환성 활성화 가능 . 대시보드란걸 사용해서 데이터를 시각화 할 수 있다 . CloudWatch Logs를 OpenSearch에 주입할 수 있다 그러면 로그를 필터링 해서 볼 수 있겠다 . ",
    "url": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#amazon-opensearch",
    
    "relUrl": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#amazon-opensearch"
  },"171": {
    "doc": "16. 데이터 분석",
    "title": "EMR",
    "content": "Elastic MapReduce 빅데이터 작업을 위한 하둡 클러스터 생성에 사용 . 프로비저닝 필요 . 수백개의 EC2인스턴스로 구성될 수 있다 . 사용 이유? Apache Spark, HBase, Presto Apache Flink는 설정이 어려운데 Amazon EMR이 상기 서비스에 관한 프로비저닝과 구성을 대신 처리해줌 . 전체 클러스터를 자동으로 확장할 수 있다 스팟 인스턴스와 통합되므로 가격 할인 혜택. 기계학습, 웹 인덱싱 , 빅데이터 작업 등에 사용 . EMR은 EC2 인스턴스의 클러스터로 구성괴며 여러 유형의 노드가 있다 . 마스터노드 : 클러스터 관리, 다른노드의 상태 관리 . 코어노드 : 태스크 실행, 데이터 저장 . 태스크 노드 : 스팟 인스턴스를 사용하며 태스크 노드 사용은 선택사항 . ",
    "url": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#emr",
    
    "relUrl": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#emr"
  },"172": {
    "doc": "16. 데이터 분석",
    "title": "QuickSight",
    "content": "서버리스 머신러닝 기반 . 비즈니스 인텔리전스 서비스? . 대화형 대시보드 생성 소유한 데이터 소스와 연결 멋진 시각화, 오토스케일링 가능 . 세션당 비용 지불 . RDS, Aurora, Athena 등 다양한 데이터 소스에 연결 가능 . SPICE엔진 : 인메모리 연산 엔진 QuickSight로 데이터를 가져올때 사용 . QuickSight는 다른 DB에 연결돼 있을때 동작하지 않음 . 일부 열이 표시되지 않도록 열단위 보안 설정 가능(CLS) . 다양한 데이터 소스와 통합 가능 . QuickSight의 세가지 개념 대시보드 분석 사용자 . 스탠다드 버전 - 사용자 정의 가능 엔터프라이즈 버전 - 그룹정의 가능 IAM과는 다른것임 . 대시보드는 읽기 전용 스냅샷이며 분석 결과를 공유할 수 있다 . ",
    "url": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#quicksight",
    
    "relUrl": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#quicksight"
  },"173": {
    "doc": "16. 데이터 분석",
    "title": "Glue",
    "content": "추출과 변환 로드 서비스를 관리 ETL서비스라고도 한다 . 완전 서버리스 서비스 . 파일이 S3 버킷에 삽입될 때마다 Lambda함수로 이벤트 알림을 보내 Glue ETL작업을 자동화할 수 있다 . Lambda 대신 EventBridge도 가능 . Glue Data Catalog Glue데이터 크롤러를 싱해애 S3, RDS 등 호환 가능한 온프레미스 JDBC 데이터베이스에 연결한다 . Athena는 데이터와 스키마를 검색할 때 백그라운드에서 Glue Data Catalog를 활용한다 다른것도 마찬가지 . Glue Data Catalog 서비스는 다른 여러 AWS서비스의 중심이다 . 알아야할것 Glue작업 북마크 새 ETL작업을 실행할 때 이전 데이터의 재처리를 방지 . Glue Elastic View SQL을 사용해 여러 데이터 스토어의 데이터를 결합하고 복제 다양한 데이터를 S3에 걸쳐 뷰를 생성 . Glue DataBrew 사전 빌드된 변환을 사용해 데이터를 정리하고 정규화함 . Glue Studio ETL작업을 생성, 실행 및 모니터링 하는 GUI . Glue Streaming ETL Apache Spark Structured Streaming 위에 빌드되며 ETL작업을 배치 작업이 아니라 스트리밍 작업으로 실행 . Kinesis Data Streaming Kafka또는 MSK에서 Glue 스트리밍 ETL을 사용해 데이터를 읽을 수 있다 . ",
    "url": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#glue",
    
    "relUrl": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#glue"
  },"174": {
    "doc": "16. 데이터 분석",
    "title": "Lake Formation",
    "content": "데이터 레이크 생성을 돕는다 . 데이터 레이크란? 분석을 위해 데이터를 한곳으로 모아주는 중앙 집중식 저장소 . 데이터 검색, 정제, 변환을 돕는다 . 데이터 수집, 정제, 카탈로깅, 복제 같은 복잡한 작업을 자동화 . 기계학습 변환긴 기능으로 중복 제거 . 정형 데이터와 비정형 데이터 소스를 결합 할 수 있다 ??? . 블루프린트 제공 (데이터 이전에 사용?) . S3, RDS 온프레미스에 실행되는 관계형 데이터베이스 NoSql데이터베이스 지원 . 또한 행, 열 수준의 세분화된 엑세스 제어를 할 수 있다 . Glue위에 빌드되는 계층이다 Glue와 직접 상호작용 하지 않는다 . Lake Formation을 활용하는 서비스로는 Athena, Redshift, EMR Apache Spark 프레임워크 같은 분석 도구가 있다 아무튼 분석도구에서 사용 . 데이터 분석을 할때 사용자는 허용된 데이터만 볼 수 있어야한다 이때 Lake Formation을 사용해 중앙집권시키고 사용자에게 권한을 내려준다 . ",
    "url": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#lake-formation",
    
    "relUrl": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#lake-formation"
  },"175": {
    "doc": "16. 데이터 분석",
    "title": "Kinesis Data Analytics",
    "content": "두종류 . SQL 애플리케이션용 . Apache Flink용 . SQL 애플리케이션용 부터 보면 . 중앙에 위치하여 Kinesis Data Streams와 Kinesis Data Firehose 데이터 소스에서 데이터를 읽는다 둘 중 한군데서 데이터를 읽어 온 다음 SQL 문에 적용하여 실시간 분석을 처리할 수 있다 . 기존 데이터에 S3 버킷을 참조해 데이터를 조인할 수 있다 . 여러 대상에게 데이터를 전송할 수 있다 Kinesis Data Streams는 Kinesis Data Analytics의 실시간 쿼리로 스트림을 생성한다 Kinesis Data Firehose로 바로 전송할 수도 있다 . 스트리밍 장점 -&gt; 실시간 분석 처리 . 프로비저닝 필요 없다 . 전송된 데이터 만큼 비용 지불 . 시계열 분석과 실시간 대시보드와 실시간 지표에 사용 . 다음은 Apache Flink용 Kinesis Data Analytics . Apache Flink를 사용하면 Java, Scala, SQL로 애플리케이션을 작성하고 스트리밍 데이터를 처리, 분석할 수 있다 . Apaches Flink는 표준 SQL보다 훨씬 강력하다 . 참고로 Apache Flink는 Kinesis Data Streams나 Amazon MSK의 데이터는 읽지만 Kinesis Data Firehose의 데이터는 읽지 못합니다 Kinesis Data Firehose에서 데이터를 읽고 실시간 분석하려면 SQL 애플리케이션용 Kinesis Data Analytics를 사용해야 합니다 중요할까? . ",
    "url": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#kinesis-data-analytics",
    
    "relUrl": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#kinesis-data-analytics"
  },"176": {
    "doc": "16. 데이터 분석",
    "title": "Amazon Managed Streaming for Apache Kafka",
    "content": "줄여서 Amazon MSK . Kinesis Data Firehose에서 데이터를 읽고 실시간 분석하려면 . SQL 애플리케이션용 Kinesis Data Analytics를 사용해야 합니다 . 서버 프로비저닝이나 용량 관리가 필요 없습니다 . Kafka는 Kinesis와 유사하지만 몇 가지 차이점이 있습니다 . Kinesis Data Streams에는 1MB의 메시지 크기 제한이 있습니다 . Amazon MSK에서는 1MB이 기본값이고 . 더 큰 메시지 보존을 위해 10MB로 설정할 수도 있습니다 . Kinesis Data Streams에선 샤드로 데이터를 스트리밍합니다 . Amazon MSK에선 파티션을 이용한 Kafka 주제를 사용하죠 . Kinesis Data Streams에는 TLS 전송 중 암호화 기능이 있고 . Amazon MSK에는 평문과 TLS 전송 중 암호화 기능이 있습니다 . 참고로 몇 가지 차이점 외에도 Amazon MSK에서는 . 원한다면 1년 이상 데이터를 보관할 수도 있습니다 . ",
    "url": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#amazon-managed-streaming-for-apache-kafka",
    
    "relUrl": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#amazon-managed-streaming-for-apache-kafka"
  },"177": {
    "doc": "16. 데이터 분석",
    "title": "Big Data Ingestion Pipeline",
    "content": "설계니까 안볼래 . ",
    "url": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#big-data-ingestion-pipeline",
    
    "relUrl": "/docs/aws/16.%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B6%84%EC%84%9D.html#big-data-ingestion-pipeline"
  },"178": {
    "doc": "17. 머신러닝",
    "title": "17. 머신러닝",
    "content": ". ",
    "url": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html",
    
    "relUrl": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html"
  },"179": {
    "doc": "17. 머신러닝",
    "title": "Amazon Rekognition",
    "content": "기계학습을 이용해 객체, 사람, 텍스트와 이미지와 비디오의 장면을 찾는 서비스 . 얼굴분석, 사람수 세기 비디오 라벨링, 텍스트 탐지 등 할수있음 성별이나 연령 범위 . ",
    "url": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-rekognition",
    
    "relUrl": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-rekognition"
  },"180": {
    "doc": "17. 머신러닝",
    "title": "Amazon Transcribe",
    "content": "자동으로 음성을 텍스트로 변환시켜주는 서비스 . 개인정보 식별기능이있어 자동으로 제거해줄수있다 . 다국어 오디오 자동으로 식별할 수 있다 . ",
    "url": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-transcribe",
    
    "relUrl": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-transcribe"
  },"181": {
    "doc": "17. 머신러닝",
    "title": "Amazon Polly",
    "content": "Amazon Transcribe의 반대 . 딥 러닝 기술을 사용해 텍스트를 음성으로 변환하여 . ",
    "url": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-polly",
    
    "relUrl": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-polly"
  },"182": {
    "doc": "17. 머신러닝",
    "title": "Amazon Translate",
    "content": "이름 그대로 자연스럽고 정확한 언어 번역 기능을 제공합니다 . ",
    "url": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-translate",
    
    "relUrl": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-translate"
  },"183": {
    "doc": "17. 머신러닝",
    "title": "Amazon Lex와 Connect",
    "content": "Amazon Lex의 기술은 . Amazon의 Alexa 장치를 구현하는 기술과 같습니다 . 즉 Amazon Lex를 사용하여 . 자동 음성 인식을 할 수 있지요 . Lex가 자연어 이해를 통해 말의 의도를 파악하고 . 문장을 이해할 수 있다는 것입니다 . 콜 센터 봇 구축에 도움을 줍니다 그런데 여기서 콜 센터는 . 어떻게 만들어야 할까요? . Amazon Connect라는 가상 고객 센터가 있습니다 . 이는 전화를 받고 고객 응대 흐름을 생성하는 . 클라우드 기반 서비스예요 . ",
    "url": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-lex%EC%99%80-connect",
    
    "relUrl": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-lex와-connect"
  },"184": {
    "doc": "17. 머신러닝",
    "title": "Amazon Comprehend",
    "content": "Comprehend는 이해하는 서비스입니다 . 머신 러닝을 사용하여 텍스트에서 인사이트와 . 관계를 도출하지요, 예를 들어 텍스트 언어를 이해할 수 있고 . 텍스트에서 주요 문구, 장소 및 사람, 브랜드, 이벤트를 추출해요 . 그리고 분석 중인 텍스트가 . 긍정적인지 부정적인지 파악하는 감정 분석을 할 수 있습니다 . 자연어를 처리하는 NLP 서비스라고 생각하세요 . ",
    "url": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-comprehend",
    
    "relUrl": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-comprehend"
  },"185": {
    "doc": "17. 머신러닝",
    "title": "Amazon Comprehend Medical",
    "content": "비정형 의료 텍스트에서 . 유용한 정보를 탐지해서 반환해 주는 서비스입니다 . 의사 소견서나 퇴원 요약서, 검사 결과서 . 의료 사례 기록을 발견하면 . NLP, 즉 자연어 처리를 사용해 텍스트를 탐지합니다 . 문서와 문서 속의 보호된 개인 건강 정보(PHI)를 . DetectPHI API로 탐지해 냅니다 . ",
    "url": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-comprehend-medical",
    
    "relUrl": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-comprehend-medical"
  },"186": {
    "doc": "17. 머신러닝",
    "title": "Amazon SageMaker",
    "content": "  머신 러닝 모델을 구축하는 개발자와 데이터 과학자를 위한 서비스 입니다 . 이번 섹션에서 보았던 서비스는 모두 . 특정한 목적을 가진 관리형 머신 러닝 서비스였어요 . 텍스트를 번역하고 오디오를 글로 옮기거나 . 텍스트를 오디오로 변환하고 텍스트 일부를 분석하는 거였죠 . 하지만 SageMaker는 더 높은 수준의 머신 러닝 서비스로 . 여러분 조직의 실제 개발자와 데이터 과학자가 . 머신 러닝 모델을 만들고 구축하기 위해 사용합니다 . SageMaker는 전 과정에서 도움을 줍니다 . 라벨링, 구축, 그리고 훈련 및 조정까지요 . 그뿐만이 아닙니다 머신 러닝 모델을 생성해서 . 잘 작동된다고 합시다 그러면 이제 사용을 해야죠 . 바로 머신 러닝 모델을 배포 하는 거죠 . ",
    "url": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-sagemaker",
    
    "relUrl": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-sagemaker"
  },"187": {
    "doc": "17. 머신러닝",
    "title": "Amazon Forecast",
    "content": "이건 아주 쉬워요, 단순히 말하면 예측을 도와주는 기능입니다 어떻게 작동될까요? . 예를 들어 과거 시계열 데이터에 . 다음을 추가합니다 제품 특징, 가격, 할인 . 웹사이트 트래픽, 상점 위치 . 기본적으로 모델을 향상시킬 어떤 데이터도 가능합니다 . 그리고 Amazon S3에 이를 업로드한 뒤에 . Amazon Forecast 서비스를 시작합니다 . ",
    "url": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-forecast",
    
    "relUrl": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-forecast"
  },"188": {
    "doc": "17. 머신러닝",
    "title": "Amazon Kendra",
    "content": "머신 러닝으로 제공되는 완전 관리형 문서 검색 서비스예요 . 문서 내에서 답변을 추출할 수 있게 도와줍니다 . 이때 문서는 text, pdf, HTML PowerPoint, MS Word, FAQ 등이죠 . ",
    "url": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-kendra",
    
    "relUrl": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-kendra"
  },"189": {
    "doc": "17. 머신러닝",
    "title": "Amazon Personalize",
    "content": "실시간 맞춤화 추천으로 애플리케이션을 구축합니다 . 무엇을 추천할까요? . 예를 들어 맞춤화된 제품 추천 그리고 재순위화(re-ranking) 또는 . 맞춤화된 직접 마케팅이죠 . 사용자가 원예 도구를 많이 구매했다면 . Personalize 서비스를 기반으로 . 다음번 구매 제품을 추천하는 겁니다 . ",
    "url": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-personalize",
    
    "relUrl": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-personalize"
  },"190": {
    "doc": "17. 머신러닝",
    "title": "Amazon Textract",
    "content": "즉 텍스트, 손글씨, 또는 스캔을 한 문서의 데이터를 추출하고 . ",
    "url": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-textract",
    
    "relUrl": "/docs/aws/17.%20%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.html#amazon-textract"
  },"191": {
    "doc": "AOP",
    "title": "AOP",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/aop/src/main/java/com/example/aop/aop/Advice.java . @Before : 메소드가 실행되기 이전에 실행됩니다. @After : 메소드의 종료 후 무조건 실행됩니다. (try-catch에서 finally와 같은 동작) @After-returning : 메소드가 성공적으로 완료되고 리턴한 다음에 실행됩니다. @After-throwing : 메소드 실행 중 예외가 발생하면 실행됩니다. (try-catch에서 catch와 같은 동작) @Around : 메소드 호출 자체를 가로채서 메소드 실행 전후에 처리할 로직을 삽입할 수 있습니다. @Around(“execution(* com.example.MyClass.myMethod(..))”) - 위 예시에서는 com.example.MyClass 클래스의 myMethod() 메서드 호출 시 어드바이스가 실행됩니다. @Around(“within(com.example.MyPackage)”) - 위 예시에서는 com.example.MyPackage 패키지에 속하는 모든 메서드 호출 시 어드바이스가 실행됩니다. @Around(“args(String)”) - 위 예시에서는 첫 번째 인수가 String 타입인 메서드 호출 시 어드바이스가 실행됩니다. @Slf4j @Aspect @Order(1) @Component @RequiredArgsConstructor public class TaskAdvice { @Around(\"execution(* com.example.aop..application..*Service.*(..))\") public Object testAdvice(ProceedingJoinPoint joinPoint) throws Throwable { Object o = null; try { log.info(\"메소드 실행 전\"); o = joinPoint.proceed(); log.info(\"메소드 실행 후\"); } catch (Exception e) { log.error(e.getMessage(), e); } return o; } } . | @Around(“execution(* com.example.aop..application..Service.(..))”) . | 타입: 메서드 실행 | 패키지: . | com.example.aop 패키지 하위의 모든 패키지 | application 패키지 포함 | . | 클래스: . | Service로 끝나는 모든 클래스 | . | 메서드: . | 모든 메서드 이름 | 모든 매개변수 | . | . | . testAdvice함수가 void라면 함수 호출 후 null을 리턴하므로 주의해야합니다. 2024-03-16 23:16:39.928 INFO 10150 --- [nio-8080-exec-8] com.example.aop.aop.TaskAdvice : 메소드 실행 전 Hibernate: select member0_.`id` as id1_0_, member0_.`name` as name2_0_ from `member` member0_ 2024-03-16 23:16:41.461 INFO 10150 --- [nio-8080-exec-8] com.example.aop.aop.TaskAdvice : 메소드 실행 후 . 멀티 테넌시 사용시 루프문을 사용하여 여러 테넌트를 한번에 동작 시킬 수 있습니다. @Slf4j @Aspect @Order(1) @Component @RequiredArgsConstructor public class TaskAdvice { @Around(\"execution(* com.example..task.tenant..*Task.*(..))\") public void tenantTaskAdvice(ProceedingJoinPoint joinPoint) throws Throwable { List&lt;TenantContext&gt; tenantContexts = new ArrayList&lt;&gt;(); tenantContexts.add(new TenantContext(null,\"test1\")); tenantContexts.add(new TenantContext(null,\"test2\")); for (TenantContext tenantContext : tenantContexts) { try { TenantContextHolder.setTenantContext(tenantContext); LocaleContextHolder.setLocale(Locale.KOREA); EnvironmentContextHolder.setEnvironmentContext(environment); joinPoint.proceed(); } catch (Exception e) { log.error(e.getMessage(), e); } finally { TenantContextHolder.resetTenantContext(); LocaleContextHolder.resetLocaleContext(); EnvironmentContextHolder.resetEnvironmentContext(); } } } } . ",
    "url": "/docs/git/AOP.html",
    
    "relUrl": "/docs/git/AOP.html"
  },"192": {
    "doc": "AWS 코어 서비스로 간단한 웹 애플리케이션 만들기",
    "title": "AWS 코어 서비스로 간단한 웹 애플리케이션 만들기",
    "content": ". https://catalog.workshops.aws/general-immersionday/ko-KR/00-setup/0-2 . | EC2 - EC2 key pair 생성 ![[스크린샷 2024-03-30 오후 1.08.24.png]] | 웹서버 인스턴스가 정상적으로 떠있는지 확인 ![[스크린샷 2024-03-30 오후 1.10.48.png]] | 인스턴스에 SSH 접근되는지 확인 ![[스크린샷 2024-03-30 오후 1.31.29.png]] | EC2 자원 삭제 확인 ![[스크린샷 2024-03-30 오후 1.33.34.png]] | 오토스케일링 CloudFormation Stack 생성 확인 ![[스크린샷 2024-03-30 오후 2.02.07.png]] | 인스턴스 확인 ![[스크린샷 2024-03-30 오후 2.02.44.png]] | 로드밸런서 생성 확인 ![[스크린샷 2024-03-30 오후 2.29.30.png]] | CPU 부하 발생 하는지 확인 (로드밸런서 DNS 접속) 및 인스턴스 증가 확인 ![[스크린샷 2024-03-30 오후 2.43.08.png]] ![[스크린샷 2024-03-30 오후 2.43.28.png]] | 실습 자원 삭제 (로드밸런서, Target Group, 오토스케일링 그룹 등 전체) ![[스크린샷 2024-03-30 오후 2.44.40.png]] . | 네트워크 VPC - VPC 및 Subnet 생성 확인 ![[스크린샷 2024-03-30 오후 2.45.15.png]] . | 보안그룹 생성 확인 ![[스크린샷 2024-03-30 오후 2.46.19.png]] . | VPC 자원 삭제하기 ![[스크린샷 2024-03-30 오후 2.51.37.png]] | IAM - EC2생성 및 Tag 입력 확인 ![[스크린샷 2024-03-30 오후 3.03.07.png]] | IAM 계정 생성 확인 및 로그인 ![[스크린샷 2024-03-30 오후 3.10.51.png]] ![[스크린샷 2024-03-30 오후 3.11.33.png]] | prod / dev 인스턴스 종료 시도 후 캡쳐 ![[스크린샷 2024-03-30 오후 3.12.24.png]] ![[스크린샷 2024-03-30 오후 3.13.06.png]] | prod-instance 접근 테스트 ![[스크린샷 2024-03-30 오후 3.21.34.png]] | IAM - 실습 자원 삭제하기(EC2, IAM,S3) ![[스크린샷 2024-03-30 오후 3.26.59.png]] | CloudWatch -SNS 토픽생성하기 ![[스크린샷 2024-03-30 오후 3.27.18.png]] | EC2 생성 및 Alarm 구성 ![[스크린샷 2024-03-30 오후 3.37.25.png]] . | CloudWatch - 실습 자원 삭제하기(EC2, SNS, CloudWatch Alarm) ![[스크린샷 2024-03-30 오후 3.37.53.png]] | RDS - VPC 보안 그룹 생성 및 RDS 접근 ![[스크린샷 2024-03-30 오후 4.10.34.png]] . | RDS - 실습 자원 삭제하기(RDS) ![[스크린샷 2024-03-30 오후 4.11.28.png]] | S3 - 버킷 생성 및 수명주기 설정하기 ![[스크린샷 2024-03-30 오후 4.13.51.png]] ![[스크린샷 2024-03-30 오후 4.15.11.png]] | S3 - 실습 자원 삭제하기 ![[스크린샷 2024-03-30 오후 4.15.38.png]] | . ",
    "url": "/docs/aws/%EC%8B%A4%EC%8A%B5/AWS%20%EC%BD%94%EC%96%B4%20%EC%84%9C%EB%B9%84%EC%8A%A4%EB%A1%9C%20%EA%B0%84%EB%8B%A8%ED%95%9C%20%EC%9B%B9%20%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98%20%EB%A7%8C%EB%93%A4%EA%B8%B0.html",
    
    "relUrl": "/docs/aws/%EC%8B%A4%EC%8A%B5/AWS%20%EC%BD%94%EC%96%B4%20%EC%84%9C%EB%B9%84%EC%8A%A4%EB%A1%9C%20%EA%B0%84%EB%8B%A8%ED%95%9C%20%EC%9B%B9%20%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98%20%EB%A7%8C%EB%93%A4%EA%B8%B0.html"
  },"193": {
    "doc": "Async",
    "title": "Async",
    "content": "@EnableAsync @SpringBootApplication public class AsyncApplication extends SpringBootServletInitializer { public static void main(String[] args) { SpringApplication.run(AsyncApplication.class, args); } } . @Service @RequiredArgsConstructor public class RequestService { private final LocalTestClient localTestClient; @Async public void request() { System.out.println(localTestClient.test()); } } . @Service @RequiredArgsConstructor public class AsyncTestService { private final RequestService requestService; public void test() { for(int i=0; i&lt;3; i++) { System.out.println(\"call\"); requestService.request(); } } } . //결과 call call call test test test . Spring Boot의 기본 스레드 풀 설정은 다음과 같습니다. | corePoolSize: 1 | maxPoolSize: Integer.MAX_VALUE | queueCapacity: Integer.MAX_VALUE | threadNamePrefix: “task-“ | . 이러한 기본 설정은 작은 규모의 애플리케이션 또는 간단한 비동기 작업을 처리하는 데 적합합니다. 그러나 상용 서비스 또는 고성능 요구 사항이 있는 애플리케이션의 경우 이러한 기본 설정을 조정하여 적합한 스레드 풀을 구성하는 것이 좋습니다. 따라서 특별한 경우가 아니라면 명시적으로 스레드 풀을 지정하지 않고도 Spring Boot의 기본 스레드 풀을 사용할 수 있습니다. @Configuration @EnableAsync public class AsyncConfig { @Bean(name = \"asyncExecutor\") public Executor asyncExecutor() { ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(3); // 기본 스레드 풀 크기 executor.setMaxPoolSize(10); // 최대 스레드 풀 크기 executor.setQueueCapacity(500); // 작업 대기 큐 크기 executor.setThreadNamePrefix(\"Async-\"); // 스레드 이름 접두사 executor.initialize(); return executor; } } . 동기 처리 및 DB 커넥션 관리 . spring: datasource: hikari: maximum-pool-size: 10 . | Spring Boot와 HikariCP를 함께 사용할 때 비동기 처리를 위해 @Async 애너테이션 또는 CompletableFuture와 같은 기술을 사용할 수 있습니다. | 비동기 메서드가 실행될 때 Spring은 쓰레드를 풀에서 가져와 해당 메서드를 실행하게 됩니다. | HikariCP는 커넥션 풀을 관리하기 위해 사용됩니다. 이것은 요청이 들어올 때마다 커넥션을 가져와서 사용하고, 처리가 완료되면 해당 커넥션을 풀에 반환합니다. | . 주의 사항 비동기 처리를 할 때는 DB 작업이 반드시 비동기로 수행되어야 합니다. 그렇지 않으면 스레드 풀이 막히거나, 불필요한 스레드가 생성될 수 있습니다. 따라서 적절한 비동기 메서드 및 기술을 사용하여 비동기 작업을 구현해야 합니다. ",
    "url": "/docs/git/Async.html",
    
    "relUrl": "/docs/git/Async.html"
  },"194": {
    "doc": "CICD",
    "title": "CICD",
    "content": ". Foundation labs . Lab 0. CodeCommit . | 실습을 전부 진행하고 [Repositories]-[Code] 의 hello.txt 내용을 캡쳐 ![[스크린샷 2024-04-14 오전 10.36.46.png]] . | 실습을 전부 진행하고 [Repositories]-[Commits]-[Commit visualizer] 의 commit 내용을 캡쳐 ![[스크린샷 2024-04-14 오전 10.41.16.png]] . | . Lab 1. Rolling Update . | [1] 레포지토리 만들기 . | [Repositories]-[Code] 에서 hello-server 캡쳐 ![[스크린샷 2024-04-14 오전 10.55.35.png]] | . | [2] ECS 리소스 생성 . | [AWS ECS]-[Clusters]-staging 선택 후, 서비스 생성 화면 캡쳐 ![[스크린샷 2024-04-14 오전 11.01.00.png]] | . | [3] 파이프라인 만들기 . | [AWS Pipelines]-[Pipeline]-[Pipeline]-hello-server-pipeline 선택 후, 파이프라인 화면 캡쳐 ![[스크린샷 2024-04-14 오전 11.21.16.png]] | . | [4] 파이프라인 실행 . | curl 명령어 실행 후, 정상적으로 서비스가 호출되는지 확인 &amp; 캡쳐 ![[스크린샷 2024-04-14 오전 11.22.40.png]] | . | [5] 변경 내용 배포 . | curl 명령어 실행 후, 정상적으로 서비스가 호출되는지 확인 &amp; 캡쳐 ![[스크린샷 2024-04-14 오전 11.23.41.png]] | . | . Lab 2. Blue/Green Deploy . | [1] ECS 프로덕션 서비스 생성 . | curl 명령어 실행 후, 정상적으로 서비스가 호출되는지 확인 &amp; 캡쳐 (웹으로도 확인 가능) ![[Pasted image 20240414164312.png]] | . | [2] 코드 배포 애플리케이션 생성 . | [AWS Deploy]-[Applications]- hello-server → hello-server-prod 선택 후, 화면 캡쳐 ![[Pasted image 20240414164325.png]] | . | [3] 파이프라인 확장 . | [AWS Pipelines]-[Pipeline]-[Pipeline]-hello-server-pipeline 선택 후, 파이프라인 화면 캡쳐 ![[Pasted image 20240414164356.png]] | . | [4] 변경 사항 푸시 및 테스트 . | curl 명령어 실행 후, 정상적으로 서비스가 호출되는지 확인 &amp; 캡쳐 (웹으로도 확인 가능) ![[Pasted image 20240414164407.png]] — | . | . Lab 3. Exploring CodeDeploy . | [1-2] 테스트 포트 설정 &amp; 푸시 변경, 테스트 및 롤백 . | curl 명령어 실행 후, 정상적으로 서비스가 호출되는지 확인 &amp; 캡쳐 . | TEST 포트(8080)에 접속하는 결과와 기존 포트(80)에 접속하는 결과 차이 비교 ![[Pasted image 20240414164443.png]] | [Reroute traffic] 클릭 후, 결과 확인 ![[Pasted image 20240414164447.png]] | [Stop and roll back deployment] 클릭 후, 결과 확인 ![[Pasted image 20240414164455.png]] | . | . | . ",
    "url": "/docs/aws/%EC%8B%A4%EC%8A%B5/CICD.html",
    
    "relUrl": "/docs/aws/%EC%8B%A4%EC%8A%B5/CICD.html"
  },"195": {
    "doc": "ChainedTransaction",
    "title": "ChainedTransaction",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/multitenancy/src/main/java/com/example/multitenancy/config/database/TenantDataSourceConfig.java . 동시에 두가지 DB에 연결하여 트랜잭션을 관리합니다. 저희 프로젝트해서는 문항과 선택지를 관리하는 common DB와 각 기업의 데이터를 관리하는 tenant DB가 있습니다. ChainedTransactionManager는 두개의 트랜잭션잉 연결해주는 역할을 합니다. @Configuration public class TransactionConfig { @Primary @Bean public ChainedTransactionManager transactionManager( @Qualifier(\"commonTransactionManager\") PlatformTransactionManager commonTransactionManager, @Qualifier(\"tenantTransactionManager\") PlatformTransactionManager tenantTransactionManager) { return new ChainedTransactionManager(commonTransactionManager, tenantTransactionManager); } } . ",
    "url": "/docs/git/ChainedTransaction.html",
    
    "relUrl": "/docs/git/ChainedTransaction.html"
  },"196": {
    "doc": "CompletableFuture",
    "title": "Executor",
    "content": "작업의 종류에 따른 Executor 선택 . CompletableFuture를 사용할 때는 작업의 종류에 따라 다른 Executor를 선택할 수 있습니다. CompletableFuture를 생성할 때 Executor를 명시적으로 지정하지 않으면 기본적으로 ForkJoinPool.commonPool()이 사용됩니다. 이는 보통 CPU 코어의 수에 기반하여 크기가 조정되는 스레드 풀입니다. 예를 들어, CPU 집약적인 계산을 수행하는 작업에는 고정 크기의 스레드 풀이 적합할 수 있습니다. 반면에 I/O 작업을 수행하는 경우에는 CachedThreadPool이나 WorkStealingPool이 더 적합할 수 있습니다. CachedThreadPool은 동적 크기의 스레드 풀로, I/O 및 CPU 바운드 작업에 사용될 수 있습니다. 반면에 WorkStealingPool은 ForkJoinPool을 기반으로 하며, CPU 바운드 작업을 처리하는 데 사용됩니다. WorkStealingPool은 작업을 분산하여 처리하기 때문에 특히 병렬 처리에 유리합니다. ",
    "url": "/docs/git/CompletableFuture.html#executor",
    
    "relUrl": "/docs/git/CompletableFuture.html#executor"
  },"197": {
    "doc": "CompletableFuture",
    "title": "CompletableFuture",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/async/src/main/java/com/example/async/application/AsyncTestService.java . CompletableFuture는 Future의 확장된 형태입니다. 비동기 계산의 결과를 나타내는데 사용되며, 작업이 완료되면 결과를 포함하는 CompletableFuture를 반환합니다. CompletableFuture 는 Future와 달리 비동기 작업의 조합, 합성, 처리 결과에 따른 다양한 조작을 지원합니다. 여러 CompletableFuture를 조합하여 병렬로 실행하고 모든 작업이 완료될 때까지 기다릴 수 있습니다. 또한 작업이 완료되면 다른 작업을 수행하거나 예외 처리를 할 수 있습니다. CompletableFuture는 콜백 함수를 통해 비동기 작업의 성공 또는 실패를 처리할 수 있습니다. public void test() throws ExecutionException, InterruptedException { ExecutorService executor = Executors.newCachedThreadPool(); CompletableFuture&lt;String&gt;[] futures = new CompletableFuture[3]; for(int i=0; i&lt;3; i++) { futures[i] = CompletableFuture.supplyAsync(() -&gt; { System.out.println(\"call\"); return requestService.request(); }, executor); } CompletableFuture&lt;Void&gt; allOfFuture = CompletableFuture.allOf(futures); allOfFuture.join(); System.out.println(\"done\"); } . public String request() { String result = localTestClient.test(); System.out.println(\"method : \"+result); return result; } . call call call method : test method : test method : test done . | .join(): 이 메서드는 CompletableFuture가 완료될 때까지 기다린 후 결과를 반환합니다. 만약 CompletableFuture가 예외로 완료된 경우에는 해당 예외를 throw합니다. 이는 checked exception이 아니기 때문에 예외를 처리할 필요가 없습니다. | .get(): 이 메서드는 CompletableFuture가 완료될 때까지 기다린 후 결과를 반환합니다. 하지만 .join()과 다르게 CompletableFuture가 예외로 완료된 경우에는 ExecutionException으로 감싸서 throw합니다. 이는 checked exception이기 때문에 예외 처리가 필요합니다. | . upplyAsync(): - 비동기 작업을 실행하고 결과를 반환하는 CompletableFuture를 생성합니다. runAsync(): - 비동기 작업을 실행하고 결과를 반환하지 않는 CompletableFuture를 생성합니다. thenApply(): - 이전 작업의 결과를 가공하여 새로운 값을 반환하는 작업을 연결합니다. thenAccept(): - 이전 작업의 결과를 인자로 받아서 해당 결과를 소비하는 작업을 연결합니다. thenRun(): - 이전 작업의 결과에 의존하지 않고 단순히 다른 작업을 실행하는 작업을 연결합니다. thenCombine(): - 두 개의 CompletableFuture 작업이 모두 완료되었을 때 결과를 조합하는 작업을 연결합니다. thenCompose(): - 이전 작업의 결과에 기반하여 비동기적으로 다른 작업을 실행하고 결과를 제공하는 작업을 연결합니다. - Function을 인자로 받아서 이전 결과에 따라 새로운 작업을 수행합니다. exceptionally(): - 예외가 발생하면, 해당 예외를 처리하고 새로운 값을 반환할 수 있습니다. CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; { // 예외 발생 throw new RuntimeException(\"Exception occurred\"); }).exceptionally(ex -&gt; { System.out.println(\"Handled exception: \" + ex.getMessage()); return 0; // 예외 처리 후 반환할 값 }); System.out.println(\"Result: \" + future.join()); // Result: 0 . handle(): - 작업이 성공적으로 완료되거나 예외를 발생시켰을 때 결과나 예외를 처리하는 작업을 연결합니다. - exceptionally()와 달리, 정상적인 결과나 예외 모두를 처리합니다. CompletableFuture&lt;Integer&gt; future = CompletableFuture.supplyAsync(() -&gt; { // 예외 발생 throw new RuntimeException(\"Exception occurred\"); }).handle((result, ex) -&gt; { if (ex != null) { System.out.println(\"Handled exception: \" + ex.getMessage()); return 0; // 예외 처리 후 반환할 값 } else { return result; // 정상적인 결과 } }); System.out.println(\"Result: \" + future.join()); // Result: 0 . allOf(): - 여러 개의 CompletableFuture가 모두 완료될 때까지 기다린 후 새로운 CompletableFuture를 반환합니다. - 모든 작업이 완료될 때까지 기다린 후 결과를 처리할 수 있습니다. anyOf(): - 여러 개의 CompletableFuture 중 하나라도 완료될 때까지 기다린 후 새로운 CompletableFuture를 반환합니다. - 가장 빨리 완료되는 작업의 결과를 처리할 수 있습니다. ",
    "url": "/docs/git/CompletableFuture.html",
    
    "relUrl": "/docs/git/CompletableFuture.html"
  },"198": {
    "doc": "DDD - 인터넷 정보",
    "title": "DDD - 인터넷 정보",
    "content": ". | DDD의 강점 . | 도메인 용어를 코드에 반영하지 않으면 개발자는 코드의 의미를 해석해야 한다. | 코드의 가독성을 높여 분석과 이해하는 시간을 절약시킨다. | 용어가 저의 되 때마다 용어 사전에 이를 기록하고 명확하게 정의 함으로써 추후 다른 사람들도 공통된 언어를 사용할 수 있도록 한다. | . | 용어 . | 도메인 : 일반적인 요구사항, 소프트웨어로 해결하고자 하는 문제 영역 솔직히 이해가 잘 안가니 나중에 예제를 찾아보자 | 도메인 모델 : 특정 도메인을 개념적으로 표현한 것 이것도 이해가 안되니 다시 찾아보자 | 엔티티 : 테이블 모델, 고유 식별자를 가짐 | 애그리게이트 : 연관된 엔티티와 값객체의 묶음, 일관성과 트랜잭션, 분산의 단위 . | JPA에서 사용하는 엔티티라고 보면 될것같다. | 다만 order - orderItem 과같은 경우 모두 연관관계 매핑이 되어있어야함. | . | 바운디드 컨텍스트 : 특정한 도메인 모델이 적용되는 제한된 영역 . | 모델은 특정한 컨텍스트(문맥)하에서 완전한 의미를 갖는데, 이렇게 구분되는 경계를 갖는 컨텍스트를 바운디드 컨텍스트라고 한다. | 좋은 바운디드 컨텍스트란 하나의 바운디드 컨택스트에는 하나의 팀만 할당되어야 한다. 하나의 팀은 여러 개의 바운디드 컨택스트를 할당받을 수 있다. 둘 이상의 팀이 하나의 바운디드 컨택스트를 같이 관리하는건 안티패턴 각각의 바운디드 컨택스트는 각각의 개발환경을 가질 수 있다. | 이게 MSA인듯? | . | 컨텍스트 맵 : 바운디드 컨텍스트 간의 관계 . | 상호 교류하는 시스템 목록을 제공하고, 팀 내 원활한 의사소통을 위해 표현되는 방식이다. | . | . | DDD를 하기위해 지켜야할것 . | 참고 : 링크 | . | DDD의 단점 | 사용하지 말아야하는 경우 | 사용시 유의 점 | . https://jaehoney.tistory.com/248 . | 상품 애그리거트 : 구매하는 상품의 가격이 필요하다. 또한 상품에 따라 배송비가 추가되기도 한다. | 주문 애그리거트 : 상품별로 구매 개수가 필요하다. | 할인 쿠폰 애그리거트 : 쿠폰별로 지정한 할인 금액이나 비율에 따라 주문 총 금액을 할인한다. | 회원 애그리거트 : 회원 등급에 따라 추가 할인이 가능하다. | . 위 4개의 애그리거트중 결제 금액 계산을 수행하는 애그리거트는? (나는 주문 이라고 생각) . public class Order { ... private Orderer orderer; private List&lt;OrderLine&gt; orderLines; private List&lt;Coupon&gt; usedCoupons; private Money calculatePayAmounts() { Money totalAmounts = calculateTotalAmounts(); // 쿠폰 별로 할인 금액 계산 Money discount = counts.stream() .map(coupon -&gt; calculateDiscount(coupon) .reduce(Money(0), (v1, v2) -&gt; v1.add(v2)); // 회원에 따른 추가 할인 계산 Money membershipDiscount = calculateDiscount(orderer.getMember().getGrade()); // 실제 결제 금액 계산 return totalAmount.minus(discount).minus(membershipDiscount); } private Money calculateDiscount(Coupon coupon) { // orderLines의 각 상품에 대해 쿠폰을 적용해서 할인 금액을 계산하는 로직 // 쿠폰의 적용 조건 등을 확인하는 코드 // 정책에 따라 복잡한 if-else와 계산 코드 ... } private Money caculateDiscount(MemberGrade grade) { // 등급에 따라 할인 금액 계산 ... } } . 이렇게 한 애그리거트에 넣기 애매한 도메인 기능을 억지로 특정 애그리거트에 구현하면 안된다. 이는 코드가 길어지고 외부에 대한 의존이 높아지게 되며 코드를 복잡하게 만들고 도메인 개념이 가려지는 요인이 된다. 이러한 문제를 해결할 수 있는 좋은 방법은 도메인 기능을 별도 서비스로 구현하는 것이다. 도메인 서비스 . 도메인 서비스는 도메인 영역에 위치한 도메인 로직을 표현할 때 사용한다. 주로 다음 상황에서 도메인 서비스를 사용한다. public class DiscountCalculationService { public Money calculateDiscountAmounts (List&lt;OrderLine&gt; orderLines, List&lt;Coupon&gt; coupons, MemberGrade grade) { Money couponDiscount = coupons.stream() .map(coupon -&gt; calculateDiscount(coupon)) .reduce(Money(0), (v1, v2) -&gt; v1.add(v2)); Money membershipDiscount = calculateDiscount(grade); return couponDiscount.add(menbershipDiscount); } private Money calculateDiscount(Coupon coupon) { ... } private Money calculateDiscount(MemberGrade grade) { ... } } . 도메인은 실세계에서 사건이 발생하는 집합이라고 생각하면 쉽습니다 옷 쇼핑몰을 한번 예로 들어볼까요? 옷 쇼핑몰에서는 손님들이 주문하는 도메인(Order Domain)이 있을 수 있고, 점주입장에서 옷들을 관리하는 도메인(Manage Domain)이 있을 수 있고, 쇼핑몰 입장에서 월세, 관리비 등 건물에 대한 관리를 담당하는 도메인(Building Domain)이 있을 수 있습니다. 주문 도메인에서의 옷은 손님들에게 팔기 위한 객체 정보(name, price .. etc)들을 담고 있지만, 옷을 관리하는 도메인에서는 옷은 점주 입장에서 관리하기 위한 객체 정보(madeTime, size, madeCountry … etc)들을 위주로 담고 있습니다. 다시 말해서 Context에 따라 객체(Object)의 역할은 바뀐다는 것이에요! 흔히 이것을 Bounded Context라고 부르기도 한답니다 그래서 이를 외부로(public)으로 노출시키지 않고, package-private으로 내부에서만 알 수 있게 하는 것이에요 . 이러한 관점을 더 나아가서 직접 서비스에 적용시킨 것이 바로 MircoService(마이크로서비스)입니다 . Domain Layer : Entity, VO를 활용하여 도메인 로직이 진행되는 계층 Entity는 고유 식별자(primary Key)를 바탕으로 객체의 정체성을 부여하고, VO(Value Object)는 상태(Attribute)를 바탕으로 객체의 정체성을 부여해요! . Aggregate 정말 정말 정말 쉽게 말하면, 각각의 도메인 영역을 대표하는 객체가 바로 Aggregate입니다. 그렇게 되면, 각각의 도메인에 Repository로 묶어야 하는 객체(Entity)가 명확해지기 때문이죠 Top-Down 방식으로 계층을 타고타고 내려갈 때 어떤 Entity를 만들기 위해 도메인이 이루어져 있는지 명확하게 들어오기도 한답니다! . DDD의 핵심 목표 . | 모듈간 의존성 최소화 | 응집성 최대화 | . 내부 구현을 프라이빗하게 가져간다. (높은 응집력, 캡슐화) 내부 구현의 변경이 인터페이스에 의존하는 객체에 영향이 없도록 한다.(낮은 결합도) . 도메인 지식을 구현 코드에 반영한다. aggregate : entity 또는 vo에 접근할때 aggregate를 통해 하라는데용? . | Primary key-참조는 Primary key 사용: 다른 Aggregate를 참조할때 객체자체를 레퍼런스하지 말고 객체의 primary key로 참조해라. Order는 Consumer 객체 자체를 참조하지 않고, consumerId값으로 Consumer aggregate를 참조함. | One to One -한 개의 트랜잭션은 한 개의 Aggregate만 Writing | . https://yoojin99.github.io/cs/DDD/ . ",
    "url": "/docs/memo/DDD%20-%20%EC%9D%B8%ED%84%B0%EB%84%B7%20%EC%A0%95%EB%B3%B4.html",
    
    "relUrl": "/docs/memo/DDD%20-%20%EC%9D%B8%ED%84%B0%EB%84%B7%20%EC%A0%95%EB%B3%B4.html"
  },"199": {
    "doc": "DDD - 인터넷 정보",
    "title": "값 객체",
    "content": "값의 성질과 값 객체 구현 값의 성질을 이해하는 것은 값 객체를 이해하는 데 중요하다. 값의 성질은 아래와 같다. | 변하지 않는다. (불변) | 주고받을 수 있다. | 등가성을 비교할 수 있다. | . 따라서 값을 바꾸는 것은 권장되지 않는다. 이를 염두해서 위에서 언급했던 FullName 클래스를 다시 보자. 그리고 만약에 이 클래스에 이름을 수정하는 동작이 있다고 해보자. var person = FullName(firstName: \"철수\", lastName: \"김\") person.changeLastName(lastName: \"이\") dump(person) . 위와 같이 코드를 작성하면 부자연스러운 부분이 생긴다. 위의 코드는 값이 수정되기 때문에 좋은 코드가 아니다. FullName은 값 객체이고, 값이기도 하다. 따라서 1이 0으로 변하면 안되는 것처럼 변해선 안된다. 따라서 changeLastName처럼 값을 수정하는 기능이 클래스에 정의되면 안된다. 불변하는 값의 장점 . 상태가 변화하지 않게 하면 프로그램을 단순하게 만들 수 있다. 병렬 처리가 일어나는 프로그램에서는 상태가 변화할 수 있는 객체를 다루는 방법이 관건이기 때문에, 객체의 상태가 변하지 않는다면 병렬/병행 처리를 쉽게 구현할 수 있다. 물론 객체의 일부만 바꾸고 싶다고 해도 객체를 아예 새로 생성해야 한다는 단점이 있다. 하지만 가변 객체 -&gt; 불변 객체로 바꾸는 작업보다 불변 객체 -&gt; 가변 객체 로 바꾸는 작업이 노력이 적게 들기 때문에 일단 불변 객체를 적용하는 것이 낫다. 2. 교환 가능하다. 값 객체를 수정하는 방법은 새로운 객체를 만들어 대입을 통해 교환하는 방식으로 구현한다. var person = FullName(firstName: \"철수\", lastName: \"김\") person = FullName(firstName: \"철수\", lastName: \"이\") . 3. 등가성 비교 가능 . 프로그래밍의 원시타입끼리는 같은 값끼리 비교할 수 있다. 이처럼 값 객체도 속성을 통해 비교할 수 있다. 하지만 값 객체에서 값을 꺼내서 비교하는 것은 자연스럽지 못하다. // 원시 타입 print(0 == 0) print(\"hi\" == \"hi\") let person1 = FullName(firstName: \"철수\", lastName: \"김\") let person2 = FullName(firstName: \"철수\", lastName: \"김\") // 값 객체의 값을 또 꺼내서 비교한다. 값에서 값을 꺼낸다? 부자연스럽다. let result = person1.firstName == person2.firstName &amp;&amp; person1.lastName == person2.lastName print(result) . 값과 마찬가지로 값 객체도 값끼리 비교하는 것이 자연스럽다. 이를 위해서 값 객체를 비교하는 메서드를 정의한다. class FullName: Equatable { private(set) var firstName: String private(set) var lastName: String init(firstName: String, lastName: String) { self.firstName = firstName self.lastName = lastName } func equals(fullName: FullName) -&gt; Bool { guard self === fullName || self.firstName == fullName.firstName &amp;&amp; self.lastName == fullName.lastName else { return false } return true } // Equatable protocol static func == (lhs: FullName, rhs: FullName) -&gt; Bool { guard lhs === rhs || lhs.firstName == rhs.firstName &amp;&amp; lhs.lastName == rhs.lastName else { return false } return true } } // 비교는 이렇게 할 것이다. let person1 = FullName(firstName: \"철수\", lastName: \"김\") let person2 = FullName(firstName: \"민수\", lastName: \"김\") let person3 = person1 print(person1.equals(fullName: person2)) print(person1.equals(fullName: person3)) print(person2.equals(fullName: person3)) print(person1 == person3) . 값 객체가 되기 위한 기준 . 위에서 언급한 예시에서 FullName안의 속성 또한 값 객체로 만들 수 있다. 이에 대한 기준은 사람마다 다른데, 기준을 아래와 같이 잡을 수 있다. | 규칙이 존재하는가 | 낱개로 다루어야 하는가 | . ",
    "url": "/docs/memo/DDD%20-%20%EC%9D%B8%ED%84%B0%EB%84%B7%20%EC%A0%95%EB%B3%B4.html#%EA%B0%92-%EA%B0%9D%EC%B2%B4",
    
    "relUrl": "/docs/memo/DDD%20-%20%EC%9D%B8%ED%84%B0%EB%84%B7%20%EC%A0%95%EB%B3%B4.html#값-객체"
  },"200": {
    "doc": "DDD - 책 정보",
    "title": "DDD - 책 정보",
    "content": ". Doamin Driven Design : 도메인 주도 설계 . ",
    "url": "/docs/memo/DDD%20-%20%EC%B1%85%20%EC%A0%95%EB%B3%B4.html",
    
    "relUrl": "/docs/memo/DDD%20-%20%EC%B1%85%20%EC%A0%95%EB%B3%B4.html"
  },"201": {
    "doc": "DDD - 책 정보",
    "title": "도메인 주도 개발 시작하기 (저자 : 최범균)",
    "content": "chepter1. 도메인 모델 시작하기 . 도메인이란? . 온라인 서점에서 우리는 . | 어떤 책이 나왔는지 검색 | 목차와 서평 조회 | 장바구니 담아두기 | 바로 구매 | 쿠폰 확인 | 간편 결제 | 외부 포인트 사용 | 배송 추적 등등의 기능을 사용한다. 이처럼 온라인 서점은 책을 판매하는데 필요한 상품 조회, 구매, 결제, 배송 추적 등의 기능을 제공해야 한다. 이때 온라인 서점은 소프트웨어로 해결하고자 하는 문제 영역, 즉 도메인에 해당한다. | . ![[Pasted image 20230102190039.png|400]] 도메인은 여러 하위 도메인으로 구성된다. 한 하위 도메인은 다른 하위 도메인과 연동하여 완전한 기능을 제공한다. 고객이 물건을 구매하면 주문, 결제, 배송, 혜택 하위 도메인의 기능이 엮이게 된다. 도메인 전문가와 개발자 간 지식 공유 . 서비스를 사용하는 각 분야의 전문가들은 개발자에게 다양한 기능을 요구할 수 있다. 당연하지만 요구사항을 이해하는것은 중요하며 ,요구사항을 올바르게 이해하지 못하면 엉뚱한 기능을 만들게 된다. 개발자와 전문가 사이에 내용을 전파하는 전달자가 많으면 많을수록 정보가 왜곡되고 손실이 발생한다. 이로인해 개발자는 최초로 요구했던 요구사항과 다른 개발을 하게된다. ← 지금은 기획리뷰를 다같이 들어가기 때문에 괜찮은 것 같다. 도메인 모델 . 도메인 모델은 특정 도메인을 개념적으로 표현한 것이다. 주문도메인 → 상품 선택 및 갯수 선택, 배송지 입력 → 결제 수단 선택 및 결제 → 주문 → 배송 추적 → 배송지 변경 또는 주문 취소 위와 같은 과정을 할 수 있는 도메인이라고 했을때 ![[Pasted image 20230102191730.png|400]] . 도메인 모델은 다양한 방법으로 표현될 수 있다. (상태 다이어그램, 그래프 등) . 위와 같은 도메인 모델을 만들 수 있다. 도메인 모델을 사용하면 여러 이해관계자들이 동일한 모습으로 도메인을 이해하고 지식을 공유하는데 도움이 된다. 도메인 모델 패턴 . 일반적인 애플리케이션 아키텍처는 네 개의 영역으로 구성된다. | 표현 - 사용자의 요청을 처리하고 사용자에게 정보를 보여준다. (여기서 사용자는 외부 시스템이 될 수 있음) | 응용 - 사용자가 요청한 기능을 실행한다. 업무 로직을 직접 구현하지 않으며 도메인 계층을 조합해서 기능을 실행한다. | 도메인 - 시스템이 제공할 도메인 규칙을 구현한다. | 인프라스트럭처 | DB 인프라스트럭쳐 : 구현기술에 대한 것을 다룬다. RDBMS 연동을 처리하고, 메시징 큐에 메시지를 전송하거나 수신하는 기능을 구현하고, 몽고 DB나 HBase를 사용해서 데이터 베이스 연동을 처리한다. 논리적인 개념을 표현하기보다는 실제 구현을 다룬다. | . 도메인 계층은 핵심 규칙을 구현한다. 예를들면 . | 출고 전에 배송지를 변경 할 수 있다. | 주문 취소는 배송 전에만 할 수 있다. 와 같은 규칙들은 도메인 계층에 위치한다. | . public enum OrderState { PAYMENT_WATING { public boolean isShippingCahngeable() { return true; } } //... 다른 주문 상태값들 } . 위와같이 주문 상태 enum 클래스에 변경 가능 여부를 판단해 주는 로직을 넣을 수 있다. 만약, 변경 가능 상태를 판단하는것이 OrderState만으로는 불가는하다면 Order 클래스에 구현한다. 모델의 종류에는 개념모델과 구현모델이 있다. 개념모델은 순수하게 문제만 분석한 결과물이다. 고로 transaction과 db와 같은 것들이 고려되어있지 않다. 처음부터 완벽한 개념모델을 만들긴 어렵다. 윤곽만 잡고 구현모델로 점진적으로 발전 시켜나가야 한다. 도메인 모델 도출 . 도메인 모델링할 때 기본이 되는 작업은 모델을 구성하는 핵심 구성요소, 규칙, 기능을 찾는것이다. | 최소 한 종류 이상의 상품을 주문해야 한다. | 한 상품을 한 개 이상 주문할 수 있다. | 총 주문 금액은 각 상품의 구매 가격 합을 모두 더한 금액이다. | 각 상품의 구매 가격 합은 상품 가격에 구매 개수를 곱한 값이다. | … 등등 | . 이 요구사항에서 알 수 있는 것은 . | 출고 상태로 변경하기 | 배송지 정보 변경하기 | 주문 취소하기 | 결제 완료하기 의 기능을 제공한다는 것이다. | . public class Order { public void changeShipped() {...} public void changeShippingInfo(ShippingInfo newShppingInfo) {...} public void cancel() {...} public void completePayment() {...} } . 기능을 찾으면 위와같이 함수를 뽑아 낼 수 있다. 다음으로 . | 한 상품을 한 개 이상 주문할 수 있다. | 각 상품의 구매 가격 합은 상품 가격에 구매 개수를 곱한 값이다. 위의 조건을 통해 ‘주문 항목’이 관리 되어야하고, 이는 주문할 상품, 상품의 가격, 구매 개수를 포함해야 하는것을 도출 할 수 있다. 또한 상품의 주문 갯수와 가격의 총 값을 계산하는 함수를 만들어 관리할 수 있다. public class OrderLine { public Product product; public int price; public int quantity; public int amounts; public OrderLine(Product product, int price, int quntity) { this.product = product; this.price = price; this.quantity = quantity; this.amounts = calculaterAmounts(); } public int calculaterAmounts() { return price * quamtity; } } . | . 책의 이하 내용은 위와같은 내용이 반복된다. 엔티티와 벨류 . 도출한 모델은 크게 ‘엔티티’와 ‘밸류’로 구분할 수 있다. 엔티티와 벨류를 제대로 구분해야 도메인을 올바르게 설계하고 구현할 수 있다. 엔티티는 식별자를 가지고있다. 시간 + UUID 조합 괜찮은거같은데? . 밸류 타입의 예로는 ShppingInfo가 있다. public class ShppingInfo { private String receiverName; private String receiverPhone; private String shppingAddress1; private String shppingAddress2; private String shppingZipcode; } . ShippingInfo의 name과 phone 필드는 서로다른 두 데이터를 담고 있지만 두 필드는 개념적으로 받는 사람을 의미한다. 처음에 왜 User테이블을 참조하지 않지? 라고 생각했지만, 한 User는 받는사람의 이름과 주소를 바꿀 수 있다는걸 깨달았다!~ . 밸류 타입은 개념적으로 완전한 하나를 표현할 때 사용한다. 예를 들어 받는사람 receiverName과 receiverPhone은 Receiver 라는 밸류로 정의될 수 있으며, shppingAddress1,shppingAddress2,shppingZipcode 는 Address라는 밸류로 정의 할 수 있다. public class ShppingInfo { private Receiver receiver; private Address address; } . 밸류타입은 꼭 두개 이상의 필드를 가져야 하는건 아니다. 주문에서의 amounts는 돈을 의미하는데, 이 때 Money라는 밸류를 만들어서 사용하면 코드를 이해하는데 도움이된다. public class Money { private int value; public Money(int value) { this.value = value; } } . Money 밸류 클래스에 add(Money money) 또는 multiplier(int multiplier)와 같은 함수를 만들어서 사용 할 수 있다. (예제는 간단하지만, 조건부가 추가되면 쓸만할듯 하다) . 밸류를 사용할때 값의 변경을 위해서는 항상 새로운 밸류를 생성해서 교체 방식으로 진행한다. OrderLine line = new OrderLine(product, price, 2); 이렇게 하지않고, setter를 허용하여 진행할 경우 line.setPrice(2000) price 값이 잘못 반영되는 참조 투명성과 관련된 문제를 발생 할 수 있다. 참조 투명성 수학과 프로그래밍에서 모두 ‘함수’라는 말을 사용하고, 유사한 개념으로 사용됩니다. 하지만 둘의 결정적으로 다른 점이 있습니다. 수학에서의 함수는 같은 입력값이면 계산 된 결과는 항상 같습니다. 예를들어 f(x) = x*2 라는 함수가 있을 때, 같은 x 값을 넣게 되면 반환되는 f(x) 값은 항상 같습니다. 하지만 프로그래밍에서는 항상 같지 않습니다. int count = 0; int count(){ return count++; } . 위와 같은 함수 count의 경우 매번 반환되는 값이 다르게 됩니다. final int x = 10; int getX(){ return x; } . 반면 위와 같은 함수는 항상 같은 x의 값을 반환하게 됩니다. 이러한 경우를 ‘참조 투명’하다 라고 합니다. 앞서서 설명한 수학에서의 함수는 모두 참조 투명성을 갖고 있습니다. 그리고 이러한 함수를 참조 투명 함수 라고 부릅니다. 엔티티도 마찬가지로 생성자를 통해 진행하자. 완전한 도메인 객체를 생성함으로써 null 체크로부터 조금이나마 자유로워질 수 있다. 도메인 용어와 유비쿼터스 언어 . STEP1, STEP2, STEP3와 같이 알아볼 수 없는 변수명은 지양 하자 라는 내용 (지금 잘 지키고 있는듯 하다.) . chepter2. 아키텍처 개요 . 네 개의 영역 . 표현, 응용, 도메인, 인프라스트럭처 . 응용서비스 영역은 도메인 서비스 영역으로 모든 로직을 위임한다. 도메인 서비스에서는 핵심 로직을 구현하고, 응용서비스에서 이를 조합하여 사용한다. 마리아DB, SMTP서버, kafka 등 구현 기술을 사용한 코드는 인프라스트럭처 영역에서 다룬다. 도메인영역, 응용 영역, 표현 영역은 구현 기술을 사용한 코드를 직접 만들지 않는다. 예를들어 응용 영역에서 DB에 보관된 데이터가 필요하면 인프라 스트럭처 영역의 DB모듈을 사용하여 데이터를 읽어온다. 계층 구조 아키텍처 . 표현 ↓ 응용 ↓ 도메인 ↓ 인프라스트럭처 . 네 영역을 구성할 때 많이 사용하는 아키텍처가 위와 같은 계층 구조이다. 계층 구조는 그 특성상 상위 계층에서 하위 계층으로의 의존만 존재하고 하위 계층은 상위 계층에 의존하지 않는다. 예를 들어, 표현 게층은 응용 계층에 의존하고 응용 계층이 도메인 계층에 의존하지만, 반대로 인프라스트럭처 계층이 도메인에 의존하거나 도메인이 응용 계층에 의존하지 않는다. 하지만, 편리를 위해 바로 하위 계층이아닌 더 아래 계층에 의존 할 수 있다. (응용계층이 인프라스트럭처 계층에 의존하는 경우) 이러한경우 동작은 하겠지만 두가지 문제를 가지고 있다. | 해당 서비스만 테스트하기 어렵다. 테스트를 위해 의존하고 있는 인프라스트럭처가 정상동작 한다는 전제 조건이 깔리게된다. | 구현 방식을 변경하기 어려워진다. 인프라스트럭처의 변경에 따라 응용계층의 코드 다량으로 수정해야 할 수 있다. 이는 DIP로 해결 할 수 있다. | . DIP . 의존성 역전 원칙 . DIP는 저수준모듈(인프라스트럭처)를 고수준모듈(응용)에 의존하도록 바꾼다. 고수준 모듈을 구현하려면 저수준모듈이 필요할텐데 이를 어떻게 해결할까? 비밀은 추상화 인터페이스에 있다. 할인 기능을 예로 들면, . | public interface RuleDiscount 라는 추상클래스를 만들고 | public class calculateDiscountServce 라는 응용 계층은 RuleDiscount 를 사용하여 할인 함수를 구현한다. | public class DroolsRuleDiscounter 라는 인프라스트럭처 계층에 implemets RuleDiscounter 를 통해 상속 받게 함으로써, 상위계층에 필요한 함수를 구현하게 만든다. | . 주의 해야할 점은 DIP를 적용할때 고수준 모듈을 기준으로 인터페이스를 추출 해야한다는 것이다 단순히 저수준 모듈에서 인터페이스와 클래스를 분리하는 개념이 아닌 고수준 모듈을 기준으로 인터페이스를 추출해야한다. ![[Pasted image 20230102212855.png|400]] 위와 같은 구조를 목표로 설계해보자. 도메인 영역의 주요 구성요소 . 도메인 영역의 모델은 도메인의 주요 개념을 표현하며 핵심 로직을 구현한다. | 요소 | 설명 | . | 엔티티 | 고유 식별자를 갖는 객체로 자신의 라이프 사이클을 갖는다. | . | 밸류 | 고유 식별자를 갖지 않는 객체로 주로 개념적으로 하나인 값을 표현할 때 사용한다. | . | 애그리거트 | 애그리거트는 연관된 엔티티와 밸류 객체를 개념적으로 하나로 묶은 것이다. 주문과 관련된 Order 엔티티, OrderLine 밸류, Orderer 밸류 객체를 ‘주문’ 애그리거트로 묶을 수 있다. | . | 레포지토리 | 도메인 모델의 영속성을 처리한다. DBMS 테이블에서 엔티티 객체를 로딩하거나 저장하는 역할을 한다. | . | 도메인 서비스 | 특정 엔티티에 속하지 않은 도메인 로직을 제공한다. 도메인 로직이 여러 엔티티와 밸류를 필요로하면 도메인 서비스에서 로직을 구현한다. | . 도메인 모델의 엔티티와 DB 관계형 모델의 엔티티는 같은것이 아니다. 두 모델의 가장 큰 차이점은 도메인 모델의 엔티티는 데이터와 함께 도메인 기능을 함께 제공한다는 점이다. 예를 들어 주문을 표현하는 엔티티는 주문과 관련된 데이터뿐만 아니라 배송지 주소 변경을 위한 기능을 함께 제공한다. 도메인 모델의 엔티티는 단순히 데이터를 담고 있는 데이토 구조라기보다는 데이터와 함께 기능을 제공하는 객체이다. 애그리거트 . 도메인이 커질수록 개발할 도메인 모델도 커지면서 많은 엔티티와 밸류가 출현한다. → 복잡성 증가 도메인 모델에서 전체 구조를 이해하는 데 도움이 되는 것이 바로 애그리거트이다. 애그리거트의 대표적인 예가 주문이다. 주문이라는 도메인 개념은 ‘주문’, ‘배송지 정보’, ‘주문자’, ‘주문 목록’, ‘총 결제 금액’의 하위 모델로 구성된다. 애그리거트를 사용하면 개별 객체가 아닌 관련 객체를 묶어서 객체 군집 단위로 모델을 바라볼 수 있게된다. 애그리거트는 군집에 속한 객체를 관리하는 루트 엔티티를 갖는다. 루트 엔티티는 애그리거트에 속해있는 엔티티와 밸류 객체를 이용해서 애그리거트가 구현해야 할 기능을 제공한다. 루트 애그리거트를 통해 하위 애그리거트와 밸류에 접근하게 함으로써 내부 구현을 숨기고 캡슐화 할 수 있도록 돕는다. 요청 처리 흐름 . controller → app service → domain service → repository . 인프라스트럭처 개요 . … 인프라스트럭처에 대한 의존을 완전히 갖지 않도록 시도하는 것은 자칫 구현을 더 복잡하고 어렵게 만들 수 있다. (주의) . 모듈 구성 . 패키지 경로를 결정하는 내용인데, 이건 취향차이인듯하다. chepter3. 애그리거트 . 애그리거트 . 애그리거트를 사용함으로써 모델 간의 관계를 개별 모델 수준과 상위 수준에서 모두 이해할 수 있다. 이해 뿐만아니라 일관성을 관리하는 기준도 된다. 애그리거트 단위로 일관성을 관리하기 때문에, 복잡성이 줄어든다. 한 애그리거트에 속한 애그리거트난 다른 애그리거트에 속하지 않는다. 애그리거트는 독립된 객체이며, 각 애그리거트는 자신을 관리할 뿐 다른 애그리거트를 관리하지 않는다. (주문 애그리거트에서는 주문 상품 개수를 변경하지만, 회원의 비밀번호를 변경하지않는다.) . 도메인 규칙에 따라 함께 생성되는 구성 요소는 한 애그리거트에 속할 가능성이 높다. 주의해야할건, ‘A가 B를 갖는다’로 해석할 수 있는 요구사항이 있더라도 한 애그리거트에 속한다는것을 의미하지 않는다. 예를들어 제품과 리뷰가 있을때 제품이 리뷰를 갖기때문에 한 애그리거트라고 볼 수 있지만 제품이 생성될 때 리뷰가 함께 생성되지 않는다. 함께 변경되지도 않는다. 애그리거트 루트 . 애그리거트는 여러 객체로 구성되기 때문에 한 객체만 상태가 정상이면 안된다. 도메인 규칙을 지키려면 애그리거트에 속한 모든 객체가 정상 상태를 가져야한다. OrderLine을 변경하면 Order의 totalAmounts도 다시 계산을 해야한다는 소리이다. 애그리거트에 속한 모든 객체가 일관된 상태를 유지하려면 애그리거트 전체를 관리할 주체가 필요한데, 그것은 애그리거트의 루트 엔티티이다. 하나의 트랜잭션에서는 하나의 애그리거트만 수정하는게 좋다. (Lock때문에) → 따로 트랜잭션 공부를 진행하자. 물론 실무에서 힘들수도있다! . 레포지토리와 애그리거트 . → 4장의 RDBMS와 JPA 이용하는 방법 참고 . ID를 이용한 애그리거트 참조 . 하나의 애그리거트에서 다른 애그리거트의 상태값을 바꿀때에 대한 문제점 제시 → ID참조를 사용하면 모든 객체가 참조로 연결되지 않고 한 애그리거트에 속한 객체들만 참조로 연결된다. 예시 ![[Pasted image 20230103004039.png|400]] Members는 Order라는 애그리거트 루트 엔티티에 속하지 않는다. 이때 구현 방식에 따라 orderer.getMember().changeAddress('주소') 와 같은 형태로 다른 애그리거트의 상태값을 변경 할 수 있다. 위와 같은 방법은 애그리거트간의 결합도를 올리며 변경에 대해 어렵게 만든다. 때문에 memberRepository.findById(orderer.getMemberId())와 같이 id값을 통해 member를 조회하고 수정한다. 애그리거트 간 집합 연관 . 당연하게도 페이지네이션을 구현해야할때 굳이 루트 엔티티를 통해서 구현 할 필요 없이 해당 도메인의 repository를 통해 구현하면된다. M-N(다대다) 관계같은경우 … 사용할일 없을것 같아서 나중에 필요하면 책 찾아보자. (p.123) … . 애그리거트를 팩토리로 사용하기 . 애그리거트가 갖고있는 데이터를 이용해서 다른 애그리거트를 생성해야 한다면 애그리거트에 팩토리 메서드(store.createProduct(id..생략)) 메서드를 추가해서 사용해보자 store에서 하지않고 Factory 클래스를 만들어 사용해도 좋다. chepter4. 레포지토리와 모델 구현 . JPA를 이용한 레포지토리 구현 . 스프링 데이터JPA를 이용한 레포지토리 구현 . 매핑 구현 . ![[Pasted image 20230103013120.png|400]] . @SecondaryTable, @Embeddable, @AttributeOverride 등 공부 필요함. @SecondaryTable을 사용하면 루트 엔티티를 조회할때 SecondaryTable을 join 해서 가져온다. 선언하는게 여태 썻던거랑 너무다른데..? 지금은 졸리니 내일 다시 정리하자. 애그리거트에서 루트 엔티티를 뺀 나머지 구성요소는 대부분 밸류이다. 루트 엔티티 외에 또 다른 엔티티가 있다면 진짜 엔티티인지 의심해 봐야 한다. 단지 별도 테이블에 데이터를 저장 한다고 해서 엔티티인 것은 아니다. 주문 애그리거트도 OrderLine을 별도 테이블에 저장하지만 OrderLine 자체는 엔티티가 아니라 밸류이다. 밸류가 아니라 엔티티가 확실하다면 엔티티가 아니라 애그리거트인지 확인해야 한다. 자신만의 독자적인 라이프 사이클을 갖는다면 구분되는 애그리거트일 가능성이 높다. 함께 속한 애그리거트는 생성이 같이되거나 수정될 때 영향을 받는다. 주의하자 . 밸류는 @Embeddable로 매핑한다. 애그리거트 로딩 전략 . 무조건적인 Lazy 또는 Eager 방식은 옳지못하다. 한 애그리거트에서도 여러 상황에 따라 방식을 다르게 가져가자 . 애그리거트의 영속성 전파 . 애그리거트는 완전한 상태여야한다. 루트 엔티티 조회 뿐만아니라 저장하고 삭제할때도 하나로 처리되어야 한다. Cascade의 사용 CascadeType.PERSIST, CascaseType.REMOVE, orphanRemoval=true 를 설정한다. 식별자 생성 기능 . Id값 생성에대한이야기… . 도메인 구현과 DIP . 급하니 넘어가도 될만한 이야기… . chepter5. 스프링 데이터 JPA를 이용한 조회 기능 . 시작에 앞서 . 검색을 위한 스펙 . 스프링 데이터 JPA를 이용한 스펙 구현 . 레포지토리 / DAO에서 스펙 사용하기 . 스펙 조합 . 스펙 조합을 위한 스펙 빌더 클레스 . 책에서는 spec이란걸 사용했지만, querydsl을 사용하면 문제 없어보인다. 정렬 지정하기 . 페이징 처리 . jpa에서 orderBy를 사용하는것보다 매개변수로 Sort를 보내주는것이 함수명을 더 짧게 가져갈 수 있다. 마찬가지로 Pageable 매개변수 사용하라는 내용 PageRequest를 사용하면 페이징처리와 정렬 동시에 가능하다는 내용 . 동적 인스턴스 생성 . Projection과 같이 db에 없는 객체를 JPQL로 생성한다는 내용 . 하이버네이트 @Subselect 사용 . 수정불가능한 조회용 Entity를 db와 매핑 할 수 있다는 내용 당장에 사용하지 않을듯 하다. chepter6. 응용 서비스와 표현 영역 . 표현 영역과 응용 영역 . 응용 서비스의 역할 . 응용 서비스의 구현 . 표현 영역 . 값 검증 . 권한 검사 . 조회 전용 기능과 응용 서비스 . chepter7. 도메인 서비스 . 여러 애그리거트가 필요한 기능 . 도메인 서비스 . chepter8. 애그리거트 트랜잭션 관리 . 애그리거트와 트랜잭션 . 선점 잠금 . 비선점 잠금 . 오프라인 선점 잠금 . chepter9부터는 개발하면서 공부해야겠다. chepter9. 도메인 모델과 바운디드 컨텍스트 . 도메인 모델과 경계 . 바운디드 컨텍스트 . 바운디드 컨텍스트 구현 . 바운디드 컨텍스트 간 통합 . 바운디드 컨텍스트 간 관계 . 컨텍스트 맵 . chepter10. 이벤트 . 시스템 간 강결합 문제 . 이벤트 개요 . 이벤트, 핸들러, 디스패처 구현 . chepter11. CQRS . 단일 모델의 단점 . CQRS . | ![[Pasted image 20230103144412.png | 400]] | . | ![[Pasted image 20230103144542.png | 400]] | . ",
    "url": "/docs/memo/DDD%20-%20%EC%B1%85%20%EC%A0%95%EB%B3%B4.html#%EB%8F%84%EB%A9%94%EC%9D%B8-%EC%A3%BC%EB%8F%84-%EA%B0%9C%EB%B0%9C-%EC%8B%9C%EC%9E%91%ED%95%98%EA%B8%B0-%EC%A0%80%EC%9E%90--%EC%B5%9C%EB%B2%94%EA%B7%A0",
    
    "relUrl": "/docs/memo/DDD%20-%20%EC%B1%85%20%EC%A0%95%EB%B3%B4.html#도메인-주도-개발-시작하기-저자--최범균"
  },"202": {
    "doc": "DTO pattern",
    "title": "DTO pattern",
    "content": ". https://climbtheladder.com/10-dto-best-practices/ https://www.baeldung.com/java-dto-pattern . The solution is to create a Data Transfer Object that can hold all the data for the call. Use a builder pattern . | you can use a builder pattern, which allows you to set the required fields in the constructor and the optional fields using setter methods. | setter를 사용하지말고, builder를 사용해서 생성자를 만들때도 setter를 사용할 필요가 없다. | . Make the class immutable (수정x) . | Just make all of the fields in the DTO final | don’t provide any setter methods. | Instead, provide a constructor that takes all of the required data as parameters. | dto 내부로직 구현, 사용 금지 | . Don’t use inheritance (상속x) . | It’s much better to simply use composition when creating your DTOs. | 상속받아서 만들지말고, dto를 여러개 만드는게 수정에 용이하다. | . Avoid using getters and setters . | Getters and setters are a code smell because they indicate that your class is doing too much. | A data transfer object should only be responsible for transferring data | Instead of using getters and setters, make your fields public and final. | getter와 setter가 있다는건 클래스가 많은 일을하고있다는것을 증명하고, 이는 악취나는 코드이다. | dto는 응답을 위해서만 존재해야한다. | 변수를 final로 선언해여 클래스를 간결하고 이해하기 쉽게 만들자. | . Keep it simple . | A DTO should only contain the fields that are absolutely necessary to complete the task at hand. | dto 내부의 변수는 절대적으로 필요한 변수만 넣는다. 여분의 변수는 지워져야한다. | 이는 클래스를 가볍게 만들어줄뿐아니라 민감데이터가 유출되는것을 막아준다. | dto 내부에는 절대 비즈니스 로직이 들어가선 안된다. | . Validate input data . | dto는 값을 담는 컨테이너일 뿐이란것을 잊지 말아야한다. | 컨테이너에 들어가는 값들은 매우 중요하며 이것들은 검증되어야한다. | 모르겠다면 공부하자,,, (test code를 돌리라는 소리일까?) | . Consider serialization . | 데이터 직렬화를 고려하자. (공부 결과 직렬화에는 변수 변경에대해 위험이 따르며, 잘 알고사용해야한다.) | 아직 지식이 부족한 나는 지양 해도 좋을거같다. | . Be careful with equals() and hashCode() . Prefer composition over inheritance . | 부모클래스의 변경이 자식클래스에게 영향을 끼칠 수 있기떄문에, 상속에 대한 유혹을 뿌리쳐야 한다. | 상속보다는 새로 구성하는쪽을 선호해야한다. | . Leverage Java 8 features . |  Date and Time API, lambdas, and Streams을 활용하자 | Date Time 은 날짜 포멧변경을 쉽게 만들어준다. 람다는 필터와 변환에 도움을주며 스트림은 병렬처리를 가능하게 해준다. | . getter는 직렬화할 때 getter를 사용합니다. 즉 DTO들을 JSON 데이터로 다시 가공할 때 getter를 사용한다고 이해 . https://www.baeldung.com/java-dto-pattern . Fowler explained that the pattern’s main purpose is to reduce roundtrips to the server by batching up multiple parameters in a single call. This reduces the network overhead in such remote operations. 여러 데이터를 한번에 묶어 처리함으로써 서버와의 통신을 줄임. DTOs normally are created as POJOs. They are flat data structures that contain no business logic. They only contain storage, accessors and eventually methods related to serialization or parsing. | Dto는 사용에 따라 최대한 쪼개야 합니다. 예를 들어 하나의 Entity를 용도에 따라 보여주는 부분이 다를 때, 화면에서의 리스트 컬럼과 엑셀 다운로드 시 보여줄 컬럼들이 다를 때 필드가 1-2개 달랐지만 하나의 Dto로 사용했었습니다. 각각의 목적에 따라 Dto를 만들어야 합니다. | . ",
    "url": "/docs/memo/DTO%20pattern.html",
    
    "relUrl": "/docs/memo/DTO%20pattern.html"
  },"203": {
    "doc": "Design Pattern - Getter Setter Constructor",
    "title": "Design Pattern - Getter Setter Constructor",
    "content": ". ",
    "url": "/docs/memo/Design%20Pattern%20-%20Getter%20Setter%20Constructor.html",
    
    "relUrl": "/docs/memo/Design%20Pattern%20-%20Getter%20Setter%20Constructor.html"
  },"204": {
    "doc": "Design Pattern - Getter Setter Constructor",
    "title": "setter 없이 개발",
    "content": "setter 없이 get post 통신 . setter없이 개발 1 setter없이 개발2 setter 없이 어떻게 데이터를 수정할까? setter의 경우 JPA의 Transaction 안에서 Entity 의 변경사항을 감지하여 Update 쿼리를 생성한다. 즉 setter 메소드는 update 기능을 수행한다. 여러 곳에서 Entity를 생성하여 setter를 통해 update를 수행한다면 복잡한 시스템일 경우 해당 update 쿼리의 출처를 파악하는 비용은 어마어마할 것이다. 그렇다면 어떻게 setter를 배제할까? 아니 setter를 어떤 방식으로 대체하는지 알아보자. 사용한 의도나 의미를 알 수 있는 메서드를 작성하자. @Getter @Entity public class Post { private Long id; private String userId; private String title; private String cont; public void updatePost(Long id, String title, String cont) { this.id = id; this.title = title; this.cont = cont; } } . post.updatePost(1L, \"수정할 제목입니다.\", \"수정할 내용입니다.\"); . ",
    "url": "/docs/memo/Design%20Pattern%20-%20Getter%20Setter%20Constructor.html#setter-%EC%97%86%EC%9D%B4-%EA%B0%9C%EB%B0%9C",
    
    "relUrl": "/docs/memo/Design%20Pattern%20-%20Getter%20Setter%20Constructor.html#setter-없이-개발"
  },"205": {
    "doc": "Design Pattern - Getter Setter Constructor",
    "title": "getter 없이 개발",
    "content": "public class Game { public void run(Car car) { int number = car.getNumber(); if (number &gt;= 4) { car.update(number+1); } } public void run2(Car car) { car.move(4); } } . 위와 같이 Car클래스와 Car클래스로부터 객체를 만들어 게임을 실행하는 Game클래스가 있다. Game의 run메소드는 getter를 이용하여 로직을 처리하고 있고, . run2메소드는 객체에 메시지를 보내서 로직을 처리하고 있다. 두 로직 모두 car객체의 number가 4이상이면 number를 1만큼 증가시키는 로직이다. 주목할 점은, 1만큼 증가시키는 판단을 누가 하는가 이다. run2같은경우, 숫자를 넘겨줄 뿐, 상태값을 변경시키는 판단을 객체에게 맡기고 있다. 하지만 run같은 경우, getter를 통해 값을 받은 후 그 값을 이용하여 객체의 상태값을 변화시키는 판단을 하게되고, update메소드를 호출함으로서 객체의 상태값을 바꾼다. 즉, 객체의 상태값을 바꾼다는 판단을 외부에서 하고 있는 것이다. getter메소드가 직접적으로 상태값을 바꾸지는 않지만, 이것이 사용되는것은 외부에게 ‘상태값 변경에 대한 판단권’을 줘버리게 될 수 있다. 이것은 계속해서 되새기고 있는 ‘독립적인 객체’설계에 위배되는 행위이다. ",
    "url": "/docs/memo/Design%20Pattern%20-%20Getter%20Setter%20Constructor.html#getter-%EC%97%86%EC%9D%B4-%EA%B0%9C%EB%B0%9C",
    
    "relUrl": "/docs/memo/Design%20Pattern%20-%20Getter%20Setter%20Constructor.html#getter-없이-개발"
  },"206": {
    "doc": "Design Pattern - Getter Setter Constructor",
    "title": "Constructor 접근 제한",
    "content": "NoArgsConstructor 접근권한을 주지 않고, 정적 팩토리 메서드를 사용한다면, JPA에서는 프록시를 생성을 위해서 기본 생성자를 반드시 하나를 생성해야한다. 이때 접근 권한을 AccessLevel.PROTECTED로 설정하여 JPA에서의 Entity 클래스 생성만 허용해줍니다. ",
    "url": "/docs/memo/Design%20Pattern%20-%20Getter%20Setter%20Constructor.html#constructor-%EC%A0%91%EA%B7%BC-%EC%A0%9C%ED%95%9C",
    
    "relUrl": "/docs/memo/Design%20Pattern%20-%20Getter%20Setter%20Constructor.html#constructor-접근-제한"
  },"207": {
    "doc": "Docker",
    "title": "network",
    "content": "docker network ls . ",
    "url": "/docs/git/Docker.html#network",
    
    "relUrl": "/docs/git/Docker.html#network"
  },"208": {
    "doc": "Docker",
    "title": "remege",
    "content": "docker rmi {IMAGE_ID} . ",
    "url": "/docs/git/Docker.html#remege",
    
    "relUrl": "/docs/git/Docker.html#remege"
  },"209": {
    "doc": "Docker",
    "title": "mariadb",
    "content": "https://hub.docker.com/_/mariadb . docker pull mariadb . docker images . docker run -v ~/data/mariadb:/data/db --name testDB -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=1111 mariadb . ",
    "url": "/docs/git/Docker.html#mariadb",
    
    "relUrl": "/docs/git/Docker.html#mariadb"
  },"210": {
    "doc": "Docker",
    "title": "mongodb",
    "content": "docker pull mongo . docker run -v ~/data/mongodb:/data/db --name mongodb -d -p 27017:27017 -e MONGO_INITDB_ROOT_USERNAME=root -e MONGO_INITDB_ROOT_PASSWORD=1111 mongo . -v ~/data:/data/db는 호스트(컨테이너를 구동하는 로컬 컴퓨터)의 ~/data 디렉터리와 컨테이너의 /data/db 디렉터리를 마운트시킨다. 이처럼 볼륨을 설정하지 않으면 컨테이너를 삭제할 때 컨테이너에 저장되어있는 데이터도 삭제되기 때문에 복구할 수 없다. ",
    "url": "/docs/git/Docker.html#mongodb",
    
    "relUrl": "/docs/git/Docker.html#mongodb"
  },"211": {
    "doc": "Docker",
    "title": "redis",
    "content": "https://hub.docker.com/_/redis . docker pull redis . docker run -d --name testRedis -p 6379:6379 redis --requirepass \"1111\" . ",
    "url": "/docs/git/Docker.html#redis",
    
    "relUrl": "/docs/git/Docker.html#redis"
  },"212": {
    "doc": "Docker",
    "title": "kafka",
    "content": "https://hub.docker.com/r/bitnami/kafka . create docker-compose.yml . version: \"3\" services: zookeeper: image: 'bitnami/zookeeper:latest' ports: - '2181:2181' environment: - ALLOW_ANONYMOUS_LOGIN=yes kafka: image: 'bitnami/kafka:latest' ports: - '9092:9092' environment: - KAFKA_BROKER_ID=1 - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092 - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://127.0.0.1:9092 - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181 - ALLOW_PLAINTEXT_LISTENER=yes depends_on: - zookeeper . docker-compose up -d . ",
    "url": "/docs/git/Docker.html#kafka",
    
    "relUrl": "/docs/git/Docker.html#kafka"
  },"213": {
    "doc": "Docker",
    "title": "kafka Web UI",
    "content": "https://github.com/obsidiandynamics/kafdrop https://github.com/provectus/kafka-ui . // kafkadrop // 아래 명령어에서 &lt;host:port,host:port&gt; 부분만 수정해서 실행하면 된다. docker run -d --rm -p 9000:9000 \\ -e KAFKA_BROKERCONNECT=&lt;host:port,host:port&gt; \\ -e JVM_OPTS=\"-Xms32M -Xmx64M\" \\ -e SERVER_SERVLET_CONTEXTPATH=\"/\" \\ obsidiandynamics/kafdrop // 명령어 실행 후 문구 Unable to find image 'obsidiandynamics/kafdrop:latest' locally latest: Pulling from obsidiandynamics/kafdrop e0b25ef51634: Pull complete d1bd2bc15eb1: Pull complete 77d0de1fd7e0: Pull complete b638505435dc: Pull complete 8bbf85e38402: Pull complete 1ceef1d1d525: Pull complete 643cf0d075ea: Pull complete Digest: sha256:5337c9e0e2dee204bdde53e90cf97001f44fb9e8c3380340436efa844901a3f4 Status: Downloaded newer image for obsidiandynamics/kafdrop:latest a8d978f7e0d0a715dfef2e0f0a6c69fd6faf4023d5d16611b8bd7a5dcba6103d kms0428@kms0428-laptop:~$ . //kafka ui docker run -p 8080:8080 \\ -e KAFKA_CLUSTERS_0_NAME=local \\ -e KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092 \\ -d provectuslabs/kafka-ui:latest . keycloak . docker run quay.io/keycloak/keycloak start-dev . ",
    "url": "/docs/git/Docker.html#kafka-web-ui",
    
    "relUrl": "/docs/git/Docker.html#kafka-web-ui"
  },"214": {
    "doc": "Docker",
    "title": "Docker",
    "content": "install for mac colima . https://velog.io/@sblee/install-colima . brew install colima docker docker-compose mkdir -p ~/.docker/cli-plugins ln -sfn $(brew --prefix)/opt/docker-compose/bin/docker-compose ~/.docker/cli-plugins/docker-compose colima start . colima start를 시작 시켜야 도커가 동작한다. 명령어를 통해 컨테이너에 접근할 수 있다. docker exec -it {container_id 또는 컨테이너 이름} bash # ctrl + p + q 를 통해 나올 수 있다. ",
    "url": "/docs/git/Docker.html",
    
    "relUrl": "/docs/git/Docker.html"
  },"215": {
    "doc": "Entity Listener",
    "title": "Entity Listener",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/entity-listener/src/test/java/com/example/entitylistener/MemberTest.java . Entity Listener를 사용하면 CRUD 이전과 이후에 메서드를 자동으로 실행할 수 있다. ------------------------- insert 이전 Hibernate: insert into ` member` ( `create_at`, `update_at`, `name` ) values (?, ?, ?) ------------------------- insert 이후 Member(id=8, name=John) Hibernate: select member0_.`id` as id1_0_0_, member0_.`create_at` as create_a2_0_0_, member0_.`update_at` as update_a3_0_0_, member0_.`name` as name4_0_0_ from `member` member0_ where member0_.`id`=? ------------------------- Select 호출 이후 ------------------------- Update 이전 Hibernate: update `member` set `update_at`=?, `name`=? where `id`=? ------------------------- Update 이후 ------------------------- Delete 이전 Hibernate: delete from `member` where `id`=? ------------------------- Delete 이후 . @PrePersist public void prePersist() { System.out.println(\"insert 이전\"); } @PostPersist public void postPersist() { System.out.println(\"insert 이후\"); } @PreUpdate public void preUpdate() { System.out.println(\"Update 이전\"); } @PostUpdate public void postUpdate() { System.out.println(\"Update 이후\"); } @PreRemove public void preRemove() { System.out.println(\"Delete 이전\"); } @PostRemove public void postRemove() { System.out.println(\"Delete 이후\"); } @PostLoad public void postLoad() { System.out.println(\"Select 호출 이후\"); } . @Getter @MappedSuperclass @EntityListeners(AuditingEntityListener.class) public abstract class BaseEntity { @CreatedDate @Column(updatable = false) private LocalDateTime createDateTime; @LastModifiedDate private LocalDateTime updateDateTime; } . @EnableJpaAuditing @SpringBootApplication public class Application extends SpringBootServletInitializer { @PostConstruct public void init() throws IOException { // 초기화 메서드 수행 } public static void main(String[] args) { SpringApplication.run(CmsApplication.class, args); } } . ",
    "url": "/docs/git/Entity%20Listener.html",
    
    "relUrl": "/docs/git/Entity%20Listener.html"
  },"216": {
    "doc": "GPT",
    "title": "GPT",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/gpt/src/main/java/com/example/gpt/application/gpt/GptService.java . GPT와 대화할때의 사용자 경험은 모든 텍스트가 완성된 후에 한번에 출력되는 것이 아닌, 스트림 방식으로 출력되게 된다. 이는 WebFlux를 사용하여 스트림 방식으로 데이터를 받아 출력하면 된다. 아래는 예제 코드이다. public Flux&lt;String&gt; streamResponse(String prompt) { GptRq request = new GptRq(\"gpt-3.5-turbo\", true, prompt); return webClient .post() .uri(getGptUri()) .header(\"Authorization\", \"Bearer \" + apiKey) .contentType(MediaType.APPLICATION_JSON) .bodyValue(request) .retrieve() .bodyToFlux(OpenAIResponse.class) .takeWhile(response -&gt; response.getChoices() != null &amp;&amp; response.getChoices().stream().noneMatch(choice -&gt; \"stop\".equals(choice.getFinish_reason()))) .flatMap(response -&gt; Flux.fromIterable(response.getChoices())) .map(choice -&gt; choice.getDelta().getContent()) .filter(content -&gt; content != null &amp;&amp; !content.isEmpty()) .onErrorResume(e -&gt; Flux.empty()); } . 일정하게 오는 객체를 파악하여 OpenAIResponse.class를 정의하여.bodyToFlux(OpenAIResponse.class)코드를 통해 변객체로 변환한다. 전달을 마무리하는 객체에는 response.getChoices().get(0)에 stop이라는 String값이 온다. 대게 0번째로 전달온다고 하지만 안정성을 위해 null처리 또는 stream().anyMatch()를 통해 처리한다. ",
    "url": "/docs/git/GPT.html",
    
    "relUrl": "/docs/git/GPT.html"
  },"217": {
    "doc": "GPT를 활용한 챗봇 기능 개발",
    "title": "GPT를 활용한 챗봇 기능 개발",
    "content": ". ",
    "url": "/docs/portfolio/GPT%EB%A5%BC%20%ED%99%9C%EC%9A%A9%ED%95%9C%20%EC%B1%97%EB%B4%87%20%EA%B8%B0%EB%8A%A5%20%EA%B0%9C%EB%B0%9C.html",
    
    "relUrl": "/docs/portfolio/GPT%EB%A5%BC%20%ED%99%9C%EC%9A%A9%ED%95%9C%20%EC%B1%97%EB%B4%87%20%EA%B8%B0%EB%8A%A5%20%EA%B0%9C%EB%B0%9C.html"
  },"218": {
    "doc": "GPT를 활용한 챗봇 기능 개발",
    "title": "GPT를 활용한 챗봇 설계 및 백엔드 API 개발",
    "content": ". | 상황 . | 리더십 평가 결과표는 다양한 항목과 지표로 구성되어 있어 일반 사용자가 해석하기에 어려움이 있을 수 있음. | 이를 해결하기 위해 사용자가 결과표 내 모르는 항목이나 해석이 필요한 부분에 대해 쉽게 설명을 제공하는 GPT 기반의 챗봇이 필요 | 기존 리더십 결과표 외에도 향후 다양한 종류의 결과표에도 적용 가능한 확장성 있는 시스템이 요구됨. | . | 과제 . | 대화가 길어질 경우 GPT 모델 사용에 따른 비용이 증가할 수 있으므로, 비용을 절감할 수 있는 효율적인 설계가 필요. | 현재 리더십 결과표 외에도 다른 다양한 결과표로 확장할 수 있도록 구조를 설계해야 하며, 각 결과표의 특성을 반영한 자연스러운 설명 제공이 필요. | . | 해결 . | GPT가 처리해야 할 대화 히스토리를 적절히 제한하여, 불필요한 토큰 사용을 최소화. | 세션당 사용되는 토큰 수를 모니터링하도록 설계하여 과도한 토큰 사용을 방지. | 컨텐츠 별로 나누어 데이터를 조회, GPT에게 필요한 데이터만 사전 제공하여 응답할 수 있도록 설계. | 다양한 결과표에 쉽게 적용될 수 있도록 모듈화된 구조로 설계, 새로운 결과표가 추가될 때는 해당 항목별 메타데이터를 바꿔 대화가 가능하도록 함. | . | 결과 . | 기존에는 PDF를 통해 용어집을 다운로드 받는 방식에서, 챗봇을 통해 리더십 결과표를 쉽게 이해할 수 있도록 모르는 용어나 해석에 대한 설명을 실시간으로 제공 | 비용 효율적인 설계를 통해 대화가 길어지더라도 불필요한 비용이 발생하지 않으며, 시스템이 안정적으로 확장 가능 | . | . ",
    "url": "/docs/portfolio/GPT%EB%A5%BC%20%ED%99%9C%EC%9A%A9%ED%95%9C%20%EC%B1%97%EB%B4%87%20%EA%B8%B0%EB%8A%A5%20%EA%B0%9C%EB%B0%9C.html#gpt%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%B1%97%EB%B4%87-%EC%84%A4%EA%B3%84-%EB%B0%8F-%EB%B0%B1%EC%97%94%EB%93%9C-api-%EA%B0%9C%EB%B0%9C",
    
    "relUrl": "/docs/portfolio/GPT%EB%A5%BC%20%ED%99%9C%EC%9A%A9%ED%95%9C%20%EC%B1%97%EB%B4%87%20%EA%B8%B0%EB%8A%A5%20%EA%B0%9C%EB%B0%9C.html#gpt를-활용한-챗봇-설계-및-백엔드-api-개발"
  },"219": {
    "doc": "Generics",
    "title": "Generics",
    "content": "@Entity @Getter @Inheritance(strategy = InheritanceType.JOINED) @DiscriminatorColumn(name = \"product_type\") @NoArgsConstructor(access = AccessLevel.PROTECTED) public abstract class Product { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @Column(name = \"product_type\", insertable = false, updatable = false) @Enumerated(EnumType.STRING) protected ProductType productType; @OneToOne(fetch = FetchType.LAZY) @JoinColumn(name = \"solver_content_version_id\") protected SolverContentVersion solverContentVersion; } @Getter @Entity @Table(name = \"product_leadership\") @DiscriminatorValue(\"LEADERSHIP\") @PrimaryKeyJoinColumn(name = \"product_id\") @NoArgsConstructor public class LeadershipProduct extends Product { @OneToOne(fetch = FetchType.LAZY) @JoinColumn(name = \"solver_grade_range_setting_id\") private SolverGradeRangeSetting gradeRangeSetting; public List&lt;SolverGradeRange&gt; getDefaultGradeRanges() { return this.gradeRangeSetting.getSolverGradeRanges(); } @Builder(builderMethodName = \"leadershipTestBuilder\") public LeadershipProduct(Long id, ProductType productType, DefaultAnalysisSettingInfo defaultAnalysisSettingInfo, SolverGradeRangeSetting gradeRangeSetting) { super(id, productType, defaultAnalysisSettingInfo); this.gradeRangeSetting = gradeRangeSetting; } } . @Getter @MappedSuperclass @NoArgsConstructor(access = lombok.AccessLevel.PROTECTED) @AllArgsConstructor(access = lombok.AccessLevel.PROTECTED) public abstract class BaseManagement&lt; Evaluator extends BaseEvaluator, Evaluation extends BaseEvaluation, Target extends BaseTarget, AnalysisStatus extends BaseAnalysisStatus, Notification extends BaseNotification &gt; implements Management { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) protected Long id; protected String title; protected Long productId; protected Integer evaluatorLimit; @Embedded protected Period period; @Enumerated(EnumType.STRING) protected BasicResultMethodType methodType; protected Boolean isOpen = false; protected Boolean isDeleted = false; @Embedded protected Description description = new Description(); protected LocalDateTime postDateTime; @Embedded protected Attention attention = new Attention(\"진단 전 체크리스트\", List.of( \"본 진단이 중요한 진단임을 알고 있다.\", \"누구보다 객관적으로 진단에 임할 것이다.\", \"다른 일을 미루고 진단에 집중할 것이다.\" )); @Getter(AccessLevel.PRIVATE) @OneToMany(mappedBy = \"management\", cascade = CascadeType.ALL, orphanRemoval = true) protected List&lt;Evaluator&gt; evaluators = new ArrayList&lt;&gt;(); @Getter(AccessLevel.PRIVATE) @OneToMany(mappedBy = \"management\", cascade = CascadeType.ALL, orphanRemoval = true) protected List&lt;Target&gt; targets = new ArrayList&lt;&gt;(); @OneToOne(fetch = FetchType.LAZY, cascade = CascadeType.ALL, orphanRemoval = true) @JoinColumn(name = \"analysis_status_id\") protected AnalysisStatus analysisStatus; @OneToOne(fetch = FetchType.LAZY, cascade = CascadeType.ALL, orphanRemoval = true) @JoinColumn(name = \"result_setting_id\") protected ResultSetting resultSetting; @OneToMany(mappedBy = \"management\", cascade = CascadeType.ALL, orphanRemoval = true) protected List&lt;Notification&gt; notifications = new ArrayList&lt;&gt;(); @Enumerated(EnumType.STRING) protected ResultReadScopeLeader leaderReadScope = ResultReadScopeLeader.NOT_ALLOWED; @Enumerated(EnumType.STRING) protected ResultReadScopeMember memberReadScope = ResultReadScopeMember.NOT_ALLOWED; } @Entity @Getter @AssociationOverrides({ @AssociationOverride( name = \"analysisStatus\", joinColumns = @JoinColumn(name = \"leadership_analysis_status_id\") ) }) @NoArgsConstructor(access = AccessLevel.PROTECTED) @AllArgsConstructor(access = AccessLevel.PRIVATE) public class LeadershipManagement extends BaseManagement&lt; LeadershipEvaluator, LeadershipEvaluation, LeadershipTarget, LeadershipAnalysisStatus, LeadershipNotification &gt; { @Enumerated(EnumType.STRING) private LeadershipManagementStep stepInfo = LeadershipManagementStep.TWO; } . private OrderSpecifier[] getOrderSpecifiers(Pageable pageable) { List&lt;OrderSpecifier&gt; orders = new ArrayList&lt;&gt;(); if (!pageable.getSort().isEmpty()) { for (Sort.Order order : pageable.getSort()) { Order direction = order.getDirection().isAscending() ? Order.ASC : Order.DESC; switch (order.getProperty()) { case ProbationResultTargetDto.Fields.id: orders.add(new OrderSpecifier(direction, probationTarget.id)); return orders.stream().toArray(OrderSpecifier[]::new); case ProbationResultTargetDto.Fields.name: orders.add(new OrderSpecifier(direction, member.name)); break; case ProbationResultTargetDto.Fields.organization: orders.add(new OrderSpecifier(direction, memberRole.organization.name)); break; case ProbationResultTargetDto.Fields.employeeId: orders.add(new OrderSpecifier(direction, member.employeeId)); break; case ProbationResultTargetDto.Fields.responsibility: orders.add(new OrderSpecifier(direction, memberRole.responsibility.name)); break; case ProbationResultTargetDto.Fields.isAnalyzed: orders.add(new OrderSpecifier(direction, solverProbationFactScore.isNull())); break; case ProbationResultTargetDto.Fields.totalScore: orders.add(new OrderSpecifier(direction, solverProbationFactScore.score)); break; case ProbationResultTargetDto.Fields.totalResult: orders.add(new OrderSpecifier(direction, solverProbationContent.totalResultType)); break; default: orders.add(new OrderSpecifier(Order.DESC, probationTarget.id)); break; } } } orders.add(new OrderSpecifier(Order.DESC, member.id)); return orders.stream().toArray(OrderSpecifier[]::new); } @Getter @Setter @NoArgsConstructor @AllArgsConstructor @FieldNameConstants &lt;- public class ProbationResultTargetDto { private Long id; //... } . ",
    "url": "/docs/git/Generics.html",
    
    "relUrl": "/docs/git/Generics.html"
  },"220": {
    "doc": "HikariCP",
    "title": "HikariCP",
    "content": "설정 코드 : https://github.com/mildw/doraemon/tree/main/jpa . ",
    "url": "/docs/git/HikariCP.html",
    
    "relUrl": "/docs/git/HikariCP.html"
  },"221": {
    "doc": "Init Database",
    "title": "Init Database",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/init-table-liquibase/src/main/java/com/example/inittableliquibase/application/database/DatabaseService.java . liquibase 사용 . 스키마 멀티테넌시를 사용하여 하나의 rds에 여러 기업의 스키마 존재 . 개발시 모든 테넌트의 동기화 작업에 불편함을 느낌 . 기존에는 단순 루프문을 통해 각 테넌트별 쿼리를 수행했다면 . 리큐베이스를 통해 모든 테넌트에 쿼리를 적용시키고 작동 여부를 각 테넌트에 저장함 . 리큐베이스는 로컬에 있는 sql파일을 읽어 수행하므로, 배포되어있는 각 환경에 적용하려면 리큐베이스를 작동시키는 프로젝트에 sql문을 추가하고 배포까지 해야함 . -&gt; s3에 sql파일을 저장하여 쿼리 추가시 s3로부터 파일을 다운받아 추가 작성하고 다시 S3에 저장 . 기업에서 계약시 테이블을 초기화해주는데에도 해당 기능으로 테이블을 초기화할 수 있도록 변경 . 각 환경별로 적용되어있는 테이블 형상이 다르다. 이 때 리큐베이스를 도입하기전에 고려해야할것은? . 리큐베이스는 버저닝을 통해 해당 쿼리를 수행했는지를 체크한다. 테이블 형상은 pr, st 환경이 같다 dv, qa 환경이 같다 (같게 만들 수 있다) . pr, st버전이 더 낮기 때문에 해당 환경 기준으로 동기화 버전이 시작되어야한다 . -&gt; pr기준의 테이블 형상으로 dv환경에 생성한 후 리큐베이스를 실행시켜 동기화 로그를 생성한다. 각 테넌트의 dv, qa환경 db에 해당 로그를 추가하여, 일치시킨다 . 변경 쿼리를 따로 관리해서 간단히 할 수 있을 것 같다. 따로 관리하지 않았더라고 해도, 인텔리제이의 db compare기능이 있으니 문제 없을 듯 하다 . 코드 . // Liquibase dependency implementation 'org.liquibase:liquibase-core:4.6.2' . Database database = null; Connection connection = null; connection = DriverManager.getConnection(\"jdbc:mariadb://localhost:3306/\" + schema, \"root\", \"1111\"); database = DatabaseFactory.getInstance() .findCorrectDatabaseImplementation(new liquibase.database.jvm.JdbcConnection(connection)); String changeLogPath = String.format(\"database/tenant/table_init.sql\"); Liquibase liquibase = new Liquibase(changeLogPath, new ClassLoaderResourceAccessor(), database); liquibase.update(new Contexts()); //try - catch - finally database.close(); connection.close(); . public Boolean initSchemas() { Bucket bucket = new Bucket(\"bucketName\",\"accessKey\",\"secretKey\"); //sql 파일 다운로드 S3Utils.downloadToLocal(bucket,s3ChangeLogPath+tableInitFileName); S3Utils.downloadToLocal(bucket,s3ChangeLogPath+tableUpdateFileName); boolean result = initTables(\"test\"); //sql 파일 삭제 deleteFile(changeLogPath+tableInitFileName); deleteFile(changeLogPath+tableUpdateFileName); return result; } public Boolean updateTables(String author, String query) { Bucket bucket = new Bucket(\"bucketName\",\"accessKey\",\"secretKey\"); //Sql 파일 다운로드 S3Utils.downloadToLocal(bucket,s3ChangeLogPath+tableUpdateFileName); //Pattern pattern = Pattern.compile(\"-- changeset\\\\s+\\\\w+:(\\\\d+)\"); //마지막 id값 추출 int lastId = getLastChangeSetId(changeLogPath+tableUpdateFileName); //file에 query 추가 updateSqlFile(author, query, lastId); List&lt;String&gt; schemas = List.of(\"test\"); boolean result = true; for (String schema : schemas) { if(!updateTable(schema)) { return false; } } if (result) { // 쿼리가 잘 실행 됐다면 S3에 파일 업로드 S3Utils.uploadFromLocal(bucket, s3ChangeLogPath + tableUpdateFileName); } return result; } . ",
    "url": "/docs/git/Init%20Database.html",
    
    "relUrl": "/docs/git/Init%20Database.html"
  },"222": {
    "doc": "JPA - Batch insert 성능 저하",
    "title": "JPA - Batch insert 성능 저하",
    "content": ". 벌크성 저장 로직 성능저하 원인에 대해 알아보자. jpa를 사용하면서 엔티티를 정의할때 아래와 같이 IDENTITY 를 많이 사용하고 있었다. GenerationType.IDENTITY : 기본키 생성을 DB에 위임한다 . @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer sn; . mysql을 사용하면서 pk를 autoincrement 를 사용하면 자연스럽게 IDENTITY 를 사용하게된다. jpa에서는 saveAll( { any_object } ) 와 같은 벌크성 저장을 할 것 같은 함수를 지원하는데, . 이는 IDENTITY 를 사용하게되면 지원하지 않게된다. 이는 people.size()가 100,000 의 데이터를 saveAll(people) 함수를 통해 저장할 경우 쿼리가 10만개 날아간다 . 이유는 새로 할당할 Key 값을 미리 알 수 없는 IDENTITY 방식을 사용할 때 Batch Support를 지원하면 Hibernate가 채택한 flush 방식인 Transactional Write Behind와 충돌이 발생하기 때문에, IDENTITY 방식에서는 Batch Insert를 비활성화 한다는 얘기다. 따라서 그냥 일상적으로 가장 널리 사용하는 IDENTITY 방식을 사용하면 Batch Insert는 동작하지 않는다. stackoverflow . ",
    "url": "/docs/memo/JPA%20-%20Batch%20insert%20%EC%84%B1%EB%8A%A5%20%EC%A0%80%ED%95%98.html",
    
    "relUrl": "/docs/memo/JPA%20-%20Batch%20insert%20%EC%84%B1%EB%8A%A5%20%EC%A0%80%ED%95%98.html"
  },"223": {
    "doc": "JPA - Batch insert 성능 저하",
    "title": "해결방법",
    "content": "SEQUENCE 또는 TABLE 전략 사용 . SEQUENCE 와 TABLE 를 사용하는 방법은 잘못 사용할 경우 본인 생각대로 작동하지 않을 위험이 있기때문에 채택하지 않았다. ( SEQUENCE 는 mysql에서 지원하지 않음 ) . UUID 사용 . uud를 id 값으로 사용하는 방법이 있다. 이는 보안상으로 좋을 수 있다. 채택하지 않은 단점으로는 . | 16 byte 를 사용하여 기존의 int형의 컬럼보다 큰 용량을 차지한다 | 외래키로 사용될때 16 byte를 사용한다는 단점은 극대화된다. | insert를 실행할때 uuid를 만들어야 하기때문에 성능에 저하가 있다. | 확률은 적지만 uuid가 중복될 수 있는점을 고려해야한다. | 정렬하는데 사용할 수 없다. | . jdbc 사용 . 또는 jooq사용 . jdbc를 사용하는 방향으로 채택했다. 이유는 성능저하가 느껴지는 대량의 insert 기능은 우리 서비스에 많지 않다. 또한 서비스의 규모가 분산 DB를 사용할정도가 아니기 때문에 auto increment를 사용하는데 제한적이지 않다. ",
    "url": "/docs/memo/JPA%20-%20Batch%20insert%20%EC%84%B1%EB%8A%A5%20%EC%A0%80%ED%95%98.html#%ED%95%B4%EA%B2%B0%EB%B0%A9%EB%B2%95",
    
    "relUrl": "/docs/memo/JPA%20-%20Batch%20insert%20%EC%84%B1%EB%8A%A5%20%EC%A0%80%ED%95%98.html#해결방법"
  },"224": {
    "doc": "JPA - OneToOne 성능 저하",
    "title": "JPA - OneToOne 성능 저하",
    "content": ". 테이블을 설계할 때 정규화 등의 목적으로 1 대 1 관계로 설계했었다. OneToOne의 N+1문제를 모른체 JPA를 사용하는 프로젝트였던 만큼 당연하게 OneToOne을 사용했다. fetch join을 통해서 N+1문제는 없앨 수 있었다. fetch join을 통해서 가져오는 데이터의 양이 너무 방대해서 또 다른 이슈를 발생시켰다. join으로 인해 너무 많은 데이터로 인해 처리가 오래 걸리고, 프로젝트 간 통신이 끊겼던 것이다. @OneToOne(fetch = FetchType.LAZY , optional = false) @JoinColumn(name = \"example_parent_property_sn\") private ExampleParentProperty exampleParentProperty;﻿ . 핫픽스 건이라 급하게 이슈를 처리해야 했고, 그 대안으로 엔티티를 똑같이 복사해서 OneToOne인 부분만 주석 처리했다.(양방향 관계-&gt; 단방향 관계) . 이렇게 해서 부모 엔티티에서 자식 엔티티(대량의 데이터) 관계를 끊었다. 앞으로 1:1 관계의 테이블은 상황을 고려하여 부모 테이블에 fk를 두는것도 고려하자. 학습 내용 . jpa를 사용하면서 gradle에 . implementation 'com.github.gavlyukovskiy:p6spy-spring-boot-starter:1.5.8' . 를 추가해주면 실제로 호출되는 쿼리를 확인할 수 있다. N+1 문제는 다음과 같은 상황을 말한다. 부모객체를 findAll()을 통해 조회(1번)를 한다. 이때 부모객체에 속해있는 자식 객체를 사용하기 위해서 또 한 번의 쿼리를 발생하는 것이 N+1문 제이다. 위의 사진에서는 4개의 부모 객체가 있고, 자식 객체를 사용하기 위해 4번의 쿼리를 더 발생시키고 있다. N+1문제 발생 원인 . JPA를 그냥 사용할 경우 자식 객체를 따로 호출하는데서 발생한다. JPQL은 Java Persistence Query Language의 약자로, DB 테이블이 아니라 엔티티의 객체를 대상으로 검색하는 객체 지향 쿼리이다. jpaRepository에 정의한 인터페이스 메서드를 실행하면 JPA는 메서드 이름을 분석해서 JPQL을 생성하여 실행하게 된다. JPQL은 SQL을 추상화한 객체지향 쿼리 언어로서 특정 SQL에 종속되지 않고 엔티티 객체와 필드 이름을 가지고 쿼리를 한다. 그렇기 때문에 JPQL은 findAll()이란 메소드를 수행하였을 때 해당 엔티티를 조회하는 select * from Owner 쿼리만 실행하게 되는것이다. JPQL 입장에서는 연관관계 데이터를 무시하고 해당 엔티티 기준으로 쿼리를 조회하기 때문이다. 그렇기 때문에 연관된 엔티티 데이터가 필요한 경우, FetchType으로 지정한 시점에 조회를 별도로 호출하게 된다. 출처 - https://incheol-jung.gitbook.io/docs/q-and-a/spring/n+1 . @Entity @Data @NoArgsConstructor public class ExampleParent { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long sn; private String name; @OneToMany(fetch = FetchType.LAZY, cascade = CascadeType.ALL) @JoinColumn(name = \"example_parent_sn\") private List&lt;ExampleChild&gt; exampleChildList = new ArrayList&lt;&gt;(); public ExampleParent(String name) { this.name = name; } public void addExampleChild(ExampleChild exampleChild) { this.exampleChildList.add(exampleChild); exampleChild.setExampleParent(this); } } . 부모 객체가 자식 객체를 호출하는 방법으로 . @OneToMany, @ManyToOne, @OneToOne은 자식 객체에 대해 정의할 때 옵션 값을 통해 호출 시점을 정할 수 있다. FetchType.EAGER : 객체를 미리 호출한다. FetchType.LAZY : 객체를 사용할 때 호출한다. EAGER옵션을 사용하면 무조건 N+1 이슈가 발생하기 때문에 특별한 경우가 아닌 이상 LAZY옵션을 사용하는 걸 권장한다. 두 옵션다 N+1을 발생하는 건 마찬가지이기 때문에 다른 조치가 필요하다. N+1문제 해결 . 1. Join Fetch . 다음과 같이 부모 객체를 조회할 때 자식 객체를 조인해서 가져올 수 있다. @Query(\"select p from ExampleParent p join fetch p.exampleChildList\") List&lt;ExampleParent&gt; findAllJoinFetch(); . 실행 결과로 N+1문제가 발생하지 않는 것을 확인할 수 있다. 2. QueryDsl . 두 번째는 queryDsl을 사용하는 방법이 있다. QueryDsl을 사용하여 fetch join하거나 원하는 필드만 조회하여 문제를 해결 할 수 있다. 다음은 fetch join의 예제 코드이다. @Override public List&lt;ExampleParent&gt; findAllLeftJoinExampleChild() { return from(exampleParent) .leftJoin(exampleParent.exampleChildList, exampleChild) .fetchJoin() .fetch(); } . 마찬가지로 N+1 문제가 발생하지 않고 로직을 수행하는 것을 볼 수 있다. 아래는 sn, name만을 필드로 가진 ExampleParentDto를 생성하여 그것만 조회할 수 있도록 하는 코드이다. @Override public List&lt;ExampleParentDto&gt; getAllExampleParentDto() { return from(exampleParent) .select(Projections.fields(ExampleParentDto.class, exampleParent.sn, exampleParent.name )) .fetch(); } . 이렇게 필요한 부분만 조회를 하면 자식객체를 불러올 일이 없기 때문에 N+1문제가 발생하지 않는다. 추가 . 다음은 @OneToOne을 추가한 부모 객체 코드이다. @Entity @Data @NoArgsConstructor public class ExampleParent { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long sn; private String name; @OneToOne(fetch = FetchType.LAZY, cascade = CascadeType.ALL) @JoinColumn(name = \"example_parent_property_sn\") private ExampleParentProperty exampleParentProperty; @OneToMany(fetch = FetchType.LAZY, cascade = CascadeType.ALL) @JoinColumn(name = \"example_parent_sn\") private List&lt;ExampleChild&gt; exampleChildList = new ArrayList&lt;&gt;(); public ExampleParent(String name) { this.name = name; this.exampleParentProperty = new ExampleParentProperty(10000L); } public void addExampleChild(ExampleChild exampleChild) { this.exampleChildList.add(exampleChild); exampleChild.setExampleParent(this); } } . 그리고 위에서 실행한 메서드를 그대로 실행했을 때 쿼리문을 살펴보자. 위에서 다뤘던 N+1의 경우는 사용할 경우에만 호출하는 반면, @OneToOne의 경우는 LAZY를 설정하고 사용하지 않았는데도 호출을 하고 있다.  . (lazy load 동작하지 않는 이유 공부) . 2.1.2.1. Lazy Loading - 객체 그래프 탐색 &amp; Proxy . 그렇다면 왜 Lazy 글로벌 패치 설정이 동작하지 않았을까? . JPA에선 객체 그래프 탐색이라는 논리적인 개념이 존재한다. 특정 도메인 객체를 조회할 때 연관 관계를 맺은 각각의 도메인의 글로벌 패치 전략을 판단하다. 이때 Lazy 전략으로 설정된 도메인에 대해선 내부적으로 default 생성자를 통해 Proxy 객체를 생성하고(참고 CGLIB) 조회할 도메인 객체는 생성된 Proxy 객체를 참조하게 된다. 즉 nullable한 도메인에 대해선 Proxy 객체 생성을 보장할 수 없다. 따라서 Lazy 패치 전략이더라도 내부적으로 객체간 참조를 보장하기 위해 쿼리를 발생시켜 연관된 객체에 데이터를 매핑시키는 동작 방식을 취하게 된다. Member와 MemberOption의 OneToOne관계로 봤을때, . 이를 토대로 앞서 본 테스트 결과를 분석하면 다음과 같다. MemberOption 클래스가 Proxy가 아니다. nullable한 OneToOne 관계라면, Proxy 객체를 감싸지 않고 내부적으로 객체를 반환한다. 단. Collection(*ToMany)은 다른 방식을 취한다. MemberOption 필드에 접근하지 않았음에도 MemberOption를 조회 쿼리가 발생한다. 하이버네이트는 객체 그래프 탐색하는 시점에 Lazy로 판단하여 쿼리 생성 시 Member 쿼리만 생성하게 된다.  . 하지만 MemberOption은 Proxy 객체가 아니므로 MemberOption 쿼리가 발생하여 참조 받을 수 있도록 쿼리를 발생시키게 된다. lazy load가 동작하기 위해서는 proxy보장되어야 하고, . Proxy 생성을 보장하기 위해선 non-null 관계가 형성되어야 한다. JPA의 연관관계 관련된 어노테이션에는 optional이라는 속성이 존재한다. 다음 속성을 통해 Proxy 생성을 보장하면 된다. @OneToOne(fetch = FetchType.LAZY , cascade = CascadeType.ALL , optional = false) // false - non-null, true - nullable @JoinColumn(name = \"example_parent_property_sn\") private ExampleParentProperty exampleParentProperty; . 또는 fetchType을 EAGER로 설정하게 되면 자동으로 join 해서 불러올 수 있다. 하지만, 사용하지 않는 데이터까지 무작정 가져오게 되면 메모리 낭비가 될 수 있다. ",
    "url": "/docs/memo/JPA%20-%20OneToOne%20%EC%84%B1%EB%8A%A5%20%EC%A0%80%ED%95%98.html",
    
    "relUrl": "/docs/memo/JPA%20-%20OneToOne%20%EC%84%B1%EB%8A%A5%20%EC%A0%80%ED%95%98.html"
  },"225": {
    "doc": "JPA - inheritance",
    "title": "조인 테이블 전략",
    "content": "Join Table Inheritance . @Entity @Inheritance(strategy = InheritanceType.JOINED) @DiscriminatorColumn(name = \"DTYPE\") public abstact class Item() { @Id @GeneratedValue @Column(name = \"itme_id\") private Long id; private String name; private int price; } @Entity @DiscriminatorValue(\"A\") public class Album extends Item { private String artist; } @Entity @DiscriminatorValue(\"M\") public class Movie extends Item { private String director; private String actor; } @Entity @DiscriminatorValue(\"B\") @PrimaryKeyJoinColumn(name = \"book_id\") // id 재정의 public class Book extends Item { private String author; private String isbn; } . | 장점 . | 테이블 정규화 | 외래 키 참조 무결성 제약조건 활용 | 저장 공간 효율적 사용 | . | 단점 . | 조회할 때 조인으로 인한 성능 저하 | 복잡한 조회 쿼리 | 1번의 Insert 쿼리가 N번으로 늘어날 수 있음 | . | . ",
    "url": "/docs/git/JPA%20-%20inheritance.html#%EC%A1%B0%EC%9D%B8-%ED%85%8C%EC%9D%B4%EB%B8%94-%EC%A0%84%EB%9E%B5",
    
    "relUrl": "/docs/git/JPA%20-%20inheritance.html#조인-테이블-전략"
  },"226": {
    "doc": "JPA - inheritance",
    "title": "단일 테이블 전략",
    "content": "Single Table Inheritance . @Entity @Inheritance(strategy = InheritanceType.SINGLE_TABLE) @DiscriminatorColumn(name = \"DTYPE\") public abstact class Item() { @Id @GeneratedValue @Column(name = \"itme_id\") private Long id; private String name; private int price; } // joined와 동일하다 @Entity @DiscriminatorValue(\"A\") public class Album extends Item { private String artist; } @Entity @DiscriminatorValue(\"M\") public class Movie extends Item { private String director; private String actor; } @Entity @DiscriminatorValue(\"B\") public class Book extends Item { private String author; private String isbn; } . | 장점 . | 조인이 필요없으므로 성능이 빠름 | 조회 쿼리가 단순함 | . | 단점 . | 자식 엔티티가 매핑한 컬럼은 모두 null을 허용해야함 | 단일 테이블에 모든것을 저장하므로 테이블이 커짐, 그러므로 상황에 따라 성능이 느려질 수 있음 | . | 특징 . | 구분 컬럼을 꼭 사용해야함 (@DiscriminatorValue 필수) | DiscriminatorValue이름을 지정해주지않는다면 기본으로 엔티티 이름을 사용함 | . | . ",
    "url": "/docs/git/JPA%20-%20inheritance.html#%EB%8B%A8%EC%9D%BC-%ED%85%8C%EC%9D%B4%EB%B8%94-%EC%A0%84%EB%9E%B5",
    
    "relUrl": "/docs/git/JPA%20-%20inheritance.html#단일-테이블-전략"
  },"227": {
    "doc": "JPA - inheritance",
    "title": "테이블 별 클래스 전략",
    "content": "Table Per Class Inheritance . @Entity @Inheritance(strategy = InheritanceType.TABLE_PER_CLASS) public abstact class Item() { @Id @GeneratedValue @Column(name = \"itme_id\") private Long id; private String name; private int price; } // joined와 동일하다 @Entity public class Album extends Item { private String artist; } @Entity public class Movie extends Item { private String director; private String actor; } @Entity public class Book extends Item { private String author; private String isbn; } . 해당 전략은 자식 엔티티마다 테이블을 만든다. 일반적으로 추천하지 않는 전략 . | 장점 . | 서브 타입을 구분해서 처리할 때 효과적 | not null 제약 조건을 사용할 수 있음 | . | 단점 . | 여러 자식 테이블을 함께 조회할 때 성능이 느림 (UNION 쿼리 불가피) | 자식 테이블을 통합해서 쿼리하기 어려움 | . | 특징 . | 구분 컬럼을 사용하지 않음 | . | . ",
    "url": "/docs/git/JPA%20-%20inheritance.html#%ED%85%8C%EC%9D%B4%EB%B8%94-%EB%B3%84-%ED%81%B4%EB%9E%98%EC%8A%A4-%EC%A0%84%EB%9E%B5",
    
    "relUrl": "/docs/git/JPA%20-%20inheritance.html#테이블-별-클래스-전략"
  },"228": {
    "doc": "JPA - inheritance",
    "title": "MappedSuperclass",
    "content": "활용 예제 [[Entity Listener]] . @Getter @MappedSuperclass @EntityListeners(AuditingEntityListener.class) public abstract class BaseEntity { @CreatedDate @Column(updatable = false) private LocalDateTime createDateTime; @LastModifiedDate private LocalDateTime updateDateTime; } . BaseEntity는 테이블 매핑이 필요없고, 자식 엔티티에게 공통으로 사용되는 매핑 정보만 제공하면 됨 . @Entity @AttributeOverrides({ @AttributeOverride(name = \"createDateTime\", @Column(name = \"create_at\")), @AttributeOverride(name = \"updateDateTime\", @Column(name = \"update_at\")) }) public class Member extends BaseEntity { //... } . @MappedSuperclass로 지정한 클래스는 엔티티가 아니므로 em.find()나 JPQL에서 사용할 수 없음 . ",
    "url": "/docs/git/JPA%20-%20inheritance.html#mappedsuperclass",
    
    "relUrl": "/docs/git/JPA%20-%20inheritance.html#mappedsuperclass"
  },"229": {
    "doc": "JPA - inheritance",
    "title": "JPA - inheritance",
    "content": "프로젝트를 진행하면서 @inheritance를 사용하려고합니다. 사용하려는 부분은 응답과 진단 부분입니다. 응답 ├─ 단일 응답 ├─ 다중 응답 ├─ 순위 응답 └─ 텍스트 응답 . @inheritance를 사용하여 ‘응답’이라는 공통적인 메서드가 있으면 좋을것 같습니다. 역량진단 └─ 대상자, 진단자 상태 스냅샷 └─ 대상자, 진단자 └─ 진단 ├─ 진단 응답 └─ 진단 분석 결과 수습진단 └─ 대상자, 진단자 └─ 회차 └─ 진단 ├─ 진단 응답 └─ 진단 분석 결과 . 진단 타입에 따라 가지고있는 정보가 조금씩 다르지만 공통되는 동작이 있어 상속을 받으면 좋을 것 같습니다. 짧은 결론 응답부분에만 상속을 적용했습니다. 책 또는 인터넷 상의 대부분이 간단한 예시로 장점을 부각하고 있습니다. (부모 - 자식) 하지만 상속 계층이 깊어지는 경우 (회사 - 부서 - 팀 - 직원) 쿼리를 작성할때 조인이 깊어지고 복잡성이 증가할 수 있기 때문에 진단에서는 사용하지 않았습니다. 참고 https://browndwarf.tistory.com/m/55 . JPA를 사용하면 상속 관계의 테이블은 어떻게 구성해야하는지 알아보겠습니다. Inheritance - 상속 관계를 매핑하기 위한 다양한 어노테이션입니다. 주요한 상속 전략에는 . | 단일 테이블 전략 | 테이블 별 클래스 전략 | 조인 테이블 전략이 있습니다. | . 조인 테이블 전략(Join Table Inheritance): - @Inheritance(strategy = InheritanceType.JOINED): 각 엔티티 클래스에 대해 별도의 테이블을 생성하고, 부모 클래스와 자식 클래스 사이의 관계를 유지하기 위해 조인 테이블을 사용합니다. ![[Pasted image 20240410154646.png]] . 단일 테이블 전략(Single Table Inheritance): - @Inheritance(strategy = InheritanceType.SINGLE_TABLE): 부모 클래스와 자식 클래스의 모든 필드를 하나의 테이블에 매핑합니다. - @DiscriminatorColumn(name = \"discriminator_column_name\"): 단일 테이블에 저장된 각 엔티티를 식별하기 위한 컬럼을 지정합니다. - @DiscriminatorValue(\"entity_discriminator_value\"): 각 엔티티의 구분 값을 지정합니다. ![[Pasted image 20240410154702.png]] . 테이블 별 클래스 전략(Table Per Class Inheritance): - @Inheritance(strategy = InheritanceType.TABLE_PER_CLASS): 각 엔티티 클래스마다 별도의 테이블을 생성합니다. ![[Pasted image 20240410154724.png]] . 선택 가이드라인 . | 상속 구조가 단순하고 조회 성능이 중요한 경우 단일 테이블 전략을 사용합니다. | 데이터베이스 정규화가 중요하고 테이블 관리가 용이해야 하는 경우 조인 전략을 사용합니다. | 상속 구조가 복잡하고 각 엔티티의 속성이 독립적인 경우 구현 클래스마다 테이블 전략을 사용합니다. | 코드 중복을 줄이고 유지 관리를 용이하게 하려는 경우 MappedSuperClass 전략을 사용합니다. | . ",
    "url": "/docs/git/JPA%20-%20inheritance.html",
    
    "relUrl": "/docs/git/JPA%20-%20inheritance.html"
  },"230": {
    "doc": "JPA",
    "title": "JPA",
    "content": "설정 코드 : https://github.com/mildw/doraemon/tree/main/jpa . 영속성 실험 1 객체 수정 후 다른 객체와 함께 리스트 조회 2 객체 수정 후 자식객체와 함께 조인 조회 . ",
    "url": "/docs/git/JPA.html",
    
    "relUrl": "/docs/git/JPA.html"
  },"231": {
    "doc": "JWT token",
    "title": "JWT token",
    "content": "설정 코드 : https://github.com/mildw/doraemon/tree/main/core/src/main/java/com/example/core/jwt . ",
    "url": "/docs/git/JWT%20token.html",
    
    "relUrl": "/docs/git/JWT%20token.html"
  },"232": {
    "doc": "JWT",
    "title": "JWT",
    "content": ". ",
    "url": "/docs/memo/JWT.html",
    
    "relUrl": "/docs/memo/JWT.html"
  },"233": {
    "doc": "JWT",
    "title": "session",
    "content": "세션은 서버의 메모리에 생성되는 저장 공간이다. 이 안에 로그인한 유저의 정보가 저장이 된다. 세션에 저장된 정보에는 고유의 세션ID가 부여된다. 사용자가 로그인을 하면 서버는 쿠키에 세션ID를 실어서 브라우저에게 보내준다. 기존에 구현한 Session은 로그인 하면 . | Session에 로그인 정보를 저장하고 그 정보를 이용한다. | 로그인을 하면 Session Id가 생성되어 Front End에 쿠키로 전달되고, 그 난수가 Session에 저장된다. | 이후 클라이언트의 요청이 있을 때 마다 withCredentials 설정을 통해 함께 전달된 쿠키를 Session에 저장된 정보와 확인한다. | 이후 확인이 완료되면 DB에서 해당 유저정보를 가져와 Request의 user에 값을 넣어준다. | . 쿠키의 세션 아이디를 다른 컴퓨터에 저장하면 로그인이 될까? . 결론만 말하자면 가능하다. 로그인이 가능한 웹사이트에서 로그인 후에 JSESSIONID(톰캣 서버가 부여해준 세션 쿠키 ID)를 로그인 된 Session Id로 바꿔치기 해주면 Id, Password 없이 로그인이 된다. 그럼 보안이 너무 취약한 것 아니야? 라고 생각할 수도 있다. 하지만 이 방식으로 로그인이 가능해지려면 웹사이트가 SSL이 적용되어있지 않은 Http 사이트여야한다.  요즘 대부분의 사이트는 Https로 SSL을 사용하기 때문에 이러한 문제는 발생하지 않는다. SSL이 적용이 되면 송수신자는 공개키-비밀키 암호화 방식을 통해서 Session Id를 전달받기 때문에 송수신자가 일치하지 않으면 로그인을 시켜주지 않는다. 이로인해 중간자 공격, 세션 하이재킹, 스니핑 공격 등으로부터 안전해진다. — . ▪ 저장 공간의 용량 세션은 서버의 메모리 내부에 저장이 된다. 유저가 한두명일때야 메모리에 무리가 가지 않겠지만 유저가 수천명인 대형 서비스에서는 세션의 양이 많아지는 만큼 메모리에 부하가 걸릴 수 있다. ▪ 확장성의 문제 서비스의 규모가 커져서 서버를 여러대로 확장 및 분산해야 한다면 세션을 분산시키는 기술을 따로 설계해야 한다. 이를 해결하기 위해 보통 JWT라는 로그인 방식을 도입한다. ",
    "url": "/docs/memo/JWT.html#session",
    
    "relUrl": "/docs/memo/JWT.html#session"
  },"234": {
    "doc": "JWT",
    "title": "jwt",
    "content": "stateless와 stateful: 상태값을 서버에서 저장하고 있다는 의미. HTTP는 무상태(stateless) 프로토콜이므로 상태를 유지하기 위해 모든 request에 cookie를 보낸다. bearer token: Authorization 헤더에 “Bearer 토큰이런식으로보내는데의을헤더의토큰”이런식으로보내는데oauth의accesstoken을헤더의{토큰} 영역에 담아서 요청에 사용한다. 참고로 access_token은 서버에서 쿠키처럼 액세스토큰 저장소에 저장해서 상태(stateful) 형태로 구현할수 있고 jwt 토큰을 써서 무상태로 구현할 수 있다. jwt: json web token의 약자로 header, payload, signature로 구성되어 있다. base64로 인코딩 되어있기 때문에 디코딩하면 사용자 식별정보들을 볼 수 있다. 악의적인 변조를 막기 위해 signature 영역은 암호화 알고리즘을 적용해서 서버에서는 사용자로부터 받은 request의 유효성을 확인하기 위해 signature 부분을 통해 validate를 진행하고 성공시 payload 영역을 base64 디코딩하고 json 문자열을 파싱해서 사용자 식별을 위한(java로 예를 들면 Principal이 될 수 있겠다.) 객체를 만들고 이를 통해 authorization을 진행 . - `iss`: 토큰 발급자 (issuer) - `sub`: 토큰 제목 (subject) - `aud`: 토큰 대상자 (audience) - `exp`: 토큰의 만료시간 (expiraton), 시간은 NumericDate 형식으로 되어있어야 하며 (예: 1480849147370) 언제나 현재 시간보다 이후로 설정되어있어야합니다. - `nbf`: Not Before 를 의미하며, 토큰의 활성 날짜와 비슷한 개념입니다. 여기에도 NumericDate 형식으로 날짜를 지정하며, 이 날짜가 지나기 전까지는 토큰이 처리되지 않습니다. - `iat`: 토큰이 발급된 시간 (issued at), 이 값을 사용하여 토큰의 `age` 가 얼마나 되었는지 판단 할 수 있습니다. - `jti`: JWT의 고유 식별자로서, 주로 중복적인 처리를 방지하기 위하여 사용됩니다. 일회용 토큰에 사용하면 유용합니다. 참고 : 보안 참고 : 보안 . JWT는 JSON Web Token의 약자로 전자 서명된 URL-safe(URL로 이용할 수 있는 문자로 구성된)의 JSON으로 유저를 인증하고 식별하기 위한 토큰(Token) 기반 인증이며, RFC 7519를 통해 자세한 명세를 확인할 수 있다. 웹에서 사용자 인증 정보를 클라이언트에 보관하는 쿠키 방식이 보안에 취약하다는 이유로 서버 측에 인증 정보를 보관하는 점점 세션을 권장 및 사용하는 형태로 변경되었지만 JWT는 다시 인증 정보를 토큰에 심고 클라이언트에 보관하는 방식을 채택했다. JWT는 JSON 데이터를 Base64 URL-safe Encode를 통해 인코딩하여 직렬화한 것이 포함되며, 토큰 내부에는 위변조 방지를 위해 개인키를 이용한 전자서명도 있다. 따라서 사용자가 JWT를 서버로 전송하면 서버는 서명을 검증하는 과정을 거치게 되며, 검증이 완료되면 요청한 응답을 돌려준다. Access Token &amp; Refresh Token . Refresh Token은 Access Token과 똑같은 형태의 JWT이다. Refresh Token은 긴 유효기간을 가지면서, Access Token이 만료됐을 때 새로 발급해주는 열쇠가 된다. 인증 순서 . 일반적으로 JWT를 사용하는 경우 아래와 같은 순서로 진행된다. 1) 클라이언트 사용자가 아이디, 패스워드를 통해 웹 서비스 인증 2) 서버에서 서명된(Signed) JWT를 생성하여 클라이언트에 응답으로 회신 3) 클라이언트가 서버에 데이터를 추가적으로 요구할 때 JWT를 HTTP Header 또는 URL 파라미터로 첨부 4) 서버에서 클라이언트로부터 온 JWT를 검증 . | 장점 JWT를 이용하면 따로 서버의 메모리에 저장 공간을 확보할 필요가 없다. 서버가 토큰을 한번 클라이언트에게 보내주면 클라이언트는 토큰을 보관하고 있다가(가장 쉬운 방법은 localstorage에 저장하는 것이다) 요청을 보낼때마다 헤더에 토큰을 실어보내면 된다. 쿠키를 사용할 수 없는(쿠키는 웹브라우저에서 사용할수 있는 기능이다!) 모바일 어플리케이션에는 JWT를 사용한 인증방식이 최적이다. | 단점 JWT는 HTTP를 통해서 전송하기 때문에 페이로드의 크기가 클수록 데이터 전송에 있어서 비용이 커진다. JWT는 유효기간을 따로 정하지 않는 이상 소멸되지 않기 때문에 장기간 방치시 해킹의 위험이 커진다. JWT를 localstorage에 보관한다면 XSS공격에 취약해진다. | (XSS는 외부의 해커가 우리의 프 로그램에 특정 javascript 코드를 심어서 localstorage에 접근하는 공격이다.) | 보통 httpOnly가 설정되서 브라우저만 접근 가능한 쿠키에 토큰을 실어보내서 XSS 공격을 막는다. | . | . ",
    "url": "/docs/memo/JWT.html#jwt-1",
    
    "relUrl": "/docs/memo/JWT.html#jwt-1"
  },"235": {
    "doc": "Kafka",
    "title": "kafka install",
    "content": "카프카 설치 방법과, cmd에서 토픽 발행, 메시지 프로듀스, 컨슘 명령어를 정리해두었다. https://kafka.apache.org/quickstart . curl \"https://downloads.apache.org/kafka/3.3.1/kafka_2.13-3.3.1.tgz\" -o ~/kafka/kafka_2.13-3.3.1.tgz tar -xzf kafka_2.13-3.3.1.tgz cd kafka_2.13-3.3.1 . create topic . bin/kafka-topics.sh --create --topic quickstart-events --bootstrap-server localhost:9092 . check topic . bin/kafka-topics.sh --describe --topic quickstart-events --bootstrap-server localhost:9092 . produce . bin/kafka-console-producer.sh --topic quickstart-events --bootstrap-server localhost:9092 . consum . bin/kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server localhost:9092 . ",
    "url": "/docs/git/Kafka.html#kafka-install",
    
    "relUrl": "/docs/git/Kafka.html#kafka-install"
  },"236": {
    "doc": "Kafka",
    "title": "﻿﻿Kafdrop : Kafka Web UI 사용해 보기",
    "content": "GitHub - obsidiandynamics/kafdrop: Kafka Web UI . GitHub - provectus/kafka-ui: Open-Source Web UI for Apache Kafka Management . 위의 두개가 실행방법에는 큰 차이가 없다. 선호에 따라 골라 사용하자. Apache Kafka . Apache Kafka: A Distributed Streaming Platform. kafka.apache.org . 카프카 메시지 조회가 너무 불편하다. web ui 로 편리하게 토픽을 조회할 수 있는 kafdrop 이란 걸 발견했다. 만약 인텔리제이를 사용한다면, . | **Kafka monitoring | IntelliJ IDEA** | . www.jetbrains.com . 플러그인을 고려해 보자. (너무 늦게알았다) . // 아래 명령어에서 &lt;host:port,host:port&gt; 부분만 수정해서 실행하면 된다. docker run -d --rm -p 9000:9000 \\ -e KAFKA_BROKERCONNECT=&lt;host:port,host:port&gt; \\ -e JVM_OPTS=\"-Xms32M -Xmx64M\" \\ -e SERVER_SERVLET_CONTEXTPATH=\"/\" \\ obsidiandynamics/kafdrop // 명령어 실행 후 문구 Unable to find image 'obsidiandynamics/kafdrop:latest' locally latest: Pulling from obsidiandynamics/kafdrop e0b25ef51634: Pull complete d1bd2bc15eb1: Pull complete 77d0de1fd7e0: Pull complete b638505435dc: Pull complete 8bbf85e38402: Pull complete 1ceef1d1d525: Pull complete 643cf0d075ea: Pull complete Digest: sha256:5337c9e0e2dee204bdde53e90cf97001f44fb9e8c3380340436efa844901a3f4 Status: Downloaded newer image for obsidiandynamics/kafdrop:latest a8d978f7e0d0a715dfef2e0f0a6c69fd6faf4023d5d16611b8bd7a5dcba6103d kms0428@kms0428-laptop:~$ . 아래는 kafka-ui 의 명령어로 실행하는데 큰 차이가 없다. docker run -p 8080:8080 \\ -e KAFKA_CLUSTERS_0_NAME=local \\ -e KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092 \\ -d provectuslabs/kafka-ui:latest . ﻿ ![[kafdropimage.png]] . localhost:9000으로 접근하게 되면 위와 같은 화면을 볼 수 있다. ﻿ 끄고 싶다면 컨테이너를 종료시켜주자. ",
    "url": "/docs/git/Kafka.html#kafdrop--kafka-web-ui-%EC%82%AC%EC%9A%A9%ED%95%B4-%EB%B3%B4%EA%B8%B0",
    
    "relUrl": "/docs/git/Kafka.html#kafdrop--kafka-web-ui-사용해-보기"
  },"237": {
    "doc": "Kafka",
    "title": "Kafka",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/kafka/src/main/java/com/example/kafka/config/kafka/KafkaConfig.java . Apache Kafka ![[producer_consumer.png]] 카프카는 topic을 통해 메시지 피드를 유지 관리한다. topic producer를 통해 kafka cluster에 메시지를 적재한다. consumer를 통해 kafka cluster에서 topic을 감지하고 메시지를 가져온다. 그림의 kafka cluster는 1개지만 그 이상의 서버로 구성될 수 있다. ![[log_anatomy.png]] . cluster에 1개의 토픽에 관한 파티션을 살펴보면 위의 그림과 같다. 각 파티션의 메시지는 지속적으로 추가되고, 정렬 또는 변경이 불가능하다. 파티션 별로 메시지에 오프셋이라는 순차 ID가 부여된다. 메시지 유지 기간 . | cluster는 구성 가능 기간 동안 소비 여부에 관계없이 모든 메시지를 유지한다. | (보존 기간이 2일로 설정된 경우 메시지가 게시된 후 2일 동안 사용할 수 있고, 그 후에는 공간 확보를 위해 삭제한다.) | . offset . | 각각의 consumer는 오프셋 번호를 가지고 있다. | 오프셋은 소비자 마음대로 왔다 갔다 할 수 있으며, 그로 인해 처리했던 메시지를 다시 처리할 수 있다. | consumer의 오프셋 변화는 cluster 또는 producer에 영향을 미치지 않는다. | . 파티션 . | 파티션은 1개의 topic에 대해 많은 양의 파티션으로 구성할 수 있고, 이것은 병렬 처리가 가능하다. | 주의할 점은 kafka를 사용하면서 파티션을 늘릴 수는 있지만 줄일 수는 없다. | 파티션을 줄이고 싶다면 토픽을 삭제하고 다시 만들어야 한다. | . 복사 전략 . | replication-factor 옵션에 따라 여러 cluster 서버에 데이터를 복제하여 안전하게 관리할 수 있다. | 2로 설정한다면 원본과 복사본의 갯수를 합쳐서 2개의 데이터가 존재한다. | 전략은 leader - follwers 방식으로 아래 사진을 참고할 수 있다. | . ![[Adv_KT_Choosing_Rep_Factor_1.jpg]] . leader-follwers 방식 . | 클러스터는 브로커라고도 부를 수 있다. | 각 파티션에서 리더를 선출하여 팔로워들은 리더의 데이터를 복사한다. | 리더가 죽게 되면 팔로워 중 하나를 리더로 선출한다. | . 메시지 적제 . | producer는 topic 내의 어떤 파티션에 메시지를 할당할지 선택해야 한다. | 방식은 메시지의 key 기반으로 분할되거나, key 값이 없다면 기본적으로 라운드 로빈 방식으로 분할된다. | . 메시지 소비 . | kafka는 소비자 그룹을 제공한다. ﻿ ![[consumer-groups.png]] | . consumer에 group-id를 지정한다. (C1과 C2는 A라는 group-id를 지정하여 하나의 그룹으로 본다.) 동일한 group-id를 가진 consumer 중 하나라도 메시지를 소비하면, 같은 그룹 내의 consumer들은 메시지를 소비하지 않고 넘어간다. (C1과 C2는 1개의 topic에 대한 파티션처럼 동작한다) . ",
    "url": "/docs/git/Kafka.html",
    
    "relUrl": "/docs/git/Kafka.html"
  },"238": {
    "doc": "Map Struct",
    "title": "Map Struct",
    "content": ". mapstruct 공식 홈페에지 : https://mapstruct.org mapping framework 성능비교 : https://www.baeldung.com/java-performance-mapping-frameworks . implementation 'org.mapstruct:mapstruct:1.5.3.Final' annotationProcessor 'org.mapstruct:mapstruct-processor:1.5.3.Final' . https://better-dev.netlify.app/java/2020/10/26/compare_objectmapper/ . ",
    "url": "/docs/memo/Map%20Struct.html",
    
    "relUrl": "/docs/memo/Map%20Struct.html"
  },"239": {
    "doc": "Mock",
    "title": "Mock",
    "content": ". ",
    "url": "/docs/memo/Mock.html",
    
    "relUrl": "/docs/memo/Mock.html"
  },"240": {
    "doc": "Mock",
    "title": "mock이란?",
    "content": "mock은 실제 객체를 만들어 사용하기에 시간, 비용이 높거나 서로간의 의존성이 강해 구현하기 힘들 경우 가짜 객체를 만들어서 사용하는 방법이다. Test Double은 xUnit Test Patterns의 저자인 제라드 메스자로스가 만든 용어로 테스트를 진행하기 어려운 경우 이를 대신해 테스트를 진행할 수 있도록 만들어주는 객체를 말합니다. 단어 자체의 뜻은 ‘대역’에 가깝고 스턴트맨과 유사한 의미를 가집니다. mock을 사용하는 이유 - https://cobbybb.tistory.com/16 . mock 을 안쓴다면? . ",
    "url": "/docs/memo/Mock.html#mock%EC%9D%B4%EB%9E%80",
    
    "relUrl": "/docs/memo/Mock.html#mock이란"
  },"241": {
    "doc": "Mock",
    "title": "mock의 장점",
    "content": "public interface UserService { User getUserById(int id); void saveUser(User user); } public class UserServiceImpl implements UserService { private UserDao userDao; public UserServiceImpl(UserDao userDao) { this.userDao = userDao; } public User getUserById(int id) { return userDao.getUserById(id); } public void saveUser(User user) { userDao.saveUser(user); } } . UserService 인터페이스를 구현한 UserServiceImpl 클래스를 테스트하는 경우, UserDao 의존성 객체를 생성해야 합니다. 하지만 실제 데이터베이스를 사용하면 테스트의 복잡성이 증가하며, 예상치 못한 결과가 발생할 수 있습니다. 이를 해결하기 위해, UserDao 인터페이스의 구현체 대신 Mockito를 사용하여 UserDao 의존성을 가짜(mock) 객체로 대체할 수 있습니다. 이를 위해서는 UserDao 인터페이스의 mock 객체를 만들고, UserServiceImpl 생성자에서 mock 객체를 전달하면 됩니다. public class UserServiceImplTest { @Mock private UserDao userDao; @InjectMocks private UserServiceImpl userServiceImpl; @Before public void setUp() { MockitoAnnotations.initMocks(this); } @Test public void testGetUserById() { // mock UserDao 객체에 getUserById 메서드 호출 시, User 객체 반환하도록 지정 when(userDao.getUserById(1)).thenReturn(new User(1, \"Alice\")); // UserServiceImpl의 getUserById 메서드 호출 시, mock UserDao 객체의 getUserById 메서드가 실행됨 User user = userServiceImpl.getUserById(1); // mock UserDao 객체의 getUserById 메서드가 호출되었는지 검증 verify(userDao).getUserById(1); // 결과 검증 assertEquals(user.getId(), 1); assertEquals(user.getName(), \"Alice\"); } } . ",
    "url": "/docs/memo/Mock.html#mock%EC%9D%98-%EC%9E%A5%EC%A0%90",
    
    "relUrl": "/docs/memo/Mock.html#mock의-장점"
  },"242": {
    "doc": "Mock",
    "title": "mock의 단점",
    "content": "모의(Mock)는 실제 객체를 대체하는 가짜 객체로, 테스트를 위해 사용됩니다. 하지만 모의(Mock)는 몇 가지 단점이 있습니다. | 코드와 모의(Mock)의 동기화: 코드에서 변경이 생기면 모의(Mock)도 함께 변경해주어야 합니다. 그렇지 않으면 모의(Mock)는 예상한 대로 작동하지 않을 수 있습니다. | 모의(Mock)의 제한: 모의(Mock)는 실제 객체의 일부 동작을 모방하므로, 실제 객체의 모든 기능을 대체하지는 못합니다. 때로는 모의(Mock)로 대체할 수 없는 복잡한 객체들도 있습니다. | 테스트 오용: 모의(Mock)를 사용하면 간단하고 빠른 테스트를 작성할 수 있습니다. 그러나 이로 인해 프로그래머가 코드에 대해 더 이상 충분한 검증을 수행하지 않는 경우가 종종 있습니다. | 의존성 문제: 모의(Mock)는 실제 객체에 대한 의존성을 줄이지만, 모의(Mock) 자체에 대한 의존성을 도입할 수도 있습니다. 모의(Mock)를 작성하려면 몇 가지 라이브러리를 사용해야 할 수도 있습니다. | 시간의 흐름에 따른 문제: 모의(Mock)는 상태를 저장하지 않습니다. 이것은 가끔 문제가 될 수 있습니다. 예를 들어, 일부 시스템은 시간의 경과에 따라 상태를 변경합니다. 이러한 상황에서는 모의(Mock) 대신 다른 방법을 사용해야 합니다. | . ",
    "url": "/docs/memo/Mock.html#mock%EC%9D%98-%EB%8B%A8%EC%A0%90",
    
    "relUrl": "/docs/memo/Mock.html#mock의-단점"
  },"243": {
    "doc": "Mock",
    "title": "사용법",
    "content": "| Mock 종류 | 의존성 주입 Target | . | @Mock | @InjectMocks | . | @MockBean | @SpringBootTest | . Mock - 어노테이션 단어 그대로 Mock 객체, 즉 가짜 객체로 쓰겠다는 뜻이다. MockBean - 어노테이션 단어 뜻 그대로 Mock Bean, 즉 가짜 Bean을 만들겠다는 뜻이다. | @Mock은 @InjectMocks에 대해서만 해당 클래스안에서 정의된 객체를 찾아서 의존성을 해결합니다. | @MockBean은 mock 객체를 스프링 컨텍스트에 등록하는 것이기 때문에 @SpringBootTest를 통해서 Autowired에 의존성이 주입되게 됩니다. | . Spring Context란? . | Bean의 확장 버전으로 Spring이 Bean을 다루기 좀 더 쉽도록 기능들이 추가된 공간이다. bean은 모두 context안에서 이루어진다. | . @WebMvcTest(controllers = Controller.class) @AutoConfigureMockMvc class ContollerTest { private MockMvc mockMvc; @MockBean private Service service; @BeforeEach void setUp(WebApplicationContext webApplicationContext) { this.mockMvc = MockMvcBuilders.webAppContextSetup(webApplicationContext) .addFilter(new CharacterEncodingFilter(\"UTF-8\", true)) .build(); } @Test void findAll() { given(service.findAll()).willReturn(...); mockMvc.perform(get(\"/\") .accept(MediaType.APPLICATION_JSON)) .andExpect(status().isOk())) ... } } . @WebMvcTest 이기 때문에 Controller까지는 로드 된다. 하지만 Controller의 협력 객체인 Service는 로드되지 않는다. 그래서 contoller에 실제로 요청을 보낼 때 controller의 협력 객체인 service가 Bean Container에 생성되어 있지 않다면 NPE가 터진다. 이 처럼 @MockBean은 Bean Container에 생성돼야만 하는 가짜 객체일 때 사용하면 된다. Mock Stub 차이 . | Stub은 테스트 중에 만들어진 호출에 미리 준비된 답변을 제공하고 일반적으로 테스트를 위해 프로그래밍된 것 외에는 전혀 응답하지 않습니다. | Mock은 호출될 것으로 예상되는 사양을 형성하는 기대값으로 미리 프로그래밍 된 객체입니다. | . Mock만 행동 검증을 수행합니다. 다른 것들은 상태 검증에 사용될 수 있습니다. ",
    "url": "/docs/memo/Mock.html#%EC%82%AC%EC%9A%A9%EB%B2%95",
    
    "relUrl": "/docs/memo/Mock.html#사용법"
  },"244": {
    "doc": "Mock",
    "title": "TestContainers",
    "content": "TestContainers는 Docker 컨테이너를 사용하여 테스트 환경을 제공합니다. 이를 통해 테스트 중에 일시적인 인스턴스의 데이터베이스, 웹 브라우저 또는 다른 서비스를 시작하고 중지할 수 있습니다. 이러한 컨테이너는 테스트가 시작될 때 생성되고 테스트가 완료되면 삭제됩니다. 예를 들어, MySQL 데이터베이스의 컨테이너화된 인스턴스를 사용하여 데이터 액세스 계층 코드의 완전한 호환성을 테스트할 수 있습니다. 이 경우 개발자의 컴퓨터에 복잡한 설정이 필요하지 않으며 테스트가 항상 알려진 DB 상태로 시작됩니다. TestContainers는 JUnit과 함께 사용하기 위해 설계되었습니다. 따라서 JUnit의 @Rule 어노테이션을 사용하여 컨테이너를 설정하고 관리할 수 있습니다. 예를 들어, 다음과 같이 MySQL 데이터베이스의 컨테이너화된 인스턴스를 만들 수 있습니다: . @Rule public MySQLContainer mysql = new MySQLContainer(); . 위의 코드는 테스트가 시작될 때 MySQL 컨테이너를 시작하고 테스트가 완료되면 컨테이너를 중지합니다. ",
    "url": "/docs/memo/Mock.html#testcontainers",
    
    "relUrl": "/docs/memo/Mock.html#testcontainers"
  },"245": {
    "doc": "Module Project",
    "title": "Module Project",
    "content": "//setting.gradle includeFlat('core') //root프로젝트 내부에 모듈이 있다면 include('core') //build.gradle dependencies { implementation project(':core') } . core는 모듈 프로젝트의 이름이다. ",
    "url": "/docs/git/Module%20Project.html",
    
    "relUrl": "/docs/git/Module%20Project.html"
  },"246": {
    "doc": "Mongodb",
    "title": "Mongodb",
    "content": ". ",
    "url": "/docs/memo/Mongodb.html",
    
    "relUrl": "/docs/memo/Mongodb.html"
  },"247": {
    "doc": "Mongodb",
    "title": "정의?",
    "content": " ",
    "url": "/docs/memo/Mongodb.html#%EC%A0%95%EC%9D%98",
    
    "relUrl": "/docs/memo/Mongodb.html#정의"
  },"248": {
    "doc": "Mongodb",
    "title": "활용사례?",
    "content": " ",
    "url": "/docs/memo/Mongodb.html#%ED%99%9C%EC%9A%A9%EC%82%AC%EB%A1%80",
    
    "relUrl": "/docs/memo/Mongodb.html#활용사례"
  },"249": {
    "doc": "Mongodb",
    "title": "장점?",
    "content": " ",
    "url": "/docs/memo/Mongodb.html#%EC%9E%A5%EC%A0%90",
    
    "relUrl": "/docs/memo/Mongodb.html#장점"
  },"250": {
    "doc": "Mongodb",
    "title": "단점?",
    "content": "https://docs.spring.io/spring-data/mongodb/docs/current/reference/html/ . https://www.mongodb.com/compatibility/spring-boot . https://ckddn9496.tistory.com/102 . ",
    "url": "/docs/memo/Mongodb.html#%EB%8B%A8%EC%A0%90",
    
    "relUrl": "/docs/memo/Mongodb.html#단점"
  },"251": {
    "doc": "Mongodb",
    "title": "예제 코드",
    "content": "// @Configuration @RequiredArgsConstructor @EnableMongoRepositories(basePackages = \"com.jainwon.cec.examinee.domain.cec\") public class MongoConfig { private final MongoProperty mongoProperty; private static final String DB_NAME = \"cec\"; private static final String DEFAULT_AUTH_DB_NAME = \"admin\"; @Bean public MongoDatabaseFactory mongoDatabaseFactory() { ConnectionString connectionString = new ConnectionString(mongoProperty.getUrl()); String authDatabase = connectionString.getDatabase() != null ? connectionString.getDatabase() : DEFAULT_AUTH_DB_NAME; MongoClientSettings settings = MongoClientSettings.builder() .applyConnectionString(connectionString) .credential(MongoCredential.createCredential(mongoProperty.getUsername() , authDatabase, mongoProperty.getPassword().toCharArray())) .build(); MongoDriverInformation driverInformation = MongoDriverInformation.builder().build(); MongoClient mongoClient = new MongoClientImpl(settings, driverInformation); return new SimpleMongoClientDatabaseFactory(mongoClient, DB_NAME); } @Bean public MongoTemplate mongoTemplate() { MongoTemplate mongoTemplate = new MongoTemplate(mongoDatabaseFactory()); MappingMongoConverter converter = (MappingMongoConverter) mongoTemplate.getConverter(); converter.setTypeMapper(new DefaultMongoTypeMapper(null)); return mongoTemplate; } } . @ToString @Document(collection = \"user_answer\") @NoArgsConstructor(access = AccessLevel.PROTECTED) public class UserAnswer { @Id public String id; public Integer questionId; public Integer answer; public UserAnswer(Integer questionId, Integer answer) { this.questionId = questionId; this.answer = answer; } } . ",
    "url": "/docs/memo/Mongodb.html#%EC%98%88%EC%A0%9C-%EC%BD%94%EB%93%9C",
    
    "relUrl": "/docs/memo/Mongodb.html#예제-코드"
  },"252": {
    "doc": "Multitenancy",
    "title": "Multitenancy",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/core/src/main/java/com/example/core/multitenancy/TenantConnectionProvider.java . 설정 코드 : https://github.com/mildw/doraemon/blob/main/multitenancy/src/main/java/com/example/multitenancy/config/database/TenantDataSourceConfig.java . MultiTenantConnectionProvider를 활용하여 기업에 따라 DB 스키마를 변경합니다. 트랜잭션이 생성되기 전인 필터 또는 인터셉터 레이어에서 TenantContextHolder를 통해 연결되는 DB스키마를 변경합니다. public class TenantConnectionProvider implements MultiTenantConnectionProvider { private final DataSource dataSource; public TenantConnectionProvider(DataSource dataSource) { this.dataSource = dataSource; } @Override public Connection getAnyConnection() throws SQLException { return dataSource.getConnection(); } @Override public void releaseAnyConnection(Connection connection) throws SQLException { connection.close(); } @Override public Connection getConnection(String tenantIdentifier) throws SQLException { Connection connection = dataSource.getConnection(); connection.createStatement() .execute(String.format(\"USE `%s`;\", tenantIdentifier)); return connection; } } . public class TenantIdentifierResolver implements CurrentTenantIdentifierResolver { @Override public String resolveCurrentTenantIdentifier() { try { return TenantContextHolder.getDatabaseName(); } catch (Exception e) { return \"common\"; } } @Override public boolean validateExistingCurrentSessions() { return false; } } . public class TenantContextHolder { public static final String TENANT_CONTEXT_KEY = \"TenantContext\"; private static final ThreadLocal&lt;TenantContext&gt; tenantContextThreadLocal = new NamedThreadLocal&lt;&gt;(TENANT_CONTEXT_KEY); private TenantContextHolder() { throw new RuntimeException(); } public static void setTenantContext(TenantContext tenantContext) { tenantContextThreadLocal.set(tenantContext); } public static TenantContext getTenantContext() { TenantContext tenantContext = tenantContextThreadLocal.get(); if (Objects.isNull(tenantContext)) { throw new RuntimeException(); } return tenantContext; } public static void resetTenantContext() { tenantContextThreadLocal.remove(); } public static Long getTenantId() { return getTenantContext().getId(); } public static String getDatabaseName() { return getTenantContext().getDatabaseName(); } } . ",
    "url": "/docs/git/Multitenancy.html",
    
    "relUrl": "/docs/git/Multitenancy.html"
  },"253": {
    "doc": "Mybatis",
    "title": "Mybatis",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/mybatis/src/main/java/com/example/mybatis/config/database/mybatis/MybatisConfig.java . mysql, auto increment, JPA를 사용할때 bulk insert에 어려움이 있습니다. 때문에 mybatis를 같이 사용하여 대량의 insert를 실행할 수 있습니다. jdbcTemplate라는 선택지도 있습니다. @Mapper public interface OrderMapper {     @InsertProvider(type = OrderSqlProvider.class, method = \"insertOrders\")     void insertOrders(@Param(\"orders\") List&lt;Order&gt; orders); } . public class OrderSqlProvider {     public String insertOrders(Map&lt;String, Object&gt; params) {         @SuppressWarnings(\"unchecked\")         List&lt;Order&gt; orders = (List&lt;Order&gt;) params.get(\"orders\");         StringBuilder sql = new StringBuilder();         sql.append(\"INSERT INTO orders (user_id, product, quantity) VALUES \");         for (int i = 0; i &lt; orders.size(); i++) {             Order order = orders.get(i);             sql.append(\"(\")                .append(order.getUserId()).append(\", \")                .append(\"'\").append(order.getProduct()).append(\"', \")                .append(order.getQuantity()).append(\")\");             if (i &lt; orders.size() - 1) {                 sql.append(\",\");             }         }         return sql.toString();     } } . ",
    "url": "/docs/git/Mybatis.html",
    
    "relUrl": "/docs/git/Mybatis.html"
  },"254": {
    "doc": "OIDC",
    "title": "OIDC",
    "content": ". OIDC 와 Oauth2에 대해 알아보자. 필자의 회사에서는 여러 웹 서비스를 운영 하고있다. 회사가 커지고 구상하는 사업이 많아 질 수록, 접근할 수 있는 웹서비스는 많아졌다. 이는 반복적인 로그인 로직 개발을 하게 만들었고, 사용자들이 회사의 제품을 계약해서 사용할 때 마다 각각의 서비스별로 로그인을 해야하는 불편함을 야기했다. 그래서 OIDC를 이용한 통합 로그인을 도입하게 되어, 본인 또한 공부하고 적용하려고한다. OIDC란? . OIDC를 검색하면 OAuth2.0에 대한 글이 많이 보인다. OIDC가 OAuth2.0 기반으로 동작하기 때문에 많이 헷갈렸다. 요약하면 OAuth2.0은 3rd Party의 API 사용”인가”가 목적이고, OIDC는 통합 “인증”, SSO(single-sign-on)가 목적이다. SSO : 구글에 로그인 함으로써 구글 드라이브, Gmail, You Tube에 각각 로그인 필요없이 접근할 수 있다. 사용자는 OIDC를 통해 인증을 하여 인증 코드(authentication code)를 반환받고, 해당 코드를 통해 OAuth2.0를 기반으로 접근 권한 토큰(access token)을 발급받아 이를통해 서비스를 사용할 수 있는 권한을 인가 받아 자유롭게 서비스를 사용한다. OIDC가 OAuth2.0 기반이므로 플로우는 유사하다. OIDC는 access_token외에 id token이라는 것을 추가로 받게 된다. id token에는 사용자 정보가 들어있다. 때문에 백엔드 서버(자사 또는 본인의)에서는 사용자 정보를 가져오기 위해 사용자의 정보를 가지고있는 Resource Server로 한번더 api를 호출하지 않아도 된다. id token은 jwt 토큰형식을 가지며, . { \"iss\": \"https://server.example.com\", \"sub\": \"24400320\", \"aud\": \"s6BhdRkqt3\", \"exp\": 1311281970, \"iat\": 1311280970 } . 위와같은 정보 또는 공식문서에 여러 값들을 가질 수 있다. 또한 사용자가 원하는 값들 넣을 수 있다. (ex. email) 참고용 openid 공식 문서 . 알아두면 좋은 용어 . Resource Owner 서비스 이용자 - 개인정보(자원-Resource)를 소유하는 자 . Client (Relying Party) 자사 또는 개인이 만든 애플리케이션 서버 클라이언트 라는 이름은 client가 Resource server에게 필요한 자원을 요청하고 응답하는 관계여서 그렇다고 한다. Authorization Server 권한을 부여(인증에 사용할 아이템을 제공주는)해주는 서버다. 사용자는 이 서버로 ID, PW를 넘겨 Authorization Code를 발급 받을 수 있다. Resource Server 사용자의 개인정보를 가지고있는 애플리케이션 (Google, Facebook, Kakao 등) 회사 서버   Client는 Token을 이 서버로 넘겨 개인정보를 응답 받을 수 있다. Access Token 자원에 대한 접근 권한을 Resource Owner가 인가하였음을 나타내는 자격증명 Refresh Token Client는 Authorization Server로 부터 access token과 refresh token을 함께 부여 받는다. token은 가지고만 있어도 자격이 증명되기때문에, 백엔드 서버는 프론트 서버와 통신할때 상대적으로 짧은 만료 기간을 가진 access token으로만 주로 통신하며, 프론트 서버는 access token의 만료기간이 다가옴에 따라 refresh token을 통해 access token을 새로 발급받는다. 만료된 access token를 사용하면 웹 서비스 사용자는 로그아웃 처리 될 것이다. Flow . ![[OIDC-flow.png]] . OpenId Provider = Authorization Server(인증 서버) Token Endpoint = Resource Server 또는 구조에 따라 token 발급 서버를 따로 둔다. UserInfo Endpoint = Resource Server Callback URL은 네이버 로그인 인증 과정에서 사용자 인증 결과를 전달받아 처리하기 위한 URL이다. ",
    "url": "/docs/memo/OIDC.html",
    
    "relUrl": "/docs/memo/OIDC.html"
  },"255": {
    "doc": "POI - Excel",
    "title": "POI - Excel",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/excel/src/main/java/com/example/excel/application/excel/ExcelTemplate.java . Java에서 엑셀 생성에 대한 코드입니다. ![[Pasted image 20240316221452.png]] . ",
    "url": "/docs/git/POI%20-%20Excel.html",
    
    "relUrl": "/docs/git/POI%20-%20Excel.html"
  },"256": {
    "doc": "QueryDsl",
    "title": "QueryDsl",
    "content": "설정 코드 : https://github.com/mildw/doraemon/tree/main/querydsl . ",
    "url": "/docs/git/QueryDsl.html",
    
    "relUrl": "/docs/git/QueryDsl.html"
  },"257": {
    "doc": "RDS Proxy & Lambda VPC & Secret Manager",
    "title": "Secrets Manager",
    "content": "환경 변수에 직접 데이터베이스의 ID와 암호를 저장하는 것 대신에 AWS Secrets Manager를 사용을 권장 하고있습니다. Lambda는 secrets manager 에 접근하기 위해 . \"secretsmanager:GetSecretValue\", \"secretsmanager:DescribeSecret\" . 두가지 권한이 필요합니다. public class AwsSecrets { private String dbInstanceIdentifier; private String engine; private String resourceId; private String username; private String password; } . @Bean public HikariConfig hikariConfig() { if(secretName != null &amp;&amp; !secretName.isBlank()) { AwsSecrets awsSecrets = getSecretValue(secretName); dbUsername = awsSecrets.getUsername(); dbPassword = awsSecrets.getPassword(); } HikariDataSource dataSource = new HikariDataSource(); dataSource.setJdbcUrl(dbUrl); dataSource.setUsername(dbUsername); dataSource.setPassword(dbPassword); dataSource.setMaximumPoolSize(1); return dataSource; } private AwsSecrets getSecretValue(String secretName) { AWSSecretsManager client = AWSSecretsManagerClientBuilder.standard().build(); GetSecretValueRequest request = new GetSecretValueRequest().withSecretId(secretName); GetSecretValueResult result = client.getSecretValue(request); String secretString = result.getSecretString(); if(secretString == null) { throw new RuntimeException(); } return ObjectMapperUtils.readValue(secretString, AwsSecrets.class); } . ",
    "url": "/docs/git/RDS%20Proxy%20&%20Lambda%20VPC%20&%20Secret%20Manager.html#secrets-manager",
    
    "relUrl": "/docs/git/RDS%20Proxy%20&%20Lambda%20VPC%20&%20Secret%20Manager.html#secrets-manager"
  },"258": {
    "doc": "RDS Proxy & Lambda VPC & Secret Manager",
    "title": "RDS Proxy & Lambda VPC & Secret Manager",
    "content": "Lambda 함수가 동시 요청을 처리할 때 RDS Proxy를 통해 데이터베이스 연결 풀링이 이루어지므로 데이터베이스에서 발생하는 부하를 분산시키고 성능을 향상시킬 수 있습니다. RDS Proxy를 사용하려면 RDS DB 인스턴스와 RDSProxy 간에 공통의 Virtual Private Cloud(VPC)가 있어야 합니다. 아래는 AWS 설정 과정입니다. ![[Pasted image 20240406215153.png]] ![[Pasted image 20240406215400.png]] . ![[Pasted image 20240406175109.png]] Lambda 생성 당시 고급 설정을 통해 VPC를 설정할 수 있으며, 생성 이후에도 가능합니다. ![[Pasted image 20240406221410.png]] . ![[Pasted image 20240406221429.png]] VPC설정을 완료하고 나면 Time out이 뜨지 않는 것을 확인할 수 있습니다. ",
    "url": "/docs/git/RDS%20Proxy%20&%20Lambda%20VPC%20&%20Secret%20Manager.html",
    
    "relUrl": "/docs/git/RDS%20Proxy%20&%20Lambda%20VPC%20&%20Secret%20Manager.html"
  },"259": {
    "doc": "Redis",
    "title": "레딧스를 어디에 사용하는가",
    "content": "운영 중인 웹 서버에서 키-값 형태의 데이터 타입을 처리해야 하고, I/O가 빈번히 발생해 다른 저장 방식을 사용하면 효율이 떨어지는 경우에 사용합니다. 조회수와 같은 카운트 형태의 데이터일 겁니다. 유튜브를 생각해보면 인기 채널의 신규 동영상을 1시간도 안돼서 100만 조회수를 넘기는 경우도 있습니다. 이때 조회수에 해당하는 데이터를 RDS 형태의 데이터에 저장해 I/O를 반복한다면 엄청난 자원이 사용될 것이란 건 불 보듯 뻔한 일입니다. 일정한 주기에 따라 RDS에 업데이트를 한다면 RDS에 가해지는 부담을 크게 줄이고, 성능은 크게 향상할 수 있습니다. 많은 I/O를 예시로 들었지만 가장 많이 사용되는 건 역시 사용자의 세션 관리입니다. 사용자의 세션을 유지하고, 불러오고, 여러 활동들을 추적하는 게 매우 효과적으로 사용할 수 있습니다. 또한 매우 빠르게 동작한다는 점을 사용해 메시지 큐잉에도 사용할 수 있습니다. 그 밖에도 강력하게 사용할 수 있는게 바로 API 캐싱입니다. 라우트로 들어온 요청에 대해 요청 값을 캐싱해면 동일 요청에 대해 캐싱된 데이터를 리턴하는 방식입니다. 이와 관련된 쉬운 링크가 있어 아래에 첨부합니다. 같은 요청이 여러 번 들어오는 경우 매번 데이터 베이스를 거치는 것이 아니라 캐시 서버에서 첫 번째 요청 이후 저장된 결괏값을 바로 내려주기 때문에 DB의 부하를 줄이고 서비스의 속도도 느려지지 않는 장점이 있습니다. ",
    "url": "/docs/git/Redis.html#%EB%A0%88%EB%94%A7%EC%8A%A4%EB%A5%BC-%EC%96%B4%EB%94%94%EC%97%90-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94%EA%B0%80",
    
    "relUrl": "/docs/git/Redis.html#레딧스를-어디에-사용하는가"
  },"260": {
    "doc": "Redis",
    "title": "Redis 사용에 주의할 점으로는",
    "content": ". | 서버에 장애가 발생했을 경우 그에 대한 운영 플랜이 꼭 필요합니다. 인메모리 데이터 저장소의 특성상, 서버에 장애가 발생했을 경우 데이터 유실이 발생할 수 있기 때문입니다. | 메모리 관리가 중요합니다. | 싱글 스레드의 특성상, 한 번에 하나의 명령만 처리할 수 있습니다. 처리하는데 시간이 오래 걸리는 요청, 명령은 피해야 합니다. | . 쿼리가 길고 복잡한 경우에도 데이터베이스를 조회하는 시간이 오래 걸리는데, 이 쿼리가 자주 사용되는 경우라면 해당 쿼리가 전체 서비스 속도의 병목이 될 수도 있겠죠? 그럴때는 쿼리 결과 자체를 캐싱을 해두고, 쿼리의 결과가 바뀔 수 있는 이벤트가 발생할 때마다 캐시에 적재를 새로한다면 전체 서비스 속도를 향상 시킬 수 있을것입니다. ",
    "url": "/docs/git/Redis.html#redis-%EC%82%AC%EC%9A%A9%EC%97%90-%EC%A3%BC%EC%9D%98%ED%95%A0-%EC%A0%90%EC%9C%BC%EB%A1%9C%EB%8A%94",
    
    "relUrl": "/docs/git/Redis.html#redis-사용에-주의할-점으로는"
  },"261": {
    "doc": "Redis",
    "title": "설정 코드",
    "content": "https://www.baeldung.com/spring-boot-redis-cache . //캐시 implementation 'org.springframework.boot:spring-boot-starter-data-redis' //세션 implementation 'org.springframework.session:spring-session-data-redis' . @Configuration @EnableCaching @RequiredArgsConstructor public class RedisConfig { private final RedisProperty redisProperty; @Bean public RedisConnectionFactory redisConnectionFactory() { RedisStandaloneConfiguration redisStandaloneConfiguration = new RedisStandaloneConfiguration(redisProperty.getHost(), redisProperty.getPort()); redisStandaloneConfiguration.setDatabase(redisProperty.getDatabase()); redisStandaloneConfiguration.setPassword(redisProperty.getPassword()); return new JedisConnectionFactory(redisStandaloneConfiguration); } @Bean public RedisOperations&lt;String, Object&gt; redisOperations() { RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory()); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setHashKeySerializer(new StringRedisSerializer()); redisTemplate.setValueSerializer(new GenericJackson2JsonRedisSerializer()); return redisTemplate; } @Bean public CacheManager cacheManager(RedisConnectionFactory connectionFactory) { CacheManager cacheManager = RedisCacheManager.builder(connectionFactory) .cacheDefaults(defaultCacheConfiguration()) .withInitialCacheConfigurations(cacheConfigurationMap()) .build(); return cacheManager; } private RedisCacheConfiguration defaultCacheConfiguration() { return RedisCacheConfiguration.defaultCacheConfig() .serializeKeysWith(fromSerializer(new StringRedisSerializer())) .serializeValuesWith(fromSerializer(new GenericJackson2JsonRedisSerializer())) .entryTtl(Duration.ofMinutes(20)); } private Map&lt;String, RedisCacheConfiguration&gt; cacheConfigurationMap() { return new HashMap&lt;&gt;(); } } . redisConnectionFactory() : redis 서버 연결 . redisTemplate() : redis 의 명령을 도와줄 템플릿 (캐시 저장에는 필요 없음 / 참고 : https://www.baeldung.com/spring-boot-redis-cache) . cacheManager() : 캐시 매니저를 통해 redis cache config 설정 . redisCacheConfiguration() : default redis cache config 설정 . redisCacheManagerBuilderCustomizer() : name space에 따른 만료 기간 처리 . RedisTemplate 를 이용해서 실제 레디스를 스프링에서 사용하는데 중요한 것은 setKeySerializer(), setValueSerializer() 메소드들이다. 이 메소드를 빠트리면 실제 스프링에서 조회할 때는 값이 정상으로 보이지만 redis-cli로 보면 key값에 \\xac\\xed\\x00\\x05t\\x00\\x0 이런 값들이 붙는다. //SSL 적용 경우 @Bean public RedisConnectionFactory redisConnectionFactory() { LettuceClientConfiguration lettuceClientConfiguration = LettuceClientConfiguration.builder().useSsl().build(); RedisStandaloneConfiguration redisStandaloneConfiguration = new RedisStandaloneConfiguration(redisProperty.getHost(), redisProperty.getPort()); redisStandaloneConfiguration.setDatabase(redisProperty.getDatabase()); redisStandaloneConfiguration.setPassword(redisProperty.getPassword()); return new LettuceConnectionFactory(redisStandaloneConfiguration, lettuceClientConfiguration); } @Bean public ConfigureRedisAction configureRedisAction() { return ConfigureRedisAction.NO_OP; } . configureRedisAction() : ConfigureRedisAction.NO_OP 는 레디스 세션 만료시 destroy event가 진행되어야 하는데, 이 destroy event는 기본적으로 자동 설정이 되어있지만 보안의 redis 환경인 경우 동작하지 않는다고 한다. @Component @RequiredArgsConstructor public class RedisComponent { private final StringRedisTemplate redisTemplate; public void saveSession(Long memberSn, String sessionId) { final int TIMEOUT = 60 * 6; String sessionIdKey = getMemberSessionIdKey(memberSn,sessionId); redisTemplate.opsForValue().set(sessionIdKey, sessionId); redisTemplate.expire(sessionIdKey, TIMEOUT, TimeUnit.MINUTES); String allowedSessionKey = getMemberAllowedSessionKey(memberSn); redisTemplate.opsForValue().set(allowedSessionKey, sessionId); redisTemplate.expire(allowedSessionKey, TIMEOUT, TimeUnit.MINUTES); } } . opsForValue() 에 대한 참고 : https://sabarada.tistory.com/105 . ",
    "url": "/docs/git/Redis.html#%EC%84%A4%EC%A0%95-%EC%BD%94%EB%93%9C",
    
    "relUrl": "/docs/git/Redis.html#설정-코드"
  },"262": {
    "doc": "Redis",
    "title": "Redis",
    "content": "\bgithub : https://github.com/mildw/doraemon/tree/main/redis . ",
    "url": "/docs/git/Redis.html",
    
    "relUrl": "/docs/git/Redis.html"
  },"263": {
    "doc": "Request API - Feign Client",
    "title": "Request API - Feign Client",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/request-api/src/main/java/com/example/requestapi/application/FeignClientService.java . 다른 서버로 요청할때 사용하는 라이브러리입니다. Spring의 REST Template보다 더 간단하고 직관적인 코드를 작성할 수 있습니다. exception 처리시 참고 . private static FeignClientException clientErrorStatus(int status, String message, Request request, byte[] body, Map&lt;String, Collection&lt;String&gt;&gt; headers) { switch (status) { case 400: return new BadRequest(message, request, body, headers); case 401: return new Unauthorized(message, request, body, headers); case 403: return new Forbidden(message, request, body, headers); case 404: return new NotFound(message, request, body, headers); case 405: return new MethodNotAllowed(message, request, body, headers); case 406: return new NotAcceptable(message, request, body, headers); case 409: return new Conflict(message, request, body, headers); case 410: return new Gone(message, request, body, headers); case 415: return new UnsupportedMediaType(message, request, body, headers); case 429: return new TooManyRequests(message, request, body, headers); case 422: return new UnprocessableEntity(message, request, body, headers); default: return new FeignClientException(status, message, request, body, headers); } } private static FeignServerException serverErrorStatus(int status, String message, Request request, byte[] body, Map&lt;String, Collection&lt;String&gt;&gt; headers) { switch (status) { case 500: return new InternalServerError(message, request, body, headers); case 501: return new NotImplemented(message, request, body, headers); case 502: return new BadGateway(message, request, body, headers); case 503: return new ServiceUnavailable(message, request, body, headers); case 504: return new GatewayTimeout(message, request, body, headers); default: return new FeignServerException(status, message, request, body, headers); } } . ",
    "url": "/docs/git/Request%20API%20-%20Feign%20Client.html",
    
    "relUrl": "/docs/git/Request%20API%20-%20Feign%20Client.html"
  },"264": {
    "doc": "Request API - RestTemplate",
    "title": "Request API - RestTemplate",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/request-api/src/main/java/com/example/requestapi/application/RestTemplateService.java . 다른 서버로 요청할때 사용하는 라이브러리입니다. 동기식 호출 방식이기 때문에 단순한 요청 처리에 사용됩니다. Spring에서는 Web Client사용을 권고하고있습니다. ",
    "url": "/docs/git/Request%20API%20-%20RestTemplate.html",
    
    "relUrl": "/docs/git/Request%20API%20-%20RestTemplate.html"
  },"265": {
    "doc": "Request API - Web Client",
    "title": "Request API - Web Client",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/request-api/src/main/java/com/example/requestapi/application/WebClientService.java . 다른 서버로 요청할때 사용하는 라이브러리입니다. ",
    "url": "/docs/git/Request%20API%20-%20Web%20Client.html",
    
    "relUrl": "/docs/git/Request%20API%20-%20Web%20Client.html"
  },"266": {
    "doc": "Request API",
    "title": "Request API",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/request-api/src/main/java/com/example/requestapi/config/feign/FeignClientConfig.java . 백엔드 서버에서 다른 백엔드 서버로 통신 요청할때 사용하는 라이브러리 입니다. [[Request API - RestTemplate]] . | 다른 서버로 요청할때 사용하는 라이브러리입니다. | 동기식 호출 방식이기 때문에 단순한 요청 처리에 사용됩니다. | Spring에서는 Web Client사용을 권고하고있습니다. | . [[Request API - Web Client]] . | 다른 서버로 요청할때 사용하는 라이브러리입니다. | . [[Request API - Feign Client]] . | 다른 서버로 요청할때 사용하는 라이브러리입니다. | Spring의 REST Template보다 더 간단하고 직관적인 코드를 작성할 수 있습니다. | . ",
    "url": "/docs/git/Request%20API.html",
    
    "relUrl": "/docs/git/Request%20API.html"
  },"267": {
    "doc": "S3 Bucket -  Life Cycle Rule",
    "title": "S3 Bucket -  Life Cycle Rule",
    "content": "temp file 업로드시 따로 지우는 로직을 구현해야하는 번거로움이 있습니다. 이는 s3에서 지원하는 \bLife Cycle Rule을 사용하여 해결할 수 있습니다. ![[Pasted image 20240407214724.png]] . // AWS implementation platform('software.amazon.awssdk:bom:2.17.102') implementation 'software.amazon.awssdk:s3' implementation 'software.amazon.awssdk:s3-transfer-manager:2.17.123-PREVIEW' . public static void tempFileUpload(Bucket bucket, String key, byte[] bytes) { S3Client s3Client = getS3Client(bucket); setLifecyclePolicy(s3Client, bucket.getBucketName()); ByteBuffer byteBuffer = ByteBuffer.wrap(bytes); PutObjectRequest request = PutObjectRequest.builder() .bucket(bucket.getBucketName()) .key(key) .contentLength((long) bytes.length) .build(); s3Client.putObject(request, RequestBody.fromByteBuffer(byteBuffer)); } public static void setLifecyclePolicy(S3Client s3Client, String bucketName) { List&lt;LifecycleRule&gt; rules = List.of( LifecycleRule.builder() .id(\"ExpirationRule\") .filter(LifecycleRuleFilter.builder().prefix(key).build()) .expiration(LifecycleExpiration.builder().days(1).build()) .status(ExpirationStatus.ENABLED) .build() ); PutBucketLifecycleConfigurationRequest request = PutBucketLifecycleConfigurationRequest.builder() .bucket(bucketName) .lifecycleConfiguration(BucketLifecycleConfiguration.builder().rules(rules).build()) .build(); s3Client.putBucketLifecycleConfiguration(request); } . ![[Pasted image 20240407214919.png]] .id(\"ExpirationRule\")id값을 동일하게 설정 할 경우 덮어 씌워버리는점 주의해야합니다. ",
    "url": "/docs/git/S3%20Bucket%20-%20%20Life%20Cycle%20Rule.html",
    
    "relUrl": "/docs/git/S3%20Bucket%20-%20%20Life%20Cycle%20Rule.html"
  },"268": {
    "doc": "S3 Bucket - Presigned Url",
    "title": "S3 Bucket - Presigned Url",
    "content": "import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import software.amazon.awssdk.services.s3.presigner.S3Presigner; @Configuration public class S3FileConfig { @Bean public S3Presigner getS3Presigner() { return S3Presigner.create(); } } . Presinger 생성에는 비용이 많이 들기 때문에 @Bean으로 등록 후 사용하는것이 좋다. public static String getPresignedUrl(S3Presigner s3Presigner, Bucket bucket, String key, Duration duration) { GetObjectRequest getObjectRequest = GetObjectRequest.builder() .bucket(bucket.getBucketName()) .key(key) .build(); GetObjectPresignRequest getObjectPresignRequest = GetObjectPresignRequest.builder() .signatureDuration(duration) .getObjectRequest(getObjectRequest) .build(); PresignedGetObjectRequest presignedGetObjectRequest = s3Presigner.presignGetObject(getObjectPresignRequest); return presignedGetObjectRequest.url().toString(); } . ",
    "url": "/docs/git/S3%20Bucket%20-%20Presigned%20Url.html",
    
    "relUrl": "/docs/git/S3%20Bucket%20-%20Presigned%20Url.html"
  },"269": {
    "doc": "S3 Bucket",
    "title": "S3 Bucket",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/core/src/main/java/com/example/core/s3/S3Utils.java . S3 파일 업로드, 다운로드 . //Upload public static boolean upload(Bucket bucket, String key, byte[] bytes) { try (S3TransferManager s3TransferManager = getS3TransferManager(bucket)) { PutObjectRequest putObjectRequest = PutObjectRequest.builder().bucket(bucket.getBucketName()).key(key) .serverSideEncryption(ServerSideEncryption.AES256).build(); UploadRequest uploadRequest = UploadRequest.builder().putObjectRequest(putObjectRequest) .requestBody(AsyncRequestBody.fromBytes(bytes)).build(); Upload upload = s3TransferManager.upload(uploadRequest); CompletedUpload completedUpload = upload.completionFuture().join(); PutObjectResponse putObjectResponse = completedUpload.response(); return putObjectResponse != null; } catch (Exception e) { throw new RuntimeException(); } } . //Download public static byte[] download(Bucket bucket, String key) { try (S3TransferManager s3TransferManager = getS3TransferManager(bucket)) { GetObjectRequest getObjectRequest = GetObjectRequest.builder().bucket(bucket.getBucketName()).key(key).build(); DownloadRequest&lt;ResponseBytes&lt;GetObjectResponse&gt;&gt; downloadRequest = DownloadRequest.builder() .getObjectRequest(getObjectRequest).responseTransformer(AsyncResponseTransformer.toBytes()).build(); Download&lt;ResponseBytes&lt;GetObjectResponse&gt;&gt; download = s3TransferManager.download(downloadRequest); CompletedDownload&lt;ResponseBytes&lt;GetObjectResponse&gt;&gt; completedDownload = download.completionFuture().join(); ResponseBytes&lt;GetObjectResponse&gt; responseBytes = completedDownload.result(); return responseBytes.asByteArray(); } catch (Exception exception) { throw new RuntimeException(); } } . private static S3Client getS3Client(Bucket bucket) { S3ClientBuilder s3ClientBuilder = S3Client.builder().region(AwsUtils.getAwsRegion()); if (bucket.getAccessKey() != null &amp;&amp; bucket.getSecretKey() != null) { s3ClientBuilder.credentialsProvider(StaticCredentialsProvider.create( AwsBasicCredentials.create(bucket.getAccessKey(), bucket.getSecretKey()))); } return s3ClientBuilder.build(); } private static S3TransferManager getS3TransferManager(Bucket bucket) { S3ClientConfiguration s3ClientConfiguration = getS3ClientConfiguration(bucket); return S3TransferManager.builder().s3ClientConfiguration(s3ClientConfiguration).build(); } private static S3ClientConfiguration getS3ClientConfiguration(Bucket bucket) { S3ClientConfiguration.Builder builder = S3ClientConfiguration.builder().region(AwsUtils.getAwsRegion()); if (bucket.getAccessKey() != null &amp;&amp; bucket.getSecretKey() != null) { builder.credentialsProvider(StaticCredentialsProvider.create( AwsBasicCredentials.create(bucket.getAccessKey(), bucket.getSecretKey()))); } return builder.build(); } . ",
    "url": "/docs/git/S3%20Bucket.html",
    
    "relUrl": "/docs/git/S3%20Bucket.html"
  },"270": {
    "doc": "Scheduler",
    "title": "Scheduler",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/scheduler/src/main/java/com/example/scheduler/task/member/MemberTask.java . @EnableScheduling @SpringBootApplication public class SchedulerApplication extends SpringBootServletInitializer { public static void main(String[] args) { SpringApplication.run(SchedulerApplication.class, args); } } . @Component //@Profile(value = \"!local\") @RequiredArgsConstructor public class MailTask { private final SendService sendService; @Scheduled(fixedDelay = Schedule.FIXED_DELAY_1M) public void sendEmail() { sendService.sendEmail(); } @Scheduled(fixedDelay = Schedule.FIXED_DELAY_1M) public void resendEmail() { sendService.resendEmail(); } @Scheduled(fixedDelay = Schedule.FIXED_DELAY_1M) public void updateEmailSendStatus() { sendService.updateEmailSendStatus(); } } . public class Schedule { //1000 = 1s private static final long SECOND = 1000L; public static final long FIXED_DELAY_1S = SECOND; public static final long FIXED_DELAY_1M = 60 * FIXED_DELAY_1S; //초 (0-59) 분 (0-59) 시 (0-23) 일 (1-31) 월 (1-12 또는 JAN-DEC) 요일 (0-7 또는 SUN-SAT) public static final String EVERY_12AM = \"0 0 0 * * *\"; } . ",
    "url": "/docs/git/Scheduler.html",
    
    "relUrl": "/docs/git/Scheduler.html"
  },"271": {
    "doc": "Serverless",
    "title": "Serverless",
    "content": ". https://catalog.us-east-1.prod.workshops.aws/event/dashboard/en-US/workshop . ",
    "url": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html",
    
    "relUrl": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html"
  },"272": {
    "doc": "Serverless",
    "title": "1. 데이터로 시작",
    "content": "1.1. DynamoDB 만들고 결과 캡쳐 . ![[Pasted image 20240420172733.png]] . 1.2. Lambda 함수를 수행하고 결과 캡쳐 . ![[Pasted image 20240420172727.png]] . ",
    "url": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#1-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A1%9C-%EC%8B%9C%EC%9E%91",
    
    "relUrl": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#1-데이터로-시작"
  },"273": {
    "doc": "Serverless",
    "title": "2. DynamoDB에 연결",
    "content": "2.1. DynamoDB 연결하고 Lambda 결과 화면 캡쳐 . ![[Pasted image 20240420172843.png]] . 2.2. Lambda 수행하고 DynamoDB 결과 화면 캡쳐 . ![[스크린샷 2024-04-19 오후 10.29.20.png]] . ",
    "url": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#2-dynamodb%EC%97%90-%EC%97%B0%EA%B2%B0",
    
    "relUrl": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#2-dynamodb에-연결"
  },"274": {
    "doc": "Serverless",
    "title": "3. API 구축",
    "content": "3.1. API GW를 구축하고 api 호출 결과 화면 캡쳐 . ![[Pasted image 20240420172903.png]] . ",
    "url": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#3-api-%EA%B5%AC%EC%B6%95",
    
    "relUrl": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#3-api-구축"
  },"275": {
    "doc": "Serverless",
    "title": "M1. 동기 호출",
    "content": " ",
    "url": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#m1-%EB%8F%99%EA%B8%B0-%ED%98%B8%EC%B6%9C",
    
    "relUrl": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#m1-동기-호출"
  },"276": {
    "doc": "Serverless",
    "title": "1. 데이터 저장소 만들기",
    "content": "1.1. DynamoDB 만들고 화면 캡쳐 . ![[Pasted image 20240420173017.png]] . ",
    "url": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#1-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%80%EC%9E%A5%EC%86%8C-%EB%A7%8C%EB%93%A4%EA%B8%B0",
    
    "relUrl": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#1-데이터-저장소-만들기"
  },"277": {
    "doc": "Serverless",
    "title": "2. 비즈니스 로직 추가",
    "content": "2.1. Lambda 만들고 화면 캡쳐 . ![[Pasted image 20240420173051.png]] . ",
    "url": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#2-%EB%B9%84%EC%A6%88%EB%8B%88%EC%8A%A4-%EB%A1%9C%EC%A7%81-%EC%B6%94%EA%B0%80",
    
    "relUrl": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#2-비즈니스-로직-추가"
  },"278": {
    "doc": "Serverless",
    "title": "3. API 연결",
    "content": "3.1. API GW 만들고 화면 캡쳐 . ![[Pasted image 20240420173107.png]] . 3.2. API GW 만들고 API 호출 화면 캡쳐 . ![[Pasted image 20240420173122.png]] . ",
    "url": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#3-api-%EC%97%B0%EA%B2%B0",
    
    "relUrl": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#3-api-연결"
  },"279": {
    "doc": "Serverless",
    "title": "3-1. 사용자 풀 생성",
    "content": "3-1.1. Amazon Cognito 를 만들고 화면 캡쳐 . ![[Pasted image 20240420173128.png]] . ",
    "url": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#3-1-%EC%82%AC%EC%9A%A9%EC%9E%90-%ED%92%80-%EC%83%9D%EC%84%B1",
    
    "relUrl": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#3-1-사용자-풀-생성"
  },"280": {
    "doc": "Serverless",
    "title": "3-2. API 보안",
    "content": "3-2.1. 보안에 필요한 Lambda를 만들고 화면 캡쳐 . ![[Pasted image 20240420173135.png]] . ",
    "url": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#3-2-api-%EB%B3%B4%EC%95%88",
    
    "relUrl": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#3-2-api-보안"
  },"281": {
    "doc": "Serverless",
    "title": "3-3. 승인 확인",
    "content": "3-3.1. API GW 요청을 보낼 때 승인된 API 요청 화면을 캡쳐 . ![[Pasted image 20240420173222.png]] . ",
    "url": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#3-3-%EC%8A%B9%EC%9D%B8-%ED%99%95%EC%9D%B8",
    
    "relUrl": "/docs/aws/%EC%8B%A4%EC%8A%B5/Serverless.html#3-3-승인-확인"
  },"282": {
    "doc": "Spring Cloud Function",
    "title": "Spring Cloud Function",
    "content": "s설정 코드 : https://github.com/mildw/doraemon/blob/main/spring-cloud-function/src/main/java/com/example/springcloudfunction/LambdaHandler.java . Lambda에 Spring Cloud Function 프로젝트를 배포하기 위한 과정을 다룹니다. // For Local Test implementation 'org.springframework.cloud:spring-cloud-starter-function-web:3.1.6' // Spring Cloud Function implementation 'org.springframework.cloud:spring-cloud-function-adapter-aws:3.1.6' implementation 'com.amazonaws:aws-lambda-java-core:1.2.1' implementation 'com.amazonaws:aws-lambda-java-events:3.11.0' . spring cloud function에 필요한 의존성을 추가합니다. lambda에 필요한 의존성을 추가합니다. @Slf4j @Component public class ExampleFunction implements Function&lt;String, String&gt; { @Override public String apply(String request) { log.info(request); return request; } } . Funtion, Consumer, Supplier와 같은 함수형 인터페이스를 구현합니다. implementation 'org.springframework.cloud:spring-cloud-starter-function-web:3.1.6' 위에서 선언한 의존성을 통해 로컬환경에서 테스트할 수 있습니다. curl -X POST -H \"Content-Type: application/json\" -d '{\"body\":\"1111\"}' http://localhost:8080/exampleFunction  . - 결과값 {\"body\":\"1111\"} . 해당 프로젝트를 aws에 올리기전에 . public class LambdaHandler extends SpringBootStreamHandler { } . Lamda가 Spring Cloud Function 프로젝트를 다루기 위해서 Spring Cloud Function AWS에서 제공하는 핸들러를 상속받은 클래스가 필요합니다. 다음으로 핸들러 정보 입력이 필요합니다. com.example.springcloudfunction.LambdaHandler . ![[Pasted image 20240305213820.png]] . 환경변수의 입력도 필요합니다. FUNCTION_NAME에서 맨앞의글자가 소문자인점을 고려합니다. MAIN_CLASS에는 메인메서드가 있는 클래스 경로를 입력합니다. ![[Pasted image 20240305213813.png]] . 이후 테스트를하면 결과값을 확인 할 수 있습니다. ![[Pasted image 20240406125203.png]] . ",
    "url": "/docs/git/Spring%20Cloud%20Function.html",
    
    "relUrl": "/docs/git/Spring%20Cloud%20Function.html"
  },"283": {
    "doc": "Spring Retry",
    "title": "Spring Retry",
    "content": "가끔 로직 수행하다 실패한 경우 재시도가 필요한 경우가 있습니다. 다양한 방법이 있지만 Spring Retry를 사용해서 해결할 수 있습니다. // Spring Retry implementation 'org.springframework.retry:spring-retry' // AOP implementation 'org.springframework:spring-aspects' . @EnableRetry @SpringBootApplication public class AsyncApplication extends SpringBootServletInitializer { public static void main(String[] args) { SpringApplication.run(AsyncApplication.class, args); } } . @EnableRetry 추가 . @Retryable(maxAttempts = 2, backoff = @Backoff(delay = 3000)) public Boolean runtimeException() { String result = localTestClient.runtimeException(); System.out.println(\"method : \"+result); return true;} . @Retryable(maxAttempts = 2, backoff = @Backoff(delay = 3000)) 추가 maxAttempts 기본값은 3입니다. RetryTemplate Configuration 설정방법도 있으니 좀 더 알아보기 . ",
    "url": "/docs/git/Spring%20Retry.html",
    
    "relUrl": "/docs/git/Spring%20Retry.html"
  },"284": {
    "doc": "Spring Security",
    "title": "Spring Security",
    "content": "설정 파일 : https://github.com/mildw/doraemon/blob/main/spring-security/src/main/java/com/example/springsecurity/config/security/SecurityConfig.java . ",
    "url": "/docs/git/Spring%20Security.html",
    
    "relUrl": "/docs/git/Spring%20Security.html"
  },"285": {
    "doc": "Swagger UI",
    "title": "Swagger UI",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/swagger-ui/src/main/java/com/example/swaggerui/config/swagger_ui/SwaggerConfig.java . Springdoc 설정 . springdoc: swagger-ui: path: /swagger-ui disable-swagger-default-url: true display-request-duration: true tags-sorter: alpha operations-sorter: alpha doc-expansion: none urls-primary-name: CEC API persist-authorization: true query-config-enabled: true syntax-highlight: theme: nord pre-loading-enabled: true . | path: /swagger-ui (기본값): 스웨거 UI에 접근할 수 있는 경로를 정의합니다. 이 경우 http://localhost:8080/swagger-ui에서 접근할 수 있습니다. | disable-swagger-default-url: true (기본값: false): 기본 스웨거 UI URL (/swagger-ui.html) 자동 생성을 비활성화합니다. | display-request-duration: true (기본값: false): 스웨거 UI에 요청 실행 시간을 표시합니다. | tags-sorter: alpha (기본값: none): API 태그를 알파벳 순으로 정렬합니다. | operations-sorter: alpha (기본값: none): 각 태그 내에서 API 작업을 알파벳 순으로 정렬합니다. | doc-expansion: none (기본값: list): API 문서 확장의 초기 상태를 설정합니다. none은 모든 것을 축소된 상태로 유지합니다. 다른 옵션으로는 list (최상위 섹션 확장) 및 full (모든 항목 확장)이 있습니다. | urls-primary-name: TEST API (기본값: 애플리케이션 이름): 스웨거 UI 제목에 표시되는 기본 이름을 설정합니다. | persist-authorization: true (기본값: false): 스웨거 UI 세션 간에 권한 정보를 기억합니다. | query-config-enabled: true (기본값: false): URL의 쿼리 매개변수를 사용하여 스웨거 UI를 구성할 수 있도록 합니다. | syntax-highlight: 스웨거 UI의 코드 샘플에 대한 구문 강조 표시를 활성화합니다. | theme: nord (기본값: github): 구문 강조 표시 테마를 “nord”로 설정합니다. | . | . 추가 참고 사항 . | pre-loading-enabled: true (기본값: false): 이 옵션은 Springdoc 문서에 명시적으로 설명되어 있지는 않지만, 더 빠른 초기 렌더링을 위해 스웨거 UI를 사전 로딩하는 것과 관련이 있을 수 있습니다. 정확한 확인을 위해서는 사용 중인 Springdoc 버전의 문서를 확인하는 것이 좋습니다. | . ",
    "url": "/docs/git/Swagger%20UI.html",
    
    "relUrl": "/docs/git/Swagger%20UI.html"
  },"286": {
    "doc": "Template Method Pattern",
    "title": "Template Method Pattern",
    "content": "설정 코드 : https://github.com/mildw/doraemon/blob/main/template-method-pattern/src/main/java/com/example/templatemethodpattern/application/TemplateService.java . 타입에 따라 로직을 다르게 수행해야할 때 사용할 수 있는 디자인 패턴입니다. Case별로 Enum을 지정하여 타입별로 서비스레이어를 다양하게 호출하여 사용합니다. @Service @RequiredArgsConstructor public class TemplateService { private final List&lt;TemplateAbstract&gt; caseServices; private final EnumMap&lt;CaseType, TemplateAbstract&gt; caseMap = new EnumMap&lt;&gt;(CaseType.class); @PostConstruct public void init() { for (TemplateAbstract template : caseServices) { caseMap.put(template.getCase(), template); } } public Object step1(CaseType caseType) { TemplateAbstract caseService = caseMap.get(caseType); return caseService.step1(); } public Object step2(CaseType caseType) { TemplateAbstract caseService = caseMap.get(caseType); return caseService.step2(); } public Object step3(CaseType caseType) { TemplateAbstract caseService = caseMap.get(caseType); return caseService.step3(); } . public abstract class TemplateAbstract { abstract CaseType getCase(); abstract Object step1(); abstract Object step2(); abstract Object step3(); } . @Service public class Case1Service extends TemplateAbstract { @Override CaseType getCase() { return CaseType.CASE_1; } @Override Object step1() { return \"case 1 - step 1\"; } @Override Object step2() { return \"case 1 - step 2\"; } @Override Object step3() { return \"case 1 - step 3\"; } } . @Service public class Case2Service extends TemplateAbstract { @Override CaseType getCase() { return CaseType.CASE_2; } @Override Object step1() { return \"case 2 - step 1\"; } @Override Object step2() { return \"case 2 - step 2\"; } @Override Object step3() { return \"case 2 - step 3\"; } } . ",
    "url": "/docs/git/Template%20Method%20Pattern.html",
    
    "relUrl": "/docs/git/Template%20Method%20Pattern.html"
  },"287": {
    "doc": "Utils - Page Rq Rs",
    "title": "Utils - Page Rq Rs",
    "content": "설정 코드 : https://github.com/mildw/doraemon/tree/main/core/src/main/java/com/example/core/paging . Pageable 그대로의 객체는 가지고있는 필드가 많아 필요한 부분만 사용하도록 객체를 구성했습니다. @Getter @NoArgsConstructor(access = AccessLevel.PROTECTED) public class PageRq { private Integer page; private Integer size; private Sort.Direction direction; private String property; public Pageable toPageable() { if (direction != null &amp;&amp; property != null) { Sort sort = Sort.by(new Sort.Order(this.direction, this.property)); return PageRequest.of(this.page, this.size, sort); } return PageRequest.of(this.page, this.size); } public PageRq(Integer page, Integer size, Sort.Direction direction, String property) { this.page = page; this.size = size; this.direction = direction; this.property = property; } } . @Getter @NoArgsConstructor public class PageRs { private Integer page; private Integer size; private Integer totalPages; private long totalElements; public PageRs(Pageable pageable, int totalPages, long totalElements) { this.page = pageable.getPageNumber(); this.size = pageable.getPageSize(); this.totalPages = totalPages; this.totalElements = totalElements; } public PageRs(int page, int size, int totalPages, int totalElements) { this.page = page; this.size = size; this.totalPages = totalPages; this.totalElements = totalElements; } public PageRs(Pageable pageable, long totalElements) { this.page = pageable.getPageNumber(); this.size = pageable.getPageSize(); this.totalPages = (int) Math.ceil((double) totalElements / pageable.getPageSize()); this.totalElements = totalElements; } public PageRs(Page&lt;?&gt; page) { this.page = page.getPageable().getPageNumber(); this.size = page.getPageable().getPageSize(); this.totalPages = page.getTotalPages(); this.totalElements = page.getTotalElements(); } } . ",
    "url": "/docs/git/Utils%20-%20Page%20Rq%20Rs.html",
    
    "relUrl": "/docs/git/Utils%20-%20Page%20Rq%20Rs.html"
  },"288": {
    "doc": "csrf",
    "title": "csrf",
    "content": ". ",
    "url": "/docs/memo/csrf.html",
    
    "relUrl": "/docs/memo/csrf.html"
  },"289": {
    "doc": "csrf",
    "title": "cross site request forgery attack",
    "content": "CSRF 공격이란, 인터넷 사용자(희생자)가 자신의 의지와는 무관하게 공격자가 의도한 행위(등록, 수정, 삭제 등)를 특정 웹사이트에 요청하도록 만드는 공격 . get . GET http://bank.com/trasnfer?accountNumber=1122&amp;amount=10000 . 위 예시는 로그인을 한 사용자가 특정 계좌(“1122”)로 금액(10000)을 이체하기 위해 사용하는 GET 요청 . &lt;a href=\"http://bank.com/transfer?accountNumber=5678&amp;amount=10000\"&gt; Pictures@ &lt;/a&gt; . Link(링크): 공격자는 이체를 실행하도록 하기 위해 사용자(희생자)가 링크를 클릭하도록 유도 . &lt;img src=\"http://bank.com/transfer?accountNumber=5678&amp;amount=10000\"/&gt; . Image(이미지): 이미지 태그를 사용하여 클릭하지 않더라도 페이지가 로드되면 요청은 자동적으로 실행 . post . &lt;form action=\"http://bank.com/transfer\" method=\"POST\"&gt; &lt;input type=\"hidden\" name=\"accountNumber\" value=\"5678\"/&gt; &lt;input type=\"hidden\" name=\"amount\" value=\"10000\"/&gt; &lt;input type=\"submit\" value=\"Pictures@\"/&gt; &lt;/form&gt; . post의 경우 클릭을 유도할 수 도, 이미지로 로드할 수도 없다. 공격자는 from 태그가 필요 . &lt;body onload=\"document.forms[0].submit()\"&gt; &lt;form&gt; . 자바스크립트를 사용한다면 양식을 자동으로 전송(submit) 하도록 설정할 수 있다. ",
    "url": "/docs/memo/csrf.html#cross-site-request-forgery-attack",
    
    "relUrl": "/docs/memo/csrf.html#cross-site-request-forgery-attack"
  },"290": {
    "doc": "csrf",
    "title": "Spring Security CSRF Token",
    "content": "임의의 토큰을 발급한 후 자원에 대한 변경 요청일 경우 Token 값을 확인한 후 클라이언트가 정상적인 요청을 보낸것인지 확인 . 만약 CSRF Token이 존재하지 않거나, 기존의 Token과 일치하지 않는 경우 4XX 상태코드를 리턴 . Spring Security에서는 @EnableWebSecurity 어노테이션을 지정할 경우 자동으로 CSRF 보호 기능이 활성화된다. 따라서 CSRF 비활성화가 필요할 경우 아래와 같이 csrf().disable() 설정을 추가합니다. Rest api에서의 CSRF . 그래서 이렇게 보안 수준을 향상시키는 CSRF를 왜 disable 하였을까? spring security documentation에 non-browser clients 만을 위한 서비스라면 csrf를 disable 하여도 좋다고 한다. ![[Pasted image 20230116111026.png]] . 이 이유는 rest api를 이용한 서버라면, session 기반 인증과는 다르게 stateless하기 때문에 서버에 인증정보를 보관하지 않는다. rest api에서 client는 권한이 필요한 요청을 하기 위해서는 요청에 필요한 인증 정보를(OAuth2, jwt토큰 등)을 포함시켜야 한다. 따라서 서버에 인증정보를 저장하지 않기 때문에 굳이 불필요한 csrf 코드들을 작성할 필요가 없다. ",
    "url": "/docs/memo/csrf.html#spring-security-csrf-token",
    
    "relUrl": "/docs/memo/csrf.html#spring-security-csrf-token"
  },"291": {
    "doc": "Real MySQL 8.0",
    "title": "Real MySQL 8.0",
    "content": " ",
    "url": "/docs/mysql/",
    
    "relUrl": "/docs/mysql/"
  },"292": {
    "doc": "오브젝트",
    "title": "오브젝트",
    "content": " ",
    "url": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/",
    
    "relUrl": "/docs/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/"
  },"293": {
    "doc": "구글 엔지니어는 어떻게 일할까",
    "title": "구글 엔지니어는 어떻게 일할까",
    "content": "[[01. 구글 엔지니어는 어떻게 일할까]] : 구글과 다른 대다수의 기업의 차이를 설명합니다. [[02. 구글 엔지니어는 어떻게 일할까]] : 개발자로서 가져 할 마음가짐들을 설명합니다. [[03. 구글 엔지니어는 어떻게 일할까]] : 리더로서 가져야 할 마음가짐들을 설명합니다. ",
    "url": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/",
    
    "relUrl": "/docs/%EA%B5%AC%EA%B8%80%20%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%8A%94%20%EC%96%B4%EB%96%BB%EA%B2%8C%20%EC%9D%BC%ED%95%A0%EA%B9%8C/"
  },"294": {
    "doc": "가상면접 사례로 배우는 대규모 시스템 설계 기초",
    "title": "가상면접 사례로 배우는 대규모 시스템 설계 기초",
    "content": " ",
    "url": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/",
    
    "relUrl": "/docs/%EA%B0%80%EC%83%81%EB%A9%B4%EC%A0%91%20%EC%82%AC%EB%A1%80%EB%A1%9C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%8C%80%EA%B7%9C%EB%AA%A8%20%EC%8B%9C%EC%8A%A4%ED%85%9C%20%EC%84%A4%EA%B3%84%20%EA%B8%B0%EC%B4%88/"
  },"295": {
    "doc": "aws",
    "title": "aws",
    "content": "[[실습]] . [[01. IAM]] : 권한 처리에 대한 내용을 다룹니다. [[02. EC2]] : Elastic Compute Cloud에 대한 생성과 요금에 대한 내용을 다룹니다. [[03. EC2 - associate level]] : EC2 접근 설정에대한 내용을 다룹니다. [[04. EC2 - EBS]] : EC2 저장소에 관한 내용을 다룹니다. [[05. ELB 및 ASG]] : 엘라스틱 로드밸런서에 대한 내용을 다룹니다. ASG는 오토스케일링 그룹의 약자입니다. [[06. RDS]] : RDS에 대한 내용을 다룹니다. [[07. Route53]] : 도메인 주소를 관리하는 Route53에 대한 내용을 다룹니다. [[09. S3]] : 파일 저장소인 S3에 대한 내용을 다룹니다. [[10. CloudFront]] : 컨텐츠 전송 네트워크인 CloudFront로 S3에 저장되어있는 프론트 파일에 접근하는 방식을 사용하여 프론트 프로젝트를 배포할 수 있습니다. [[12. SQS,SNS,Kinesis, Active MQ]] : AWS에서 제공하는 메시지 큐 서비스, 알림서비스 등의 내용을 다룹 니다. [[13. ECS, Fargate, ECR 및 EKS]] : 도커 컨테이너 배포에 대한 내용을 다룹니다. [[14. 서버리스]] : Lambda와 같은 서버리스에 대한 내용을 다룹니다. [[15. DB]] : DB특징에 대한 간략한 내용이 있습니다. [[16. 데이터 분석]] : aws를 활용한 데이터 분석에 대한 내용입니다. [[17. 머신러닝]] : aws에서 제공하는 머신러닝 서비스에 대한 내용입니다. ",
    "url": "/docs/aws/",
    
    "relUrl": "/docs/aws/"
  },"296": {
    "doc": "portfolio",
    "title": "portfolio",
    "content": " ",
    "url": "/docs/portfolio/",
    
    "relUrl": "/docs/portfolio/"
  },"297": {
    "doc": "실습",
    "title": "실습",
    "content": " ",
    "url": "/docs/aws/%EC%8B%A4%EC%8A%B5/",
    
    "relUrl": "/docs/aws/%EC%8B%A4%EC%8A%B5/"
  },"298": {
    "doc": "git",
    "title": "git",
    "content": " ",
    "url": "/docs/git/",
    
    "relUrl": "/docs/git/"
  },"299": {
    "doc": "memo",
    "title": "memo",
    "content": " ",
    "url": "/docs/memo/",
    
    "relUrl": "/docs/memo/"
  },"300": {
    "doc": "port forwarding",
    "title": "port forwarding",
    "content": ". 특정 포트 번호를 허용하여 내 pc에 접근할 수 있도록 할 수 있다. ipconfig 명령어를 통해 내부 ip주소를 알 수 있다. 결과 : 192.168.219.184 . 공유기 ip 주소 : 192.168.219.1 . id : admin password : mac주소 끝의 6자리 + _admin . 접속 후 포트포워드 가서 설정하고, 제어판의 보안설정에 접근하여 방화벽 설정을 풀어주자. 근데 왜안됨? . 확인해보니 방화벽은 잘 풀린상태였다. 원격 접속을 위해 윈도우기능으로 원격 기능을 키고 skb설정에서 3389 번 포트를 허용하니 잘 동작함. 그리고 윈도우의 원격접속 기능을 끄면 포트포워딩이 fail이 뜬다. 즉 포트만 여는게 아니라 받아주는 서버가 있어야 한다는것. 마찬가지로 mysql서버를 설치 후 동작시키면 ture가 뜬다. 하지만 내가 하고싶은건 도커컨터네이너 동작이기 떄문에 아직 헤매는중이다 . 그에대한 해결 방법 : https://codeac.tistory.com/118 . netsh interface portproxy show all . 적용 확인 . 포트 포워딩을 리눅스에서 ifconfig를 통해 정보를 찾는다. en0으로 시작하는 부분에서 inet주소가 연결되어야 하는 주소이다. netsh interface portproxy add v4tov4 listenport=$port listenaddress='0.0.0.0' connectport=$port connectaddress=$my_wsl_address . $my_wsl_address 는 정확하게는 리눅스에서 ifconfig를 통해 나온주소를 입력해야한다. 파워쉘에서 ipconfig를 통해 나온 주소로 입력해서 계속 갸우뚱했다. 해결! . ",
    "url": "/docs/memo/port%20forwarding.html",
    
    "relUrl": "/docs/memo/port%20forwarding.html"
  },"301": {
    "doc": "spring cloud function 사용, 엑셀 생성용 Lambda 개발",
    "title": "spring cloud function 사용, 엑셀 생성용 Lambda 개발",
    "content": ". [[Spring Cloud Function]] [[RDS Proxy &amp; Lambda VPC &amp; Secret Manager]] . | 상황 . | 진단의 응시 결과 PDF 또는 Excel파일을 생성하는 파일함 서버 존재 | 타 유닛에서 pdf생성 람다개발 이후 기존의 파일함 서버는 엑셀 파일 생성만을 위해 존재 | 엑셀 파일은 상시 사용되지 않음 | 파일함 서버는 항상 구동 중이지만 엑셀 파일 생성 요청은 드문 편이어서 비효율적인 서버 자원 사용 문제가 발생함. | . | 과제 . | 엑셀 파일 생성 기능의 비효율성을 해결하고, 서버 자원을 절감할 수 있는 방법 모색 | 기존의 엑셀 생성 로직에 Java와 QueryDsl을 사용한 코드가 있어 이를 최대한 활용해야함 | . | 해결 . | Excel 파일도 생성 요청 시점에만 자원을 사용할 수 있도록 Lambda로 전환 | Spring Cloud Function을 사용하여 서버리스 환경에서 기존 Spring Boot 구조를 유지하며 Excel 파일 생성 기능을 서버리스로 전환 . | 문제 1: Cold Start 지연 . | Spring Cloud Function을 사용해 Spring Boot 기반 코드를 Lambda로 전환할 때 Cold Start로 인해 응답 시간이 길어짐 | . | 해결 . | Cold Start 시간을 줄이기 위해 Spring Cloud Function 설정을 경량화하고, 불필요한 빈(bean)들을 제거하여 성능 최적화 | . | 문제 2: DB 커넥션 과부하 . | 여러 Lambda 인스턴스가 동시에 실행되면 데이터베이스 연결 수가 과도하게 증가할 가능성 발생 | . | 해결 . | RdsProxy를 통해 데이터베이스 연결을 관리하고, 다수의 Lambda 요청 시에도 안정적으로 DB 연결을 처리할 수 있도록 설정 | . | . | . | 결과 . | 파일 생성 요청이 적은 기간에도 서버를 유지할 필요가 없어, 효율적인 리소스 관리가 가능해짐 | . | . ",
    "url": "/docs/portfolio/spring%20cloud%20function%20%EC%82%AC%EC%9A%A9,%20%EC%97%91%EC%85%80%20%EC%83%9D%EC%84%B1%EC%9A%A9%20Lambda%20%EA%B0%9C%EB%B0%9C.html",
    
    "relUrl": "/docs/portfolio/spring%20cloud%20function%20%EC%82%AC%EC%9A%A9,%20%EC%97%91%EC%85%80%20%EC%83%9D%EC%84%B1%EC%9A%A9%20Lambda%20%EA%B0%9C%EB%B0%9C.html"
  },"302": {
    "doc": "가상의 네트워크 환경 구축",
    "title": "가상의 네트워크 환경 구축",
    "content": ". 시나리오 . | OOO 은 AWS 를 접하고 AWS 를 활용하여 회사들에 “사내 네트워크 구성 및 가상 PC 자원을 제공”하는 사업을 구상했다. | 해당 아이템을 가지고 회사 A 를 차린 OOO 은 다양한 요청을 가진 고객사의 네트워크 환경을 알맞게 구축하여 사업을 유지할 수 있을까..? . | 기본정보 . | 가상 PC 제공은 하나의 PC 당 EC2 한 대(private ip 할당)를 제공한다고 가정한다. | 네트워크 구성시 기본적으로 private subnet 과 public subnet 을 구분하여 구성한다. | Private Subnet 의 외부 통신은 NAT Gateway 를 활용한다. | 고객사 요청에 맞게 네트워크 (ex. CIDR / subnet / Connect / VPN) 를 구성한다. | 적절한 크기의 VPC 대역을 확보하여 네트워크를 구성한다. | 주소범위의 중복을 고려하여 네트워크를 구성한다. | 기본적으로 서비스의 가용성 달성을 위한 서브넷 환경을 구성하도록 한다. (최소 2+) | . | 회사 A (본사) 의 네트워크 구성도는 다음과 같다. | . | 시나리오 1 - 회사 B . | 회사 B 는 대기업으로 회사 구성원은 2000명 이다. | 사업 도메인 특성상 구성원은 최대 4000명으로 제한된다. | . | 회사 B 는 사업 특성상 2개의 지사를 가지고 있습니다. (총 3개 - 본사 / 지사 1 / 지사 2) . | 각 본사 + 지사별로 다른 Subnet 으로 분리되기를 원합니다. | . | . | 시나리오 2 - 회사 C . | 회사 C 는 스타트업으로 회사 구성원은 10명이 되지 않는다. (IoT 제품) . | 사업 도메인 특성상 구성원은 최대 200명으로 제한된다. | . | 기본적인 사내 구성원들의 가상 PC 제공 요청 외로 제품 홍보 홈페이지 제작을 위한 서비스도 VPC 에 올리고자 한다. | 기본적인 보안 구성을 맞춰 3-tier 로 subnet 을 분리하여 구성 한다. | 참고 : 사내 네트워크 구성도 (public - private - private) | . | 제품 홍보 홈페이지는 외부의 사용자들이 접근할 수 있어야 한다. | 해당 제품 홈페이지는 하루 50명 정도 접근하는 사이트이다. (많은 트래픽 X) | . | . | . | 시나리오 3 - 통합 / 연결 . | 해당 사업을 운영하고 있는 회사 A 는 고객사 요청에 따라 각 회사별 PC 에 접근 하여 유지보수까지 지원하게 되었습니다. | 회사 A 의 AWS 네트워크 환경에서 B / C 회사에 접근하여 PC 를 점검할 수 있는 방안에 대해 모색하고 네트워크 구성도로 작성해주세요. | ex. VPC Peering / Transit Gateway | . | . | . 결과 [캡쳐1] 회사 B 의 네트워크 구성도 ![[aws002.drawio.png]] . | B company 192.168.0.0/18 | 가용 영역 1: . | Public 서브넷: 192.168.0.0/21 | Private 서브넷 1: 192.168.8.0/21 | Private 서브넷 2: 192.168.16.0/21 | Private 서브넷 3: 192.168.24.0/21 | . | 가용 영역 2: . | Public 서브넷: 192.168.32.0/21 | Private 서브넷 1: 192.168.40.0/21 | Private 서브넷 2: 192.168.48.0/21 | Private 서브넷 3: 192.168.56.0/21 | . | . [캡쳐1] 회사 C 의 네트워크 구성도 ![[aws004.drawio.png]] . | C company 192.168.0.0/21 | 가용 영역 1: . | Public 서브넷: 192.168.0.0/24 | Private 서브넷 1: 192.168.4.0/24 | Private 서브넷 2: 192.168.8.0/24 | Private 서브넷 3: 192.168.12.0/24 | . | 가용 영역 2: . | Public 서브넷: 192.168.16.0/24 | Private 서브넷 1: 192.168.20.0/24 | Private 서브넷 2: 192.168.24.0/24 | Private 서브넷 3: 192.168.28.0/24 | . | . [캡쳐3] 회사 A/B/C 통합 네트워크 구성도 ![[스크린샷 2024-03-24 오후 10.40.37.png]] . 오답 노트 . B기업과 C기업의 Public Subnet을 가용영역당 한개씩뒀는데, 네트워크 장비 추가 여부에 따라 각각의 Private Subnet당 Public Subnet이 1개씩 있는게 조금 더 유연한 구조라고 한다. 또한 CIDR도 3개의 Private Subnet을 수용할 수 있을정도로 블록의 크기를 늘려야한다. 또한 VPC CIDR의 크기에 따라 요금이 더 부과될 줄 알았는데, 그것은 아닌듯 하다. 때문에 B company 192.168.0.0/18라고 설정 했던 부분도 최대 크기인 B company 192.168.0.0/16으로 잡는것이 좋겠다. 수정 . B company 192.168.0.0/16 - 가용 영역 1: - Public 서브넷 1: 192.168.0.0/21 - Public 서브넷 2: 192.168.8.0/21 - Public 서브넷 3: 192.168.16.0/21 - Private 서브넷 1: 192.168.24.0/21 - Private 서브넷 2: 192.168.32.0/21 - Private 서브넷 3: 192.168.40.0/21 - 가용 영역 2: - Public 서브넷 4: 192.168.48.0/21 - Public 서브넷 5: 192.168.56.0/21 - Public 서브넷 6: 192.168.64.0/21 - Private 서브넷 4: 192.168.72.0/21 - Private 서브넷 5: 192.168.80.0/21 - Private 서브넷 6: 192.168.88.0/21 . A/B/C 통합구성도에서는 비용을 생각해서 VPC Peering을 사용했는데, 규모가 커질경우 관리상 Transit Gateway를 사용하는것도 좋을 것 같다. ",
    "url": "/docs/aws/%EC%8B%A4%EC%8A%B5/%EA%B0%80%EC%83%81%EC%9D%98%20%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC%20%ED%99%98%EA%B2%BD%20%EA%B5%AC%EC%B6%95.html",
    
    "relUrl": "/docs/aws/%EC%8B%A4%EC%8A%B5/%EA%B0%80%EC%83%81%EC%9D%98%20%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC%20%ED%99%98%EA%B2%BD%20%EA%B5%AC%EC%B6%95.html"
  },"303": {
    "doc": "객체지향의 사실과 오해",
    "title": "객체지향의 사실과 오해",
    "content": ". 객체지향의 목표는 실세계를 모방하는 것이 아니다. 오히려 새로운 세계를 창조하는 것이다. 실세계의 모방이라는 개념이 비현실적임에도 여전히 많은 사람들이 실세계 객체와 소프트웨어 객체 간의 대응이라는 과거의 유산을 반복적으로 재생산하는 이유는 뭘까? . 그것은 실세계에 대한 비유가 객체지향의 다양한 측면을 이해하고 학습하는 데 매우 효과적이기 때문이다. ",
    "url": "/docs/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98%20%EC%82%AC%EC%8B%A4%EA%B3%BC%20%EC%98%A4%ED%95%B4.html",
    
    "relUrl": "/docs/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98%20%EC%82%AC%EC%8B%A4%EA%B3%BC%20%EC%98%A4%ED%95%B4.html"
  },"304": {
    "doc": "객체지향의 사실과 오해",
    "title": "협력하는 객체들의 공동체",
    "content": "카페에서 내손에 커피가 들어오기 까지는 주문하는 손님(나), 주문을 받는 캐시어, 커피를 제조하는 바리스타의 역할이 존재한다. 손님, 캐시어, 바리스타는 손님에게 커피를 제공하기 위해 협력하는 과정에서 맡은 바 책임을 다한다. | ![[Pasted image 20240430224817.png | 400]] | . 특정 역할을 맡은 사람은 그에 대한 책임을 갖는다. 바리스타라는 역할은 커피를 제조해야 할 책임을 가지고 있다. 역할과 책임은 협력이 원활하게 진행되는 데 필요한 핵심적인 구성 요소이다. 사람들이 협력을 위해 특정한 역할을 맡고 역할에 적합한 책임을 수행한다는 사실은 몇가지 중요한 개념을 제시한다. | 여러 사람이 동일한 역할을 수행할 수 있다. | 커피를 마실 수 있다면, 어떤 캐시어가 주문을 받는지 중요하지 않다. | . | 역할은 대체 가능성을 의미한다 . | 원하는 일처리만 해준다면 그 역할을 맡은 사람이 누구인지는 중요하지 않다. | . | 책임을 수행하는 방법은 자율적으로 선택할 수 있다. | 한 사람이 동시에 여러 역할을 수행할 수 있다. | . 목표를 달성하기 위해 목표는 더 작은 책임으로 분할되고 책임을 수행할 수 있는 적절한 역할을 가진 사람에 의해 수행된다. 협력에 참여하는 각 개인은 책임을 수행하기 위해 다른 사람에게 도움을 요청하기도 하며, 이를 통해 연쇄적인 요청과 응답으로 구성되는 협력 관계가 완성된다. 객체지향 설계는 적절한 객체에게 적절한 책임을 할당하는 것에서 시작된다. 협력 공동체의 일원으로서 객체는 두가지 덕목을 갖춰야 한다. | 객체는 충분히 협력적이어야 한다. 객체는 다른 객체의 요청에 충실히 귀 기울이고 다른 객체에게 적극적으로 도움을 요청할 정도로 열린 마음을 지녀야 한다. (전지전능한 객체는 복잡도에 의해 자멸해버린다) | 객체는 충분히 자율적 이여야 한다. 자율적이라는 뜻은 자기 스스로의 원칙에 따라 어떤 일을 하거나 자기 스스로를 통제하여 절제하는것 이라는 뜻이다. | . 객체가 협력하는 과정에서 스스로 판단하고 결정하는 자율적인 존재로 남기 위해서는 필요한 행동과 상태를 함께 지녀야한다. 객체의 사적인 부분은 객체 스스로 관리하고 외부에서 일체 간섭할 수 없도록 차단해야 하며, 외부와는 허락된 수단만을 동해서 소통해야한다. 객체지향의 본질 . | 자율적인 객체들의 공동체 | 상태와 행위를 지니며 자기자신을 책임지는 객체를 의미 | 다른 객체와 협력하며, 정해진 역할을 수행하며 역할은 관련된 책임의 집합이다 | 객체는 다른 객체와 협력하기 위해 메시지를 전송하고, 메시지를 수신한 객체는 메시지를 처리하는 데 적합한 메서드를 자율적으로 선택한다 | . ",
    "url": "/docs/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98%20%EC%82%AC%EC%8B%A4%EA%B3%BC%20%EC%98%A4%ED%95%B4.html#%ED%98%91%EB%A0%A5%ED%95%98%EB%8A%94-%EA%B0%9D%EC%B2%B4%EB%93%A4%EC%9D%98-%EA%B3%B5%EB%8F%99%EC%B2%B4",
    
    "relUrl": "/docs/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98%20%EC%82%AC%EC%8B%A4%EA%B3%BC%20%EC%98%A4%ED%95%B4.html#협력하는-객체들의-공동체"
  },"305": {
    "doc": "객체지향의 사실과 오해",
    "title": "이상한 나라의 객체",
    "content": "이상한 나라의 엘리스는 시간의 지남에 따라 자신의 키가 변화되는데, 이는 자신이 어떤 행동을 하느냐에 따라 키(상태)가 결정된다. 또한 자신의 키(상태)에 따라 다음 행동이 결정된다. 이처럼 객체는 다음과 같은 특징을 갖는다 . | 객체는 상태를 가지며 상태는 변경 가능하다 | 상태를 변경시키는 것은 행동이다 . | 행동은 결과는 상태에 의존적이며 상태를 이용해 서술할 수 있다. | 행동의 순서가 결과에 영향을 미친다 | . | 객체는 어떤 상태에 있더라도 유일하게 식별 가능하다 | . 하나의 개별적인 실체로 식별 가능한 물리적인 또는 개념적인 사물은 어떤 것이라도 객체가 될 수 있다. 인간의 인지 능력 안에서 개수를 셀 수 있고, 다른 사물과 구분할 수 있으며, 생성 시점을 알 수 있고, 독립적인 하나의 단위로 인식할 수 있는 모든 사물은 객체이다. 객체를 상태, 행동, 식별자를 지닌 실체로 보는것이 가장 효과적이다 . 상태가 왜 중요한가? 상태를 이용하면 과거에 얽매이지 않고 현재를 기반으로 객체의 행동 상식을 이해할 수 있다. (객체의 상태를 구성하는 모든 특징을 통틀어 프로퍼티 라고한다. 가령 엘리스의 키, 위치 등) ![[Pasted image 20240430233048.png|400]] . 행동은? 객체가 협력에 참여할 수 있는 유일한 방법이다. 객체의 행동은 두가지 관점의 부수 효과를 명확하게 서술해야 한다. | 객체 자신의 상태 변경 | 행동 내에서 협력하는 다른 객체에 대한 메시지 전송 | . 상태의 캡슐화 ![[Pasted image 20240430234013.png|400]] 엘리스는 drinkBeverage()메시지를 전달받고 음료에게 전달하는 메시지는 drunken(quantity)이다. 두 메시지를 보고 엘리스의 키가 크거나 음료의 양이 줄어듦을 예상할 수 있는가? 이처럼 송신자는 수신자의 상태를 전혀 알지 못하는것이 캡슐화이다. 객체의 상태를 변경할지 여부는 객체 스스로 결정한다. 메시지 송신자는 단지 자신의 요구를 메시지로 포장해서 전달 할 뿐이다. 메시지를 해석하고 그에 반응해서 상태를 변경할지 여부는 전적으로 메시지 수신자의 자율적 판단에 따른다. 송신자가 상태 변경을 기대하더라도 수신자가 자신의 상태를 변경하지 않는다면 송신자가 간섭할 수 있는 어떤 여지도 없다. 상태의 캡슐화는 결과적으로 객체의 자율성을 높인다. 자율적인 객체는 스스로 판단하고 스스로 결정하기 때문에 객체의 지능도 높아진다. 객체의 지능이 높아질수록 협력은 유연하고 간결해진다. 식별자 인간의 인지 능력을 이용해 식별 가능한 경계를 가진 모든 사물을 의미한다. 값과 객체의 차이는 값은 식별자가 없지만 객체는 식별자가 있다는 것이다. 시스템 설계할 때는 이런 단순한 값과 객체의 차이점을 명확하게 구분하고 명시적으로 표현하는 것이 매우 중요하다. 값은 숫자, 문자열, 날짜, 시간, 금액 등과 같이 변하지 않는 양을 모델링한다. 기계로서의 객체 . 일반적으로 객체의 상태를 조회하는 작업을 쿼리라고 하고 객체의 상태를 변경하는 작업을 명령이라고 한다. ![[Pasted image 20240430235407.png|400]] 기계로서의 엘리스 . 엘리스는 . | 음료를 마시다 | 케이크를 먹다 | 부채질하다 | 버섯을 먹다 | 문을 통과하다 와 같은 5개의 행동이 있다. 그리고 키와 위치라는 상태를 가진다 | . 앞 4개의 네모난 버튼을 통해 키를 변경시킬 수 있으며, 마지막 네모 버튼으로 위치를 변경시킬 수 있다. 동그란 두 버튼으로 키와 위치를 확인할 수 있다. 사용자가 객체 기계의 버튼을 눌러 상태를 변경하거나 상태를 조회를 요청하는 것은 객체의 행동을 유발하기 위해 메시지를 전송하는 것과 유사하다. 행동이 상태를 결정한다 . 객체지향에 갓 입문한 사람들이 가장 쉽게 빠지는 함정은 상태를 중심으로 객체를 바라보는 것이다. 애플리케이션 안에 살아갈 앨리스 객체를 설계할 때 초보자들은 앨리스 객체에게 필요한 상태가 무엇인지 찾고 키와 위치를 앨리스에 추가한다. 그리고 나서야 키와 위치를 변경하거나 조회할 수 있는 행동이 무엇인지를 고민한다. 안타깝게도 상태를 먼저 결정하고 행동을 나중에 결정하는 방법은 설계에 나쁜 영향을 끼친다. | 상태를 먼저 결정할 경우 캡슐화가 저해된다. 상태에 초점을 맞출 경우 상태가 객체 내부로 깔끔하게 캡슐화되지 못하고 공용 인터페이스에 그대로 노출되버릴 확률이 높아진다 | 협력에 적합하지 못한 객체를 창조하게 된다. | 객체의 재사용성이 저하된다. 상태에 초점을 맞춘 객체는 다양한 협력에 참여하기 어렵기 때문에 재사용성이 저하된다. | . 결국 어떤 책임이 필요한가를 결정하는 과정이 전체 설계를 주도해야한다. (RDD) . 두번째 도시 전설 현실세계의 모방 . 모방과 추상화라는 개념만으로는 현실 객체와 소프트웨어 객체 사이의 관계를 깔끔하게 설명하지 못한다. 의인화 . 그렇다면 현실속의 객체와 소프트웨어 객체 사이의 가장 큰 차이점은 뭘까? 그것은 현실 속에서는 수동적인 존재가 소프트웨어 객체로 구현될 때는 능동적으로 변한다는 것이다. 소프트웨어 객체를 창조할 때 우리는 결코 현실 세계의 객체를 모방하지 않는다. 오히려 소프트웨어 안에 창조하는 객체에게 현실 세계의 객체와는 전혀 다른 특징을 부여하는것이 일반적이다. 음료는 스스로 줄어들 수 없으며, 계좌는 스스로 금액을 이체할 수 없다. 레베카 워프스브록은 현실의 객체보다 더 많은 일을 할 수 있는 소프트웨어 객체의 특징을 의인화라고 부른다 . 소프트웨어 안에 구축되는 객체지향 세계는 현실을 모방한 것이 아니다. 조금 참조 할 뿐이다. 이상한 나라를 창조하라… . ",
    "url": "/docs/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98%20%EC%82%AC%EC%8B%A4%EA%B3%BC%20%EC%98%A4%ED%95%B4.html#%EC%9D%B4%EC%83%81%ED%95%9C-%EB%82%98%EB%9D%BC%EC%9D%98-%EA%B0%9D%EC%B2%B4",
    
    "relUrl": "/docs/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98%20%EC%82%AC%EC%8B%A4%EA%B3%BC%20%EC%98%A4%ED%95%B4.html#이상한-나라의-객체"
  },"306": {
    "doc": "객체지향의 사실과 오해",
    "title": "타입과 추상화",
    "content": "![[Pasted image 20240501012854.png|400]] ![[Pasted image 20240501012909.png|400]] 해리 벡은 승객이 꼭 알아야 하는 사실만 정확하게 표현하고 몰라도 되는 정보는 무시함으로써 이해하기 쉽고 단순하며 목적에 부합하는 지하철 노선도를 창조해 낼 수 있었다. 해리 벡의 가장 위대한 업적은 지하철 노선을 추상화한 것이다. 훌륭한 추상화는 목적에 부합하는 것이어야 한다. 추상화 어떤 양상, 세부사항, 구조를 좀 더 명확하게 이해하기 위해 특정 절차나 물체를 의도적으로 생량하거나 감춤으로써 복잡도를 극복하는 방법이다. - 첫 번째 차원은 구체적인 사물들 간의 공통점은 취하고 차이점은 버리는 일반화를 통해 단순하게 만드는 것이다. - 두 번째 차원은 중요한 부분을 강조하기 위해 불필요한 세부 사항을 제거함으로써 단순하게 만드는 것이다. 모든 경우에 추상화의 목적은 복잡성을 이해하기 쉬운 수준으로 단순화하는 것이라는 점을 기억하자 . 개념 . ![[Pasted image 20240501014326.png|400]] 앨리스는 정원의 인물들을 트럼프와 토끼라는 두개의 그룹으로 나누어 표현했다. 인물들의 차이점을 의도적으로 무시하고 공통점만을 강조 함으로써 트럼프라는 그룹에 속할 수 있는 인물들을 취사 선택한 것이다. 이처럼 공통점을 기반으로 객체들을 묶기 위한 그릇을 개념이라고한다. 개념이란 일반적으로 우리가 인식하고 있는 다양한 사물이나 객체에 적용할 수 있는 아이디어나 관념을 뜻한다. 우리는 개념을 적용하는데 익숙하다. 길 거리를 빠른 속도로 누비는 교통수단에 대해서는 자동차 라는 개념을 적용한다. 개념을 이용하면 객체를 여러 그룹으로 분류 할 수 있다. 결과적으로 개념은 공통점을 기반으로 객체를 분류할 수 있는 일종의 체라고 할 수 있다. 이처럼 객체에 어떤 개념을 적용하는 것이 가능해서 개념 그룹의 일원이 될때 객체를 그 개념의 인스턴스라고한다. 개념의 세가지 관점 . | 심볼 : 개념을 가리키는 간략한 이름이나 명칭 . | 트럼프 | . | 내연 : 개념의 완전한 정의를 나타내며 내연의 의미를 이용해 객체가 개념에 속하는지 여부를 확인할 수 있다. | 몸이 납작하고 두 손과 두 발이 네모난 몸 모서리에 달려있다는 설명 | . | 외연 : 개념에 속하는 모든 객체의 집합 . | 인스턴스들이 모여 이뤄진 집합을 가르킴 (하트 잭, 하트 왕, 하트 여왕 등등) | . | . 분류는 객체 지향의 가장 중요한 개념 중 하나다. 어떤 객체를 어떤 개념으로 분류할지가 객체지향의 품질을 결정한다. 타입 . ![[Pasted image 20240501020115.png|400]] 트럼프 인간은 트럼프보다 좀 더 특화된 행동을 하는 특수한 개념이다. 이 두 개념 사이의 관계를 일반화/특수화 관계라고 한다. 일반화/특수화 관계 . 중요한 것은 객체지향에서 일반화/특수화 관계를 결정하는 것은 객체의 상태를 표현하는 데이터가 아니라 행동이라는 것이다. 두 타입 간에 일반화/특수화 관계가 성립하려면 한 타입이 다른 타입보다 더 특수하게 행동해야 하고 반대로 한 타입은 다른 타입보다 더 일반적으로 행동해야 한다. 일반적인 타입이랑 특수한 타입이 가진 모든 행동들 중에서 일부 행동만을 가지는 타입을 가리킨다. 슈퍼타입과 서브타입 . 일반적인 타입을 슈퍼타입이라고하고 좀 더 특수한 타입을 서브타입이라고 한다. 다시한번 강조하지만 중요한 것은 두 타입 간의 관계가 행동에 의해 결정된다는 점이다. ![[Pasted image 20240501020649.png|400]] . 클래스 . 클래스는 단지 타입을 구현할 수 있는 여러 구현 메커니즘중 하나이다. 클래스는 타입의 구현 외에도 코드를 재사용하는 용도로도 사용되기 때문에 클래스와 타입을 동일시하는 것은 오해와 혼란을 불러일으키곤 한다. 객체지향에서 중요한 것은 동적으로 변하는 객체의 상태와 상태를 변경하는 행위다. 클래스는 그것을 구현하는 메커니즘이라는 사실을 기억하자. ",
    "url": "/docs/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98%20%EC%82%AC%EC%8B%A4%EA%B3%BC%20%EC%98%A4%ED%95%B4.html#%ED%83%80%EC%9E%85%EA%B3%BC-%EC%B6%94%EC%83%81%ED%99%94",
    
    "relUrl": "/docs/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98%20%EC%82%AC%EC%8B%A4%EA%B3%BC%20%EC%98%A4%ED%95%B4.html#타입과-추상화"
  },"307": {
    "doc": "객체지향의 사실과 오해",
    "title": "역할, 책임, 협력",
    "content": "책임을 결정한 후 실제로 협력을 정제하면서 이를 메시지로 변환할 때는 하나의 책임이 여러 메시지로 분할도는 것이 일반적이다. 역할은 책임의 집합을 의미한다. ![[Pasted image 20240501171517.png|400]] 위의 세 과정은 너무나도 유사해서 하나의 협력으로 다루고 싶다. 방법은 간단하다. 재판이라는 협력 과정 속에서 하트 왕과 하트 여왕은 ‘판사’의 역할을 한다. 모자 장수와 요리사, 앨리스는 ‘증인’의 역할을 수행한다. 따라서 ‘판사’와 ‘증인’이라는 역할을 사용하면 세가지 협력을 모두 포괄할 수 있는 하나의 협력으로 추상화할 수 있다. ![[Pasted image 20240501171731.png|400]] 역할의 가장 큰 가치는 하나의 협력 안에 여러 종류의 객체가 참여할 수 있게 함으로써 협력을 추상화할 수 있다는 것이다. 역할은 협력 안에서 구체적인 객체로 대체될 수 있는 추상적인 협력자다. 따라서 본질적으로 역할은 다른 객체에 의해 대체 가능함을 의미한다. 객체가 역할에 주어진 책임 이외에 다른 책임을 수행할 수도 있다는 사실에 주목하라. 판사의 역할을 수행할 수 있는 왕은 재판을 할 책임뿐만 아니라 국정을 돌봐야할 추가적인 책임을 가지고 있다. 결국 객체는 역할이 암시하는 책임보다 더 많은 책임을 가질 수 있다. 따라서 대부분의 경우에 객체의 타입과 역할 사이에는 일반화/특수화 관계가 성립하는 것이 일반적이다. 흔한 오류 . 많은 사람들은 시스템에 필요한 데이터를 저장하기 위해 객체가 존재한다는 선입견을 가지고 있다. 물론 객체가 상태의 일부로 데이터를 포함하는 것은 사실이지만 데이터는 단지 객체가 행위를 수행하는데 필요한 재료일 뿐이다. 두번째 선입견은 객체 지향의 클래스와 클래스 간의 관계를 표현하는 시스템의 정적인 측면에 중점을 둔다는 것이다. 중요한 것은 정적인 클래스가 아니라 협력에 참여하는 동적인 객체이다. 객체 지향의 핵심은 클래스를 어떻게 구현할 것인가가 아니라 객체가 협력 안에서 어떤 책임과 역할을 수행할 것인지를 결정하는 것이다. ",
    "url": "/docs/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98%20%EC%82%AC%EC%8B%A4%EA%B3%BC%20%EC%98%A4%ED%95%B4.html#%EC%97%AD%ED%95%A0-%EC%B1%85%EC%9E%84-%ED%98%91%EB%A0%A5",
    
    "relUrl": "/docs/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98%20%EC%82%AC%EC%8B%A4%EA%B3%BC%20%EC%98%A4%ED%95%B4.html#역할-책임-협력"
  },"308": {
    "doc": "객체지향의 사실과 오해",
    "title": "책임과 메시지",
    "content": "객체지향을 강력하게 만드는 비밀은 책임과 메시지에 숨겨져있다. 역할과 책임이 흐릿 할수록 문제를 해결하려는 객체를 도와줄 어떤 협력자도 찾지 못할것이다. 자율적인 책임의 특징은 객체가 어떻게 해야하는가가 아니라 무엇을 해야하는가를 설명한다는 것이다. 메시지를 전송할 때 추가적인 정보가 필요한 경우 메시지의 인자를 통해 추가 정보를 제공할 수 있다. 예를 들어, 왕이 모자 장수에게 증언하라라고 요청할 때 부가적으로 특정한 장소와 시간에 목격한 것을 증언하라고 요청할 수도 있다. 모자장수.증언하라(어제, 왕국) . 모자장수가 메시지를 처리하기 위해 내부적으로 선택하는 방법을 메서드라고 한다. 메시지와 메서드의 차이 관계를 이해하고 나면 객체지향의 핵심 개념인 다형성을 쉽게 이해할 수 있다. 다형성이란 서로 다른 유형의 객체가 동일한 메시지에 대해 서로 다르게 반응하는 것을 의미한다. 유연하고 확장 가능하고 재사용성이 높은 협력의 의미 . 왕의 증언하라 라는 메시지를 전송할 수 있지만 수신자의 구체적인 타입에 대해서는 알지 못한다. 따라서 왕은 수신자가 메시지를 수신할 수만 있다면 누가 되더라도 상관하지 않는다. 송신자가 수신자에 대해 매우 적은 정보만 알고 있더라도 상호 협력이 가능하다는 사실은 설계의 품질에 큰 영향을 미친다. | 협력이 유연해진다 | 협력이 수행되는 방식을 확장할 수 있다. | 협력이 수행되는 방식을 재사용할 수 있다. | . 객체 인터페이스 . 일반적으로 인터페이스란 어떤 두 사물이 마주치는 경계 지점에서 서로 상호작용할 수 있게 이어주는 방법이나 장치를 의미한다. 사람들은 말과 글이라는 인터페이스를 이용해 자신의 의사를 전달한다. 일반적으로 인터페이스는 3가지 특징을 가진다. | 사용법을 익히기만 하면 내부 구조나 동작 방식을 몰라도 쉽게 대상을 조작하거나 의사를 전달할 수 있다. | 인터페이스 자체는 변경하지 않고 단순히 내부 구성이나 작동 방식만들 변경하는 것은 인터페이스 사용자에게 어떤 영향도 미치지 않는다. | 대상이 변경되더라도 동일한 인터페이스만 제공하면 아무런 문제 없다 | . 메시지가 인터페이스를 결정한다. 객체가 다른 객체와 상호작용할 수 있는 유일한 방법은 메시지 전송이다. 따라서 객체의 인터페이스는 객체가 수신할 수 있는 메시지의 목록으로 구성된다. 인터페이스와 구현의 분리 맷 와이스펠드는 다음 3가지를 중요하다고 주장한다 . | 좀 더 추상적인 인터페이스 | 최소 인터페이스 | 인터페이스와 구현 간에 차이가 있다는 점을 인식 | . 증언 하라와 같은 요청과 달리 목격했던 장면을 떠올려라, 떠오르는 기억을 시간 순서대로 재구성해라, 말로 간결하게 표현하라 와 같은 지나치게 상세한 수준의 메시지를 보내는 것은 객체의 자율성을 저해한다. 두번째 최소 인터페이스 원칙은 외부에서 사용할 필요가 없는 인터페이스는 최대한 노출하지 말라는 것이다. 따라서 객체의 내부를 수정하더라도 외부에 미치는 영향을 최소화 할 수 있다. 객체지향의 세계에서 내부 구조와 작동 방식을 가리키는 고유의 용어는 구현이다. 객체는 상태를 가진다. 상태를 어떻게 표현할 것인가는 객체의 구현에 해당한다. 객체는 행동을 가진다. 행동은 메시지를 수신했을 때만 실행되는 일종의 메시지 처리 방법이다. 인터페이스와 구현의 분리 원칙이 왜 중요할까? 그것은 소프트웨어는 항상 변경되기 때문이다. 수정했을때 어떤 객체가 영향받는지 판단하는 것은 거의 곡예에 가깝다. 책임의 자율성이 협력의 품질을 결정한다 . | 자율적인 책임은 협력을 단순하게 만든다 | 자율적인 책임은 모자 장수의 외부와 내부를 명확하게 분리한다 | 책임이 자율적일 경우 책임을 수행하는 내부적인 방법을 변경하더라도 외부에 영향을 미치지 않는다 | 자율적인 책임은 협력의 대상을 다양하게 선택할 수 있는 유연석을 제공한다. | 객체가 수행하는 책임들이 자율적일수록 객체의 역할을 이해하기 쉬워진다. | . ",
    "url": "/docs/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98%20%EC%82%AC%EC%8B%A4%EA%B3%BC%20%EC%98%A4%ED%95%B4.html#%EC%B1%85%EC%9E%84%EA%B3%BC-%EB%A9%94%EC%8B%9C%EC%A7%80",
    
    "relUrl": "/docs/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98%20%EC%82%AC%EC%8B%A4%EA%B3%BC%20%EC%98%A4%ED%95%B4.html#책임과-메시지"
  },"309": {
    "doc": "객체지향의 사실과 오해",
    "title": "객체 지도",
    "content": "사람들의 요구사항은 계속 변하기 때문에 모델이 제공해야 하는 기능 역시 이에 따라 지속적으로 변할 수밖에 없다. 따라서 기능을 중심으로 구조를 종속시키는 접근법은 범용적이지 않고 재사용이 불가능하며 변경에 취약한 모델을 낳게 된다. 자주 변경되는 기능이 아니라 안정적인 구조를 따라 역할, 책임, 협력을 구성하라. 이것이 이번 장의 주제이다. 미래에 대비하는 가장 좋은 방법은 변경을 예측하는 것이 아니라 변경을 수용할 수 있는 선택의 여지를 설계에 마련해 놓는 것이다. 단지 언제가는 변경이 발생할 것이며 아직까지는 그것이 무엇인지 모른다는 사실을 겸허하게 받아들인다. 좋은 설게는 변경의 여지를 남겨놓는 설계이며, 소요되는 비용을 낮추는 것이다. 변경의 여지를 남겨놓는 가장 좋은 방법은 자주 변경되는 기능이 아닌 안정적인 구조를 중심으로 설계하는 것이다.시스템의 기능은 더 작은 책임으로 분할되고 적절한 객체에게 분배되기 때문에 기능이 변경되더라도 객체 간의 구조는 그대로 유지된다. | ![[Pasted image 20240501183112.png | 400]] | . 객체지향 세계를 구축하기 위해서는 사용자에게 제공할 기능과 기능을 담을 안정적인 구조라는 재료가 필요하다. | 구조는 사용자나 이해관계자들이 도메인에 관해 생각하는 개념과 개념들 간의 관계로 표현한다. | 기능은 사용자의 목표를 만족시키기 위해 책임을 수행하는 시스템의 행위 | . 일반적으로 기능을 수집하고 표현하기 위한 기법을 유스케이스 모델링 구조를 수집하고 표현하기 위한 기법을 도메인 모델링이라고 한다. 안정적인 재료 : 구조 . 도메인 모델 소프트웨어를 사용하는 사람들은 자신이 관심을 가지고 있는 특정한 분야의 문제를 해결하기 위해 소프트웨어를 사용한다. 이처럼 사용자가 프로그램을 사용하는 대상 분야를 도메인이라고 한다. 도메인 모델이란 사용자가 프로그램을 사용하는 대상 영역에 관한 지식을 선택적으로 단순화하고 의식적으로 구조화한 형태이다. 은행 업무에 종사하는 사람들은 은행 도메인을고객과 계좌 사이의 돈의 흐름으로 이해 할 것이다. 중고 자동차 판매상은 구매되는 자동차와 판매되는 자동차의 교환으로 자동차 도메인을 바라볼 것이다. 코드의 구조가 도메인의 구조를 반영하기 때문에 도메인을 이해하면 코드를 이해하기가 훨씬 수월해진다. 도메인 속의 개념과 관계가 코드 속에 녹아 있기 때문에 도메인이 알려주는 길을 따라가면 코드 속에서 길을 잃지 않을 수 있다. 결국 도메인 모델은 코드 안에 존재하는 미로를 헤쳐나갈 수 있는 지도를 제공한다. 도메인 모델을 기반으로 코드를 작성하는 두 번쨰 이유는 도메인 모델이 제공하는 구조가 상대적으로 안정적이기 때문이다. 소프트웨어 개발의 가장 큰 적은 변경이며 변경은 항상 발생한다는 사실을 기억하자. 사용자 모델에 포함된 개념과 규칙은 비교적 변경될 확률이 적기 때문에 사용자 모델을 기반으로 설계와 코드를 만들면 변경에 쉽게 대처할 수 있을 가능성이 커진다. 불안정한 재료 : 기능 . 유스케이스 기능적 요구사항이란 시스템이 사용ㅈ자에게 제공해야하는 기능의 목록을 정리한 것이다. 사용자의 목표를 달성하기 위해 사용자와 시스템 간에 이뤄지는 상호작용의 흐름을 텍스트로 정리한 것을 유스케이스라고 한다. | 유스케이스는 다이어그램이 아니다. 중요한 것은 유스케이스 안에 포함돼 있는 상호작용의 흐름이다. | 유스케이스는 하나의 시나리오가 아니라 여러 시나리오의 집합이다. | 유스케이스는 단순한 피처 목록과 다르다. | 피처는 시스템이 수행해야하는 기능의 목록을 단순하게 나열한 것이다. 피처의 단점은 연관성이 있는 두 피처를 독립적인 기능으로 보이게끔 만든다는 점이다. | . | 유스케이스는 사용자 인터페이스와 관련된 세부 정보를 포함하지 말아야 한다. | 유스케이스에는 사용자가 해지 일자를 선택하기 위해 사용자 인터페이스를 어떻게 구성해야하는지에 대한 정보가 전혀 포함돼 있지 않다. | 자주 변경되는 사용자 인터페이스 요소는 베제하고 행위에 초점을 맞춘다 | . | 유스케이스는 내부 설계와 관련된 정보를 포함하지 않는다 | . 재료 합치기 : 기능과 구조의 통합 . ![[Pasted image 20240501230704.png|400]] . 왜 이자를 계산하는 책임을 이자율 객체에게 할당하는가? 책임 할당의 기본 원칙은 책임을 수행하는 데 필요한 정보를 가진 객체에게 그 책임을 할당하는 것이다. 시스템에 할당된 커다란 책임은 이제 시스템 안의 작은 규모의 객체들이 수행해야 하는 더 작은 규모의 책임으로 세분화 된다. 그렇다면 어떤 객체를 선택할 것인가? 이 시점에 도메인 모델이 등장한다. 우리는 도메인 모델에 포함된 개념을 은유하는 소프트웨어 객체를 선택해야 한다. 협력을 완성하는 데 필요한 메시지를 식별하면서 객체들에게 책임을 할당해 나간다. 마지막으로 협력에 참여하는 객체를 구현하기 위해 클래스를 추가하고 속성과 함께 메서드를 구현하면 시스템의 기능이 완성된 것이다. ",
    "url": "/docs/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98%20%EC%82%AC%EC%8B%A4%EA%B3%BC%20%EC%98%A4%ED%95%B4.html#%EA%B0%9D%EC%B2%B4-%EC%A7%80%EB%8F%84",
    
    "relUrl": "/docs/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98%20%EC%82%AC%EC%8B%A4%EA%B3%BC%20%EC%98%A4%ED%95%B4.html#객체-지도"
  },"310": {
    "doc": "객체지향의 사실과 오해",
    "title": "추상화 기법",
    "content": "추상화 기법의 종류 ![[Pasted image 20240501231743.png|400]] . ",
    "url": "/docs/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98%20%EC%82%AC%EC%8B%A4%EA%B3%BC%20%EC%98%A4%ED%95%B4.html#%EC%B6%94%EC%83%81%ED%99%94-%EA%B8%B0%EB%B2%95",
    
    "relUrl": "/docs/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5%EC%9D%98%20%EC%82%AC%EC%8B%A4%EA%B3%BC%20%EC%98%A4%ED%95%B4.html#추상화-기법"
  },"311": {
    "doc": "단위 테스트",
    "title": "단위 테스트",
    "content": ". ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html"
  },"312": {
    "doc": "단위 테스트",
    "title": "1장",
    "content": "단위 테스트와 코드 설계의 관계 코드를 단위 테스트하기 어렵다면 코드 개선이 반드시 필요하다는 것을 의미한다. 보통 강결합에서 저품질이 나타나는데, 여기서 강결합은 제품 코드가 서로 충분히 분리되지 않아서 따로 테스트하기 어려움을 뜻한다. 안타깝게도 코드베이스를 쉽게 단위 테스트할 수 있다고 해도 반드시 코드 품질이 좋은것을 의미하지 않는다. 단위테스트의 목표? 소프트웨어 프로젝트의 지속 가능한 성장을 가능하게 하는것이다. 테스트가 없는 프로젝트의 경우 시작은 유리하지만, 이내 진척이 없을 정도로 느려진다. 코드베이스에서 무언가 변경할 때마다 무질서도는 증가한다. 지속적인 정리와 리팩터링 등과 같은 적절한 관리를 하지 않고 방치하면 시스템이 점점 더 복잡해지고 무질서해진다. 테스트는 안전망 역할을 한다. 새 기능을 도입하거나 새로운 요구사항에 맞게 리팩터링한 후에도 기존 기능이 잘 동작하는지 확인하는데 도움이 된다. 모든 테스트를 작성할 필요는 없다. 일보 테스트는 아주 중요하고 소프트웨어 품질에 매우 많은 기여를 한다. 지속 가능한 프로젝트 성장을 위해서는 고품질 테스트에만 집중해야 한다. ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#1%EC%9E%A5",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#1장"
  },"313": {
    "doc": "단위 테스트",
    "title": "2장",
    "content": "단위 테스트란 무엇인가 . 정의 . | 작은 코드 조각을 검증 | 빠르게 수행 | 격리된 방식으로 처리하는 자동화된 테스트 | . 문제는 3번째 속성으로 격리의 문제는 단위 테스트의 고전파와 런던파를 구분할 수 있게 해주는 근원적 차이에 속한다. 두 분파의 차이는 격리가 정확히 무엇인지에 대한 의견 차이 하나로 시작된다. 런던파의 접근 . 런던파에서는 테스트 대상 시스템을 협력자에게서 격리하는 것을 일컫는다. 즉 하나의 클래스가 다른 클래스 또는 여러 클래스에 의존하면 이 모든 의존석을 테스트 대역으로 대체해야 한다. (mock 객체를 사용한다는 뜻) . 고전파의 접근 . 고전적인 방법에서는 코드를 꼭 격리시키는 방식으로 테스트해야 하는 것은 아니다. 대신 단위 테스트는 서로 격리해서 실행시켜야한다. 예를 들어 어떤 테스트가 준비 단계에서 데이터베이스에서 고객을 생성할 수 있고, 이 테스트가 실행되기 전에 다른 테스트의 준비 단계에서 고객을 삭제할 수도 있다. 이 두 가지 테스트를 병렬로 실행하면 첫 번째 테스트가 실패하는데, 이는 제품이 고장 나서가 아니라 두 번째 테스트의 간섭 때문이다. 공유 의존성 테스트 간에 공유되고 서로의 결과에 영향을 미칠 수 있는 수단을 제공하는 의존성이다. 데이터베이스도 공유 의존성의 전형적인 예가 될 수 있다. 비공개 의존성 공유하지 않는 의존성이다. 프로세스 외부 의존성 애플리케이션 실행 프로세스 외부에서 실행되는 의존성이며, 아직 메모리에 없는 데이터에 대한 프록시다. 외부 의존성은 대부분 공유 의존성에 해당하지만 모두 그런것은 아니다. 예를 들어 DB를 도커 컨테이너로 시작한다면 테스트가 더이상 동일한 인스턴스로 동작하지 않기 때문에 외부이면서 공유하지 않는 의존성이 된다. 휘발성 의존성 다음 속성 중 하나를 나타내는 의존성이다 - 개발자 머신에 기본 설치된 환경 외에 런타임 환경의 설정 및 구성을 요구한다. 데이터베이스와 api 서비스가 좋은 예다. 추가 설정이 필요하며 시스템에 기본으로 설치돼 있지 않다. - 비결정적 동작을 포함한다. 예를 들어 난수 생성기 또는 현재 날짜와 시간을 반환하는 클래스 등이 있다. 이런 의존성은 각 호출에 대해 다른 결과를 제공하기 때문에 비결정적이라 한다. 공유 의존성은 거의 항상 실행 프로세스 외부에 있는 데 반해, 비공개 의존성은 보통 그 경계를 넘지 않는다. 따라서 데이터베이스나 파일 시스템 등의 공유 의존성에 대한 호출은 비공개 의존성에 대한 호출보다 더 오래 걸린다. 그리고 단위 테스트 두 번째 속성으로 빨리 실행해야 하는 필요성이 있으므로, 이러한 호출을 포함하는 공유 의존석을 가진 테스트는 단위 테스트 영역에서 통합 테스트 영역으로 넘어간다. 런던파와 고전파의 나눠진 원인은 격리 특성에 있다. 런던파는 테스트 대상 시스템에서 협력자를 격리하는것 고전파는 단위 테스트끼리 격리하는것 . |   | 격리 주체 | 단위의 크기 | 테스트 대역 사용 대상 | . | 런던파 | 단위 | 단일 클래스 | 불변 의존성 외 모든 의존성 | . | 고전파 | 단위 테스트 | 단일 클래스 또는 클래스 세트 | 공유 의존성 | . 런던파의 이점 . | 입자성이 좋다. 테스트가 세밍해서 한 번에 한 클래스만 확인한다. | 서로 연결된 클래스의 그랲프가 커져도 테스트하기 쉽다. 모든 협력자는 테스트 대역으로 대체되기 때문에 테스트 작성 시 걱정할 필요가 없다. | 테스트가 실패하면 어떤 기능이 실패했는지 확실히 알 수 있다. | . 테스트의 단위는 너무 작아서는 안된다. 이 테스트가 무엇을 검증하는지 정확하게 이해하기가 어려워지기 때문이다. 응집도가 높도 의미가 있어야한다. 예를들어 우리집 강아지를 부르면, 바로 나에게 온다. 우리집 강아지를 부르면 먼저 왼쪽 앞다리를 움직이고, 이어서 오른쪽 앞다리를 움직이고, 머리를 돌리고, 꼬리를 흔들기 시작한다. 실제 동작(개가 주인에게 오는 것)대신 개별 클래스(다리, 머리, 꼬리)를 목표로 할 때 테스트가 이렇게 보이기 시작한다. 상호 연결된 클래스의 큰 그래프를 단위 테스트하기 . 실제 협력자를 대신해 목을 사용하면 클래스를 쉽게 테스트할 수 있다. 고전파를 따라 테스트 대상 시스템을 설정하려면 전체 객체 그래프를 다시 생성해야 하는데, 작업이 많을 수 있다. 모두 사실이지만, 잘못된 문제에 초점을 맞추고 있다. 상호 연결된 클래스의 크고 복잡한 그래프를 테스트할 방법을 찾는 대신, 먼저 이러한 클래스 그래프를 갖지 않는 데 집중해야 한다. 대게 클래스가 커진 것은 코드 설계 문제의 결과이다. 목을 사용하는 것은 이 문제를 감추기만 할 뿐, 원인을 해결하지 못한다. 버그 위치 정확히 찾아내기 . 런던 스타일과 달리 고전 스타일은 하나의 버그가 전체 시스템에 걸쳐 테스트 실패를 야기하는 파급 효과를 초래한다. 결국 원인을 찾기가 더 어려워진다. 문제를 파악하고 디버깅하는데 시간이 걸릴 수 있다. 하지만 큰 문제는 아니다. 테스트를 정기적으로 실행하면 버그의 원인을 알아낼 수 있다. 즉 마지막으로 수정한게 무엇인지 알기 때문에 문제를 찾는게 그리 어렵지않다. 고전파와 런던파 사이의 다른 차이점 . | 테스트 주도 개발을 통한 시스템 설계 방식 | 과도한 명세 문제 | . 가장 중요한 차이점은 과도한 명세 문제, 즉 테스트가 구현 세부 사항에 결합되는 것이다. 런던 스타일은 고전 스타일보다 테스트가 구현에 더 자주 결합되는 편이다. ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#2%EC%9E%A5",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#2장"
  },"314": {
    "doc": "단위 테스트",
    "title": "두 분파의 통합 테스트",
    "content": "런던파는 실제 협력자 객체를 사용하는 모든 테스트를 통합 테스트로 간주한다. 고전 스타일로 작성된 대부분의 테스트는 런던파 지지자들에게 통합 테스트로 느껴질 것이다. 다시 말하지만, 단위 테스트는 다음과 같은 특징이 있는 자동화된 테스트다. | 작은 코드 조각을 검증하고 | 빠르게 수행하고 | 격리된 방식으로 처리한다. | . 통합테스트는 이러한 기준 중 하나를 충족하지 않는 테스트다. 공유 의존성에 접근하는 테스트는 다른 테스트와 분리해 실행할 수 없다 외부 의존성에 접근하면 테스트는 느려진다 둘 이상의 동작 단위를 검증할 때의 테스트는 통합 테스트다 . ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#%EB%91%90-%EB%B6%84%ED%8C%8C%EC%9D%98-%ED%86%B5%ED%95%A9-%ED%85%8C%EC%8A%A4%ED%8A%B8",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#두-분파의-통합-테스트"
  },"315": {
    "doc": "단위 테스트",
    "title": "3장",
    "content": " ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#3%EC%9E%A5",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#3장"
  },"316": {
    "doc": "단위 테스트",
    "title": "단위 테스트를 구성하는 방법",
    "content": "AAA 패턴 . 준비, 실행, 검증 . public void sum_of_two_numbers() { //준비 double first = 10; double second = 20; var calculator = new Calculator(); //실행 double result = calculator.sum(first, second); //검증 Assert.Equal(30, result); } . 테스트 내 if문 피하기 . if문이 있는 단위 테스트를 만날 수 있는데, 이것은 안티 패턴이다. 단위 테스트든 통합 테스트든 테스트는 분기가 없는 간단한 일련의 단계여야 한다. if문은 테스트가 한번에 너무 많은 것을 검증한다는 표시다. 각 구절은 얼마나 커야 하는가? . 준비 구절이 가장 큰 경우 너무 크다면 팩토리 클래스로 도출하는 것이 좋다. 코드 재사용에 도움이 되는 두가지 패턴으로 오브젝트 마더와 테스트 데이터 빌더가 있다 . // 오브젝트 마더 클래스 정의 class UserObjectMother { // 특정 상태의 사용자를 생성하는 메서드 public static User createActiveUser() { return new User(\"activeuser\", \"activeuser@example.com\"); } public static User createInactiveUser() { return new User(\"inactiveuser\", \"inactiveuser@example.com\"); } } public class Main { public static void main(String[] args) { // 오브젝트 마더 패턴을 사용하여 사용자 생성 User activeUser = UserObjectMother.createActiveUser(); User inactiveUser = UserObjectMother.createInactiveUser(); // 생성된 사용자 출력 System.out.println(\"Active User: \" + activeUser.getUsername() + \", \" + activeUser.getEmail()); System.out.println(\"Inactive User: \" + inactiveUser.getUsername() + \", \" + inactiveUser.getEmail()); } } . //테스트 빌더 패턴 예제 import java.util.Random; // 테스트 데이터 빌더 클래스 정의 class TestDataBuilder { private static Random random = new Random(); // 임의의 사용자 생성 메서드 public static User createRandomUser() { // 임의의 사용자 이름과 이메일 생성 String username = \"user\" + random.nextInt(1000); String email = \"user\" + random.nextInt(1000) + \"@example.com\"; // 사용자 객체 생성하여 반환 return new User(username, email); } } public class Main { public static void main(String[] args) { // 테스트 데이터 빌더를 사용하여 랜덤 사용자 생성 User user1 = TestDataBuilder.createRandomUser(); User user2 = TestDataBuilder.createRandomUser(); // 생성된 사용자 출력 System.out.println(\"User 1: \" + user1.getUsername() + \", \" + user1.getEmail()); System.out.println(\"User 2: \" + user2.getUsername() + \", \" + user2.getEmail()); // 사용자 정보 수정 user1.setUsername(\"newusername\"); user2.setEmail(\"newemail@example.com\"); // 수정된 사용자 정보 출력 System.out.println(\"Modified User 1: \" + user1.getUsername() + \", \" + user1.getEmail()); System.out.println(\"Modified User 2: \" + user2.getUsername() + \", \" + user2.getEmail()); } } . 실행 구절이 한 줄 이상인 경우를 경계해라 보통 실행 구절은 한 줄이다. public void pruchase_successds_when_enough_inventory() { //준비 var store = new Store(); store.addInventory(Product.Shampoo,10); var customer = new Customer(); //실행 bool success = customer.purchase(store, Product.Shampoo, 5); store.RemoveInventory(success, Product.Shampoo, 5); //검증 Assert.True(success); Assert.Equal(5, store,GetInventory(Product.Shampoo)); } . 해당 코드는 테스트에는 문제가 없지만 실제 비즈니스 로직에서 구매 메서드를 실행하고 RemoveInventory를 실행하지 않으면 모순이 생긴다. 이러한 모순을 불변 위반이라고 하며, 모순으로부터 안전하기 위해 캡슐화를 한다. 검증 구절에는 검증문이 얼마나 있어야 하는가? 단일 동작 단위는 여러 결과를 낼 수 있으며, 하나의 테스트로 그 모든 결과를 평가하는 것이 좋다. 하지만 검증 구절이 너무 커지는것은 경계해야 한다. 제품 코드에서 추상화가 누락됐을 수 있다. 종료 단계는 어떤가? 검증 이후에 종료단계를 두는 경우도 있다. 예를 들면 테스트에 의해 작성된 파일을 지우거나 DB연결을 종료하고자 종료 단계를 사용한다. ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#%EB%8B%A8%EC%9C%84-%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%A5%BC-%EA%B5%AC%EC%84%B1%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#단위-테스트를-구성하는-방법"
  },"317": {
    "doc": "단위 테스트",
    "title": "테스트 간 테스트 픽스처 재사용",
    "content": "테스트에서 언제 어떻게 코드를 재사용하는지 아는것이 중요하다. 준비 구절에서 코드를 재사용하는 것이 테스트를 줄이면서 단순화하기 좋은 방법이다. 테스트 픽스처를 재사용하는 첫 번째 방법은 다음과 같이 테스트 생성자에서 픽스처를 초기화하는 것이다. public class CustomerTests { private readonly Store _store; private readonly Customer _sut; // 클래스 내 각 테스트 이전에 호출 public CustomerTests() { _store = new Store(); _store.AddInventory(Product. Shampoo, 10); _sut = new Customer(); ｝ [Fact] public void Purchase_succeeds when_enough_inventory() { bool success = _sut.Purchase(_store, Product.Shampoo, 5); Assert.True(success); Assert.Equal (5, _store.GetInventory(Product.Shampoo)); ｝ [Fact] public void Purchase_fails when _not_enough_inventory()｛ bool success = _sut.Purchase(_store, Product.Shampoo, 15); Assert.False(success); Assert.Equal (10, _store.GetInventory(Product.Shampoo)); } } . 위와 같은 방법으로 준비 구절을 추출할 수 있는데, 이것은 두가지 단점이 있다 . | 테스트 간 결합도가 높아진다 . | 테스트 간의 높은 결합도는 안티 패턴이다 | 변경으로 인해 다른 테스트에 영향을 줄 수 있다 | . | 테스트 가독성이 떨어진다 . | 또한 테스트만 보고는 더이상 전체 그림을 볼 수 없다 | . | . ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#%ED%85%8C%EC%8A%A4%ED%8A%B8-%EA%B0%84-%ED%85%8C%EC%8A%A4%ED%8A%B8-%ED%94%BD%EC%8A%A4%EC%B2%98-%EC%9E%AC%EC%82%AC%EC%9A%A9",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#테스트-간-테스트-픽스처-재사용"
  },"318": {
    "doc": "단위 테스트",
    "title": "더 나은 픽스처 재사용법",
    "content": "public class CustomerTests { [Fact] public void Purchase_succeeds_when_enough_inventory() { Store store = CreateStoreWithInventory (Product. Shampoo, 10); Customer sut = CreateCustomer (); bool success = sut. Purchase(store, Product. Shampoo, 5); Assert. True (success) ; Assert. Equal (5, store.GetInventory (Product.Shampoo)); } [Fact] public void Purchase_fails_when_not_enough_inventory() { Store store = CreateStoreWithInventory (Product. Shampoo, 10); Customer sut = CreateCustomer (); bool success = sut. Purchase(store, Product. Shampoo, 15); Assert. False(success) ; Assert. Equal(10, store.GetInventory(Product.Shampoo)); } private Store CreateStoreWithInventory(Product product, int quantity)｛ Store store = new Store(); store.addInventory(product, quantity); return store; } private static Customer createCustomer() { return new Customer(); } } . ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#%EB%8D%94-%EB%82%98%EC%9D%80-%ED%94%BD%EC%8A%A4%EC%B2%98-%EC%9E%AC%EC%82%AC%EC%9A%A9%EB%B2%95",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#더-나은-픽스처-재사용법"
  },"319": {
    "doc": "단위 테스트",
    "title": "단위 테스트 명명법",
    "content": "[테스트 대상 메서드]_[시나리오]_[예상결과] . | 엄격한 정책을 따르지 않는다. 복잡한 동작에 대한 높은 수준을 설명하려면 좁은 정책 안에서 해결할 수 없다 | 비 개발자에게 설명하는 것처럼 이름을 짓자 | underscore(_)를 통해 가독성을 향상 시키자 | . ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#%EB%8B%A8%EC%9C%84-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%AA%85%EB%AA%85%EB%B2%95",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#단위-테스트-명명법"
  },"320": {
    "doc": "단위 테스트",
    "title": "매개변수화 된 테스트 리팩터링하기",
    "content": "public class DeliveryServiceTests { //[InlineData] 특성은 테스트 메서드에 입력 값 집합을 보낸다. //각 라인은 동작에 대해 별개의 사실을 나타낸다. [InlineData(-1, false)] [InlineData(0, false)] [InlineData(1, false)] [InlineData(2, true)] [Theory] public void Can_detect_an_invalid_delivery_date(int daysFromNow, bool expected) { DeliveryService sut = new DeliveryService(); DateTime deliveryDate = DateTime. Now .AddDays (daysFromNow); Delivery delivery = new Delivery Date = deliveryDate bool isValid = sut. IsDeliveryValid(delivery); Assert. Equal (expected, isValid); } } . 동작이 너무 복잡하면 매개변수화된 테스트를 조금도 사용하지 말것을 추천한다 . ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98%ED%99%94-%EB%90%9C-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81%ED%95%98%EA%B8%B0",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#매개변수화-된-테스트-리팩터링하기"
  },"321": {
    "doc": "단위 테스트",
    "title": "4장",
    "content": "좋은 단위 테스트의 4대 요소 . | 회귀 방지 | 리팩터링 내성 | 빠른 피드백 | 유지 보수성 | . ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#4%EC%9E%A5",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#4장"
  },"322": {
    "doc": "단위 테스트",
    "title": "회귀 방지",
    "content": "회귀 방지 지표에 대한 테스트 점수가 얼마나 잘 나오는지 평가하려면 다음 사항을 고려해야한다. 회귀란 소프트웨어 버그이다. | 테스트 중에 실행되는 코드의 양 . | 일반적으로 코드가 많을수록 테스트에서 회귀가 나타날 가능성이 높다. | . | 복잡도와 도메인 유의성 . | 비즈니스에 중요한 기능에서 발생한 버그가 가장 큰 피해를 입히기 떄문이다. | . | 외부 라이브러리 | . 회귀 방지 지표를 극대화하려면 테스트가 가능한 많은 코드를 실행하는 것을 목표로 해야 한다. ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#%ED%9A%8C%EA%B7%80-%EB%B0%A9%EC%A7%80",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#회귀-방지"
  },"323": {
    "doc": "단위 테스트",
    "title": "리팩터링 내성",
    "content": "이는 테스트를 빨간색으로 바꾸지 않고 기본 애플리케이션 코드를 리팩터링할 수 있는지에 대한 척도다. 모든것을 완벽하게 동작하게 리팩터링 했다. 테스트코드가 실패하고 있다는 것만 빼고, 정확히 무엇이 고장났는지 확인해 봤지만, 알고 보니 아무것도 고장나지 않았다. 기능은 예전과 같이 완벽하게 동작한다. 문제는 코드를 수정하면 테스트가 빨간색으로 바뀌게끔 작성됐다는 것이다. 이러한 상황을 거짓 양성이라고 한다. 거짓 양성은 허위 경보이다. 아니 이책은 왜 거짓 양성이란 어려운말을쓰지? 허위 경보라고 작성하면 다들 알아듣기 편할텐데? . 거짓 양성의 원인 . 테스트와 테스트 대상 시스템(SUT)의 구현 세부 사항이 많이 결합 할수록 허위 경보가 더 많이 생긴다. 줄이는 방법은 구현 세부사항에서 테스트를 분리하는 것 뿐이다. 테스트를 구성하기에 가장 좋은 방법은 문제 영역에 대해 이야기하는 것이다. 테스트는 최종 사용자의 관점에서 sut를 검증해야 하고 최종 사용자에게 의미 있는 결과만 확인해야 한다. 다른 모든 것은 무시해야 한다. public class Message { public String header {get;set;} public String body {get;set;} public String footer {get;set;} } public interface IRenderer { String render(Message message); } public class MessageRenderer : IRenderer { public IReadOnlyList&lt;IRenderer&gt; subRenderers {get;} public MessageRenderer() { subRenderers = new List&lt;IRenderer&gt; { new HeaderRenderer(). new BodyRenderer(), new FooterRenderer() }; } public String render(Message message) { return subRenderers.select(x-&gt;x.render(message)) .aggregate(\"\", (str1, str2) -&gt; str1 + str2) } } . public class BodyRenderer : IRenderer { public String Render(Message message) { return $\"&lt;b&gt;{message.body}&lt;/b&gt;\"; } } . MessageRenderer를 어떻게 테스트할 수 있을까? . public void MessageRenderer_uses_correct_sub_renderers) { var sut = new MessageRenderer (); IReadOnlyList&lt; IRenderer&gt; renderers = sut.SubRenderers; Assert. Equal (3, renderers. Count); Assert. IsAssignableFrom&lt;HeaderRenderer&gt;(renderers [0]); Assert. ISAssignableFrom&lt;BodyRenderer&gt; (renderers (1]); Assert. IsAssignableFrom&lt;FooterRenderer&gt;(renderers [2]); } . 위 테스트는 하위 렌더링 클래스가 예상하는 모든 유형이고 올바른 순서대로 나타나는지 여부를 확인한다. 여기서 MessageRenderer가 메시지를 처리하는 방식도 정확해야 한다고 가정한다. 처음에는 테스트가 좋아보이지만, MessageRenderer의 식별할 수 있는 동작을 실제로 확인하는가? 하위 렌더링 클래스를 재배열하거나 그중 하나를 새 것으로 교체하면 어떻게 될까? 버그로 이어지는가? 반드시 그렇지는 않다. 하위 렌더링 클래스의 구성을 변경해도 HTML 문서가 동일하게 유지될 수 있다. 예를들어 BodyRenderer를 동일한 작업을 수행하는 BoldRenderer로 바꿀 수 있다. 또는 모든 하위 렌드링 클래스를 제거하고 MessageRenderer에서 직접 렌더링을 구현할 수도 있다. 최종 결과가 바뀌지 않을지라도, 테스트를 수행하면 빨간색으로 변할 것이다. 이는 테스트가 sut가 생성한 결과가 아니라 sut의 구현 세부와 결합했기 때문이다. 구현 세부 사항 대신 최종 결과를 목표로 하기 . [Fact] public void Rendering_a_message() { var sut = new MessageRenderer (); var message = new Message Header = \"h\"， Body = \"b\", Footer = \"f\" string html = sut. Render (message); Assert.Equal(\"&lt;h1&gt;h&lt;/h1&gt;‹b&gt;b&lt;/b&gt;&lt;i&gt;f‹/i&gt;\", html); } . MessageRenderer를 블랙박스 취급하고 식별할 수 있는 동작에만 신경쓴다. 이로인해 리팩터링 내성이 증가했다. ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#%EB%A6%AC%ED%8C%A9%ED%84%B0%EB%A7%81-%EB%82%B4%EC%84%B1",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#리팩터링-내성"
  },"324": {
    "doc": "단위 테스트",
    "title": "빠른 피드백과 유지 보수성",
    "content": "유지보수성 지표는 유지비를 평가한다. 다음 두가지 주요 요소로 구성된다. | 테스트가 얼마나 이해하기 어려운가 . | 테스트 코드의 품질은 제품 코드만큼 중요하다. | . | 테스트가 얼마나 실행하기 어려운가 . | 외부 종속성으로 작동하면, 데이터베이스 서버를 재부팅하고 네트워크 연결 문제를 해결하는 등 의존성을 상시 운영하는데 시간을 들여야 한다. | . | . ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#%EB%B9%A0%EB%A5%B8-%ED%94%BC%EB%93%9C%EB%B0%B1%EA%B3%BC-%EC%9C%A0%EC%A7%80-%EB%B3%B4%EC%88%98%EC%84%B1",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#빠른-피드백과-유지-보수성"
  },"325": {
    "doc": "단위 테스트",
    "title": "이상적인 테스트를 찾아서",
    "content": "4가지 요소를 모두 만족시키는 이상적인 테스트를 만드는것은 불가능하다. 회귀 방지, 리팩터링 내성, 빠른 피드백은 상호 배타적이기 떄문이다. 셋중 하나를 희생해야 나머지 둘을 최대로 할 수 있다. | 엔드 투 엔드 : 빠른 피드백 희생 | 간단한 테스트 : 무의미한 테스트로 인해 회귀 희생 | 깨지기 쉬운 테스트 : 거짓 양성이 많은 테스트를 작성하기 쉽다. 리팩터링 내성 희생 | . 결론 다 챙기는것은 불가능 하다. 하지만 리팩터링 내성은 꼭 챙겨야 한다. 이유는 다른 특성은 절충안이 있지만 리팩터링 내성은 0아니면1이기때문에 회귀 방지나 빠른 피드백 부분에서 절충안을 찾아야한다. ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#%EC%9D%B4%EC%83%81%EC%A0%81%EC%9D%B8-%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%A5%BC-%EC%B0%BE%EC%95%84%EC%84%9C",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#이상적인-테스트를-찾아서"
  },"326": {
    "doc": "단위 테스트",
    "title": "자동화 개념",
    "content": "테스트 피라미드 분해 . 테스트 피라미드는 테스트 스위트에서 테스트 유형 간의 일정한 비율을 일컫는 개념이다 . | 엔드 투 엔드 | 통합 테스트 | 단위 테스트 아래로 갈수록 테스트 수가 많음 위로 갈수록 최종 사용자 경험에 가깝게 흉내 | . 예외적으로 비즈니스 규칙이나 기타 복잡도가 없는 기본적인 crud라면, 테스트 피라미드는 단위 테스트와 통합 테스트의 수가 같고 엔드 투 엔드 테스트가 없는 직사각형처럼 보일것이다. 단위 테스트는 알고리즘이나 비즈니스 복잡도가 없는 환경에서는 유용하지 않다. 통합 테스트는 코드가 아무리 단순하더라도 데이터베이스와 같이 다른 하위 시스템과 통합되어 잘 작동하는지 확인하는것이 중요하다. 블랙박스 테스트와 화이트박스 테스트 . | 블랙박스 : 내부 구조를 몰라도 검사할 수 있는 테스트방법 | 화이트박스 : 그 반대 | . 장단점 . |   | 회귀방지 | 리팩터링 내성 | . | 화이트 박스 | 좋음 | 나쁨 | . | 블랙 박스 | 나쁨 | 좋음 | . 테스트를 작성할 때는 블랙박스 방법을, 테스트를 분석할때는 화이트박스 방법을 사용 . ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#%EC%9E%90%EB%8F%99%ED%99%94-%EA%B0%9C%EB%85%90",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#자동화-개념"
  },"327": {
    "doc": "단위 테스트",
    "title": "5장",
    "content": "목과 테스트 취약성 . ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#5%EC%9E%A5",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#5장"
  },"328": {
    "doc": "단위 테스트",
    "title": "목과 스텁 구분",
    "content": "테스트 대역 유형 테스트 대역의 주 용도는 테스트를 편리하게 하는것이다. 테스트 대상 시스템으로 실제 의존성 대신 전달되므로 설정이나 유지보수가 어려울 수 있다. 테스트 대역에는 더미, 스텁, 스파이, 목, 페이크 라는 다섯가지가 있다. | 목 (목, 스파이) . | 외부로 나가는 상호작용을 모방하고 검사하는데 도움을 준다. 이러한 상호 작용은 sut가 상태를 변경하기 위한 의존석을 호출하는 것에 해당한다. | . | 스텁 (스텁, 더미, 페이크) . | 내부로 들어오는 상호작용을 모방하는데 도움을 준다. 이러한 상호 작용은 sut가 입력 데이터를 얻기 위한 의존성을 호출하는 것에 해당한다. | . | . 테스트 대상 시스템(sut) -&gt; 이메일 발송 (mock) - &gt; smtp 서버 테스트 대상 시스템(sut) -&gt; 데이터 검색 (stub) - &gt; 데이터베이스 . 스파이는 수동으로 작성하는 반면, 목은 목 프레임워크의 도움을 받아 생성된다. 더미는 null 값이나 가짜 문자열과 같이 단순하고 하드코딩된 값이다. 스텁은 시나리오마다 다른 값을 반환하게끔 구성할 수 있도록 필요한 것을 다 갖춘 완전한 의존성이다. 페이크는 아직 존재하지 않는 의존성을 대체하고자 구현한다. 도구로서의 목과 테스트 대역으로서의 목 . mock라이브러리를 사용하면 도구로서의 목(stub)과 테스트 대역으로서의 목 두가지 유형을 생성할 수 있기 때문에 헷갈려선 안된다. 스텁으로 상호 작용을 검증하지 말라 . 스텁은 sut가 출력을 생성하도록 입력을 제공할 뿐 검증을 하지 않는다. \b리팩터링 내성을 향상 시키는 방법은 구현 세부 사항이 아니라 최종 결과를 검증하는 것이다. 최종 결과가 아닌 사항을 검증하는 이러한 관행을 과잉 명세라고 부른다. 과잉 명세는 상호 작용을 검사할 때 가장 흔하게 발생한다. 스텁과의 상호 작용을 확인하는 것은 쉽게 발견할 수 있는 결함이다. 테스트가 스텁과의 상호 작용을 확인해서는 안 되기 때문이다. 목은 더 복잡하다. 목을 쓰면 무조건 테스트 취약성을 초래하는 것은 아니지만, 대다수가 그렇다. 목과 스텁의 개념은 명령 조회 분리 원칙(CQS)과 관련이 있다. 모든 메서드는 명령이거나 조회여야 하며, 이 둘을 혼용해서는 안된다. 이렇게 명확하게 분리하면 코드를 읽기 쉽다. 물론 항상 CQS 원칙을 따를 수 있는 것은 아니다. 전형적인 예로 stack.pop()이 있다. 그래도 가능하면 CQS를 따르는 것이 좋다. 명령을 대체 -&gt; 목, 조회를 대체 -&gt; 스텁 . 식별할 수 있는 독장은 공개 API와 다르다. 모든 제품 코드는 2차원으로 분류할 수 있다. | 공개 API 또는 비공개 API | 식별할 수 있는 동작 또는 구현 세부 사항 각 차원의 범주는 겹치지 않는다. 즉 메서드는 공개 API와 비공개 API 둘 다에 속할 수 없다. | . 식별할 수 있는 동작과 내부 구현 세부 사항에는 미묘한 차이가 있다. 코드가 시스템의 식별할 수 있는 동작이려면 다음 중 하나를 해야 한다. | 클라이언트가 목표를 달성하는 데 도움이 되는 연산을 노출하라. 연산은 계산을 수행하거나 사이드 이펙트를 초래하거나 둘 다 하는 메서드다. | 클라이언트가 목표를 달성하는데 도움이 되는 상태를 노출하라. 상태는 시스템의 현재 상태다. 구현 세부 사항은 이 두가지 중 아무것도 하지 않는다. | . 이상적으로 시스템의 공개 API는 식별할 수 있는 동작과 일치해야 하며, 모든 구현 세부 사항은 클라이언트 눈에 보이지 않아야 한다. 공개 API - 식별할 수 있는 동작 비공개 API - 구현 세부 사항 . 실별할 수 있는 동작 -&gt; 결과값 . 그러나 종종 시스템의 공개 API가 식별할 수 있는 동작의 범위를 넘어 구현 세부 사항을 노출하기 시작한다. 이러한 시스템의 구현 세부 사항은 공개 API로 유출된다. 클래스가 구현 세부 사항을 유출하는지 판단하는 데 도움이 되는 유용한 규칙이 있다. 단일한 목표를 달성하고자 클래스에서 호출해야하는 연산의 수가 1보다 크면 해달 클래스에서 구현 세부 샇항을 유출할 가능성이 있다. // 유출 String normalizedName = user.normalizedName(newName); user.setName(normalizedName); // 숨김 user.setName(newName); . 캡슐화는 궁극적으로 단위 테스트와 동일한 목표를 달성한다. 즉, 소프트웨어 프로젝트의 지속적인 성장을 가능하게 하는 것이다. 구현부 세부 사항을 숨기면 클라이언트의 시야에서 클래스 내부를 가릴 수 있기 때문에 내부를 손상시킬 위험이 적다. 데이터와 연산을 결합하면 해당 연산이 클래스의 불변성을 위반하지 않도록 할 수 있다. ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#%EB%AA%A9%EA%B3%BC-%EC%8A%A4%ED%85%81-%EA%B5%AC%EB%B6%84",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#목과-스텁-구분"
  },"329": {
    "doc": "단위 테스트",
    "title": "목과 테스트 취약성 간의 관계",
    "content": "육각형 아키텍처 정의 전형적인 애플리케이션은 도메인과 애플리케이션 서비스라는 두 계층으로 구성된다. 도메인 계층은 애플리케이션의 중심부이기 때문에 도표의 중앙에 위치한다. 도메인에는 애플리케이션의 필수 기능으로 비즈니스 로직이 포함돼 있다. 도메인 계층과 해당 비즈니스 로직은 이 애플리케이션을 다른 애플리케이션과 차별화하고 조직의 경쟁력을 향상시킨다. 애플리케이션 서비스 계층은 도메인 계층 위에 있으며 외부 환경과의 통신을 조정한다. 예를 들어 애플리케이션이 Restful API인 경우 API에 대한 모든 요청이 먼저 애플리케이션 서비스 계층에 도달한다. 이 계층은 도메인 클래스와 프로세스 외부 의존성 간의 작업을 조정한다. | 데이터베이스를 조회하고 해당 데이터로 도메인 클래스 인스턴스 구체화 | 해당 인스턴스에 연산 호출 | 결과를 데이터베이스에 다시 저장 | . 육각형은 애플리케이션을 나타낸다. (서로 다른 \b애플리케이션 서비스와 연결되기 위해 모양을 육각형으로 표현한듯?) . | 도메인 계층과 애플리케이션 서비스 계층 간의 관심사 분리 . | 비즈니스 로직은 애플리케이션의 가장 중요한 부분이다. 따라서 도메인 계층은 해당 비즈니스 로직에 대해서만 책임을 져야하며, 다른 모든 책임에서는 제외돼야 한다. | . | 애플리케이션 내부 통신 . | 유각형 아키텍처는 애플리케이션 서비스 계층에서 도메인 계층으로 흐르는 단반향 의존성 흐름을 규정한다. 도메인은 외부인 애플리케이션 서비스에 의존하지 않는다. | . | 애플리케이션 간의 통신 . | 외부 애플리케이션은 애플리케이션 서비스 계층에 있는 공통 인터페이스를 통해 해당 애플리케이션에 연결된다. 아무도 도메인 계층에 직접 접근할 수 없다. 육각형은 내외부 연결을 의미한다. | . | . 목을 사용하면 시스템과 외부 애플리케이션 간의 통신 패턴을 확인할 때 좋다. 반대로 시스탬 내 클래스 간의 통신을 검증하는 데 사용하면 테스트가 구현 세부 사항과 결합되며, 그에 따라 리팩터링 내성 지표가 미흡해진다. 시스템 내부 통신과 시스템 간 통신 차이 . | 고객이 상점에서 제품을 구매하려고 한다 | 매장 내 제품 수량이 충분하면 . | 재고가 상점에서 줄어든다 | 고객에게 이메일로 영수증을 발송한다 | 확인 내역을 반환한다 | . | . 구매라는 동작은 시스템 내부 통신과 시스템 간 통신이 모두 있는 비즈니스 유스케이스다. 시스템간 통신 - 구매, 메일발송 시스템 내부 통신 - customer, store 도메인클래스 간의 통신 . SMTP 서비스에 대한 호출을 목으로 하는 이유는 타당하다. 리팩터링 이후에도 이러한 통신 유형이 그대로 유지도되록 하기 때문에 테스트 취약성을 야기하지 않는다. customer와 store의 경우 애플리케이션 경계를 넘지 않는다. 호출자와 수신자 모두 애플리케이션 내에 있다. RemoveInventory()메서드(구매 후 store의 재고 -1 역할) 호출은 고객의 목표로 가는 중간 단계(구현 세부 사항)에 해당한다. 목을 사용한 동작 검증 . 종종 목이 동작을 검증한다고 한다. 하지만 대부분의 경우 그렇지 않다. 개별 클래스가 이웃 클래스와 소통하는 방식은 식별할 수 있는 동작과는 아무런 관계가 없다. (이는 구현 세부 사항이다.) 클래스 간의 통신을 검증하는 것은 두뇌의 뉴런이 서로 통과하는 신호를 측정해 사람의 행동을 유추하는 것과 유사하다. (너무 세밀하다는 뜻) . ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#%EB%AA%A9%EA%B3%BC-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EC%B7%A8%EC%95%BD%EC%84%B1-%EA%B0%84%EC%9D%98-%EA%B4%80%EA%B3%84",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#목과-테스트-취약성-간의-관계"
  },"330": {
    "doc": "단위 테스트",
    "title": "6장",
    "content": "단위 테스트 스타일 . | 출력 기반 테스트 | 상태 기반 테스트 | 통신 기반 테스트 하나의 테스트에서 둘, 세가지 스타일 모두 함께 사용할 수 있다. | . 출력 기반 테스트 . 테스트 대상 시스템에 입력을 넣고 생성되는 출력을 점검하는 방식이다. 힘수형 이라고도 한다. 해당 테스트는 내부 컬렉션에 상품을 추가하거나 데이터베이스에 저장하지 않는다. ex. 상품의 할인된 반환값을 검증한다. 상태 기반 스타일 . 작업이 완료된 후 시스템 상태를 확인하는 것이다. 이 테스트 스타일에서 상태라는 용어는 sut나 협력자 중 하나, 또는 데이터베이스나 파일 시스템 등과 같은 프로세스 외부 의존성의 상태 등을 의미할 수 있다. ex. 상품을 추가 한 후 컬렉션을 검증한다. 통신 기반 스타일 정의 . 목을 사용해 테스트 대상 시스템과 협력자 간의 통신을 검증한다. 협력자를 목으로 대체하고 sut가 협력자를 올바르게 호출하는지 검증한다. ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#6%EC%9E%A5",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#6장"
  },"331": {
    "doc": "단위 테스트",
    "title": "단위 테스트 스타일 비교",
    "content": "리팩터링 내성 지표 출력 기반 테스트는 테스타 테스트 대상 메서드만 결합되므로 거짓 양성 방지가 가장 우수하다. 상태 기반 테스트는 일반적으로 거짓 양성이 되기 쉽다. 이러한 테스트는 테스트 대상 메서드 외에도 클래스 상태와 함께 작동한다. 확률적으로 말하면, 테스트와 제품 코드 간의 결합도가 클수록 유출되는 구현 세부 사항에 테스트가 얽매일 가능성이 커진다. 통신 기반 테스트가 허위 경보에 가장 취약하다. 테스트 대역으로 상호 작용을 확인하는 테스트는 대부분 깨지기 쉽다. 애플리케이션 경계를 넘는 상호작용을 확인 하고 해당 상호 작용의 사이드 이펙트가 외부 환경에 보이는 경우에만 목이 괜찮다. 여러가지 내용이 있지만 결론은 출력기반 테스트가 가장 좋다는 의견 . 함수형 프로그래밍을 기반으로 출력 기반 테스트를 진행한다. 메서드가 수학적 함수인지 판별하는 가장 좋은 방법은 프로그램의 동작을 변경하지 않고 해당 메서드에 대한 호출을 반환값으로 대체할 수 있는지 확인하는 것이다. 메서드 호출을 해당 값으로 바꾸는 것을 참조 투명성 이라고 한다. 함수형 아키텍처의 단점 실행의 흐름이 간단하지 않은 경우. 의사 결정 절차의 중간 결과에 따라 프로세스 외부 의존성에서 추가 데이터가 필요할 수 있다. 해결방법은 로직 전면부에서 필요한 데이터를 먼저 호출해 가능 방법이 있다. 하지만 이러한 방법은 성능 저하를 유발한다. 함수형 하키텍처는 함수형 코어와 가변 셸 사이를 명확하게 분리해야하낟. 궁극적으로 코드 복잡도가 낮아지도 유지보수성이 향상되지만, 초기 코딩이 더 필요하다. 하지만 모든 시스템이 복잡도가 높고 중요하지않다. 시스템의 복잡도와 중요성을 고려해 함수형 아키텍처를 전략적으로 사용하자. 마지막으로 대부분의 모든 도메인 모델을 불변으로 할 수 없기 때문에 출력 기반 테스트에만 의존할 수 없다. 대부분의 경우 출력 기반 스타일과 상태 기반 스타일을 조합하게 되며, 통신 기반 스타일을 약간 섞어도 괜찮다. ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#%EB%8B%A8%EC%9C%84-%ED%85%8C%EC%8A%A4%ED%8A%B8-%EC%8A%A4%ED%83%80%EC%9D%BC-%EB%B9%84%EA%B5%90",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#단위-테스트-스타일-비교"
  },"332": {
    "doc": "단위 테스트",
    "title": "7장",
    "content": "가치 있는 단위 테스트를 위한 리팩터링 . | 도메인 모델과 알고리즘 . | 보통 복잡한 코드는 도메인 모델이지만, 100%는 아니다. 문제 도메인과 직접적으로 관련이 없는 복잡한 알고리즘이 있을 수 있다. | . | 지나치게 복잡한 코드 . | 이러한 코드는 두 가지 지표 모두 높다. 협력자가 많으며 복잡하거나 중요하다. | . | . 간단한 코드와 컨트롤러는 제외하고 위 두가지 케이스의 단위테스트를 진행하는것이 좋다. 커버리지는 100%를 달성할 수 없으며 이를 목표로 해서는 안된다. 지나치게 복잡한 코드를 쪼개려면, 험블 객체 패턴을 써야한다. 코드가 프레임워크 의존성에 결합돼 있기 때문에 테스트가 어렵다는 사실을 종종 깨달는다. | 테스트 . | 지나치게 복잡한 코드 . | 테스트하기 어려운 의존성 | 로직 | . | . | . 테스트 대상 코드의 로직을 테스트 하려면, 테스트가 가능한 부분을 추출해야 한다. 결과적으로 코드는 테스트 가능한 부분을 둘러싼 험블 래퍼가 된다. 이하 내용은 예제 코드 위주의 설명. ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#7%EC%9E%A5",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#7장"
  },"333": {
    "doc": "단위 테스트",
    "title": "8장",
    "content": "통합 테스트 . ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#8%EC%9E%A5",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#8장"
  },"334": {
    "doc": "단위 테스트",
    "title": "9장",
    "content": "목 처리에 대한 모범 사례 . ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#9%EC%9E%A5",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#9장"
  },"335": {
    "doc": "단위 테스트",
    "title": "10장",
    "content": "데이터베이스 테스트 . ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#10%EC%9E%A5",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#10장"
  },"336": {
    "doc": "단위 테스트",
    "title": "11장",
    "content": "단위 테스트 안티패턴 . ",
    "url": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#11%EC%9E%A5",
    
    "relUrl": "/docs/%EB%8B%A8%EC%9C%84%20%ED%85%8C%EC%8A%A4%ED%8A%B8.html#11장"
  },"337": {
    "doc": "멀티테넌트 동기화 개선",
    "title": "멀티테넌트 동기화 개선",
    "content": ". | 상황 . | ISMS 보안 심사를 통과하기 위해 멀티테넌트 정책이 필요하게 됨. | 스키마 단위 멀티테넌트 구조에서 모든 테넌트 스키마의 형상을 동일하게 유지해야 하는 어려움이 있음. | 데이터베이스 변경 또는 마이그레이션 작업 시, 모든 테넌트에 동일한 변경을 적용해야 했고, 이는 작업의 효율성을 저하시킴. | 새로운 기업 고객이 가입할 때마다 동일한 형상의 스키마를 자동으로 생성해야 함. | . | 과제 . | 각 테넌트의 DB 스키마가 동일하게 유지되도록 관리하는 방법 필요. | 기업 고객 가입 시, 자동으로 새로운 테넌트 스키마를 생성하는 기능이 요구됨. | DB 변경 사항을 모든 테넌트에 쉽게 적용할 수 있는 방식이 필요함. | . | 해결 . | 백오피스에서 변경이 필요한 DDL, DML 쿼리를 수집하는 유닛 정책을 수립함. | 백오피스에서 쿼리를 실행하고, 변경 내역을 Change Log로 관리하여 changelog.sql 파일로 S3에 저장함. | 각 테넌트는 Liquibase를 통해 DB Change Log를 관리하고, 모든 테넌트의 스키마 형상을 동일하게 유지할 수 있도록 함. | 새로운 기업 고객이 가입할 때, S3에 저장된 changelog.sql 파일을 참조하여 자동으로 테넌트 스키마를 생성함으로써, 새 테넌트 생성 시 일관성을 유지. | . | 결과 . | Liquibase와 S3를 활용하여 모든 테넌트 스키마의 일관성을 유지하는 데 성공. | DB 변경 작업이 중앙 관리 방식으로 개선되어 DB 마이그레이션 시간이 절감됨. | 신규 기업 고객 가입 시, 자동으로 테넌트 스키마가 생성되면서 운영 효율성이 크게 향상됨. | . | . ",
    "url": "/docs/portfolio/%EB%A9%80%ED%8B%B0%ED%85%8C%EB%84%8C%ED%8A%B8%20%EB%8F%99%EA%B8%B0%ED%99%94%20%EA%B0%9C%EC%84%A0.html",
    
    "relUrl": "/docs/portfolio/%EB%A9%80%ED%8B%B0%ED%85%8C%EB%84%8C%ED%8A%B8%20%EB%8F%99%EA%B8%B0%ED%99%94%20%EA%B0%9C%EC%84%A0.html"
  },"338": {
    "doc": "소프트웨어 설계 - 인사 평가 관리 서비스",
    "title": "소프트웨어 설계 - 인사 평가 관리 서비스",
    "content": ". ",
    "url": "/docs/portfolio/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4%20%EC%84%A4%EA%B3%84%20-%20%EC%9D%B8%EC%82%AC%20%ED%8F%89%EA%B0%80%20%EA%B4%80%EB%A6%AC%20%EC%84%9C%EB%B9%84%EC%8A%A4.html",
    
    "relUrl": "/docs/portfolio/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4%20%EC%84%A4%EA%B3%84%20-%20%EC%9D%B8%EC%82%AC%20%ED%8F%89%EA%B0%80%20%EA%B4%80%EB%A6%AC%20%EC%84%9C%EB%B9%84%EC%8A%A4.html"
  },"339": {
    "doc": "소프트웨어 설계 - 인사 평가 관리 서비스",
    "title": "신규 프로젝트 소프트웨어 아키텍처 설계 및 백엔드 API 개발",
    "content": ". | 상황 . | 진단 일정 관리와, 진단 결과 등을 관리할 수 있는 관리자 서비스 필요 | 진단에는 동료진단, 수습진단, 리더십 진단 등 다양한 타입의 진단이 생길것을 고려해야함 | . | 과제 . | 요구사항 분석 | 아키텍처 패턴 선택 | 데이터베이스 설계 | API 설계 | 보안 설계 | 배포 및 운영 | . | 해결 . | 요구사항 분석 . | 진단 일정 관리와 진단 결과 관리를 통해 인사 평가의 효율성을 높이고, 더 나은 의사결정을 지원하기 위한 서비스 필요 | 인사 평가 관리 서비스는 로그인 기능, 진단자 대상자 대량 등록, 응시 현황 및 대상자의 결과 확인, Excel, PDF 다운로드 기능 등이 제공됨 | 특정 사용자에게 결과 보기, 결과 다운로드 등 권한을 부여하여 역할을 나눌 수 있어야 함 | . | 아키텍처 패턴 선택 . | 모놀리식 아키텍처를 기반으로 진행 | 결과를 Excel 또는 Pdf 파일로 생성하여 다운로드 받을시에 하나의 어플리케이션에서 대량의 데이터를 처리하게 되면 다른 작업 처리가 불가능할 수 있음 | 필요에 따라 기능을 독립적인 서비스로 나눠 관리함 . | 전체적인 기능을 담당하는 관리 서비스 | 결과 Excel 생성 Lambda | 결과 Pdf 생성 Lambda | 대상자 데이터 분석 서비스 | . | . | 데이터베이스 설계 (인사평가 응시 서비스와 동일) . | 인사 평가와 같은 시스템에서는 정확한 스키마와 트랜잭션, 조인 등의 기능이 중요함 | 사내의 많은 서비스들이 MariaDB를 사용하고 있고 서버 운영팀의 구축 경험과 기술지원, DB사용 경험을 고려 | MariaDB 사용 | 고려 사항 . | ISMS 인증을 통과하기 위해 기업별 데이터 분리가 필요 | 기업별 RDS를 생성하는 것은 비용이 큼 | 이때 당시 컬럼을 통한 구분은 조건에 충족하지 못하는것으로 인지 | 결론적으로, 기업별 데이터는 하나의 RDS에 스키마 단위로 분리하여 데이터를 저장 | 개발을 많이 진행하고 나서 알게되었지만, ISMS 인증을 위해 스키마 단위로 분리해야 한다는 조건은 사라졌다고 함. 다시 진행한다면 컬럼으로 구분하는것이 좋을 듯 하다. (기업 추가 삭제시 스키마 관리, 트랜잭션 등 유지보수가 불편하다는 단점이 있었음) | . | . | API 설계 (인사평가 응시 서비스와 동일) . | API 개발 시 RESTful원칙을 기반으로 GET, POST, PATCH, DELETE 등을 사용하여 URL이 직관적일 수 있도록 함 | 고려 사항 . | Client 서비스와 Back End 서비스가 따로 배포되는 구조로 Client에서 Back End에 접근하려면 Back End서버가 퍼블릭 상태를 유지해야함. | client에서 사용할 api와 내부적으로 사용할 api를 구분하여 /api, /internal-api 등으로 구분함 | api gateway를 이용하여 내부 api에는 접근하지 못하도록 설계함 | . | swagger-ui를 통해 문서화를 진행 | . | 보안 설계 (인사평가 응시 서비스와 동일) . | 초기 개발 시 JWT를 통해 로그인을 구현 | 이후 사내 통합 로그인 OAuth가 만들어져 변경 | OAuth, JWT를 이용하여 로그인 구현![[oauth.jpg]] | . | 배포 및 운영 (인사평가 응시 서비스와 동일) . | 운영팀이 구축해놓은 CI/CD를 통한 배포 | 운영팀에 요청하여 DataDog을 통해 문제 발생 시 로그 분석 | . | . | 결과 . | Excel과 Pdf 기능을 Lambda 생성하여 부하를 분산할 수 있음 | OAuth사용을 통해, 사내에서 제공하는 여러 서비스들에 대해 SSO 기능을 사용자에게 제공할 수 있음 | 사내 인사 평가에 도입되어 대상자에게 결과표를 전달하고, 연봉 측정에 기준이 됨 | 서비스가 판매가 되어 외부 기업에서 사용중 | . | . ",
    "url": "/docs/portfolio/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4%20%EC%84%A4%EA%B3%84%20-%20%EC%9D%B8%EC%82%AC%20%ED%8F%89%EA%B0%80%20%EA%B4%80%EB%A6%AC%20%EC%84%9C%EB%B9%84%EC%8A%A4.html#%EC%8B%A0%EA%B7%9C-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-%EC%84%A4%EA%B3%84-%EB%B0%8F-%EB%B0%B1%EC%97%94%EB%93%9C-api-%EA%B0%9C%EB%B0%9C",
    
    "relUrl": "/docs/portfolio/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4%20%EC%84%A4%EA%B3%84%20-%20%EC%9D%B8%EC%82%AC%20%ED%8F%89%EA%B0%80%20%EA%B4%80%EB%A6%AC%20%EC%84%9C%EB%B9%84%EC%8A%A4.html#신규-프로젝트-소프트웨어-아키텍처-설계-및-백엔드-api-개발"
  },"340": {
    "doc": "소프트웨어 설계 - 인사 평가 응시 서비스",
    "title": "소프트웨어 설계 - 인사 평가 응시 서비스",
    "content": ". ",
    "url": "/docs/portfolio/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4%20%EC%84%A4%EA%B3%84%20-%20%EC%9D%B8%EC%82%AC%20%ED%8F%89%EA%B0%80%20%EC%9D%91%EC%8B%9C%20%EC%84%9C%EB%B9%84%EC%8A%A4.html",
    
    "relUrl": "/docs/portfolio/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4%20%EC%84%A4%EA%B3%84%20-%20%EC%9D%B8%EC%82%AC%20%ED%8F%89%EA%B0%80%20%EC%9D%91%EC%8B%9C%20%EC%84%9C%EB%B9%84%EC%8A%A4.html"
  },"341": {
    "doc": "소프트웨어 설계 - 인사 평가 응시 서비스",
    "title": "신규 프로젝트 소프트웨어 아키텍처 설계 및 백엔드 API 개발",
    "content": ". | 상황 . | 관리 서비스로부터 설정된 진단 일정을 확인하고, 진단에 응시할 수 있는 서비스 필요 | 진단에는 동료진단, 수습진단, 리더십 진단 등 다양한 타입의 진단이 생길것을 고려해야함 | 질문에는 여러 타입이 있음 . | N개의 보기중 1개만 선택 | N개의 보기중 a~b개 선택 | N개의 보기중 a~b개 우선순위대로 선택 | 서술형(문자) 답변 | 서술형(숫자) 답변 | . | . | 과제 . | 요구사항 분석 | 아키텍처 패턴 선택 | 데이터베이스 설계 | API 설계 | 보안 설계 | 배포 및 운영 | . | 해결 . | 요구사항 분석 . | 모바일 또는 PC기기를 통해 언제 어디서든 편하게 진단에 응할 수 있는 환경 필요 | 출제 문항이 여러 언어로 지원될 것을 고려 (KR, JP, EN, CN) | 평가된 대상자들의 점수 및 순위보기 지원 고려 | . | 아키텍처 패턴 선택 . | 모놀리식 아키텍처를 기반으로 진행 | 다양한 타입의 질문 [[JPA - inheritance]]를 사용한 상속 구조로 진행 | Redis Sorted Set을 사용하여 스코어 보드 개발 | . | 데이터베이스 설계 (인사평가 관리 서비스와 동일) . | 인사 평가와 같은 시스템에서는 정확한 스키마와 트랜잭션, 조인 등의 기능이 중요함 | 사내의 많은 서비스들이 MariaDB를 사용하고 있고 서버 운영팀의 구축 경험과 기술지원, DB사용 경험을 고려 | MariaDB 사용 | 고려 사항 . | ISMS 인증을 통과하기 위해 기업별 데이터 분리가 필요 | 기업별 RDS를 생성하는 것은 비용이 큼 | 이때 당시 컬럼을 통한 구분은 조건에 충족하지 못하는것으로 인지 | 결론적으로, 기업별 데이터는 하나의 RDS에 스키마 단위로 분리하여 데이터를 저장 | 개발을 많이 진행하고 나서 알게되었지만, ISMS 인증을 위해 스키마 단위로 분리해야 한다는 조건은 사라졌다고 함. 다시 진행한다면 컬럼으로 구분하는것이 좋을 듯 하다. (기업 추가 삭제시 스키마 관리, 트랜잭션 등 유지보수가 불편하다는 단점이 있었음) | . | . | API 설계 (인사평가 관리 서비스와 동일) . | API 개발 시 RESTful원칙을 기반으로 GET, POST, PATCH, DELETE 등을 사용하여 URL이 직관적일 수 있도록 함 | 고려 사항 . | Client 서비스와 Back End 서비스가 따로 배포되는 구조로 Client에서 Back End에 접근하려면 Back End서버가 퍼블릭 상태를 유지해야함. | client에서 사용할 api와 내부적으로 사용할 api를 구분하여 /api, /internal-api 등으로 구분함 | api gateway를 이용하여 내부 api에는 접근하지 못하도록 설계함 | . | swagger-ui를 통해 문서화를 진행 | 반복적으로 호출되는 부분은 캐싱하여 리소스 낭비를 줄일 수 있도록 함 . | 반복적으로 사용되는 출제 문항 정보, 사용자 정보 등 | . | . | 보안 설계 (인사평가 관리 서비스와 동일) . | 초기 개발 시 JWT를 통해 로그인을 구현 | 이후 사내 통합 로그인 OAuth가 만들어져 변경 | OAuth, JWT를 이용하여 로그인 구현![[oauth.jpg]] | . | 배포 및 운영 (인사평가 관리 서비스와 동일) . | 운영팀이 구축해놓은 CI/CD를 통한 배포 | 운영팀에 요청하여 DataDog을 통해 문제 발생 시 로그 분석 | . | . | 결과 . | 내 인사 평가에 도입되어 대상자에게 결과표를 전달하고, 연봉 측정에 기준이 됨 | 서비스가 판매가 되어 외부 기업에서 사용중 | 모바일 및 PC 환경 모두에서 다양한 언어로 진단을 편리하게 응시할 수 있게 되어, 여러 언어권의 사용자들이 진단에 문제없이 참여할 수 있었음 | 다양한 유형의 질문을 유연하게 처리할 수 있는 구조 덕분에, 추가적인 진단 유형이 생길 때도 간편하게 확장 가능 | . | . ",
    "url": "/docs/portfolio/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4%20%EC%84%A4%EA%B3%84%20-%20%EC%9D%B8%EC%82%AC%20%ED%8F%89%EA%B0%80%20%EC%9D%91%EC%8B%9C%20%EC%84%9C%EB%B9%84%EC%8A%A4.html#%EC%8B%A0%EA%B7%9C-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-%EC%84%A4%EA%B3%84-%EB%B0%8F-%EB%B0%B1%EC%97%94%EB%93%9C-api-%EA%B0%9C%EB%B0%9C",
    
    "relUrl": "/docs/portfolio/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4%20%EC%84%A4%EA%B3%84%20-%20%EC%9D%B8%EC%82%AC%20%ED%8F%89%EA%B0%80%20%EC%9D%91%EC%8B%9C%20%EC%84%9C%EB%B9%84%EC%8A%A4.html#신규-프로젝트-소프트웨어-아키텍처-설계-및-백엔드-api-개발"
  },"342": {
    "doc": "엑셀 데이터 업로드 성능 개선",
    "title": "엑셀 데이터 업로드 성능 개선",
    "content": ". | 상황 . | 인사평가 시스템에서 엑셀 업로드를 통해 진단자-대상자 지정 기능을 제공 중. | 기존에는 단일 등록 로직을 그대로 재활용하여 성능 저하 문제가 발생했으며, 대량 데이터 처리 시 connection timeout이 빈번히 발생함. | IDENTITY 전략을 사용한 JPA로 인해 id 생성 과정에서 병목이 발생함. | . | 과제 . | 기존 단일 등록 로직을 최대한 유지하되, 성능을 개선하여 대량 데이터 처리에 적합하도록 수정이 필요. | IDENTITY 전략의 병목을 해소하고, 대량 데이터를 한 번에 insert할 수 있도록 쿼리 최적화가 요구됨. | AWS API Gateway에서 30초 내에 응답을 받지 못하는 경우 connection timeout이 발생하는 제한이 있어, 이를 고려한 비동기 처리 방식 도입 필요. | . | 해결 . | 기존 로직을 유지하면서 성능을 개선하기 위해 read-only 처리를 적용하여 더티체킹을 최소화. 엔티티의 id 값 여부로 새 객체를 구분해 저장하는 로직을 사용. | 대량 insert 처리를 위해 JPA 대신 jdbcTemplate을 사용하여 batch insert 구현. | 단, jdbcTemplate으로 저장 시 애플리케이션에서는 DB에 생성된 id 값을 알 수 없는 문제가 발생. 이를 해결하기 위해 객체의 특정 컬럼을 조합하여 고유 값을 조회하고, 이를 통해 id 값을 도출. | 도출한 id 값을 하위 자식 엔티티에게 전달하여 일관성 유지. | . | API Gateway의 30초 timeout 문제를 해결하기 위해 Kafka를 사용한 비동기 처리 도입. | 엑셀 파일 업로드 요청 시, 파일을 서버에 저장한 뒤 Kafka 메시지를 발행. | 어플리케이션은 해당 메시지를 컨슘하여 비동기적으로 처리 로직을 수행하고, 업로드 상태를 클라이언트에서 주기적으로 확인할 수 있도록 구현. | . | . | 결과 . | 엑셀 업로드 속도가 기존 대비 7배 개선되었으며, connection timeout 문제 없이 안정적으로 대량 데이터 처리가 가능해짐. | 비동기 처리 도입으로 클라이언트는 업로드 상태를 실시간으로 모니터링 가능해져 사용자 경험이 향상됨. | . | . ",
    "url": "/docs/memo/%EC%97%91%EC%85%80%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%97%85%EB%A1%9C%EB%93%9C%20%EC%84%B1%EB%8A%A5%20%EA%B0%9C%EC%84%A0.html",
    
    "relUrl": "/docs/memo/%EC%97%91%EC%85%80%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%97%85%EB%A1%9C%EB%93%9C%20%EC%84%B1%EB%8A%A5%20%EA%B0%9C%EC%84%A0.html"
  },"343": {
    "doc": "파일 다운로드 성능 개선",
    "title": "파일 다운로드 성능 개선",
    "content": ". | 상황 . | 인사 평가 결과로 PDF, Excel 파일 등의 대용량 첨부 파일이 존재. 특히 다수의 PDF 파일을 묶어놓은 zip 파일의 경우, 200명 기준 1GB 이상. | S3에 저장된 파일을 서버로 다운로드한 후 사용자에게 전달하는 방식으로 구현되어 있었으나, 대용량 파일을 여러 개 동시에 다운로드할 경우 성능 저하나 서버 다운이 발생할 수 있음. | 기존에는 모든 S3에 저장된 이미지나 파일을 백엔드 서버를 거쳐 프론트로 전달하는 구조로 되어 있었음. | 또한, 평가 완료 후 일정 기간이 지나면 더 이상 파일을 사용할 필요가 없었지만, 파일 관리가 어려워 쌓인 파일들이 스토리지 비용 증가를 유발함. | . | 과제 . | 성능 저하나 서버 다운 문제를 해결할 방법을 모색. | 대용량 파일의 경우, 백엔드 서버를 거치지 않고도 안전하게 파일을 사용자에게 전달할 수 있는 방식을 설계. | 이미지 및 로고 등 공개적으로 사용할 수 있는 파일과 그렇지 않은 파일을 적절하게 구분하여 효율적인 접근 방식을 구축. | 평가 결과 파일이 일정 기간이 지난 후 자동으로 삭제되어야 함. | . | 해결 . | 백엔드 서버의 스펙을 올려 해결할 수 있겠지만 근본적인 해결 방법이 아닌것으로 판단 | CloudFront와 Presigned URL을 적용하여 파일 전달 방식을 개선함. | 사용자가 파일을 다운로드할 때 백엔드 서버를 거치지 않고 S3로부터 직접 다운로드할 수 있도록 Presigned URL을 발급하여 성능 문제를 해결. | 공개적으로 사용할 수 있는 이미지나 로고 파일은 CloudFront를 통해 public 경로로 설정하여, 서버에 부하를 주지 않고 자유롭게 접근할 수 있도록 개선. | private한 파일은 Presigned URL을 이용해 필요한 사용자가 일정 시간 동안만 접근 가능하도록 설정. | 기존 방식에서 프론트가 백엔드 서버를 거치지 않도록 개선함으로써 서버 부하를 크게 줄일 수 있었음. | S3의 라이프사이클 정책을 활용하여, 유효 기간이 지난 파일은 자동으로 삭제되도록 설정. 평가가 완료된 후 일정 기간이 지나면 사용되지 않는 파일을 자동으로 삭제하여 스토리지 비용을 절감하고 관리 효율성을 높임. | . | . | 결과 . | Presigned URL을 적용하여 사용자가 대용량 파일을 다운로드하는 경우에도 백엔드 서버의 성능 저하 없이 빠르고 안정적으로 파일을 전달할 수 있게 됨. | CloudFront를 통해 public 파일은 자유롭게 조회 가능하게 하여, 이미지, 로고 등의 정적 파일 요청 처리 속도가 향상되고 백엔드 서버 부하를 줄이는 데 성공함. | 이러한 개선 작업으로 서버 다운 및 성능 저하 이슈가 사라졌으며, 안정적인 파일 전달이 가능해짐. | 파일 관리가 간소화되었고, 서버의 리소스 사용이 줄어들어 서비스 안정성 및 성능이 향상됨. | . | . ",
    "url": "/docs/portfolio/%ED%8C%8C%EC%9D%BC%20%EB%8B%A4%EC%9A%B4%EB%A1%9C%EB%93%9C%20%EC%84%B1%EB%8A%A5%20%EA%B0%9C%EC%84%A0.html",
    
    "relUrl": "/docs/portfolio/%ED%8C%8C%EC%9D%BC%20%EB%8B%A4%EC%9A%B4%EB%A1%9C%EB%93%9C%20%EC%84%B1%EB%8A%A5%20%EA%B0%9C%EC%84%A0.html"
  }
}
